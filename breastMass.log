######################## Epoch 0 - Batch 1 ########################
IDs in batch 1: tensor([ 507, 3695, 3272, 4094,  160, 1496, 3459, 3168, 4249, 2417,  893, 2642,
        1380, 3891,  325,  992])
Epoch: 0, Training Loss: 1.11, Validation Loss: 1.11, accuracy = 0.24
######################## Epoch 1 - Batch 1 ########################
IDs in batch 1: tensor([3781, 3130, 3926, 3516, 2724,  287, 1197,  529, 1708,  426, 1310, 2349,
         217,  670, 1594,  828])
Epoch: 1, Training Loss: 1.16, Validation Loss: 1.11, accuracy = 0.23
######################## Epoch 2 - Batch 1 ########################
IDs in batch 1: tensor([ 376, 1174, 1944, 2667, 1347, 4212, 2072, 3749, 3863, 3976, 2316, 3503,
        3362, 2476, 1918, 1885])
Epoch: 2, Training Loss: 1.15, Validation Loss: 1.11, accuracy = 0.23
######################## Epoch 3 - Batch 1 ########################
IDs in batch 1: tensor([2680, 2407,  186, 3283, 4195, 3368, 2897, 3328, 3243, 4254, 1015, 4037,
         794, 4012, 2711, 1122])
Epoch: 3, Training Loss: 1.07, Validation Loss: 1.11, accuracy = 0.23
######################## Epoch 4 - Batch 1 ########################
IDs in batch 1: tensor([2741,  119, 2780,   28,  644,  937, 1456, 1042, 3083, 3493, 3975, 1879,
        3146, 1417, 3674, 2879])
Epoch: 4, Training Loss: 1.12, Validation Loss: 1.12, accuracy = 0.23
######################## Epoch 5 - Batch 1 ########################
IDs in batch 1: tensor([2934, 3856, 4197, 3917, 3754, 2934,  318, 3144, 3456, 3700, 2167, 1032,
        1754, 1409,  678, 2738])
Epoch: 5, Training Loss: 1.13, Validation Loss: 1.12, accuracy = 0.23
######################## Epoch 6 - Batch 1 ########################
IDs in batch 1: tensor([ 678, 2206,  408, 3658,  318, 2804,  816,  968, 3328, 2937, 1677, 3102,
        2426, 1770, 3036, 2776])
Epoch: 6, Training Loss: 1.13, Validation Loss: 1.11, accuracy = 0.24
######################## Epoch 7 - Batch 1 ########################
IDs in batch 1: tensor([4224,  753,  941,  262,  229, 1206, 1206, 2671, 1256, 3807, 2410, 3196,
        2226, 2286,  557, 2617])
Epoch: 7, Training Loss: 1.13, Validation Loss: 1.11, accuracy = 0.24
######################## Epoch 8 - Batch 1 ########################
IDs in batch 1: tensor([1346,  785,  167, 1970, 2304, 1482, 4009, 2399, 2516, 1952, 2683, 2356,
        3039,  660, 1506, 1251])
Epoch: 8, Training Loss: 1.12, Validation Loss: 1.11, accuracy = 0.27
######################## Epoch 9 - Batch 1 ########################
IDs in batch 1: tensor([3908,  721,  961, 2377,   93,  645, 1218, 2127, 2213, 1199, 2219, 1925,
        1124, 1882, 3836,  214])
Epoch: 9, Training Loss: 1.06, Validation Loss: 1.11, accuracy = 0.28
######################## Epoch 10 - Batch 1 ########################
IDs in batch 1: tensor([3286,  591, 2709, 2024, 3218, 1121, 2598,  981, 3501, 4057, 2448, 2235,
        1834,  994,  224, 2891])
Epoch: 10, Training Loss: 1.05, Validation Loss: 1.10, accuracy = 0.30
######################## Epoch 11 - Batch 1 ########################
IDs in batch 1: tensor([ 843,  852, 3060,  612,  914,  147, 1047, 3749, 3553, 3529,  110, 2329,
        2025, 3203, 2475, 3476])
Epoch: 11, Training Loss: 1.08, Validation Loss: 1.10, accuracy = 0.31
######################## Epoch 12 - Batch 1 ########################
IDs in batch 1: tensor([1335, 3767, 1390, 2500,  899, 2056, 3831, 2287, 2802, 2228, 1057,  610,
        2394, 1093, 1780, 1022])
Epoch: 12, Training Loss: 1.15, Validation Loss: 1.10, accuracy = 0.32
######################## Epoch 13 - Batch 1 ########################
IDs in batch 1: tensor([ 790, 1781, 2406, 1681, 4093,  482, 1282, 1882, 1099, 1655, 2148, 1335,
        1299, 2777, 3671, 1773])
Epoch: 13, Training Loss: 1.07, Validation Loss: 1.10, accuracy = 0.34
######################## Epoch 14 - Batch 1 ########################
IDs in batch 1: tensor([2540, 1330,   14, 3640, 3004, 1047, 3573,  815,  701, 1080, 2203,  135,
        3102, 2161, 3762, 2740])
Epoch: 14, Training Loss: 1.09, Validation Loss: 1.10, accuracy = 0.36
######################## Epoch 15 - Batch 1 ########################
IDs in batch 1: tensor([3357, 3829, 1681, 3723, 2470,  284, 3573, 1050, 3558, 4089,  211, 1982,
        3785,  236, 3617, 3514])
Epoch: 15, Training Loss: 1.13, Validation Loss: 1.09, accuracy = 0.37
######################## Epoch 16 - Batch 1 ########################
IDs in batch 1: tensor([3488,  546, 4039, 3039, 3696, 3869,  190, 1605,  143, 3498, 1877, 4176,
        2866, 3732, 1138,  631])
Epoch: 16, Training Loss: 1.09, Validation Loss: 1.09, accuracy = 0.39
######################## Epoch 17 - Batch 1 ########################
IDs in batch 1: tensor([3718, 2098, 2046,  923, 1484, 2947, 1596, 2228, 3094,  693, 4069, 2976,
        2949, 2372, 1579, 1414])
Epoch: 17, Training Loss: 1.05, Validation Loss: 1.09, accuracy = 0.39
######################## Epoch 18 - Batch 1 ########################
IDs in batch 1: tensor([1585, 1034, 3790,  666, 4016, 1994,  891,  335,   77, 1712, 2362, 3688,
        2286, 1849, 2898,  933])
Epoch: 18, Training Loss: 1.11, Validation Loss: 1.09, accuracy = 0.39
######################## Epoch 19 - Batch 1 ########################
IDs in batch 1: tensor([1372,  351,   64, 3376, 3728, 4061, 4198, 1388, 2242, 3991,  732,  134,
        3309, 2804,   34,  303])
Epoch: 19, Training Loss: 1.11, Validation Loss: 1.08, accuracy = 0.39
######################## Epoch 20 - Batch 1 ########################
IDs in batch 1: tensor([1101, 3845, 3902, 2198,   78, 2895,  252, 3481,  167, 2775, 1185, 3782,
        1190, 2056, 3262, 3991])
Epoch: 20, Training Loss: 1.10, Validation Loss: 1.08, accuracy = 0.40
######################## Epoch 21 - Batch 1 ########################
IDs in batch 1: tensor([1789,  131, 2579, 2002,  484,  714,  709, 1242, 1957, 3049, 2680, 3291,
        2828, 3873, 4235, 1270])
Epoch: 21, Training Loss: 1.05, Validation Loss: 1.08, accuracy = 0.41
######################## Epoch 22 - Batch 1 ########################
IDs in batch 1: tensor([  41,  193, 3647, 1579, 2558, 2039, 3731, 3180, 1334, 3692, 3268, 1134,
         673, 2192, 3962, 1894])
Epoch: 22, Training Loss: 1.09, Validation Loss: 1.08, accuracy = 0.42
######################## Epoch 23 - Batch 1 ########################
IDs in batch 1: tensor([2965, 3926, 4108, 3362, 1113, 2822, 3473, 1090, 2255,  811,  326, 3259,
        1990, 1781, 2370,  855])
Epoch: 23, Training Loss: 1.12, Validation Loss: 1.08, accuracy = 0.42
######################## Epoch 24 - Batch 1 ########################
IDs in batch 1: tensor([3875, 2195, 3339,  155, 1644, 3401,  407, 2064,  524,  539,  794, 1910,
         314, 1830,  183, 1420])
Epoch: 24, Training Loss: 1.04, Validation Loss: 1.07, accuracy = 0.41
######################## Epoch 25 - Batch 1 ########################
IDs in batch 1: tensor([ 587, 4198, 2815, 4002, 2517, 3551,  161, 2179, 3569, 2523,  154, 4120,
        4180, 4236,  524, 2645])
Epoch: 25, Training Loss: 1.09, Validation Loss: 1.07, accuracy = 0.42
######################## Epoch 26 - Batch 1 ########################
IDs in batch 1: tensor([3876, 2687, 3051, 2770, 3875, 2383, 4131, 2690, 3256, 3833,  753,  218,
        2847, 1556,  159,  774])
Epoch: 26, Training Loss: 1.11, Validation Loss: 1.07, accuracy = 0.43
######################## Epoch 27 - Batch 1 ########################
IDs in batch 1: tensor([2053,  914, 3904, 3366,  657,  721,  467,  838, 1252, 2755,  538, 2553,
        3914, 3787, 1559, 3598])
Epoch: 27, Training Loss: 1.09, Validation Loss: 1.07, accuracy = 0.43
######################## Epoch 28 - Batch 1 ########################
IDs in batch 1: tensor([3488, 1212, 3939, 1463, 2372, 2901, 2111,  569,  200,  740,  921, 2498,
         699, 1117, 1517, 3976])
Epoch: 28, Training Loss: 1.02, Validation Loss: 1.07, accuracy = 0.44
######################## Epoch 29 - Batch 1 ########################
IDs in batch 1: tensor([ 427, 2899, 4036, 3630,  997,  260, 1204, 3961, 4249, 4107, 1282, 2126,
        1641, 3945, 1032,  568])
Epoch: 29, Training Loss: 1.12, Validation Loss: 1.07, accuracy = 0.43
######################## Epoch 30 - Batch 1 ########################
IDs in batch 1: tensor([1439, 3943,  596, 1272, 2003, 2632, 4222, 2645,  869, 2497, 1680, 4125,
        3692, 1770, 4007, 2899])
Epoch: 30, Training Loss: 1.07, Validation Loss: 1.07, accuracy = 0.44
######################## Epoch 31 - Batch 1 ########################
IDs in batch 1: tensor([4148, 2412, 2327, 1118,   92, 1681, 2134, 3123, 3996,  135,  943, 1381,
        3214, 2828, 4188,  469])
Epoch: 31, Training Loss: 1.11, Validation Loss: 1.06, accuracy = 0.44
######################## Epoch 32 - Batch 1 ########################
IDs in batch 1: tensor([2587, 3782, 2013, 2924,  872, 2880,  127, 3077, 3401, 2968, 3635,  904,
         994,  904, 1405, 3797])
Epoch: 32, Training Loss: 1.05, Validation Loss: 1.06, accuracy = 0.44
######################## Epoch 33 - Batch 1 ########################
IDs in batch 1: tensor([2646,  259, 2011, 1044,  858, 2038, 2192, 2433,  956, 2131, 2897,  379,
         326, 2253, 2511, 2285])
Epoch: 33, Training Loss: 1.04, Validation Loss: 1.06, accuracy = 0.45
######################## Epoch 34 - Batch 1 ########################
IDs in batch 1: tensor([3495, 1779,  277, 3872, 1432, 3035,  593, 1415, 1024,  316, 2782, 3261,
        3465,  863, 1727, 3927])
Epoch: 34, Training Loss: 1.05, Validation Loss: 1.06, accuracy = 0.45
######################## Epoch 35 - Batch 1 ########################
IDs in batch 1: tensor([ 322,  558, 3938, 2372, 3981, 1028, 2111,  324, 1146, 1600,   96, 2509,
        4099, 1257, 1345, 2765])
Epoch: 35, Training Loss: 1.09, Validation Loss: 1.06, accuracy = 0.45
######################## Epoch 36 - Batch 1 ########################
IDs in batch 1: tensor([1141, 1537, 1306,  680, 1222, 2905, 3755, 2220, 3166, 2810,  842, 1568,
         623, 2231, 1822, 3715])
Epoch: 36, Training Loss: 1.03, Validation Loss: 1.06, accuracy = 0.46
######################## Epoch 37 - Batch 1 ########################
IDs in batch 1: tensor([3863, 2204, 2887,  727, 3258, 4232, 2236, 2564, 3671, 3874,  573, 1190,
        2610,   21, 1996, 3995])
Epoch: 37, Training Loss: 1.08, Validation Loss: 1.06, accuracy = 0.46
######################## Epoch 38 - Batch 1 ########################
IDs in batch 1: tensor([2286,  792, 2754, 4016,  895,  269, 2095, 1600, 3226,  335,  942, 1580,
        4268, 1663, 1199, 2452])
Epoch: 38, Training Loss: 1.08, Validation Loss: 1.06, accuracy = 0.47
######################## Epoch 39 - Batch 1 ########################
IDs in batch 1: tensor([3870, 3524, 3344,  787, 1846, 2738, 2631,  733, 1957,  342, 2495, 1937,
         181, 4258,  807, 4085])
Epoch: 39, Training Loss: 1.12, Validation Loss: 1.05, accuracy = 0.47
######################## Epoch 40 - Batch 1 ########################
IDs in batch 1: tensor([3480, 2545, 3972, 3827, 3265, 3262, 1371,  755, 2452,  667, 2419, 4049,
        3524, 2133, 3523, 2290])
Epoch: 40, Training Loss: 1.11, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 41 - Batch 1 ########################
IDs in batch 1: tensor([2309, 1747, 3399, 1054, 4096, 1663, 1089, 3499,  578, 2466, 3511, 3902,
         710, 2579, 1396, 3423])
Epoch: 41, Training Loss: 1.07, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 42 - Batch 1 ########################
IDs in batch 1: tensor([2275, 1846, 3326, 3408, 2731, 2167, 3616, 3531, 4194, 1482, 1310, 1252,
        1897, 3592,  945,   72])
Epoch: 42, Training Loss: 1.06, Validation Loss: 1.05, accuracy = 0.47
######################## Epoch 43 - Batch 1 ########################
IDs in batch 1: tensor([1132, 1484, 1595,  424, 1235, 2457,  303, 3024,  531,  150, 3866, 3465,
        2736, 3176, 2050, 3119])
Epoch: 43, Training Loss: 1.04, Validation Loss: 1.05, accuracy = 0.48
######################## Epoch 44 - Batch 1 ########################
IDs in batch 1: tensor([3674, 2681,  591,  852, 2278, 1423, 1125, 2683, 2640, 2598, 3037, 2113,
         982,  257, 2292, 4218])
Epoch: 44, Training Loss: 1.02, Validation Loss: 1.05, accuracy = 0.49
######################## Epoch 45 - Batch 1 ########################
IDs in batch 1: tensor([4139,  337, 3608, 4050,  814, 1972, 1488, 1828,  342,  515, 1241, 3643,
        1102, 2034, 1504, 3713])
Epoch: 45, Training Loss: 1.10, Validation Loss: 1.05, accuracy = 0.50
######################## Epoch 46 - Batch 1 ########################
IDs in batch 1: tensor([ 978, 4103, 3009, 1965, 1315,  409,  704,  371, 3371, 2092, 3314, 1543,
          61,  513,  792, 1031])
Epoch: 46, Training Loss: 1.08, Validation Loss: 1.05, accuracy = 0.51
######################## Epoch 47 - Batch 1 ########################
IDs in batch 1: tensor([4197, 4264, 3746, 2171, 3299, 3385, 2258, 3188, 1509, 2956, 2394, 3203,
        2586, 2969, 2178, 2496])
Epoch: 47, Training Loss: 1.02, Validation Loss: 1.05, accuracy = 0.52
######################## Epoch 48 - Batch 1 ########################
IDs in batch 1: tensor([3865, 3668,  914, 2081, 3807, 1474,  883, 1136, 2775,  756,  269, 3654,
        1312,  180,  667, 1927])
Epoch: 48, Training Loss: 1.07, Validation Loss: 1.05, accuracy = 0.52
######################## Epoch 49 - Batch 1 ########################
IDs in batch 1: tensor([ 627, 3982, 2555, 4180, 2565, 3441, 3056, 3429, 3440, 3927, 1751, 2442,
        1499, 4118, 1488,  507])
Epoch: 49, Training Loss: 1.06, Validation Loss: 1.04, accuracy = 0.53
######################## Epoch 50 - Batch 1 ########################
IDs in batch 1: tensor([3147, 2860, 1250, 2398, 2806, 1057, 2235, 3028, 2134,   93,  263, 2457,
        3110, 3271, 1178, 1199])
Epoch: 50, Training Loss: 0.96, Validation Loss: 1.04, accuracy = 0.53
######################## Epoch 51 - Batch 1 ########################
IDs in batch 1: tensor([1994,  260, 1553, 2555, 2640, 3503, 1892, 4185, 3321, 3859,  341, 1638,
        3707,  276, 4114, 3943])
Epoch: 51, Training Loss: 1.01, Validation Loss: 1.04, accuracy = 0.53
######################## Epoch 52 - Batch 1 ########################
IDs in batch 1: tensor([4011, 2604,  407, 3025, 1488, 2373, 3829, 2112, 3084,  401,  777,  510,
        2196, 2731, 3410,    7])
Epoch: 52, Training Loss: 0.99, Validation Loss: 1.04, accuracy = 0.54
######################## Epoch 53 - Batch 1 ########################
IDs in batch 1: tensor([ 295, 2783, 1157, 1559, 4119, 3669,  505, 1343,   19, 1340, 3733,  326,
        3132, 1072, 3999, 1297])
Epoch: 53, Training Loss: 1.09, Validation Loss: 1.04, accuracy = 0.53
######################## Epoch 54 - Batch 1 ########################
IDs in batch 1: tensor([ 683, 3650, 1185, 2126, 3436,  515, 3349, 1808, 4049, 2412, 3216, 2993,
        2817, 3079, 1219, 2261])
Epoch: 54, Training Loss: 1.08, Validation Loss: 1.04, accuracy = 0.52
######################## Epoch 55 - Batch 1 ########################
IDs in batch 1: tensor([2584, 3632, 4268,  920, 1138, 3516,  894, 3389, 2833, 2597,  287,  184,
         933,  497, 3597, 3003])
Epoch: 55, Training Loss: 1.02, Validation Loss: 1.04, accuracy = 0.53
######################## Epoch 56 - Batch 1 ########################
IDs in batch 1: tensor([2669, 1950, 2578, 1345, 1630,  220, 1809, 4204, 3024, 3792, 2314, 2448,
        3306, 2017,  138, 4099])
Epoch: 56, Training Loss: 1.07, Validation Loss: 1.04, accuracy = 0.54
######################## Epoch 57 - Batch 1 ########################
IDs in batch 1: tensor([1679, 2931, 3030, 1904, 2553, 4235,  918, 2894,  226,   15, 3701,  954,
         101, 1061, 1113, 3765])
Epoch: 57, Training Loss: 1.08, Validation Loss: 1.03, accuracy = 0.54
######################## Epoch 58 - Batch 1 ########################
IDs in batch 1: tensor([4140, 4033, 1823,  724, 3473, 3036,  393, 3018, 1156, 3961, 2428, 3073,
        2148, 3458, 2095, 1723])
Epoch: 58, Training Loss: 1.02, Validation Loss: 1.03, accuracy = 0.54
######################## Epoch 59 - Batch 1 ########################
IDs in batch 1: tensor([2663, 2408, 1159, 4110, 2127,  138, 4044,  546, 2453,  954,   93, 2835,
          72,  620,   50, 3812])
Epoch: 59, Training Loss: 1.06, Validation Loss: 1.03, accuracy = 0.53
######################## Epoch 60 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 3858,  683,  714, 2874, 2767, 2217, 1450, 2993, 3463,  822, 2185,
        4224, 1949, 2591,  425])
Epoch: 60, Training Loss: 1.08, Validation Loss: 1.03, accuracy = 0.53
######################## Epoch 61 - Batch 1 ########################
IDs in batch 1: tensor([2614,  516, 2231, 2120,  212, 2809, 4180, 3872, 1781, 1220, 1590, 1682,
        3700, 1340, 1434, 1576])
Epoch: 61, Training Loss: 1.03, Validation Loss: 1.03, accuracy = 0.53
######################## Epoch 62 - Batch 1 ########################
IDs in batch 1: tensor([ 678, 1592,  258,  894, 1846, 3017, 1277, 3544, 2857, 1566, 4217, 2859,
        2624, 3414, 2842, 2433])
Epoch: 62, Training Loss: 0.93, Validation Loss: 1.03, accuracy = 0.54
######################## Epoch 63 - Batch 1 ########################
IDs in batch 1: tensor([ 920, 4141, 2051, 2617, 1676,  508, 3989, 3841, 2159, 1445, 2023, 2150,
        1306, 1693, 4230, 3443])
Epoch: 63, Training Loss: 1.04, Validation Loss: 1.03, accuracy = 0.53
######################## Epoch 64 - Batch 1 ########################
IDs in batch 1: tensor([2973, 1399,  269, 2780, 2056,   38,  424, 3635, 3366, 2363, 2441, 3372,
        1124, 2115, 3385,  426])
Epoch: 64, Training Loss: 0.95, Validation Loss: 1.03, accuracy = 0.52
######################## Epoch 65 - Batch 1 ########################
IDs in batch 1: tensor([4187, 3111, 2551, 3458,  985, 3547, 3543, 3265, 1222,  218,  251,  229,
        2166, 3037,  238, 2309])
Epoch: 65, Training Loss: 0.98, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 66 - Batch 1 ########################
IDs in batch 1: tensor([2697, 1361, 2692, 2142, 3996, 3740, 3658, 1861, 3943, 3935, 1159,   93,
        1737, 1467, 1111, 2788])
Epoch: 66, Training Loss: 1.11, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 67 - Batch 1 ########################
IDs in batch 1: tensor([1396, 1899, 4204, 3245, 3797, 3830,  649,  258, 1708,  947, 4051, 2320,
        3486, 1951,  835, 1914])
Epoch: 67, Training Loss: 1.01, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 68 - Batch 1 ########################
IDs in batch 1: tensor([3582, 1096, 2618, 3980, 3583, 1787, 2940, 1248,  991, 1009, 2420,  604,
        3721,  796,  467, 4096])
Epoch: 68, Training Loss: 1.14, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 69 - Batch 1 ########################
IDs in batch 1: tensor([ 426, 3490,  484, 4180, 1011, 3108, 2329, 2408,  398, 2235, 2567,  769,
         550, 1967, 2967, 2968])
Epoch: 69, Training Loss: 0.99, Validation Loss: 1.03, accuracy = 0.51
######################## Epoch 70 - Batch 1 ########################
IDs in batch 1: tensor([3688, 3644, 1275,  563,  167,  412, 2787, 2034, 2265, 2433, 1454, 3734,
         244,  387, 2821, 2998])
Epoch: 70, Training Loss: 0.98, Validation Loss: 1.03, accuracy = 0.50
######################## Epoch 71 - Batch 1 ########################
IDs in batch 1: tensor([3436, 1308,  792, 2367, 3004, 2711, 2936, 1562,  245,  923, 3401, 3437,
          14, 1043, 3851, 3988])
Epoch: 71, Training Loss: 0.98, Validation Loss: 1.03, accuracy = 0.50
######################## Epoch 72 - Batch 1 ########################
IDs in batch 1: tensor([1258,  610, 2284, 3552, 2305, 1611, 2652, 2063, 4033, 2514, 2739, 2309,
        3870, 1010,  962, 1299])
Epoch: 72, Training Loss: 1.01, Validation Loss: 1.03, accuracy = 0.50
######################## Epoch 73 - Batch 1 ########################
IDs in batch 1: tensor([3744, 2874, 2132,  177, 2350, 3154, 2414,  524, 2706,  785, 1402, 3903,
        1448, 1364, 1911, 2376])
Epoch: 73, Training Loss: 0.99, Validation Loss: 1.02, accuracy = 0.50
######################## Epoch 74 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 1833, 3166, 2829, 3056, 2499, 3146,  601,  187,  442, 2193, 1045,
        1537,  284, 2763,  496])
Epoch: 74, Training Loss: 0.93, Validation Loss: 1.02, accuracy = 0.50
######################## Epoch 75 - Batch 1 ########################
IDs in batch 1: tensor([2901, 1346,   25,  474, 2355, 2196,  496, 2009, 2921, 1258, 3500,  188,
        2112, 3669, 2402, 3497])
Epoch: 75, Training Loss: 0.96, Validation Loss: 1.02, accuracy = 0.50
######################## Epoch 76 - Batch 1 ########################
IDs in batch 1: tensor([4058, 2899, 2252, 3535, 1630, 2847, 3289, 1736, 2661, 1331, 1938, 2508,
        2376, 2025,  821, 1421])
Epoch: 76, Training Loss: 0.99, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 77 - Batch 1 ########################
IDs in batch 1: tensor([3193, 3299, 2925, 3036, 3387, 3652, 3607, 2161,  530,  360,  735, 2797,
        2391,  896, 1198, 3940])
Epoch: 77, Training Loss: 1.04, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 78 - Batch 1 ########################
IDs in batch 1: tensor([1360, 2667,  584,  516,  907, 2437,  776, 1510, 1853, 4157, 2148, 3803,
        1087,  207, 1120, 3265])
Epoch: 78, Training Loss: 1.04, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 79 - Batch 1 ########################
IDs in batch 1: tensor([4048, 3968,   13, 2464,  557, 2274, 1787, 1651, 3382, 3994, 2146,  828,
        1944, 2905, 2743, 2506])
Epoch: 79, Training Loss: 1.08, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 80 - Batch 1 ########################
IDs in batch 1: tensor([4033, 1724, 1949, 1597, 2153, 3668, 2281, 4085, 2731, 1155, 3985,  177,
        2784,  554, 1974, 2552])
Epoch: 80, Training Loss: 1.03, Validation Loss: 1.02, accuracy = 0.51
######################## Epoch 81 - Batch 1 ########################
IDs in batch 1: tensor([1405, 3903,  900,  300, 1579,  834, 2826, 1396,  100, 3250,  825, 1455,
        1116, 1871, 3853,  651])
Epoch: 81, Training Loss: 1.01, Validation Loss: 1.02, accuracy = 0.52
######################## Epoch 82 - Batch 1 ########################
IDs in batch 1: tensor([  18,  492, 3203,  591, 2845, 2153,  680, 2796,  422, 3616, 1861, 3549,
        2500,   73, 2899, 3755])
Epoch: 82, Training Loss: 0.92, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 83 - Batch 1 ########################
IDs in batch 1: tensor([2044,  140, 2132,  398, 1459, 1132, 1892, 1020, 2509, 2182, 1041, 2234,
         220,  694, 3404, 3953])
Epoch: 83, Training Loss: 0.95, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 84 - Batch 1 ########################
IDs in batch 1: tensor([1075,   96,  960, 3719, 2572,  117, 3227, 2959, 4176, 4037, 4004, 1968,
        2898, 1402,  151, 3577])
Epoch: 84, Training Loss: 1.06, Validation Loss: 1.01, accuracy = 0.53
######################## Epoch 85 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 3951, 2264, 2621, 2003, 1247, 3058,  503, 2996, 3136, 4107, 2449,
        3810,  866, 1502, 3715])
Epoch: 85, Training Loss: 0.95, Validation Loss: 1.01, accuracy = 0.52
######################## Epoch 86 - Batch 1 ########################
IDs in batch 1: tensor([ 351, 3074, 1575, 2051, 3384, 1214, 3866, 3031, 3185, 2609,   14, 3184,
        3974, 2738, 1853,  896])
Epoch: 86, Training Loss: 0.98, Validation Loss: 1.01, accuracy = 0.53
######################## Epoch 87 - Batch 1 ########################
IDs in batch 1: tensor([ 418, 1397,   62,   73,  652, 1385, 1787, 2398, 2542, 3289, 1491,   41,
        1481, 2804,  771,  112])
Epoch: 87, Training Loss: 0.93, Validation Loss: 1.01, accuracy = 0.53
######################## Epoch 88 - Batch 1 ########################
IDs in batch 1: tensor([1039, 1130, 4215,  743, 2157, 3607, 2504,  195,  501, 3421,  613, 1336,
        2835, 3527, 2942, 1661])
Epoch: 88, Training Loss: 0.97, Validation Loss: 1.01, accuracy = 0.54
######################## Epoch 89 - Batch 1 ########################
IDs in batch 1: tensor([1501, 3511, 2337, 1834, 2710, 2661, 3417, 3896,  919,   42, 3002, 1027,
        1063, 1005, 1558, 2360])
Epoch: 89, Training Loss: 0.97, Validation Loss: 1.01, accuracy = 0.54
######################## Epoch 90 - Batch 1 ########################
IDs in batch 1: tensor([2894, 2700, 4114, 3681, 2568,  145, 3972, 3461,  430, 1591, 1722,  532,
        3896, 1699,   49,  390])
Epoch: 90, Training Loss: 0.98, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 91 - Batch 1 ########################
IDs in batch 1: tensor([2499, 3105, 4165, 3226,  454,    5, 3271,  710, 3453, 2882, 3126,  835,
         649, 3006, 3903, 1009])
Epoch: 91, Training Loss: 0.96, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 92 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 3701, 1011, 3671, 3895, 2777, 2957, 1571, 1201,  397, 3495,  359,
        3238, 4077, 1747, 2448])
Epoch: 92, Training Loss: 1.03, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 93 - Batch 1 ########################
IDs in batch 1: tensor([ 182, 2183, 2782, 2399, 2067, 2016, 1871, 2839, 2135, 3829, 4227, 1387,
        2793, 2219, 3121, 2475])
Epoch: 93, Training Loss: 0.97, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 94 - Batch 1 ########################
IDs in batch 1: tensor([4154, 2968, 3970,  269, 4238,  899, 3075, 2672, 4185, 1076, 3956, 3112,
        1589,  541, 3254, 3963])
Epoch: 94, Training Loss: 1.11, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 95 - Batch 1 ########################
IDs in batch 1: tensor([3628, 2777,  663, 1256, 2041, 2535, 1162, 3862, 4172, 2352, 3913, 1133,
         512, 4014,  964, 1228])
Epoch: 95, Training Loss: 1.02, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 96 - Batch 1 ########################
IDs in batch 1: tensor([ 357, 2315,  220, 3710,  870, 2721, 2798, 1445,  289, 1146, 2688,  224,
        1156, 1221,  978, 2842])
Epoch: 96, Training Loss: 0.91, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 97 - Batch 1 ########################
IDs in batch 1: tensor([2495, 1404, 1090,  400,  591, 1016, 3256,   38, 1802, 4217, 1372, 4006,
         819, 4218, 1278, 3020])
Epoch: 97, Training Loss: 1.00, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 98 - Batch 1 ########################
IDs in batch 1: tensor([4061, 1802, 3829, 2734, 4172, 1418, 1049,   82, 1236, 3647, 2760, 2842,
          96,  238,  117,  373])
Epoch: 98, Training Loss: 1.04, Validation Loss: 1.00, accuracy = 0.54
######################## Epoch 99 - Batch 1 ########################
IDs in batch 1: tensor([ 401,  588,  538,  122, 2337, 4012, 1851, 1975, 3544, 2795, 2141,   25,
        4190, 4184,   19, 3763])
Epoch: 99, Training Loss: 0.96, Validation Loss: 1.00, accuracy = 0.55
######################## Epoch 100 - Batch 1 ########################
IDs in batch 1: tensor([2297,   57, 2039, 3218, 2993,  954, 1895, 1073, 3308, 2366,  625, 2715,
        1670, 1380, 2256,  120])
Epoch: 100, Training Loss: 0.95, Validation Loss: 0.99, accuracy = 0.54
######################## Epoch 101 - Batch 1 ########################
IDs in batch 1: tensor([3569,  729, 1349,  148,  317, 2764, 3659, 1443,  557, 3390, 1781, 1895,
         217,  588, 1600, 3049])
Epoch: 101, Training Loss: 0.99, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 102 - Batch 1 ########################
IDs in batch 1: tensor([1920, 1399, 4197, 4037, 4018,  258,  112,  962, 2287, 2950, 2431, 4089,
        2098,  396, 1101, 2506])
Epoch: 102, Training Loss: 1.01, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 103 - Batch 1 ########################
IDs in batch 1: tensor([ 397, 3113, 3242, 1766, 2045, 1308,  456, 3925, 1482, 2938, 2663,  257,
         455, 3143, 3876, 1231])
Epoch: 103, Training Loss: 0.96, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 104 - Batch 1 ########################
IDs in batch 1: tensor([ 244, 2217,   24, 2539, 1007,  445, 3082, 2109, 1655, 1559,   44, 4031,
        1795, 2182, 1152, 1355])
Epoch: 104, Training Loss: 0.96, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 105 - Batch 1 ########################
IDs in batch 1: tensor([ 120,  481,  739, 2067, 1947,  140, 2002, 1810, 2145, 3179, 3196, 3470,
        4179, 3696, 1267, 3673])
Epoch: 105, Training Loss: 0.95, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 106 - Batch 1 ########################
IDs in batch 1: tensor([2659,  511, 2462, 3618, 3714,  150, 2198, 3994, 3981, 4017, 2655, 1852,
         290, 2752, 3658, 1779])
Epoch: 106, Training Loss: 1.04, Validation Loss: 0.99, accuracy = 0.56
######################## Epoch 107 - Batch 1 ########################
IDs in batch 1: tensor([1170, 3743,  148, 1921, 3495,  346, 3543,  747,  134,  653,  251, 3112,
         194, 3505,  279,  113])
Epoch: 107, Training Loss: 0.93, Validation Loss: 0.99, accuracy = 0.56
######################## Epoch 108 - Batch 1 ########################
IDs in batch 1: tensor([1766, 2797, 3676,  238,  537, 1256, 1450, 2418,   18, 2473, 3470, 3372,
         354, 3265, 1077, 2835])
Epoch: 108, Training Loss: 0.83, Validation Loss: 0.99, accuracy = 0.56
######################## Epoch 109 - Batch 1 ########################
IDs in batch 1: tensor([1767,  693, 1315, 2213, 1138, 2663, 3532,  384,  872, 1139, 3207, 4258,
        3538,  382, 1387, 3539])
Epoch: 109, Training Loss: 0.89, Validation Loss: 0.99, accuracy = 0.55
######################## Epoch 110 - Batch 1 ########################
IDs in batch 1: tensor([2885, 3038, 2957, 2264,  376, 3177, 1745, 2646, 2161, 1681, 3079, 4172,
        3492,  869, 2805, 1419])
Epoch: 110, Training Loss: 0.95, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 111 - Batch 1 ########################
IDs in batch 1: tensor([ 224, 4105,  228,  432, 3479, 3614,  251, 3242, 3252, 2670,  200,  177,
         555, 1020, 3624, 4055])
Epoch: 111, Training Loss: 0.97, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 112 - Batch 1 ########################
IDs in batch 1: tensor([2666, 1877, 3894, 3558, 2901,   93,  829, 2879,  196, 2378, 1862, 2426,
        2695, 3846, 3841, 3052])
Epoch: 112, Training Loss: 1.00, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 113 - Batch 1 ########################
IDs in batch 1: tensor([3397, 1953, 2253, 3323,  250, 1485, 3490, 2638, 3592,  691,  830, 1656,
        1313, 1600, 2373, 1720])
Epoch: 113, Training Loss: 0.95, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 114 - Batch 1 ########################
IDs in batch 1: tensor([4030, 2276, 1852, 3692,  907, 1347, 2106,  518, 3466, 4133, 2447, 3192,
         724, 2940, 4116, 2890])
Epoch: 114, Training Loss: 1.03, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 115 - Batch 1 ########################
IDs in batch 1: tensor([2824, 1576, 2231, 1909,  785, 1452, 2110, 3344, 1707, 1594, 1409,  388,
        2693, 1181, 3409, 1065])
Epoch: 115, Training Loss: 0.87, Validation Loss: 0.98, accuracy = 0.55
######################## Epoch 116 - Batch 1 ########################
IDs in batch 1: tensor([3875,  402, 3452, 3058,  566, 3112,  846, 3381, 3637, 4077, 2996, 1850,
        2731, 4258, 2844, 1287])
Epoch: 116, Training Loss: 1.03, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 117 - Batch 1 ########################
IDs in batch 1: tensor([2315,  106,   37, 3142,  803, 1039,  471, 2301, 1451, 3037,  717, 3842,
        1396, 3203, 1083, 1267])
Epoch: 117, Training Loss: 0.87, Validation Loss: 0.98, accuracy = 0.56
######################## Epoch 118 - Batch 1 ########################
IDs in batch 1: tensor([2853, 1005,  652,  923, 2291, 3455, 3354,  335, 1193, 3812, 2364, 1094,
        3544, 4263, 2545, 1272])
Epoch: 118, Training Loss: 0.93, Validation Loss: 0.97, accuracy = 0.55
######################## Epoch 119 - Batch 1 ########################
IDs in batch 1: tensor([3668, 3465, 4061, 2161,  437, 2446,  314, 2511, 3743, 3664, 3030,  471,
        3772, 2535,  682,  900])
Epoch: 119, Training Loss: 0.92, Validation Loss: 0.97, accuracy = 0.55
######################## Epoch 120 - Batch 1 ########################
IDs in batch 1: tensor([2567,  411,  612, 4224, 2997, 1226, 3176, 2072,  755, 1077, 3715, 2805,
         665, 1022, 1016, 1991])
Epoch: 120, Training Loss: 0.98, Validation Loss: 0.97, accuracy = 0.56
######################## Epoch 121 - Batch 1 ########################
IDs in batch 1: tensor([1305, 3903, 1152, 2343,  976, 2383, 2383, 3415,   62, 2853, 1152, 1322,
        3769, 1371, 3563, 2526])
Epoch: 121, Training Loss: 1.01, Validation Loss: 0.97, accuracy = 0.56
######################## Epoch 122 - Batch 1 ########################
IDs in batch 1: tensor([3779, 1562, 3669,  778, 4115, 1655, 3594, 2195,  795,  111, 1363, 2205,
        2407, 2663, 4254, 1082])
Epoch: 122, Training Loss: 1.01, Validation Loss: 0.97, accuracy = 0.55
######################## Epoch 123 - Batch 1 ########################
IDs in batch 1: tensor([  41, 4122, 3242, 3221, 3897, 3404, 3426, 2257, 1193, 3528, 3900, 2008,
          42, 2016, 2437, 2065])
Epoch: 123, Training Loss: 1.00, Validation Loss: 0.97, accuracy = 0.55
######################## Epoch 124 - Batch 1 ########################
IDs in batch 1: tensor([3446, 3242, 1423, 2386, 1223,  279, 2365,   68,  921,    7, 2120, 3860,
        2134, 1397, 3525, 2965])
Epoch: 124, Training Loss: 0.94, Validation Loss: 0.97, accuracy = 0.55
######################## Epoch 125 - Batch 1 ########################
IDs in batch 1: tensor([3168, 3850,  770, 3446, 2729,   93, 1784, 3875, 1092, 1372,  255, 3781,
        2615, 1076, 1326,  729])
Epoch: 125, Training Loss: 0.95, Validation Loss: 0.97, accuracy = 0.56
######################## Epoch 126 - Batch 1 ########################
IDs in batch 1: tensor([2148, 3930, 3872, 2405, 3655, 1730, 1103, 1255, 2435, 2842, 2362, 1988,
        2343,  795, 2009, 2783])
Epoch: 126, Training Loss: 0.99, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 127 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 3904,  164,  530, 3000,  544, 3018, 4018, 1057, 2428, 3627, 2499,
        3581,  609, 2537,  202])
Epoch: 127, Training Loss: 1.01, Validation Loss: 0.97, accuracy = 0.57
######################## Epoch 128 - Batch 1 ########################
IDs in batch 1: tensor([ 284, 2690,  387,  586, 4069, 2784, 2025,  635, 2457, 3692,  512,  284,
        1708, 2355,  232, 1363])
Epoch: 128, Training Loss: 0.84, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 129 - Batch 1 ########################
IDs in batch 1: tensor([3128, 3531, 1219, 3568,  243,  513, 3564, 2836, 2505, 3537,  306,  251,
        1730, 1383, 3846, 4268])
Epoch: 129, Training Loss: 0.98, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 130 - Batch 1 ########################
IDs in batch 1: tensor([  47, 1116, 3593,  602, 3912, 1886, 3447, 1808, 3336, 2036, 3342,  712,
        1069, 1024, 3829, 1286])
Epoch: 130, Training Loss: 0.93, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 131 - Batch 1 ########################
IDs in batch 1: tensor([1868, 2067, 3838, 2538, 3298, 1580, 4032,  284, 2236, 1956, 1221, 2429,
        2695, 4070, 1130, 4046])
Epoch: 131, Training Loss: 0.97, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 132 - Batch 1 ########################
IDs in batch 1: tensor([2019,  803, 1296, 3425, 3265, 1111, 3360, 4230,  575,  622,  112, 2749,
        2119,  819, 3897, 3925])
Epoch: 132, Training Loss: 0.87, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 133 - Batch 1 ########################
IDs in batch 1: tensor([  51, 1397, 2456,  332,  649, 3014, 1182, 2413, 1284,  182, 4166, 3091,
        2410, 1525,  338,  137])
Epoch: 133, Training Loss: 0.90, Validation Loss: 0.96, accuracy = 0.58
######################## Epoch 134 - Batch 1 ########################
IDs in batch 1: tensor([3738, 1959, 4095, 3486, 3832,  755, 3504, 3333, 3181,  342, 2338,  490,
        3939, 2772, 1256, 2804])
Epoch: 134, Training Loss: 1.02, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 135 - Batch 1 ########################
IDs in batch 1: tensor([3710, 2178,  264, 1443,  645,  756, 2385, 2483, 3935, 1478, 1763, 3872,
         280, 1226, 1331,  822])
Epoch: 135, Training Loss: 1.05, Validation Loss: 0.96, accuracy = 0.57
######################## Epoch 136 - Batch 1 ########################
IDs in batch 1: tensor([ 591,  685, 3692, 3871, 2956, 3099, 2863,  837, 1774,  609, 4084, 2695,
         966, 1108, 3146, 2871])
Epoch: 136, Training Loss: 1.00, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 137 - Batch 1 ########################
IDs in batch 1: tensor([ 991, 1493,  717, 4144, 1083, 3537, 3597, 2842,   85, 2448, 3540, 2821,
        1927, 1869, 1855, 2883])
Epoch: 137, Training Loss: 0.95, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 138 - Batch 1 ########################
IDs in batch 1: tensor([3468, 2166, 1543, 3876,   20, 2472, 3057, 1710,  184, 1613, 1167, 2541,
        2126, 1793,  605, 3447])
Epoch: 138, Training Loss: 0.93, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 139 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 3756,  864, 1124,  239, 2030,  489,  147, 1942, 3279,  251, 3179,
         470, 1120, 3538, 3548])
Epoch: 139, Training Loss: 0.86, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 140 - Batch 1 ########################
IDs in batch 1: tensor([2868, 2899,  101, 3543, 1640, 1963, 4174, 2085, 3190, 3795, 3187, 3207,
         978, 3859,  601, 1277])
Epoch: 140, Training Loss: 0.94, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 141 - Batch 1 ########################
IDs in batch 1: tensor([2839, 1406,  583,  264,  774,  603, 2579, 3494, 1495, 2643, 3585, 4016,
        4012, 3109, 1795, 2561])
Epoch: 141, Training Loss: 0.98, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 142 - Batch 1 ########################
IDs in batch 1: tensor([2781, 3509, 3829, 2338, 1921,   99,  490, 1595,  472, 3430, 4084,  820,
        1228, 3786,  586, 3367])
Epoch: 142, Training Loss: 0.92, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 143 - Batch 1 ########################
IDs in batch 1: tensor([ 841, 4089, 4094, 4133, 3185,    4,   86,  666,   81, 2092,  897, 2415,
         612, 4049, 4149, 1343])
Epoch: 143, Training Loss: 0.97, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 144 - Batch 1 ########################
IDs in batch 1: tensor([2521, 3549, 3608, 2883, 4212, 3234, 3528, 3278, 3974, 1870, 3558, 2899,
         489,  492,  607, 1049])
Epoch: 144, Training Loss: 1.02, Validation Loss: 0.95, accuracy = 0.57
######################## Epoch 145 - Batch 1 ########################
IDs in batch 1: tensor([3400,  469, 3958, 1302, 3628, 1077, 3789, 2857, 1388,  819, 4170, 3206,
        3400,  522,   85, 1010])
Epoch: 145, Training Loss: 1.10, Validation Loss: 0.95, accuracy = 0.58
######################## Epoch 146 - Batch 1 ########################
IDs in batch 1: tensor([  81,  756, 3536, 1972, 3114,  365, 2098, 1409, 3081, 2826, 1455, 2091,
         712, 3035, 2914, 3985])
Epoch: 146, Training Loss: 0.91, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 147 - Batch 1 ########################
IDs in batch 1: tensor([ 924, 3035, 2338, 2799,  180, 1159, 2166, 1927, 1490, 2060, 3161, 1140,
         838, 3472, 1732, 4199])
Epoch: 147, Training Loss: 0.96, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 148 - Batch 1 ########################
IDs in batch 1: tensor([1419, 3739, 3339, 4120, 2145, 2652, 2443,  412, 3024, 1977,   46, 1894,
        3342, 1754, 1925,  448])
Epoch: 148, Training Loss: 0.88, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 149 - Batch 1 ########################
IDs in batch 1: tensor([2155, 1146, 1408, 1973, 3961, 4175, 3404, 1679, 2224, 2287,  172,  818,
        4094, 2898, 4128,  472])
Epoch: 149, Training Loss: 0.94, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 150 - Batch 1 ########################
IDs in batch 1: tensor([ 788, 1897, 3549, 3943,  151, 3369, 2073,  109, 1718, 4060,   73,  843,
        1086, 3100, 1006,  252])
Epoch: 150, Training Loss: 0.87, Validation Loss: 0.94, accuracy = 0.58
######################## Epoch 151 - Batch 1 ########################
IDs in batch 1: tensor([3693, 2805, 2137,   37, 1436, 3833,  656, 4214,  469, 3005, 2917,  412,
         694,  250, 3839, 3624])
Epoch: 151, Training Loss: 0.98, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 152 - Batch 1 ########################
IDs in batch 1: tensor([1399, 1236, 1137,  971,  418, 1346, 2660, 2360, 1232,  630, 4127, 1636,
        2025, 2135, 1448, 1896])
Epoch: 152, Training Loss: 0.96, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 153 - Batch 1 ########################
IDs in batch 1: tensor([ 214, 3904, 1085,  454, 1763, 3627, 3826, 1530, 1883,  223, 1289, 2558,
        1481, 2604,  767, 3150])
Epoch: 153, Training Loss: 0.89, Validation Loss: 0.95, accuracy = 0.58
######################## Epoch 154 - Batch 1 ########################
IDs in batch 1: tensor([3495, 2844, 3987, 2049, 1123,  919, 1440, 1537, 2535, 2546, 3337, 2452,
        2771, 2413, 4184, 1470])
Epoch: 154, Training Loss: 0.95, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 155 - Batch 1 ########################
IDs in batch 1: tensor([ 380, 1421,  904, 3757, 2301, 2595, 3593, 2812, 1166, 3309, 2114, 1600,
        3845,  740, 1425,  101])
Epoch: 155, Training Loss: 0.95, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 156 - Batch 1 ########################
IDs in batch 1: tensor([3740, 2223,  244, 2337,  505, 3601,  921, 1730, 2242,  226, 4016, 1644,
         390, 3525,  726, 1273])
Epoch: 156, Training Loss: 0.95, Validation Loss: 0.94, accuracy = 0.58
######################## Epoch 157 - Batch 1 ########################
IDs in batch 1: tensor([1088, 3681,  426, 3729,  873, 3166, 1255, 1655, 3719, 2913, 2710, 4022,
        2784, 1028, 3121, 2624])
Epoch: 157, Training Loss: 1.02, Validation Loss: 0.94, accuracy = 0.57
######################## Epoch 158 - Batch 1 ########################
IDs in batch 1: tensor([3074, 1049, 2851, 1646,  921, 2783, 3866, 2692, 2857, 2190, 2475, 2671,
        1671, 3952, 1041, 3751])
Epoch: 158, Training Loss: 1.03, Validation Loss: 0.94, accuracy = 0.58
######################## Epoch 159 - Batch 1 ########################
IDs in batch 1: tensor([2179, 1241,  815, 3542, 1233,  661, 2838, 1047,  642, 2940, 3532, 1025,
        3115, 3349, 1988,  965])
Epoch: 159, Training Loss: 0.89, Validation Loss: 0.94, accuracy = 0.58
######################## Epoch 160 - Batch 1 ########################
IDs in batch 1: tensor([3731, 1765, 2772, 3387, 2371, 4179, 3808, 1332, 4000, 1452, 1518, 2841,
        2106,  617, 3333, 1765])
Epoch: 160, Training Loss: 0.98, Validation Loss: 0.94, accuracy = 0.58
######################## Epoch 161 - Batch 1 ########################
IDs in batch 1: tensor([1295, 4035, 2264, 2428, 3483, 2590, 2627,  452, 1764,  591, 1558, 2860,
        3769,  284,   61, 1120])
Epoch: 161, Training Loss: 0.85, Validation Loss: 0.94, accuracy = 0.59
######################## Epoch 162 - Batch 1 ########################
IDs in batch 1: tensor([1381, 2690, 2366, 2210, 2976, 3865, 3109,  566, 2553,  990,  375, 1032,
        1277, 3785, 3408,   22])
Epoch: 162, Training Loss: 0.79, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 163 - Batch 1 ########################
IDs in batch 1: tensor([2124, 1386, 1423, 2209, 2066, 1035, 3697, 3005, 1438, 1635, 2884, 2450,
        3753, 1085, 1974, 3842])
Epoch: 163, Training Loss: 1.03, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 164 - Batch 1 ########################
IDs in batch 1: tensor([2687, 4149,  409, 2895, 1197, 3154, 2217,  779,  786, 1476, 1199, 3818,
        1583, 1639, 2947, 2520])
Epoch: 164, Training Loss: 1.04, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 165 - Batch 1 ########################
IDs in batch 1: tensor([4230, 3990, 2632, 2463, 2488, 1957,  978, 3020,  724, 2796, 1612, 2364,
        1809,  523, 2710, 3601])
Epoch: 165, Training Loss: 0.89, Validation Loss: 0.93, accuracy = 0.58
######################## Epoch 166 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 3795,  200, 1131, 3587, 3378, 1668, 3634,  909, 1601, 3358, 3651,
        2272, 4179, 2959, 1111])
Epoch: 166, Training Loss: 1.09, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 167 - Batch 1 ########################
IDs in batch 1: tensor([2667, 2689, 4113,  398, 2154, 2278,   63,  340, 3056, 2784, 4225, 2777,
         888,  635,  980, 2275])
Epoch: 167, Training Loss: 0.83, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 168 - Batch 1 ########################
IDs in batch 1: tensor([ 491, 1464, 3822, 1448, 2559, 3217, 2027, 2390, 1684,  815, 1880, 1180,
        1118, 3972, 1576, 1498])
Epoch: 168, Training Loss: 0.92, Validation Loss: 0.93, accuracy = 0.58
######################## Epoch 169 - Batch 1 ########################
IDs in batch 1: tensor([1548, 2709, 1642,  160, 2027, 2094, 3053, 2247, 4168, 2297, 3729, 3494,
        2936, 2170, 1818, 2203])
Epoch: 169, Training Loss: 0.95, Validation Loss: 0.93, accuracy = 0.58
######################## Epoch 170 - Batch 1 ########################
IDs in batch 1: tensor([1501, 3433, 1417, 1316, 1794,  878, 4084, 1772, 3206, 2482, 3100, 1200,
        4138,  683, 1380, 2399])
Epoch: 170, Training Loss: 0.95, Validation Loss: 0.93, accuracy = 0.58
######################## Epoch 171 - Batch 1 ########################
IDs in batch 1: tensor([ 610, 2863, 1925,  321, 2464,  320,  946, 3601, 2587, 1025, 3132,  712,
        2019, 2583, 3860, 2133])
Epoch: 171, Training Loss: 0.80, Validation Loss: 0.93, accuracy = 0.59
######################## Epoch 172 - Batch 1 ########################
IDs in batch 1: tensor([2523, 1385, 2378, 3276, 3192, 1263, 3557,  440, 1030, 2732,  832, 2301,
        2578, 2108,  281,  637])
Epoch: 172, Training Loss: 1.03, Validation Loss: 0.92, accuracy = 0.59
######################## Epoch 173 - Batch 1 ########################
IDs in batch 1: tensor([3330, 2771, 3466, 2305, 3610, 1110,  340, 2179, 4229, 3668, 3873, 3589,
        3366, 1199,  334, 2440])
Epoch: 173, Training Loss: 1.14, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 174 - Batch 1 ########################
IDs in batch 1: tensor([1821,  788, 1493, 2520, 2399,  682, 1397, 2157, 1417, 3945, 3105, 3526,
         946, 1344, 3185,  258])
Epoch: 174, Training Loss: 0.80, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 175 - Batch 1 ########################
IDs in batch 1: tensor([2719, 2526, 1509, 2410,  465, 3554, 3863, 3527, 1640, 2488, 3475, 3126,
        1710, 2410, 2049,  884])
Epoch: 175, Training Loss: 0.93, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 176 - Batch 1 ########################
IDs in batch 1: tensor([2605, 2791, 3511, 4077, 3771,  188, 3883,  454, 2559,  474,  844, 4117,
        2984, 1271, 3433, 3956])
Epoch: 176, Training Loss: 1.06, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 177 - Batch 1 ########################
IDs in batch 1: tensor([ 214, 1032,  226, 3308, 1049,  305, 1175, 3763, 3426, 3757, 2291, 3190,
         474, 1567,   26, 1499])
Epoch: 177, Training Loss: 0.79, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 178 - Batch 1 ########################
IDs in batch 1: tensor([1197, 4075, 3277, 2666,  323,  474,  105, 2578, 1684, 2190, 4085, 3328,
        3688, 2810,  243, 3885])
Epoch: 178, Training Loss: 0.99, Validation Loss: 0.92, accuracy = 0.60
######################## Epoch 179 - Batch 1 ########################
IDs in batch 1: tensor([1665, 4144, 3609,  769, 1747, 3190, 4055, 1061,  351, 1200, 1953, 1414,
        2734, 1087, 2088, 3655])
Epoch: 179, Training Loss: 0.98, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 180 - Batch 1 ########################
IDs in batch 1: tensor([4009,  977, 1138, 1679, 3886, 3475, 2180, 4158,  874, 1417, 2192, 4220,
        1094,  155,   22, 1153])
Epoch: 180, Training Loss: 0.89, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 181 - Batch 1 ########################
IDs in batch 1: tensor([3744, 4266, 1794,  894,  680, 3746, 2031, 3991, 4013, 4157,  119, 1546,
         186, 2616, 3430, 3234])
Epoch: 181, Training Loss: 1.09, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 182 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3530, 3971, 1592, 2746,  489, 2406, 3188,  985, 3808, 1846, 2807,
        2592, 3475,  100, 1463])
Epoch: 182, Training Loss: 0.91, Validation Loss: 0.92, accuracy = 0.61
######################## Epoch 183 - Batch 1 ########################
IDs in batch 1: tensor([ 617, 1620, 3618, 4016, 1315, 3992, 3726,  821, 3564, 1718, 4003, 2080,
        2124, 2672, 4073, 2354])
Epoch: 183, Training Loss: 1.16, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 184 - Batch 1 ########################
IDs in batch 1: tensor([3275, 4154, 3643, 2641, 2398, 2652, 3859,  302, 3120, 3401,  843, 3370,
         334, 4161,  981, 3314])
Epoch: 184, Training Loss: 0.93, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 185 - Batch 1 ########################
IDs in batch 1: tensor([2496, 4000, 1472,  214, 3743, 2376, 3591,  858, 1948, 2990, 2505, 3475,
        4076,  223, 1031,  960])
Epoch: 185, Training Loss: 0.99, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 186 - Batch 1 ########################
IDs in batch 1: tensor([ 960, 1124, 1260, 3851, 2135, 1123,  736, 2172, 1065, 2973, 3989, 2301,
         494,   35,  981, 2558])
Epoch: 186, Training Loss: 0.80, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 187 - Batch 1 ########################
IDs in batch 1: tensor([ 170, 4012, 1810, 4097, 2663,  261, 1056, 1745,  232, 1032, 3617,  356,
        1347,  357, 3196, 1128])
Epoch: 187, Training Loss: 0.90, Validation Loss: 0.91, accuracy = 0.61
######################## Epoch 188 - Batch 1 ########################
IDs in batch 1: tensor([3961, 1937, 3423,  552,  848, 3533, 2711,  871, 3729, 2299, 2788, 2353,
        1453, 1957,   84,  454])
Epoch: 188, Training Loss: 0.78, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 189 - Batch 1 ########################
IDs in batch 1: tensor([2272, 1732, 1753, 1754, 1025,   92, 2809, 2249, 2002, 1774, 4249, 3895,
        4033, 1228,  196, 4203])
Epoch: 189, Training Loss: 0.85, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 190 - Batch 1 ########################
IDs in batch 1: tensor([2272, 1397, 1881, 2856, 1965,  689, 2191, 3304, 3881,   84, 2213, 1993,
        3036, 3459, 2393, 2370])
Epoch: 190, Training Loss: 0.86, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 191 - Batch 1 ########################
IDs in batch 1: tensor([4236, 3009, 1680, 3783, 3588, 2420, 2278, 2467, 2598,  694,  160, 4007,
         358,   14, 1381,  947])
Epoch: 191, Training Loss: 0.94, Validation Loss: 0.91, accuracy = 0.62
######################## Epoch 192 - Batch 1 ########################
IDs in batch 1: tensor([3025,  524, 4245,  858, 2306, 1062, 1789, 3025, 2018, 3147, 1811, 2360,
        3701, 1312,  674,  112])
Epoch: 192, Training Loss: 0.83, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 193 - Batch 1 ########################
IDs in batch 1: tensor([1099, 2776, 2073, 1436, 1570, 3507, 2278, 1356, 3373,  356, 3000, 3485,
        3102, 4212, 3168, 4049])
Epoch: 193, Training Loss: 0.98, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 194 - Batch 1 ########################
IDs in batch 1: tensor([1762, 2390, 1973,  881, 2858,  732, 2870, 2298,  350, 3990, 2379, 4031,
         262, 2195, 1761,  378])
Epoch: 194, Training Loss: 0.70, Validation Loss: 0.90, accuracy = 0.63
######################## Epoch 195 - Batch 1 ########################
IDs in batch 1: tensor([1132, 3389, 3718, 2614, 1239, 1231, 2508, 2328,  809,  303,   60, 1020,
        1808, 3023, 3795, 2751])
Epoch: 195, Training Loss: 0.86, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 196 - Batch 1 ########################
IDs in batch 1: tensor([3494, 2344,  333, 1296, 1186, 1933, 3700, 2973, 3461,   46,  982, 3443,
        1762,  814, 2218, 3375])
Epoch: 196, Training Loss: 0.72, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 197 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 2423, 3069, 2279, 3238, 3755, 3127, 2746, 2350, 1506, 1229, 1464,
         522,  403, 2734,  182])
Epoch: 197, Training Loss: 0.82, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 198 - Batch 1 ########################
IDs in batch 1: tensor([2347, 4249, 4157, 2188,  519, 2718, 3372, 3154,  360, 2030, 3593, 4089,
          31, 3541, 1153, 1844])
Epoch: 198, Training Loss: 0.86, Validation Loss: 0.90, accuracy = 0.62
######################## Epoch 199 - Batch 1 ########################
IDs in batch 1: tensor([1728,  893,  565, 2537, 1573,  871, 2770, 1092, 1231,   25, 3376, 4093,
         976,  978, 3480, 3534])
Epoch: 199, Training Loss: 0.84, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 200 - Batch 1 ########################
IDs in batch 1: tensor([ 412, 1025, 4218, 2542,  941, 2279, 2767, 3042, 2066, 4005, 2291, 3769,
        2279, 2241,  974,  930])
Epoch: 200, Training Loss: 0.96, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 201 - Batch 1 ########################
IDs in batch 1: tensor([4010, 3246, 4008, 3658, 1952,    5, 3927, 3593, 3110, 2671, 1224,  757,
        1225,  674,  513, 3052])
Epoch: 201, Training Loss: 0.97, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 202 - Batch 1 ########################
IDs in batch 1: tensor([ 850,  467,  239, 1440,  456, 1802, 2517, 1937, 2242, 2787, 3743,  639,
        2723, 3073, 3521, 1001])
Epoch: 202, Training Loss: 0.75, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 203 - Batch 1 ########################
IDs in batch 1: tensor([2504, 2465, 3144, 1818, 2120,  478,  789, 2169,  795, 1583, 3542,  587,
        2589, 2960, 2598,  909])
Epoch: 203, Training Loss: 0.76, Validation Loss: 0.89, accuracy = 0.61
######################## Epoch 204 - Batch 1 ########################
IDs in batch 1: tensor([2754, 3400, 2314, 1675,  834, 2828, 4215, 3388,  281, 2840,  103,  334,
        4168, 1138,  131, 1984])
Epoch: 204, Training Loss: 0.81, Validation Loss: 0.89, accuracy = 0.61
######################## Epoch 205 - Batch 1 ########################
IDs in batch 1: tensor([1821, 3069, 1481, 3721, 2711, 1871, 2257,  788, 2304, 1383, 3388,  183,
        2198,  455, 2034, 2383])
Epoch: 205, Training Loss: 0.84, Validation Loss: 0.89, accuracy = 0.61
######################## Epoch 206 - Batch 1 ########################
IDs in batch 1: tensor([ 921,   52, 1405,  155, 2039, 4055, 3311, 1518, 1473, 4223, 2115,  873,
         324, 1093, 2013, 3771])
Epoch: 206, Training Loss: 0.85, Validation Loss: 0.89, accuracy = 0.61
######################## Epoch 207 - Batch 1 ########################
IDs in batch 1: tensor([2682, 1425, 3723, 1102, 3369,  954, 3900, 1399, 4254, 2114, 2736, 2765,
        4036, 3681, 2407, 3564])
Epoch: 207, Training Loss: 1.04, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 208 - Batch 1 ########################
IDs in batch 1: tensor([3372,  308,  218, 4065,  874,  995,  881, 4087, 3156,  672, 3188, 2804,
         850, 1263, 3428,  396])
Epoch: 208, Training Loss: 0.89, Validation Loss: 0.89, accuracy = 0.62
######################## Epoch 209 - Batch 1 ########################
IDs in batch 1: tensor([ 914, 2226, 2251, 4174, 1428, 2496, 2060,  873, 1693, 3813, 3803, 2882,
        1334,  498, 1754, 1154])
Epoch: 209, Training Loss: 0.91, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 210 - Batch 1 ########################
IDs in batch 1: tensor([2894, 1130,  376, 2867,  442, 2667, 2763, 2046,  401, 3111, 3112, 1553,
         687, 3146, 1163,  981])
Epoch: 210, Training Loss: 0.70, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 211 - Batch 1 ########################
IDs in batch 1: tensor([1041, 1043, 3040,  756, 3102,  324, 4120, 2443, 3494, 4238, 3079, 1578,
         605, 2690, 1102, 3330])
Epoch: 211, Training Loss: 0.95, Validation Loss: 0.88, accuracy = 0.62
######################## Epoch 212 - Batch 1 ########################
IDs in batch 1: tensor([3221,  226, 2745, 4238, 3850, 3798, 1428, 1283, 3387, 2815, 3031, 1537,
        2965, 1209, 1824, 3414])
Epoch: 212, Training Loss: 0.88, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 213 - Batch 1 ########################
IDs in batch 1: tensor([ 321,  587,  183,   49, 3948,  454, 2091, 2347, 2109,  257, 3940, 3115,
        2371, 1417,  732, 1559])
Epoch: 213, Training Loss: 0.86, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 214 - Batch 1 ########################
IDs in batch 1: tensor([ 140,   30, 3233, 1113,  100, 1499, 2821, 1731, 3391, 1733, 2695, 2286,
        4138, 3553,  649,  203])
Epoch: 214, Training Loss: 0.94, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 215 - Batch 1 ########################
IDs in batch 1: tensor([1499, 2874, 1658, 1559, 4227, 1563,  712,  213,  159, 3798, 3441, 3373,
        1176, 3558,  838,  200])
Epoch: 215, Training Loss: 0.91, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 216 - Batch 1 ########################
IDs in batch 1: tensor([1107, 3958,  427, 3983, 3503, 1804,  733, 3115, 1911, 1953, 2225, 2800,
        2371, 2565, 2902, 1789])
Epoch: 216, Training Loss: 0.78, Validation Loss: 0.88, accuracy = 0.61
######################## Epoch 217 - Batch 1 ########################
IDs in batch 1: tensor([1512,  937, 1682, 2041, 2575, 1518,  514, 1562, 2797,   46, 3974,  557,
        3656, 2305, 1485, 1299])
Epoch: 217, Training Loss: 0.77, Validation Loss: 0.88, accuracy = 0.62
######################## Epoch 218 - Batch 1 ########################
IDs in batch 1: tensor([3254, 3105,  397, 1320, 1850, 1406, 3829, 2290,  375, 3004, 1092,  718,
         786,  449,  113, 1250])
Epoch: 218, Training Loss: 0.76, Validation Loss: 0.88, accuracy = 0.62
######################## Epoch 219 - Batch 1 ########################
IDs in batch 1: tensor([2176,  714, 1012, 3399, 3769, 2272, 4119, 2315, 1264,  681, 1834, 1660,
        2839,  713, 2636, 3039])
Epoch: 219, Training Loss: 1.00, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 220 - Batch 1 ########################
IDs in batch 1: tensor([3291, 4012, 3727, 1062, 3873, 1495, 1212, 1224, 2337,   88, 1878, 3903,
        3494, 3208, 3344,  590])
Epoch: 220, Training Loss: 0.95, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 221 - Batch 1 ########################
IDs in batch 1: tensor([2579,  842, 1415, 4242, 1569, 2989, 1880, 1748, 3094,  505, 1437, 1812,
        1994, 1141,  181, 3344])
Epoch: 221, Training Loss: 0.81, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 222 - Batch 1 ########################
IDs in batch 1: tensor([ 104, 2905,  365,  883, 3217, 1111,  541, 3497,  747,  127, 3291, 3399,
        1419, 2317,  312, 1763])
Epoch: 222, Training Loss: 0.75, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 223 - Batch 1 ########################
IDs in batch 1: tensor([1861,  606, 3253, 3077, 2640,  766, 2668, 3872, 1344, 4245,   71,  345,
        3047,  496, 3896,  232])
Epoch: 223, Training Loss: 0.84, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 224 - Batch 1 ########################
IDs in batch 1: tensor([ 352, 3895, 1507,   47, 2044, 3102, 2098, 3246, 1904,  997, 2661,   98,
        4198,  164, 3371, 1439])
Epoch: 224, Training Loss: 0.75, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 225 - Batch 1 ########################
IDs in batch 1: tensor([2572,  173, 1778, 3778, 2220, 2905, 3853, 1802, 1051, 2177, 1373, 2995,
        3114, 1015, 2476, 2305])
Epoch: 225, Training Loss: 0.74, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 226 - Batch 1 ########################
IDs in batch 1: tensor([1569, 2462, 1176, 1686,  691, 2099, 2023, 1601, 3862, 4103,  835, 2614,
        1244, 2780, 3869, 4194])
Epoch: 226, Training Loss: 0.96, Validation Loss: 0.87, accuracy = 0.63
######################## Epoch 227 - Batch 1 ########################
IDs in batch 1: tensor([3484,  269, 3572, 3832, 3178, 1673, 1360, 1166, 3219, 3496, 2014,  954,
        1627,  497, 1093, 1680])
Epoch: 227, Training Loss: 0.99, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 228 - Batch 1 ########################
IDs in batch 1: tensor([1627, 1473,  928, 4181, 3667, 2892, 2332, 3139, 3002,  226, 2142, 2280,
        1442,  419, 4257, 4197])
Epoch: 228, Training Loss: 0.92, Validation Loss: 0.86, accuracy = 0.63
######################## Epoch 229 - Batch 1 ########################
IDs in batch 1: tensor([2468, 3781, 3530, 3733, 3888, 1899,  661, 2571, 3563, 1958, 4058, 1832,
        3688, 2885, 3312, 3264])
Epoch: 229, Training Loss: 1.26, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 230 - Batch 1 ########################
IDs in batch 1: tensor([3349, 4215,  956, 3950, 3437, 2039, 3414, 3751, 1644, 4089,  185, 1551,
         691, 3113, 3148,  512])
Epoch: 230, Training Loss: 0.88, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 231 - Batch 1 ########################
IDs in batch 1: tensor([3223, 3898,  413, 4030, 1032, 3430,   11, 4067, 3240, 2822, 2324, 3027,
        1887, 2104, 1777, 1680])
Epoch: 231, Training Loss: 0.92, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 232 - Batch 1 ########################
IDs in batch 1: tensor([3318, 2855, 2218, 1682, 2601, 2247, 1444, 1209, 3030, 2090,  305,  529,
        1220, 3087, 1008,  588])
Epoch: 232, Training Loss: 0.54, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 233 - Batch 1 ########################
IDs in batch 1: tensor([1189, 2213, 2167, 3787,  397, 1902, 2072, 1507,  689, 1331, 2671, 1219,
        4180, 2035, 1138,  873])
Epoch: 233, Training Loss: 0.87, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 234 - Batch 1 ########################
IDs in batch 1: tensor([2648, 1525,   42,  874, 2106, 2301,  607, 1734, 1286, 2691, 2419,  682,
        3914, 3072, 2429, 3154])
Epoch: 234, Training Loss: 0.66, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 235 - Batch 1 ########################
IDs in batch 1: tensor([2506, 3471, 2354, 4258, 1951, 3628, 2122, 2419, 2853,  667,  554,  635,
        1047, 2572,  960, 4121])
Epoch: 235, Training Loss: 0.72, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 236 - Batch 1 ########################
IDs in batch 1: tensor([2599,  394,   88, 2398, 1668, 1722,  712, 3969, 1024,  484, 2405, 2003,
         827, 3203, 1927, 4048])
Epoch: 236, Training Loss: 0.85, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 237 - Batch 1 ########################
IDs in batch 1: tensor([1648,  247,   37,  519, 1881, 1455, 1235, 3391, 2783, 4113, 3793, 3572,
        2780,  417, 3603, 2815])
Epoch: 237, Training Loss: 1.08, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 238 - Batch 1 ########################
IDs in batch 1: tensor([2663, 4181, 2990, 2541, 2070, 4038, 2836, 2011, 4156,  870,  717, 1685,
        4149, 2652, 4002, 2193])
Epoch: 238, Training Loss: 1.21, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 239 - Batch 1 ########################
IDs in batch 1: tensor([3082, 1601, 3953, 3151, 3635, 3394,  813, 2155, 2856, 1927,  763, 2712,
         492,  908, 2973, 3257])
Epoch: 239, Training Loss: 0.79, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 240 - Batch 1 ########################
IDs in batch 1: tensor([2559,  538, 1885, 3298, 1794, 1057, 4170, 1143, 3268, 3779, 2986, 3726,
        2540, 3318, 2087, 2551])
Epoch: 240, Training Loss: 0.94, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 241 - Batch 1 ########################
IDs in batch 1: tensor([ 661,  465,  820, 3940, 2915, 2225, 1320,  335, 2230, 2223, 1223, 2260,
        2700, 1686, 2907, 4072])
Epoch: 241, Training Loss: 0.69, Validation Loss: 0.86, accuracy = 0.61
######################## Epoch 242 - Batch 1 ########################
IDs in batch 1: tensor([1396, 1178, 3278, 1702, 1540,  340, 1318, 1196, 1676, 2107, 1967,  694,
        1870, 2505, 2800, 2763])
Epoch: 242, Training Loss: 0.62, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 243 - Batch 1 ########################
IDs in batch 1: tensor([1034,  814, 2835, 4205,  483, 4118, 3656, 3726,  565,  394, 4197, 3841,
        1319, 3098, 1573, 2144])
Epoch: 243, Training Loss: 1.06, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 244 - Batch 1 ########################
IDs in batch 1: tensor([ 626, 2463, 2856, 3385,  777, 3487,  577, 3446, 2727, 3370, 3948, 2350,
        1128, 2653, 3891, 1269])
Epoch: 244, Training Loss: 0.86, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 245 - Batch 1 ########################
IDs in batch 1: tensor([2360, 1850, 1285,  866, 3039, 2349, 2876,  823, 2329, 3689, 2938, 2652,
        2488, 1787, 2432, 2135])
Epoch: 245, Training Loss: 0.94, Validation Loss: 0.87, accuracy = 0.62
######################## Epoch 246 - Batch 1 ########################
IDs in batch 1: tensor([3010, 2584,  688,  520, 1014, 3830, 3981, 3400, 2344, 2296, 3217,  303,
        3494, 3027,   42, 1099])
Epoch: 246, Training Loss: 0.72, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 247 - Batch 1 ########################
IDs in batch 1: tensor([ 666, 1860, 4086, 4097,   42, 1426, 2393, 4220, 1546, 3695, 2306, 1518,
         601, 3474,  514, 4163])
Epoch: 247, Training Loss: 0.91, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 248 - Batch 1 ########################
IDs in batch 1: tensor([ 316, 2024, 2731, 3130, 2110, 2412, 2767, 1132, 1832, 2995,  572,  325,
        3286,  685,  438, 3987])
Epoch: 248, Training Loss: 0.98, Validation Loss: 0.87, accuracy = 0.61
######################## Epoch 249 - Batch 1 ########################
IDs in batch 1: tensor([3885,  327, 1080,  920,  919, 2781, 1213,  964, 1047, 3483, 1166,  767,
        2217, 3152, 2575, 3952])
Epoch: 249, Training Loss: 0.69, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 250 - Batch 1 ########################
IDs in batch 1: tensor([2993,  556,  182, 3545, 3345, 1121, 1525, 1231, 3664, 3988, 1994, 1559,
        1698, 1574, 3833,  805])
Epoch: 250, Training Loss: 0.93, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 251 - Batch 1 ########################
IDs in batch 1: tensor([3435, 2508, 1122, 2171, 4007, 3954,  283, 2465,  701, 3902, 2823,   37,
        1404, 3075, 1640, 3357])
Epoch: 251, Training Loss: 0.93, Validation Loss: 0.86, accuracy = 0.62
######################## Epoch 252 - Batch 1 ########################
IDs in batch 1: tensor([ 452,   28, 2238, 3388, 4226, 3780, 2134, 1736, 1454,  512, 2017, 4003,
        3444, 1850, 3810,  194])
Epoch: 252, Training Loss: 0.94, Validation Loss: 0.86, accuracy = 0.63
######################## Epoch 253 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 3473, 2752, 2664, 2074, 1967, 4003,  558,  584, 1900, 2368, 1219,
        3398, 1700, 2736, 4018])
Epoch: 253, Training Loss: 0.72, Validation Loss: 0.85, accuracy = 0.63
######################## Epoch 254 - Batch 1 ########################
IDs in batch 1: tensor([3988, 2447,  125, 2666, 2551, 1537, 2344,  612, 2133,  161,  870,  257,
        3130, 3537, 2758, 2690])
Epoch: 254, Training Loss: 0.73, Validation Loss: 0.85, accuracy = 0.63
######################## Epoch 255 - Batch 1 ########################
IDs in batch 1: tensor([1723, 1367, 3451, 3726, 3426,  305, 3406,  805, 2312,  170, 1439, 1920,
        1897, 3157,  287, 3304])
Epoch: 255, Training Loss: 0.81, Validation Loss: 0.85, accuracy = 0.63
######################## Epoch 256 - Batch 1 ########################
IDs in batch 1: tensor([3250, 3047, 2891,  343, 4257, 1204, 2931,  590, 2337, 4172,  261, 2260,
         825, 1051, 3003, 3845])
Epoch: 256, Training Loss: 0.63, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 257 - Batch 1 ########################
IDs in batch 1: tensor([1573, 2416,  828, 2670, 1183, 3498, 1846,  226, 4223, 2970,  137, 1440,
        2183, 1080, 3807, 1901])
Epoch: 257, Training Loss: 1.00, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 258 - Batch 1 ########################
IDs in batch 1: tensor([ 995, 2070, 3733,  718, 3707, 3577, 1590, 3874,   99, 3506,  825,  665,
        2088, 1787,  496, 1857])
Epoch: 258, Training Loss: 1.09, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 259 - Batch 1 ########################
IDs in batch 1: tensor([ 552,  512, 2482,  990,  515, 3199,  278, 3432, 1328,  819,  342, 2844,
        1794,  899, 1635,  842])
Epoch: 259, Training Loss: 0.78, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 260 - Batch 1 ########################
IDs in batch 1: tensor([  10, 1363, 1364, 2749, 1600, 1214,  120, 1991,  957, 2242, 2752,  812,
        3094, 4222, 3284, 4007])
Epoch: 260, Training Loss: 0.81, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 261 - Batch 1 ########################
IDs in batch 1: tensor([1380, 1251, 1753,  537, 3704, 4134,  717, 3490, 3323, 1974, 3151, 3264,
          88, 2697, 2761, 2148])
Epoch: 261, Training Loss: 0.75, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 262 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 3837, 2653, 1372,  120, 3669,  498, 2991,  591, 2131, 1732, 2031,
        1037, 1442, 2133, 2108])
Epoch: 262, Training Loss: 0.73, Validation Loss: 0.84, accuracy = 0.65
Save best Model_1 @ epoch 262 acc: 0.6506447831184057
######################## Epoch 263 - Batch 1 ########################
IDs in batch 1: tensor([ 228, 1168, 2558, 3530, 1570, 3591,  709,  201, 1247, 1559,  173, 3060,
        4174, 2876, 3778, 2599])
Epoch: 263, Training Loss: 0.88, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 264 - Batch 1 ########################
IDs in batch 1: tensor([ 361, 3778, 4174, 1960, 1201, 3652, 3221, 3885, 4118, 2884, 3568, 3818,
        1623, 4119,  342,   49])
Epoch: 264, Training Loss: 1.00, Validation Loss: 0.85, accuracy = 0.64
######################## Epoch 265 - Batch 1 ########################
IDs in batch 1: tensor([2185, 3044, 3627,  981, 1331,  367, 3549, 4037, 1614, 1386, 1954, 3312,
         964, 1916, 3466, 1255])
Epoch: 265, Training Loss: 0.87, Validation Loss: 0.85, accuracy = 0.63
######################## Epoch 266 - Batch 1 ########################
IDs in batch 1: tensor([1420, 1175,  857, 2344,  437,  257, 2305, 2924,  876,  896, 2874, 1125,
        2315, 2364, 2912, 3081])
Epoch: 266, Training Loss: 0.61, Validation Loss: 0.85, accuracy = 0.63
######################## Epoch 267 - Batch 1 ########################
IDs in batch 1: tensor([2519, 2414,  236,  266, 1453, 3424, 2655, 1956,  481,  796, 1272, 1484,
        1485, 3647,  155, 1951])
Epoch: 267, Training Loss: 0.73, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 268 - Batch 1 ########################
IDs in batch 1: tensor([ 610,  419, 3785, 1506, 4215, 2024, 1351, 3156,   99,  796, 3789,  170,
        2065,  148, 1038,  691])
Epoch: 268, Training Loss: 0.87, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 269 - Batch 1 ########################
IDs in batch 1: tensor([2969, 2468, 1861, 2965,  601,  533, 2131, 1410, 3695, 3836, 1569, 2081,
        3037, 1823,  883, 1097])
Epoch: 269, Training Loss: 0.79, Validation Loss: 0.84, accuracy = 0.64
######################## Epoch 270 - Batch 1 ########################
IDs in batch 1: tensor([2275, 1009, 3711, 1035, 2663, 2190, 1097, 2649, 1159,  434, 1756, 1226,
        1415, 1950, 3667,  926])
Epoch: 270, Training Loss: 0.80, Validation Loss: 0.84, accuracy = 0.65
######################## Epoch 271 - Batch 1 ########################
IDs in batch 1: tensor([ 976, 4097, 1726, 2945,  875, 3976,  658, 2815, 2845,  792, 1334, 1635,
        2388, 2327, 3614, 3718])
Epoch: 271, Training Loss: 0.91, Validation Loss: 0.83, accuracy = 0.66
Save best Model_1 @ epoch 271 acc: 0.6565064478311841
######################## Epoch 272 - Batch 1 ########################
IDs in batch 1: tensor([3049, 2204, 1798, 1120,  627,  533, 3607, 2856,  269, 1377,  852, 2279,
        1990, 4225,  425, 3700])
Epoch: 272, Training Loss: 0.87, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 273 - Batch 1 ########################
IDs in batch 1: tensor([2709, 3234,  492, 2192, 3308,   47, 2683, 2837, 1825, 1011, 3500,  555,
        4261, 1396, 2544,  964])
Epoch: 273, Training Loss: 0.71, Validation Loss: 0.83, accuracy = 0.66
Save best Model_1 @ epoch 273 acc: 0.6576787807737398
######################## Epoch 274 - Batch 1 ########################
IDs in batch 1: tensor([2805,  407, 3197,  186, 2563, 1016, 1023, 3131,  890, 2693, 1209, 2879,
        3278, 2350,  834, 3839])
Epoch: 274, Training Loss: 0.64, Validation Loss: 0.83, accuracy = 0.66
Save best Model_1 @ epoch 274 acc: 0.6623681125439624
######################## Epoch 275 - Batch 1 ########################
IDs in batch 1: tensor([ 851, 2755, 2828, 3197,  207,  282, 1171, 3866, 4051, 2234, 3030, 3920,
          41, 2370, 2954, 4024])
Epoch: 275, Training Loss: 0.90, Validation Loss: 0.83, accuracy = 0.66
Save best Model_1 @ epoch 275 acc: 0.6635404454865181
######################## Epoch 276 - Batch 1 ########################
IDs in batch 1: tensor([3038, 3876, 4122, 2244, 2254,  553,  552,  308,   68, 2064, 4119, 1007,
         284, 1318, 3376, 1747])
Epoch: 276, Training Loss: 0.83, Validation Loss: 0.83, accuracy = 0.66
######################## Epoch 277 - Batch 1 ########################
IDs in batch 1: tensor([4009, 2821,  514, 3815, 2044, 3932,  149, 2314,  821, 2265, 3388,  819,
        3836, 3418, 2799, 2870])
Epoch: 277, Training Loss: 0.79, Validation Loss: 0.83, accuracy = 0.66
Save best Model_1 @ epoch 277 acc: 0.6647127784290738
######################## Epoch 278 - Batch 1 ########################
IDs in batch 1: tensor([4099, 1870,  471, 2898, 2402, 1920, 3166, 1958, 3075, 1509, 2354, 1706,
        1139,  767, 3474,  919])
Epoch: 278, Training Loss: 0.62, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 279 - Batch 1 ########################
IDs in batch 1: tensor([3157,  325, 1108, 4264,  292, 1823,  752, 3534,  815, 4144,  324,   13,
         770,  749, 1795, 4238])
Epoch: 279, Training Loss: 0.78, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 280 - Batch 1 ########################
IDs in batch 1: tensor([2738, 3141, 2257,  980, 2960,   10, 2344, 2782, 2650,  982,  523, 3763,
        2819, 1591, 3894, 3187])
Epoch: 280, Training Loss: 0.60, Validation Loss: 0.83, accuracy = 0.65
######################## Epoch 281 - Batch 1 ########################
IDs in batch 1: tensor([2419, 2667, 2107, 3838, 1413, 4004, 2842, 4075,  373,  672, 2784, 2545,
         517, 2498,  498, 2013])
Epoch: 281, Training Loss: 0.68, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 282 - Batch 1 ########################
IDs in batch 1: tensor([3765,  884, 2499, 1682, 1384, 3203, 3630,   13, 3340, 1710, 3378, 4069,
         515, 1409, 3709, 4205])
Epoch: 282, Training Loss: 0.86, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 283 - Batch 1 ########################
IDs in batch 1: tensor([ 516, 3702,  869,   30, 2072,  729, 3896, 3650, 3036, 2078, 1116,  969,
        1679, 3961,  975, 1910])
Epoch: 283, Training Loss: 0.94, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 284 - Batch 1 ########################
IDs in batch 1: tensor([2091, 1122, 3092, 2999, 4149, 3640,  134, 3654, 3932, 1075, 1894,  808,
         832, 1976,  882, 1381])
Epoch: 284, Training Loss: 1.03, Validation Loss: 0.83, accuracy = 0.63
######################## Epoch 285 - Batch 1 ########################
IDs in batch 1: tensor([1131, 3132, 2724,  610, 2926, 3078, 3651, 3072, 2649, 1722, 4220,   30,
        2772, 3982, 3600, 2018])
Epoch: 285, Training Loss: 0.92, Validation Loss: 0.83, accuracy = 0.63
######################## Epoch 286 - Batch 1 ########################
IDs in batch 1: tensor([2040, 1986, 2746, 2296, 2536, 3407, 3808,  105, 3970, 2278, 1481, 1546,
        2106, 2008, 2009, 3084])
Epoch: 286, Training Loss: 0.73, Validation Loss: 0.83, accuracy = 0.63
######################## Epoch 287 - Batch 1 ########################
IDs in batch 1: tensor([3698,  395,  427, 3423,  138, 2223, 1233, 3782, 1685, 1693, 3706, 2559,
        2688, 3992, 2226, 3443])
Epoch: 287, Training Loss: 0.97, Validation Loss: 0.83, accuracy = 0.63
######################## Epoch 288 - Batch 1 ########################
IDs in batch 1: tensor([1727, 1193, 1363,   60, 4168, 3207, 3564,  725,  362, 2783, 4168, 1420,
        1413, 2806, 2706,  609])
Epoch: 288, Training Loss: 0.74, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 289 - Batch 1 ########################
IDs in batch 1: tensor([2793, 4095, 4181, 2448, 2051, 3971, 2452, 2977, 1375, 2304, 1423, 2791,
        2156, 1137, 3318, 1686])
Epoch: 289, Training Loss: 0.97, Validation Loss: 0.83, accuracy = 0.64
######################## Epoch 290 - Batch 1 ########################
IDs in batch 1: tensor([ 866, 3895, 3540, 3084, 1365,  736, 3458,  974, 1006, 1942, 3518, 1225,
        3052, 3447, 4128, 1336])
Epoch: 290, Training Loss: 0.78, Validation Loss: 0.82, accuracy = 0.64
######################## Epoch 291 - Batch 1 ########################
IDs in batch 1: tensor([ 812, 2355, 1231,  522,  490, 1299, 3276, 2492, 3940, 4230, 1337,  566,
        3276, 1588, 4218, 1663])
Epoch: 291, Training Loss: 0.74, Validation Loss: 0.82, accuracy = 0.64
######################## Epoch 292 - Batch 1 ########################
IDs in batch 1: tensor([1225, 3532, 2604, 2031, 1291, 3531, 2112,  456, 1993, 3564, 2204,  409,
         139, 1341,  844, 1234])
Epoch: 292, Training Loss: 0.70, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 293 - Batch 1 ########################
IDs in batch 1: tensor([1570, 1489,  827, 1661,  522, 3635,  496, 2467, 2719, 1765,  823, 2236,
        3409,  691, 1720, 3493])
Epoch: 293, Training Loss: 0.76, Validation Loss: 0.81, accuracy = 0.65
######################## Epoch 294 - Batch 1 ########################
IDs in batch 1: tensor([3238, 3133, 3934, 1034, 2870, 3451, 3806, 3676, 2372, 1761, 2934, 3427,
        3314, 2176,  513, 1821])
Epoch: 294, Training Loss: 0.84, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 295 - Batch 1 ########################
IDs in batch 1: tensor([3453, 1583,  259,  154, 3468, 3529, 4004, 1231, 2119, 1822, 2292, 2280,
        2605, 4038, 1747,  639])
Epoch: 295, Training Loss: 0.70, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 296 - Batch 1 ########################
IDs in batch 1: tensor([1395, 2632, 1397, 3244, 3120, 2120,  441,  489, 1010, 3410, 1511, 2182,
        4016, 3234,  653, 2049])
Epoch: 296, Training Loss: 0.73, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 297 - Batch 1 ########################
IDs in batch 1: tensor([ 555,  729, 4152, 3583, 1041, 4007,   98, 3072, 1235, 2116, 1626, 3802,
         992,  327,  750, 2295])
Epoch: 297, Training Loss: 0.76, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 298 - Batch 1 ########################
IDs in batch 1: tensor([1860, 4190,  781, 2087, 1710,  214, 2379, 2936, 2390,  595, 3342,  269,
        2344, 1045, 2680, 3193])
Epoch: 298, Training Loss: 0.61, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 299 - Batch 1 ########################
IDs in batch 1: tensor([3656,  892,  928, 1833, 1947, 4263, 2002, 3525,   96, 4121, 1153, 2264,
        1408, 3092,  930, 1546])
Epoch: 299, Training Loss: 0.74, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 300 - Batch 1 ########################
IDs in batch 1: tensor([2476, 2244, 3456, 2836, 1200, 3525, 4099, 2213, 1711,  993,  727, 3729,
        1517, 2254, 3006, 1977])
Epoch: 300, Training Loss: 0.81, Validation Loss: 0.81, accuracy = 0.67
Save best Model_1 @ epoch 300 acc: 0.6658851113716295
######################## Epoch 301 - Batch 1 ########################
IDs in batch 1: tensor([2575,  359,  769, 1294, 2407, 3874, 1732,  129, 3647, 3764, 2821, 3881,
         612, 3872, 2344,  866])
Epoch: 301, Training Loss: 0.86, Validation Loss: 0.81, accuracy = 0.67
Save best Model_1 @ epoch 301 acc: 0.6682297772567409
######################## Epoch 302 - Batch 1 ########################
IDs in batch 1: tensor([1684, 2115, 2059, 1556, 1041,  796,  684, 2542, 1060,  757, 3363, 2592,
         451, 2721, 1649,  250])
Epoch: 302, Training Loss: 0.70, Validation Loss: 0.81, accuracy = 0.67
Save best Model_1 @ epoch 302 acc: 0.6705744431418523
######################## Epoch 303 - Batch 1 ########################
IDs in batch 1: tensor([ 148, 1041,  839, 2797, 2629,  952, 2142, 1699, 1973, 3587,  666,  393,
        3087, 4027, 4114,  303])
Epoch: 303, Training Loss: 0.76, Validation Loss: 0.81, accuracy = 0.67
######################## Epoch 304 - Batch 1 ########################
IDs in batch 1: tensor([2583, 1025, 4086,  636,  275, 1087,  478, 1553, 3220, 2435, 2550, 1408,
         519, 1448, 3192,  718])
Epoch: 304, Training Loss: 0.72, Validation Loss: 0.81, accuracy = 0.67
######################## Epoch 305 - Batch 1 ########################
IDs in batch 1: tensor([ 505,  149, 3669, 1841, 3668,  193,  218,  255, 1712, 3718,  220, 2898,
        2646, 1101, 1602, 4255])
Epoch: 305, Training Loss: 0.79, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 306 - Batch 1 ########################
IDs in batch 1: tensor([1794,  632, 2148,   64,  729, 2798, 3516, 1434, 4266, 4229, 1094, 1356,
         751,    5, 3991, 2272])
Epoch: 306, Training Loss: 0.78, Validation Loss: 0.80, accuracy = 0.67
######################## Epoch 307 - Batch 1 ########################
IDs in batch 1: tensor([2615, 3379,  354, 2558,  555, 2066, 1648, 3282, 1367, 1619, 2364, 1971,
        1655, 3337,  997, 1809])
Epoch: 307, Training Loss: 0.60, Validation Loss: 0.80, accuracy = 0.68
Save best Model_1 @ epoch 307 acc: 0.6764361078546307
######################## Epoch 308 - Batch 1 ########################
IDs in batch 1: tensor([3058, 2480,  324, 4240, 1990, 4088, 3262, 2090, 3545, 3430,  642, 4095,
        2835, 2126, 2078,  795])
Epoch: 308, Training Loss: 0.83, Validation Loss: 0.80, accuracy = 0.68
Save best Model_1 @ epoch 308 acc: 0.6776084407971864
######################## Epoch 309 - Batch 1 ########################
IDs in batch 1: tensor([4036,  488, 2828, 3747, 3113, 2126, 2551, 4067, 2024, 3925, 4117, 2005,
        3200, 1273, 1365, 1332])
Epoch: 309, Training Loss: 0.90, Validation Loss: 0.80, accuracy = 0.68
######################## Epoch 310 - Batch 1 ########################
IDs in batch 1: tensor([2391, 2876,  219, 4146, 3538, 4229,   60, 1633,  512, 2091,  333,  960,
        4200, 1660,  666, 2934])
Epoch: 310, Training Loss: 0.79, Validation Loss: 0.80, accuracy = 0.68
######################## Epoch 311 - Batch 1 ########################
IDs in batch 1: tensor([4097,  787, 3636, 2663, 2589, 1438, 2638, 4199, 1991, 2179, 2277,  921,
         976,  482, 2141, 3664])
Epoch: 311, Training Loss: 0.83, Validation Loss: 0.80, accuracy = 0.68
Save best Model_1 @ epoch 311 acc: 0.6787807737397421
######################## Epoch 312 - Batch 1 ########################
IDs in batch 1: tensor([   7, 1574, 2295, 2073, 1706, 2387, 2459, 1681, 2770, 1887, 2833, 3379,
        1650, 4253,  397, 2379])
Epoch: 312, Training Loss: 0.58, Validation Loss: 0.80, accuracy = 0.67
######################## Epoch 313 - Batch 1 ########################
IDs in batch 1: tensor([2483, 3853, 3092, 4190,  992,  507, 3823, 1286, 3364, 2584, 2496, 2412,
        3351, 3714, 3284, 1799])
Epoch: 313, Training Loss: 0.87, Validation Loss: 0.80, accuracy = 0.67
######################## Epoch 314 - Batch 1 ########################
IDs in batch 1: tensor([  13,  182,  823, 3385, 3275, 1779, 1132, 2112, 4070, 1118, 2444, 3592,
        1039, 2819, 4116,  160])
Epoch: 314, Training Loss: 0.84, Validation Loss: 0.80, accuracy = 0.67
######################## Epoch 315 - Batch 1 ########################
IDs in batch 1: tensor([3147, 2839, 1278,  459, 1543, 2242, 2542,  609, 1405, 3245,  261, 3738,
        1590, 3802, 4149, 4176])
Epoch: 315, Training Loss: 0.81, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 316 - Batch 1 ########################
IDs in batch 1: tensor([2943, 3197,  519, 1292, 1118, 3190,  171, 2228,  355, 3798, 1779, 1617,
        3424, 2666, 2552, 2848])
Epoch: 316, Training Loss: 0.71, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 317 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 1222, 1140, 2498, 3548, 1086, 4056, 1568,  553,  554, 1993, 2390,
        3327, 3540, 1499,  424])
Epoch: 317, Training Loss: 0.60, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 318 - Batch 1 ########################
IDs in batch 1: tensor([ 303, 1185,  136, 3311,  811,  149, 3726,  953, 3974,  290, 2796, 2773,
        3604,  606, 1113,  794])
Epoch: 318, Training Loss: 0.83, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 319 - Batch 1 ########################
IDs in batch 1: tensor([ 795, 2989, 3573, 3351,  851, 1315, 3886,  987, 3696, 2689,  838, 2568,
        1032,   51, 1168, 3480])
Epoch: 319, Training Loss: 0.79, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 320 - Batch 1 ########################
IDs in batch 1: tensor([2841,  882, 3286,  588, 2614,  211,  393,  904,  613,  122,  471, 1925,
        4100, 1498,  818, 1474])
Epoch: 320, Training Loss: 0.64, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 321 - Batch 1 ########################
IDs in batch 1: tensor([ 346, 1418,  544, 1681, 3194,  964,   32, 2522, 3358,  926,  904, 2300,
         843, 2312, 2456, 1960])
Epoch: 321, Training Loss: 0.61, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 322 - Batch 1 ########################
IDs in batch 1: tensor([2228, 2362, 3056,  126, 3459, 3994, 1343, 3643, 1093,  199, 2013, 1116,
         232, 3779, 1418, 3787])
Epoch: 322, Training Loss: 0.83, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 323 - Batch 1 ########################
IDs in batch 1: tensor([ 787, 1425,  292, 4119, 2497, 2398, 4215, 3242, 3083, 3971, 1437, 1371,
          13,  609, 2262,  873])
Epoch: 323, Training Loss: 0.76, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 324 - Batch 1 ########################
IDs in batch 1: tensor([2339, 2892, 3252,  195, 4088, 3333, 4149, 3594, 1276, 4159,  752, 3084,
         334, 2393,  430, 1098])
Epoch: 324, Training Loss: 0.75, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 325 - Batch 1 ########################
IDs in batch 1: tensor([2414, 3908,  120,  487, 2067,  848, 3388, 2248, 2821, 1600,  275,  314,
        3226, 2379, 3672, 2034])
Epoch: 325, Training Loss: 0.71, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 326 - Batch 1 ########################
IDs in batch 1: tensor([2181,  373, 3882, 3404, 1626, 4236,  394,  717,  332, 1748, 2116, 1485,
        1310, 1826, 4254, 4204])
Epoch: 326, Training Loss: 0.81, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 327 - Batch 1 ########################
IDs in batch 1: tensor([ 807,  864, 1097, 3647,   20, 3718,  269, 2616,  518, 2968, 3727, 1457,
        3216, 3178, 1882,  992])
Epoch: 327, Training Loss: 0.66, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 328 - Batch 1 ########################
IDs in batch 1: tensor([1773, 3939, 2009, 2250, 1892, 1885, 2159,  672, 3111, 2258, 4125, 2712,
        2752, 3344,  822, 1862])
Epoch: 328, Training Loss: 0.79, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 329 - Batch 1 ########################
IDs in batch 1: tensor([1892,  393, 3539,  225, 2399, 4189, 2235, 1474,  481, 2836, 1218,  970,
        2115, 1594,  143, 3990])
Epoch: 329, Training Loss: 0.66, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 330 - Batch 1 ########################
IDs in batch 1: tensor([ 514, 2980, 2961, 3834, 1487, 2075, 3310,  841,   98, 3218, 3489,  851,
        1009, 1266,  172, 2059])
Epoch: 330, Training Loss: 0.69, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 331 - Batch 1 ########################
IDs in batch 1: tensor([ 234, 2708,  985, 2219, 1636, 3308, 1093, 2371, 1198, 4058, 1509, 2587,
        3970, 1636,    7,  180])
Epoch: 331, Training Loss: 0.82, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 332 - Batch 1 ########################
IDs in batch 1: tensor([3314, 2262, 1218,  281, 1066, 4267, 4030, 2743, 2523, 2358, 1281,  463,
         751, 4190, 4075,  535])
Epoch: 332, Training Loss: 0.77, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 333 - Batch 1 ########################
IDs in batch 1: tensor([3530, 3839,   25, 2592, 2783, 3856, 2609,  438, 3671,  892, 1953, 1778,
         342, 1571, 3895, 1404])
Epoch: 333, Training Loss: 0.82, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 334 - Batch 1 ########################
IDs in batch 1: tensor([  28, 1625, 2271, 3908, 3183, 2738, 4018,  532, 3993, 2088, 1490, 2355,
        4256,  152, 3739,   78])
Epoch: 334, Training Loss: 0.84, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 335 - Batch 1 ########################
IDs in batch 1: tensor([2964, 2360, 1672,  389, 2133, 2678, 3049,  354, 1866,  657, 4101, 2656,
         450, 1455,  247,  312])
Epoch: 335, Training Loss: 0.67, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 336 - Batch 1 ########################
IDs in batch 1: tensor([4180,   49, 2154, 3289, 4134, 1374, 3772,  771, 2248, 4018, 3673, 2874,
        2108, 2828,  858, 2715])
Epoch: 336, Training Loss: 0.84, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 337 - Batch 1 ########################
IDs in batch 1: tensor([1469, 2724,  771, 2879, 2582,  639, 3540,  804, 1722, 2198, 1761, 2141,
        2724, 2112, 1136, 2103])
Epoch: 337, Training Loss: 0.55, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 338 - Batch 1 ########################
IDs in batch 1: tensor([ 369, 3004, 4159,  803,  915, 3913, 1418, 3092, 2271, 1504, 3436, 2645,
        2426,   19, 1139,  727])
Epoch: 338, Training Loss: 0.66, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 339 - Batch 1 ########################
IDs in batch 1: tensor([1904,   82, 3692, 2887, 1419, 1404,  553, 1161, 1337, 3073,  659,  988,
        3345, 2856, 2925,  875])
Epoch: 339, Training Loss: 0.69, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 340 - Batch 1 ########################
IDs in batch 1: tensor([3355, 2393,  807, 1193,  412, 3927, 1001, 1710, 2483, 3401, 1655,  907,
        2013, 1182, 2213, 2871])
Epoch: 340, Training Loss: 0.66, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 341 - Batch 1 ########################
IDs in batch 1: tensor([1704, 1104, 2579, 1367, 1011, 3115,  104, 1793,  666, 2376, 1252, 3156,
        3374, 1925,  334, 3874])
Epoch: 341, Training Loss: 0.62, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 342 - Batch 1 ########################
IDs in batch 1: tensor([2754, 3142, 1881, 3497, 3917, 1039, 3429, 1779, 1916, 3099, 1335,  278,
        2832, 1198, 1793,   43])
Epoch: 342, Training Loss: 0.69, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 343 - Batch 1 ########################
IDs in batch 1: tensor([1377, 2452, 2149,  399, 2237, 1459, 2360,  977, 3366, 3795, 3439, 1239,
        1511, 4205,  308, 3600])
Epoch: 343, Training Loss: 0.63, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 344 - Batch 1 ########################
IDs in batch 1: tensor([4251,  660,  306, 1841, 3651, 1974, 3644, 3813, 3490, 3573, 2584, 1311,
          15, 1650,  261, 2095])
Epoch: 344, Training Loss: 0.93, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 345 - Batch 1 ########################
IDs in batch 1: tensor([1498,  435, 3865,  181, 1710, 4200, 3475,  954, 2758, 3021, 4087,  577,
        2119, 3529,  252, 3938])
Epoch: 345, Training Loss: 0.82, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 346 - Batch 1 ########################
IDs in batch 1: tensor([1682, 4113, 3429, 3850, 1219, 3507, 1480, 3355, 2788, 1585,  411,  980,
        1034,  661, 2209,  809])
Epoch: 346, Training Loss: 0.68, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 347 - Batch 1 ########################
IDs in batch 1: tensor([3303,  820, 3837, 1640,  954,  239, 3661,  234,  704,   77, 1869, 1128,
        1355,  876, 2606, 2691])
Epoch: 347, Training Loss: 0.76, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 348 - Batch 1 ########################
IDs in batch 1: tensor([3568,   38, 2098, 4139, 4141, 3587, 1925,  150, 1774, 3509,  809, 1718,
         962, 3284,  513, 3463])
Epoch: 348, Training Loss: 0.91, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 349 - Batch 1 ########################
IDs in batch 1: tensor([3744,  411,  226, 2437, 1043, 2375, 3812, 4223, 3161, 4003,  485, 1755,
        2643, 2131, 3021,  826])
Epoch: 349, Training Loss: 0.70, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 350 - Batch 1 ########################
IDs in batch 1: tensor([ 660,  250,   46, 2561, 3144, 3056, 3821, 1383, 2354, 1657, 2807, 1782,
         900, 4012, 1988, 3160])
Epoch: 350, Training Loss: 0.94, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 351 - Batch 1 ########################
IDs in batch 1: tensor([2337, 1887,  985, 3994, 4172, 2837, 3310, 2264, 4263, 4009,  474, 2764,
        1844, 4204,  411, 2789])
Epoch: 351, Training Loss: 0.83, Validation Loss: 0.78, accuracy = 0.65
######################## Epoch 352 - Batch 1 ########################
IDs in batch 1: tensor([4006, 3433, 3615,  796, 4181, 2390, 4027, 1619, 1702,   25, 3015, 2327,
        2313, 3366,  538, 2827])
Epoch: 352, Training Loss: 1.04, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 353 - Batch 1 ########################
IDs in batch 1: tensor([2976, 2767, 1668, 1684,   11,  221, 2306, 3601, 1707, 1094, 1057,  262,
        2390,  632, 3732, 2173])
Epoch: 353, Training Loss: 0.60, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 354 - Batch 1 ########################
IDs in batch 1: tensor([1125, 4027, 3099, 1066, 3415, 2137, 4214, 1825,  631, 3961,  712,  691,
        3907, 3483, 2292, 2109])
Epoch: 354, Training Loss: 0.86, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 355 - Batch 1 ########################
IDs in batch 1: tensor([2355, 2461,  577, 4075, 2373, 2544, 3581,  953, 2341,  408, 3804, 3467,
        3314, 3028, 2498, 2950])
Epoch: 355, Training Loss: 0.93, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 356 - Batch 1 ########################
IDs in batch 1: tensor([2452,  858, 1198, 1255, 3351, 1760, 3693, 1972, 1258,   28, 2822,  534,
        1504, 1641, 3447, 3689])
Epoch: 356, Training Loss: 0.70, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 357 - Batch 1 ########################
IDs in batch 1: tensor([2297, 1845, 1130,  475, 3505, 3391, 4157, 3321, 1014, 3236, 2912, 2730,
        3311, 3504, 1448, 3399])
Epoch: 357, Training Loss: 0.75, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 358 - Batch 1 ########################
IDs in batch 1: tensor([3075, 2148, 2011,  335, 2229, 1266, 3081, 3461,  489, 1473, 1306,  741,
        1870, 3430,   82, 2967])
Epoch: 358, Training Loss: 0.58, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 359 - Batch 1 ########################
IDs in batch 1: tensor([1286, 2378, 2606, 1014, 1247, 3806,  422,  975, 2727, 2890,  640,  981,
        2732, 2148, 1670, 2433])
Epoch: 359, Training Loss: 0.56, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 360 - Batch 1 ########################
IDs in batch 1: tensor([3888, 3135, 1976,  435, 2023, 3746, 3567, 1214, 3351, 1140, 1634, 2313,
         862, 2876, 1731, 3779])
Epoch: 360, Training Loss: 0.82, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 361 - Batch 1 ########################
IDs in batch 1: tensor([ 851, 3834,  682,  274, 1121, 1200, 1950, 1089, 1258,   61, 3497, 3069,
        2506, 2179, 1504, 3964])
Epoch: 361, Training Loss: 0.76, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 362 - Batch 1 ########################
IDs in batch 1: tensor([1947,   51, 1789, 1781, 2997,   70, 2328, 2458,  995, 2275,  360,  484,
        2859, 3390, 1196,  553])
Epoch: 362, Training Loss: 0.57, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 363 - Batch 1 ########################
IDs in batch 1: tensor([3971, 3148, 3523,  510, 1558,  203,  871, 2706, 3663,  396, 1569, 2329,
        4048,  826, 1773, 3083])
Epoch: 363, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 364 - Batch 1 ########################
IDs in batch 1: tensor([3366, 2281, 1583, 1656, 1408, 1222, 1080, 4258, 1868,  871,  874, 2731,
        3680,  444, 1794, 1472])
Epoch: 364, Training Loss: 0.87, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 365 - Batch 1 ########################
IDs in batch 1: tensor([2416, 4085, 2457, 4226, 2795, 2366, 2449, 1886, 3591, 2195, 1512, 2961,
        1057, 1678, 1452, 1054])
Epoch: 365, Training Loss: 0.68, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 366 - Batch 1 ########################
IDs in batch 1: tensor([1764,  674,  908, 3836, 1206, 2306, 3743,  505,  193,  534, 1346, 3289,
         106, 3246,  122, 1092])
Epoch: 366, Training Loss: 0.69, Validation Loss: 0.77, accuracy = 0.68
Save best Model_1 @ epoch 366 acc: 0.6822977725674091
######################## Epoch 367 - Batch 1 ########################
IDs in batch 1: tensor([2917, 3727, 3897, 1723, 2640, 1341, 2339,  733,  857,  733, 1779, 2005,
        3131,  211,  890, 2892])
Epoch: 367, Training Loss: 0.78, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 368 - Batch 1 ########################
IDs in batch 1: tensor([ 662,  482, 3513,  680, 1397, 1707, 1331,  408, 3250, 2711, 2629,  365,
        3872,  834, 4096, 3911])
Epoch: 368, Training Loss: 0.63, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 369 - Batch 1 ########################
IDs in batch 1: tensor([2805, 1455, 1270,  159, 1081, 1548, 3446,  384, 2859,  483,  295, 1347,
        4220,  960, 2551, 3898])
Epoch: 369, Training Loss: 0.76, Validation Loss: 0.76, accuracy = 0.68
Save best Model_1 @ epoch 369 acc: 0.6834701055099648
######################## Epoch 370 - Batch 1 ########################
IDs in batch 1: tensor([1224, 1333, 3509, 1363, 3593, 1901, 2794,  918, 1231, 2290, 3111,  915,
        1491, 3962,  869, 4158])
Epoch: 370, Training Loss: 0.83, Validation Loss: 0.76, accuracy = 0.69
Save best Model_1 @ epoch 370 acc: 0.6858147713950762
######################## Epoch 371 - Batch 1 ########################
IDs in batch 1: tensor([2999, 1009, 2024, 2385, 2537, 3057, 2581, 1377,  343, 2251, 3245,  104,
        1116, 4245, 2540, 3940])
Epoch: 371, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 372 - Batch 1 ########################
IDs in batch 1: tensor([ 121, 3235, 3135, 3497,  212, 1882,  732, 3352,  485, 3675, 4266,  190,
        2391, 2073,  862, 1010])
Epoch: 372, Training Loss: 0.72, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 373 - Batch 1 ########################
IDs in batch 1: tensor([1579, 2876, 4057, 2107, 1524, 1536, 2836,  492, 2567, 3135, 3845, 1073,
        1781, 1053, 1453,  478])
Epoch: 373, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 374 - Batch 1 ########################
IDs in batch 1: tensor([ 779, 2524, 2489, 1037, 3597,  557, 4228, 2863, 2991, 1039,  830, 1457,
        2945, 3073, 1821, 3500])
Epoch: 374, Training Loss: 0.78, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 375 - Batch 1 ########################
IDs in batch 1: tensor([2065, 1271, 3896, 3362, 1680, 2577, 1132, 3928, 1808, 3036,  827,  205,
        3051, 1921, 2451,  507])
Epoch: 375, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 376 - Batch 1 ########################
IDs in batch 1: tensor([1332, 3144, 4245,  795,  555, 1822,  510, 4222,  869,  314, 3159, 3882,
         529, 3436, 2856, 1156])
Epoch: 376, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 377 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 2002, 1976,  173, 2205,  943, 1052, 2341, 1405,  563,  771, 1512,
         389, 2035, 4199, 3873])
Epoch: 377, Training Loss: 0.80, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 378 - Batch 1 ########################
IDs in batch 1: tensor([1772, 1626, 2106, 4016, 1287, 2406,  595, 3183, 3763, 2320,  988, 1052,
        2206, 2914, 1373, 1627])
Epoch: 378, Training Loss: 0.61, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 379 - Batch 1 ########################
IDs in batch 1: tensor([2383, 2314, 3161,  653,   49, 1463, 3777, 1060,  203, 3481, 2104, 1116,
        1803,  218, 2552, 3493])
Epoch: 379, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 380 - Batch 1 ########################
IDs in batch 1: tensor([3570,  743,  151,   14,  826, 1509, 3238,  582, 3498, 2982, 1716, 3717,
        2224,  807, 2726,  699])
Epoch: 380, Training Loss: 0.75, Validation Loss: 0.79, accuracy = 0.67
######################## Epoch 381 - Batch 1 ########################
IDs in batch 1: tensor([ 855, 4031, 3327, 4022, 2051, 2663,  323, 3878,  953, 4114, 3031,  928,
        3841, 2464, 3433, 4067])
Epoch: 381, Training Loss: 0.88, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 382 - Batch 1 ########################
IDs in batch 1: tensor([1651, 1116, 2990, 2478,  234, 1336, 1963, 1675,  930, 1118, 1336, 1614,
        1968, 3214, 2963, 3590])
Epoch: 382, Training Loss: 0.61, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 383 - Batch 1 ########################
IDs in batch 1: tensor([ 430, 1451, 1765,  823, 1994, 3539,  788, 1495,  583, 1602, 3483,  823,
        2598,  777, 2802, 3998])
Epoch: 383, Training Loss: 0.57, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 384 - Batch 1 ########################
IDs in batch 1: tensor([2737,  584, 2312, 3772, 2040, 4058, 1500, 2575, 4170,  812,  484, 2124,
        3875, 4030, 1487, 1311])
Epoch: 384, Training Loss: 0.79, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 385 - Batch 1 ########################
IDs in batch 1: tensor([3554, 2241, 1640, 2890, 2526, 1180, 3199, 4265,  841,  513, 1037,  752,
         863, 1858, 3721, 1639])
Epoch: 385, Training Loss: 0.98, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 386 - Batch 1 ########################
IDs in batch 1: tensor([2457, 1326, 2052, 1809, 3757, 3407, 2144,  796, 4065, 2229, 2203, 1910,
        3756, 2856, 1625,  986])
Epoch: 386, Training Loss: 0.99, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 387 - Batch 1 ########################
IDs in batch 1: tensor([1104, 3233, 4139, 4117, 2260, 2562, 2022, 1994, 3507, 1643, 3479, 2400,
         229, 2410, 1291,  553])
Epoch: 387, Training Loss: 0.53, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 388 - Batch 1 ########################
IDs in batch 1: tensor([2921, 1089, 1630, 3478, 1421, 3126, 3136,  376,  105, 2845, 2315, 2954,
        3865,  550, 3114, 3542])
Epoch: 388, Training Loss: 0.58, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 389 - Batch 1 ########################
IDs in batch 1: tensor([2882, 4165, 2464, 1228, 2295,  259, 3326, 1291, 2449, 2837, 2669, 1880,
        3006, 3108, 2529, 3823])
Epoch: 389, Training Loss: 0.80, Validation Loss: 0.80, accuracy = 0.65
######################## Epoch 390 - Batch 1 ########################
IDs in batch 1: tensor([2696, 1787, 1371, 3489, 1234, 2868, 3100, 2932, 3593, 2153, 4261, 3609,
        2943, 2314,   21, 2196])
Epoch: 390, Training Loss: 0.79, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 391 - Batch 1 ########################
IDs in batch 1: tensor([1274,  704, 1421, 1490,  828, 3258,  196,  832, 1642, 1685, 1128, 3822,
        1672, 4166, 3421, 2855])
Epoch: 391, Training Loss: 0.61, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 392 - Batch 1 ########################
IDs in batch 1: tensor([ 518,  660, 3618, 3798,  792, 1595, 2618,  357, 3082, 2932,  485, 3715,
        2109, 2069,  365,  888])
Epoch: 392, Training Loss: 0.69, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 393 - Batch 1 ########################
IDs in batch 1: tensor([3152, 2841,  749,  892, 2362, 2091, 3157, 3022, 1765, 1672, 2109, 3049,
        2192,  915, 2393, 1220])
Epoch: 393, Training Loss: 0.47, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 394 - Batch 1 ########################
IDs in batch 1: tensor([1060, 3487,  875,   22, 1858, 3643, 3701, 1712, 1840, 2352, 2099,  645,
        1335, 3769, 3803, 3115])
Epoch: 394, Training Loss: 0.84, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 395 - Batch 1 ########################
IDs in batch 1: tensor([ 488,  781, 4016, 3836, 2980, 2601, 2648,   74, 1284, 1508, 2111, 2419,
        2721,  787, 3661,   62])
Epoch: 395, Training Loss: 0.67, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 396 - Batch 1 ########################
IDs in batch 1: tensor([ 687, 1809, 1967, 2692, 3942, 2183, 2894, 3278, 3660,  882,  467, 1251,
         826, 1385, 3826, 1680])
Epoch: 396, Training Loss: 0.92, Validation Loss: 0.78, accuracy = 0.65
######################## Epoch 397 - Batch 1 ########################
IDs in batch 1: tensor([1540, 2417, 2244, 3914, 2523, 4195, 2465,  723, 2362, 2144, 1208, 1236,
        1779, 2251, 1193, 2109])
Epoch: 397, Training Loss: 0.57, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 398 - Batch 1 ########################
IDs in batch 1: tensor([ 821, 4053,  895,   13, 1251,  962, 1335, 2833, 1485,  825,  117, 1858,
         243,  471, 2328, 1643])
Epoch: 398, Training Loss: 0.69, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 399 - Batch 1 ########################
IDs in batch 1: tensor([1120, 1832, 1232, 1351, 1718, 3049,  628,  965, 3370, 2126, 2457, 2470,
        3813, 2870,  524, 1904])
Epoch: 399, Training Loss: 0.53, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 400 - Batch 1 ########################
IDs in batch 1: tensor([3568, 2181,  448,  587, 1819, 3883,  378, 2938, 3871,  201, 3509, 4013,
        2763, 3732, 2518,  661])
Epoch: 400, Training Loss: 0.86, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 401 - Batch 1 ########################
IDs in batch 1: tensor([1773, 3052, 2606, 2190, 2080, 3387, 1480,  211, 1851, 1638,  672, 3816,
        3672, 4218,  155, 3872])
Epoch: 401, Training Loss: 0.91, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 402 - Batch 1 ########################
IDs in batch 1: tensor([1072, 1432,  727, 1625, 1017, 3265,  612, 3113,   46, 3349, 2123, 2546,
         388, 3318, 1540, 1526])
Epoch: 402, Training Loss: 0.60, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 403 - Batch 1 ########################
IDs in batch 1: tensor([3598,  218, 2509, 3538, 1548,  640,  260, 3934, 1670,  262,  665, 2599,
        4225, 4013, 2196,  194])
Epoch: 403, Training Loss: 1.01, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 404 - Batch 1 ########################
IDs in batch 1: tensor([1007, 1947, 3496, 2169, 4165,  612,  434, 3727,  265, 3938, 4095, 3913,
        1043,  886, 4010, 1918])
Epoch: 404, Training Loss: 1.09, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 405 - Batch 1 ########################
IDs in batch 1: tensor([4265, 3498, 1993, 3552, 3698, 1960,  776, 2683, 1655, 3056, 1414, 2710,
        1267, 3570,  341, 2973])
Epoch: 405, Training Loss: 0.92, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 406 - Batch 1 ########################
IDs in batch 1: tensor([4229, 1328, 1219, 1604,  494,  792, 1599,  978, 3593, 3326,  239, 3870,
        2196, 2631,  670, 3022])
Epoch: 406, Training Loss: 0.66, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 407 - Batch 1 ########################
IDs in batch 1: tensor([3251,  520, 2807, 1226, 2431, 2050, 3101, 1490, 1546, 3659, 1880, 3395,
        2244, 2044, 1493,  724])
Epoch: 407, Training Loss: 0.55, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 408 - Batch 1 ########################
IDs in batch 1: tensor([3632,  839, 1476,  225, 1901, 4184, 1778,  154, 2849, 3124,  128, 3444,
        3769, 1706, 1273,  436])
Epoch: 408, Training Loss: 0.81, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 409 - Batch 1 ########################
IDs in batch 1: tensor([ 968, 3047, 2065,  968, 2059, 2122, 2206, 3938, 2285, 2090, 1256, 3120,
        2249, 2226, 2192, 3443])
Epoch: 409, Training Loss: 0.97, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 410 - Batch 1 ########################
IDs in batch 1: tensor([1108, 1170, 3648, 4256, 2035, 3217,  255,  219, 3783,  991, 3377, 2849,
         454,  322, 1208, 1540])
Epoch: 410, Training Loss: 0.69, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 411 - Batch 1 ########################
IDs in batch 1: tensor([3527, 4175, 1751,  602, 1337, 1999, 3270,   96, 1858, 1380, 1224,   10,
         785, 2664, 2551, 2857])
Epoch: 411, Training Loss: 0.60, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 412 - Batch 1 ########################
IDs in batch 1: tensor([1935, 2141, 1863, 2124, 2943, 4050, 1051, 2915, 2151, 2963, 2213, 3996,
         645, 1809, 1974, 3673])
Epoch: 412, Training Loss: 0.88, Validation Loss: 0.78, accuracy = 0.66
######################## Epoch 413 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 1730,  340, 2853,  630, 4168, 3135, 1467, 4149, 1493, 3786, 1745,
        2667, 1467, 4094, 2276])
Epoch: 413, Training Loss: 0.59, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 414 - Batch 1 ########################
IDs in batch 1: tensor([3429,  595, 2144, 2680, 2452, 2770, 2914, 3554, 1840, 3710, 2346, 3945,
        1863,   57, 3417, 4105])
Epoch: 414, Training Loss: 0.90, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 415 - Batch 1 ########################
IDs in batch 1: tensor([ 625,  849, 1525, 1470, 3715, 1748,  881, 2314, 1026, 2943, 4235,  164,
        1442, 2902, 2500, 1108])
Epoch: 415, Training Loss: 0.69, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 416 - Batch 1 ########################
IDs in batch 1: tensor([ 455, 1041, 3453,  377, 1602, 1011,  252, 1073,  732, 1453, 2109, 1599,
        2467,  962, 4036, 1638])
Epoch: 416, Training Loss: 0.72, Validation Loss: 0.78, accuracy = 0.67
######################## Epoch 417 - Batch 1 ########################
IDs in batch 1: tensor([1942, 1601,  673, 2760, 4122,  756, 1794, 3772, 1927, 3692, 1638, 2217,
        2204, 1764,  923, 2993])
Epoch: 417, Training Loss: 0.74, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 418 - Batch 1 ########################
IDs in batch 1: tensor([1352,  623, 1417, 2859, 3207, 1862, 3545, 1162,  658, 3897, 2659,  354,
        2854,  871, 3358, 2729])
Epoch: 418, Training Loss: 0.78, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 419 - Batch 1 ########################
IDs in batch 1: tensor([2748, 1086, 4194, 2691, 1453,  605, 1231, 3960, 4199, 3964, 1120, 3314,
        2949, 4016, 3870, 2017])
Epoch: 419, Training Loss: 1.00, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 420 - Batch 1 ########################
IDs in batch 1: tensor([4159, 2425, 1185, 3913, 3919, 1055,  281, 3713, 3973,  334, 2279, 3388,
        3841, 2991, 1458,  674])
Epoch: 420, Training Loss: 0.84, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 421 - Batch 1 ########################
IDs in batch 1: tensor([3786, 1481, 3360, 1017, 3248, 3119,  985, 1063, 2827, 1222, 2358, 1101,
         667,  221, 2035, 1067])
Epoch: 421, Training Loss: 0.56, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 422 - Batch 1 ########################
IDs in batch 1: tensor([1569, 1634,   77,  946, 2204,  276, 2545, 2627, 2432,  402, 1042, 2990,
         134, 2446,  101, 3426])
Epoch: 422, Training Loss: 0.71, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 423 - Batch 1 ########################
IDs in batch 1: tensor([ 278, 3044,  642,  369, 4227, 1081,  261, 1140, 4056, 3088, 4179,  510,
        2656, 1292, 1234,  623])
Epoch: 423, Training Loss: 0.79, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 424 - Batch 1 ########################
IDs in batch 1: tensor([1613, 1506,  851, 1216, 3818, 3872,  148,  880, 3729, 2661, 1332, 3135,
        2324, 2777, 2890,   39])
Epoch: 424, Training Loss: 0.64, Validation Loss: 0.77, accuracy = 0.65
######################## Epoch 425 - Batch 1 ########################
IDs in batch 1: tensor([1357, 3465, 1098,  986, 2645,   46, 2660, 3185, 1325, 3317, 1910, 3886,
        1845,  202, 1823,  510])
Epoch: 425, Training Loss: 0.49, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 426 - Batch 1 ########################
IDs in batch 1: tensor([1289, 1436, 3255, 1377,  640,  934, 2278, 4128, 1630, 2977, 1316, 3435,
        1546, 2899,  238, 2587])
Epoch: 426, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 427 - Batch 1 ########################
IDs in batch 1: tensor([3146, 2410, 2046,  741, 1226, 3470, 3969,  407,  658, 1340,   74,  838,
        4113, 2810,  492,  371])
Epoch: 427, Training Loss: 0.73, Validation Loss: 0.76, accuracy = 0.65
######################## Epoch 428 - Batch 1 ########################
IDs in batch 1: tensor([1604,  937,  988, 2794, 1232,  171, 1053, 1284, 2443,  219, 3603, 1234,
          46, 1311, 2522, 4156])
Epoch: 428, Training Loss: 0.71, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 429 - Batch 1 ########################
IDs in batch 1: tensor([1139, 4196, 2693, 1961, 1081, 4099, 4127,  642, 1618, 4103,  471, 3865,
         610,  826,  439, 1663])
Epoch: 429, Training Loss: 0.80, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 430 - Batch 1 ########################
IDs in batch 1: tensor([3547, 3345, 2564, 3772,  672, 2957, 2425, 2822, 1275, 4154, 3091,  883,
         131, 2973, 3504, 2051])
Epoch: 430, Training Loss: 0.66, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 431 - Batch 1 ########################
IDs in batch 1: tensor([1434,  402,  494, 1247, 2817,  487, 2936, 1604, 4246, 1409, 3971, 4038,
        1884, 2489,  465, 1537])
Epoch: 431, Training Loss: 0.63, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 432 - Batch 1 ########################
IDs in batch 1: tensor([2743, 1016, 3428, 1319,  787, 3699, 2357,  180,  234, 2354, 2104, 3505,
         396,   37,  823, 2376])
Epoch: 432, Training Loss: 0.62, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 433 - Batch 1 ########################
IDs in batch 1: tensor([ 968, 3398, 2137, 2738, 3150, 3616, 2627, 1345, 3962, 3148,  510, 2323,
        1352, 2155, 2265, 1183])
Epoch: 433, Training Loss: 0.66, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 434 - Batch 1 ########################
IDs in batch 1: tensor([2245, 4180, 3498, 3418,   96, 1069, 1260,  642,  574, 3933, 2189,   56,
        1051, 3161, 1032, 1060])
Epoch: 434, Training Loss: 0.74, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 435 - Batch 1 ########################
IDs in batch 1: tensor([1849, 2466, 2517, 3439, 3573,  399, 1383,  928, 1007, 2045,  691, 1996,
        1116, 3808, 2858, 3032])
Epoch: 435, Training Loss: 0.71, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 436 - Batch 1 ########################
IDs in batch 1: tensor([3259,  244,  779,  577, 3425, 1600, 3793, 1451,  441,  341, 1497, 3028,
        1868,  554, 4224, 3371])
Epoch: 436, Training Loss: 0.61, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 437 - Batch 1 ########################
IDs in batch 1: tensor([  84,  937, 2681, 2874, 2440,  379,   77, 1808, 1284, 2179, 1365, 2416,
          99, 3787, 3143, 4069])
Epoch: 437, Training Loss: 0.52, Validation Loss: 0.75, accuracy = 0.66
######################## Epoch 438 - Batch 1 ########################
IDs in batch 1: tensor([3015, 3699, 4013, 3994, 1512,  943, 3192, 4140, 1279, 2674, 3680,  320,
        3671,  445,  892,  154])
Epoch: 438, Training Loss: 0.90, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 439 - Batch 1 ########################
IDs in batch 1: tensor([ 904, 2429, 2343, 3427, 3109, 3496,  687, 2540, 1119, 3837, 3627, 2406,
        3290, 3717, 2806, 1228])
Epoch: 439, Training Loss: 0.79, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 440 - Batch 1 ########################
IDs in batch 1: tensor([2399,  258,  893, 3777, 2700, 4087, 4265, 1730, 3765, 1911, 3659, 2937,
         959, 2815, 1900,   20])
Epoch: 440, Training Loss: 0.81, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 441 - Batch 1 ########################
IDs in batch 1: tensor([1123, 2488,  524, 3114,  646, 2086,  201, 3289, 1454,  155, 3494, 3988,
        1706, 1121, 2558, 2405])
Epoch: 441, Training Loss: 0.45, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 442 - Batch 1 ########################
IDs in batch 1: tensor([1163, 1646,   41,  977, 4076, 2207, 1933, 2643, 3785, 3423, 2225, 1086,
         990,  818, 1369,  930])
Epoch: 442, Training Loss: 0.60, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 443 - Batch 1 ########################
IDs in batch 1: tensor([3448,   56,  348, 4198, 3092, 1817, 4086,  380, 1852, 4025, 1183,  777,
        1975,  442, 2141, 3398])
Epoch: 443, Training Loss: 0.92, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 444 - Batch 1 ########################
IDs in batch 1: tensor([1044,  676,   68, 3443, 1316, 2358,  628, 2112, 3187, 1628, 3410, 3732,
         508, 3473, 4265, 3658])
Epoch: 444, Training Loss: 0.69, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 445 - Batch 1 ########################
IDs in batch 1: tensor([2398, 3572, 1281, 4263,  256, 1139, 1110, 2609, 2226, 3879,  103, 1309,
        2125, 3480,  322, 1020])
Epoch: 445, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 446 - Batch 1 ########################
IDs in batch 1: tensor([2258, 3956, 3006,  808,  623, 2553, 3869, 3366, 3853, 1292,  573,   25,
        2355, 2110, 3934, 2938])
Epoch: 446, Training Loss: 0.84, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 447 - Batch 1 ########################
IDs in batch 1: tensor([3833,  225, 2123, 3314, 1004,  463, 3290,  326,  463, 2610, 1812,   57,
         873,  568,  704, 1489])
Epoch: 447, Training Loss: 0.77, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 448 - Batch 1 ########################
IDs in batch 1: tensor([1469, 1765, 2565,  132,  578,  536, 3329, 2212, 3409, 2154, 3553,  518,
        3638, 1636, 1110, 2656])
Epoch: 448, Training Loss: 0.57, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 449 - Batch 1 ########################
IDs in batch 1: tensor([  93,  173, 2732, 1782, 2369,  173,  455, 3781, 2993, 2796, 4075,  582,
         813, 2449, 3732, 4025])
Epoch: 449, Training Loss: 0.63, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 450 - Batch 1 ########################
IDs in batch 1: tensor([2112,  362, 3434, 3390,  535, 2537, 2921, 4096, 2787,  904, 4265, 2857,
        1128, 1197, 4205, 3426])
Epoch: 450, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 451 - Batch 1 ########################
IDs in batch 1: tensor([ 871, 3404, 2545, 3813, 1356, 2407, 1263, 3839, 2256,  412, 2324,  645,
        3667, 1171, 3069, 2234])
Epoch: 451, Training Loss: 0.61, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 452 - Batch 1 ########################
IDs in batch 1: tensor([1134, 2616, 2155,  417, 2353, 4017, 4044,  995, 4095, 1025, 1647, 1830,
         704,  852, 2819, 3974])
Epoch: 452, Training Loss: 0.76, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 453 - Batch 1 ########################
IDs in batch 1: tensor([1711, 1174, 2059,   72, 2245,  432, 3277, 1364, 2895, 2155, 3423, 2838,
        2113, 4051, 1459,   11])
Epoch: 453, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 454 - Batch 1 ########################
IDs in batch 1: tensor([1646,  350, 1311, 2857, 1967, 2761, 1101, 1444, 3336, 2552,  837, 1752,
        3251,  494, 3701,  477])
Epoch: 454, Training Loss: 0.60, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 455 - Batch 1 ########################
IDs in batch 1: tensor([3709, 1846, 3577, 3057, 1370, 1456, 2067,  221, 3272, 2355, 4097, 1056,
        4103, 3438, 2892, 2003])
Epoch: 455, Training Loss: 1.02, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 456 - Batch 1 ########################
IDs in batch 1: tensor([4143,   74,  790,  612, 1235, 2238,  340,  954, 1954, 3409, 1730, 2597,
        4080,  837, 2884, 1119])
Epoch: 456, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 457 - Batch 1 ########################
IDs in batch 1: tensor([2656, 2724,  685, 2583,  830, 3425, 3381,  610, 2849, 2689,  338, 3862,
         833, 3597, 2114,  191])
Epoch: 457, Training Loss: 0.61, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 458 - Batch 1 ########################
IDs in batch 1: tensor([2595, 3753, 3715,  172, 2477, 4014, 2764,  442, 3661, 1459, 1399, 1583,
        3567, 3688, 3094, 1540])
Epoch: 458, Training Loss: 0.83, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 459 - Batch 1 ########################
IDs in batch 1: tensor([2953,  947, 2320, 2548, 2871,  478,  601,  873, 2314, 2210, 1952, 1290,
         363, 4044, 1499, 1320])
Epoch: 459, Training Loss: 0.64, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 460 - Batch 1 ########################
IDs in batch 1: tensor([1981, 3962, 3254, 2390, 1032, 1832, 4013,  482,  384, 2040, 3272, 2358,
        1499, 1914, 4003,  767])
Epoch: 460, Training Loss: 0.68, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 461 - Batch 1 ########################
IDs in batch 1: tensor([2316, 1354, 1849, 3746, 4163, 3304, 1346, 2995, 2091, 1421, 3544,  983,
        3608, 2284, 2112, 3920])
Epoch: 461, Training Loss: 0.83, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 462 - Batch 1 ########################
IDs in batch 1: tensor([2885, 3313, 2668, 1315, 1913, 3000, 2886, 3837, 4264, 3277, 1845,   97,
        3527,  492, 1722,  974])
Epoch: 462, Training Loss: 0.79, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 463 - Batch 1 ########################
IDs in batch 1: tensor([ 976,  884, 2956, 1945, 2459, 3754, 4120, 2983,  826,  552, 1481, 2462,
        1558, 1367, 1437, 2465])
Epoch: 463, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 464 - Batch 1 ########################
IDs in batch 1: tensor([4080, 1673, 3885, 3637,  529, 1918,  818, 1562, 3204, 2053, 3731, 3772,
        3977, 4016, 3841, 2408])
Epoch: 464, Training Loss: 0.95, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 465 - Batch 1 ########################
IDs in batch 1: tensor([1044, 1116, 4218, 2695, 3651,  858,  680, 1640, 3481, 1057, 3240, 2457,
        3551, 1859, 2341, 1075])
Epoch: 465, Training Loss: 0.66, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 466 - Batch 1 ########################
IDs in batch 1: tensor([ 224, 3643, 2998, 1808, 2827, 1224, 3616, 2402,  609, 3102, 3557, 2907,
        3783,  956, 2401, 1636])
Epoch: 466, Training Loss: 0.83, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 467 - Batch 1 ########################
IDs in batch 1: tensor([2315, 1010, 2314, 1927, 1247, 3156, 2970, 1428, 2614, 1812, 1393, 1476,
        2072, 3257,  895, 3525])
Epoch: 467, Training Loss: 0.58, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 468 - Batch 1 ########################
IDs in batch 1: tensor([1241, 1216, 1580, 2857,  507, 1311, 2701, 2449,  452, 2514, 1356, 1833,
        3583, 4180, 3480, 1336])
Epoch: 468, Training Loss: 0.54, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 469 - Batch 1 ########################
IDs in batch 1: tensor([2609,   72, 3930,  223, 3742, 1395,  879,  615, 3908, 2416, 3151, 2038,
        2298, 1967,  323, 1897])
Epoch: 469, Training Loss: 0.55, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 470 - Batch 1 ########################
IDs in batch 1: tensor([2697, 2692, 2954, 3677, 4194, 4187, 1062, 3823, 2104, 2103, 3284, 3345,
        3336, 3592, 2915, 3200])
Epoch: 470, Training Loss: 1.02, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 471 - Batch 1 ########################
IDs in batch 1: tensor([1179, 3441, 3535,  496, 3130, 4018, 1212, 2817, 1551,  944, 2341, 1548,
        1496, 2872, 1925, 3135])
Epoch: 471, Training Loss: 0.63, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 472 - Batch 1 ########################
IDs in batch 1: tensor([3014, 3883,  201, 1176, 3006,   19, 2644, 3313, 2151,   34, 2615,  171,
        3973, 2791, 3648,  660])
Epoch: 472, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 473 - Batch 1 ########################
IDs in batch 1: tensor([ 936, 2993,  194, 3235, 1073, 1204, 2410, 2226,  526, 2838, 1041, 4249,
        3487,  894, 1285, 4036])
Epoch: 473, Training Loss: 0.78, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 474 - Batch 1 ########################
IDs in batch 1: tensor([1084, 3312,  524, 1511, 2646, 1982, 1675, 3439, 3221,   14, 2672, 1730,
        1224, 3328, 2103, 1968])
Epoch: 474, Training Loss: 0.52, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 475 - Batch 1 ########################
IDs in batch 1: tensor([2346, 1762,  232,  534, 2867, 4048, 4256, 3769,  743,  820, 1880,   24,
          96,  257, 3780, 4008])
Epoch: 475, Training Loss: 0.86, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 476 - Batch 1 ########################
IDs in batch 1: tensor([4176, 2406, 2663,  869, 2287, 3706, 4264, 3692, 2202,  180, 1330, 1833,
         434, 2120, 3453,  892])
Epoch: 476, Training Loss: 1.00, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 477 - Batch 1 ########################
IDs in batch 1: tensor([3425, 3552, 1117,   43, 2636, 1059, 2415, 3489, 2598, 2895, 2995,  681,
         367,  488,  872, 1872])
Epoch: 477, Training Loss: 0.76, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 478 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2447,  849, 1092, 2851, 3025, 1655, 4061, 4033, 2367, 1782, 3640,
        3344, 2420, 2970, 2663])
Epoch: 478, Training Loss: 0.65, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 479 - Batch 1 ########################
IDs in batch 1: tensor([2711,   59,  327, 3218, 3609,  849, 1330,  147, 1649, 1501, 3028, 3029,
        2726, 1092, 3523, 3367])
Epoch: 479, Training Loss: 0.52, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 480 - Batch 1 ########################
IDs in batch 1: tensor([ 832, 1778, 2316, 2479, 2297, 2159,  513,  622, 3298, 2664, 1077, 1933,
        2423, 1233,  996, 1670])
Epoch: 480, Training Loss: 0.65, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 481 - Batch 1 ########################
IDs in batch 1: tensor([3235,  909,  122, 2688,  881, 3485, 1553,  767,  359, 1722, 1979, 2754,
        1578, 1087,  394,  763])
Epoch: 481, Training Loss: 0.64, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 482 - Batch 1 ########################
IDs in batch 1: tensor([  97, 3242, 1747, 1726, 3524, 1765, 3719,  788, 3615, 3954, 1595,  679,
        1852, 1337,  547, 4125])
Epoch: 482, Training Loss: 0.79, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 483 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 2690, 1489, 1297, 2931, 2477,  463, 2081,  803,  982, 3453, 3024,
        1716,  816, 1030,  980])
Epoch: 483, Training Loss: 0.62, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 484 - Batch 1 ########################
IDs in batch 1: tensor([1760, 1383, 1613,  287, 3793, 2844, 1773,  622, 2506,  846, 1530, 2177,
        1450, 2204, 3183, 2120])
Epoch: 484, Training Loss: 0.53, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 485 - Batch 1 ########################
IDs in batch 1: tensor([3222,  971, 3304, 3587,  131, 3963, 4267, 3650,  657,  455, 2947,  432,
        1334, 4133, 2075,  964])
Epoch: 485, Training Loss: 0.86, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 486 - Batch 1 ########################
IDs in batch 1: tensor([3456,  400, 3569,  900, 3526,  872, 2765, 3836,  237, 3710,  194, 1197,
        2091, 2315, 2857, 2028])
Epoch: 486, Training Loss: 0.78, Validation Loss: 0.77, accuracy = 0.65
######################## Epoch 487 - Batch 1 ########################
IDs in batch 1: tensor([2519, 2562, 3727, 3381, 3340, 2731,  287, 2466, 1158,  280,  828, 3984,
        3474, 4069, 1390, 4170])
Epoch: 487, Training Loss: 0.74, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 488 - Batch 1 ########################
IDs in batch 1: tensor([2064,  280, 2109, 1720,  117, 2618, 3397, 2432, 2205,  582, 2425, 3727,
        4062, 3192, 3843, 1126])
Epoch: 488, Training Loss: 0.72, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 489 - Batch 1 ########################
IDs in batch 1: tensor([ 503, 2014,  190, 1410, 4251, 2431, 1438, 2249, 3627,  130, 1375, 1087,
        3039,  755,  991, 3547])
Epoch: 489, Training Loss: 0.77, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 490 - Batch 1 ########################
IDs in batch 1: tensor([2326, 3683,  635,   24,  863, 3381, 3015,   74,  944, 2498, 2368,  777,
        1198, 3196,  419,   82])
Epoch: 490, Training Loss: 0.57, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 491 - Batch 1 ########################
IDs in batch 1: tensor([3501, 1911, 3368, 2192, 1672,   18,  478, 1113, 3309, 3484,  991, 1774,
         127,  426, 2122, 3501])
Epoch: 491, Training Loss: 0.47, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 492 - Batch 1 ########################
IDs in batch 1: tensor([3407,  380, 1037,  829, 1766, 1125, 2562, 1482, 1673, 1372, 1530, 1110,
         471, 1948,  456,  148])
Epoch: 492, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 493 - Batch 1 ########################
IDs in batch 1: tensor([3352, 1551, 1425,  522, 1933, 1432, 2919, 3337, 2882, 1025,  346,  128,
        3983,  644, 4168, 1250])
Epoch: 493, Training Loss: 0.61, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 494 - Batch 1 ########################
IDs in batch 1: tensor([3004, 1962, 3908, 2120, 2035, 2522, 4174, 3112,  494, 2049, 4212, 2365,
        1426, 3451,  753, 3142])
Epoch: 494, Training Loss: 0.63, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 495 - Batch 1 ########################
IDs in batch 1: tensor([3400,  723, 3166, 3738, 1506, 2726, 1745, 4175, 1487, 2959, 1546, 1961,
        4008, 3472, 4133, 2059])
Epoch: 495, Training Loss: 0.66, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 496 - Batch 1 ########################
IDs in batch 1: tensor([ 630, 3731, 2614,  743, 2069, 2706, 3492, 1038, 3847, 2604, 3470, 1355,
        2880, 1639, 2582, 2517])
Epoch: 496, Training Loss: 0.75, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 497 - Batch 1 ########################
IDs in batch 1: tensor([2115, 3795,  965, 3564,  372,   95, 2826, 1835, 3236, 3763,  781,  344,
        3983, 4134,  776, 3426])
Epoch: 497, Training Loss: 0.69, Validation Loss: 0.74, accuracy = 0.69
Save best Model_1 @ epoch 497 acc: 0.6869871043376319
######################## Epoch 498 - Batch 1 ########################
IDs in batch 1: tensor([2606, 2708, 3053, 2347, 1798, 3426, 1044, 3027, 1485, 3235, 1489, 2678,
        3671, 3028, 2951, 4135])
Epoch: 498, Training Loss: 0.83, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 499 - Batch 1 ########################
IDs in batch 1: tensor([3135, 1649, 3447, 1132, 1575, 2550,  110, 1324, 2924,  378, 3588, 3180,
        2891, 2885, 1947,  556])
Epoch: 499, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.69
Save best Model_1 @ epoch 499 acc: 0.690504103165299
######################## Epoch 500 - Batch 1 ########################
IDs in batch 1: tensor([ 866, 2366, 2697, 3039, 2431, 3152, 3074, 2018, 2170, 1345, 3071, 3529,
        3483,  615, 2461, 2780])
Epoch: 500, Training Loss: 0.95, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 501 - Batch 1 ########################
IDs in batch 1: tensor([  78, 3407, 1450, 2498, 2546,  141, 1275, 2446, 2688, 3888, 2749, 1675,
        2799, 2631, 3661,  981])
Epoch: 501, Training Loss: 0.52, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 502 - Batch 1 ########################
IDs in batch 1: tensor([3652, 1625, 1600, 1289, 2251, 2182, 3913, 4222, 4238, 3082,  739, 3055,
        2643, 2309, 1083, 4139])
Epoch: 502, Training Loss: 0.92, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 503 - Batch 1 ########################
IDs in batch 1: tensor([1673, 3934, 1885, 3659, 1488, 3448,  126, 3228, 1119,  794, 1728, 2316,
         456, 4080, 2578, 4007])
Epoch: 503, Training Loss: 0.66, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 504 - Batch 1 ########################
IDs in batch 1: tensor([1937,  165,  180,  963, 3308, 2441, 1676, 3376,  593, 2991,  673,  823,
        1072, 1967,  388, 1096])
Epoch: 504, Training Loss: 0.66, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 505 - Batch 1 ########################
IDs in batch 1: tensor([3968, 3200, 3444,  211, 3226, 2159,  497, 2046, 2219, 2261, 3257, 2504,
         151,  110, 3448, 3934])
Epoch: 505, Training Loss: 0.61, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 506 - Batch 1 ########################
IDs in batch 1: tensor([3925, 3540,  251, 4027, 2406,  236,  324, 4127, 4246, 1472, 2683,  688,
        1977, 3244, 2137,  437])
Epoch: 506, Training Loss: 0.54, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 507 - Batch 1 ########################
IDs in batch 1: tensor([1251, 3564, 4128, 3962, 2331, 3388,  184, 3760, 3168,  862, 2592,  794,
        3710, 2571, 1704,  630])
Epoch: 507, Training Loss: 0.66, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 508 - Batch 1 ########################
IDs in batch 1: tensor([3781, 2429, 1778, 3779, 3696, 2687, 2199, 2241, 2807, 2241, 2853, 1354,
        2219, 3984, 3479, 2027])
Epoch: 508, Training Loss: 0.68, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 509 - Batch 1 ########################
IDs in batch 1: tensor([ 484, 2711,  302, 1710, 2703,  894, 3988, 2228, 1832,  681,  967, 1369,
        3947, 1853, 1817, 3091])
Epoch: 509, Training Loss: 0.83, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 510 - Batch 1 ########################
IDs in batch 1: tensor([3597, 1504, 3317, 4218, 3254, 4133, 2402, 3016, 3483, 1132, 2126, 1740,
        2548, 3930,  774,  352])
Epoch: 510, Training Loss: 0.59, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 511 - Batch 1 ########################
IDs in batch 1: tensor([3395, 4217, 3494, 1834, 3177,  632,  350, 3862, 1409, 3618, 1066, 3753,
        2746, 3627, 2730, 2796])
Epoch: 511, Training Loss: 0.80, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 512 - Batch 1 ########################
IDs in batch 1: tensor([2387, 3826, 3098, 4126, 2841,  512, 2584, 1524, 1585, 1822, 2367, 1510,
        1640, 3261, 2983, 1927])
Epoch: 512, Training Loss: 0.49, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 513 - Batch 1 ########################
IDs in batch 1: tensor([1595, 2142, 3179, 2966, 4163,  615, 2568,  563, 1004, 3838,  871, 3832,
        3827, 3498, 3858, 3053])
Epoch: 513, Training Loss: 0.69, Validation Loss: 0.74, accuracy = 0.69
Save best Model_1 @ epoch 513 acc: 0.6928487690504103
######################## Epoch 514 - Batch 1 ########################
IDs in batch 1: tensor([2551, 1160, 3977, 2537,  183,  978, 2926, 3907, 3071, 2847, 1673, 3697,
        2204, 3935,  128, 2388])
Epoch: 514, Training Loss: 0.58, Validation Loss: 0.74, accuracy = 0.70
Save best Model_1 @ epoch 514 acc: 0.6963657678780774
######################## Epoch 515 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 3397, 4266, 3047,  921, 1812, 1958, 3589,  771, 1464, 3632, 2363,
        2344, 2827,  753,  556])
Epoch: 515, Training Loss: 0.80, Validation Loss: 0.73, accuracy = 0.70
Save best Model_1 @ epoch 515 acc: 0.7010550996483002
######################## Epoch 516 - Batch 1 ########################
IDs in batch 1: tensor([3926, 1761, 2102, 2094, 2419, 3395, 2703, 3447, 3355,  726, 4100, 3254,
        2505, 3328,  915, 3866])
Epoch: 516, Training Loss: 0.78, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 517 - Batch 1 ########################
IDs in batch 1: tensor([2025, 2476, 3311, 2209,  685,  858, 2745, 2462,  352, 1968, 3925, 1250,
        4118, 3651, 2847, 3329])
Epoch: 517, Training Loss: 0.72, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 518 - Batch 1 ########################
IDs in batch 1: tensor([2550, 1346,  276, 1186, 2465, 1488, 3343, 3991, 1436, 2309, 1498, 4172,
        1852, 2629,  292,  556])
Epoch: 518, Training Loss: 0.58, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 519 - Batch 1 ########################
IDs in batch 1: tensor([ 390,  251,  997, 2347, 3427, 1478, 2387, 1365, 2932, 2957, 2127, 3577,
        3996, 3400, 2936, 2250])
Epoch: 519, Training Loss: 0.70, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 520 - Batch 1 ########################
IDs in batch 1: tensor([3898, 1331, 2983, 2360, 1385,  317, 2199, 1821, 4108, 2157,  191, 1981,
          49, 3943, 1132,  213])
Epoch: 520, Training Loss: 0.72, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 521 - Batch 1 ########################
IDs in batch 1: tensor([ 804, 2649,  398, 3808, 3742,  515,  767, 2056, 3902, 1377,  895, 1335,
         805, 2385, 3663, 3839])
Epoch: 521, Training Loss: 0.88, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 522 - Batch 1 ########################
IDs in batch 1: tensor([1428, 1965, 2173,   78,  539,  636,  758, 4016,  463, 1614, 2115, 3943,
        2967, 3408, 2851,  496])
Epoch: 522, Training Loss: 0.76, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 523 - Batch 1 ########################
IDs in batch 1: tensor([4223,  569, 2278, 2261, 1635, 1592, 2743, 2693, 2497, 3841,  334,  787,
        2993, 1476, 3738, 1175])
Epoch: 523, Training Loss: 0.60, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 524 - Batch 1 ########################
IDs in batch 1: tensor([3732, 2571, 3882, 3143, 3426, 3418,  448,  556, 3202, 2024, 3139, 3539,
        1330, 3763, 2807, 3370])
Epoch: 524, Training Loss: 0.63, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 525 - Batch 1 ########################
IDs in batch 1: tensor([3616,  807, 3257, 3283, 2204, 1702, 2597,  362,  295, 2718, 1832, 1263,
        4080, 1008, 2902, 1236])
Epoch: 525, Training Loss: 0.55, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 526 - Batch 1 ########################
IDs in batch 1: tensor([2627, 1385, 3078,  944, 3569, 3368, 1283, 2127,  326,  221, 4046, 1862,
        1384, 4116, 3533, 1007])
Epoch: 526, Training Loss: 0.65, Validation Loss: 0.76, accuracy = 0.66
######################## Epoch 527 - Batch 1 ########################
IDs in batch 1: tensor([1920,  874, 2011, 2795, 1778, 2656, 3139, 1826,  582, 3267, 1179, 1933,
        3648, 2159, 3592, 1841])
Epoch: 527, Training Loss: 0.69, Validation Loss: 0.77, accuracy = 0.66
######################## Epoch 528 - Batch 1 ########################
IDs in batch 1: tensor([1356,  688, 3954, 2788, 3449, 3917, 1944, 2828,  883, 1484,  278, 1336,
         659, 1423, 3071,    4])
Epoch: 528, Training Loss: 0.63, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 529 - Batch 1 ########################
IDs in batch 1: tensor([2322, 3838,  967,   51, 2256, 2666, 2872, 1158, 3349, 3110,  494, 3764,
        2776,  289, 3658, 2609])
Epoch: 529, Training Loss: 0.55, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 530 - Batch 1 ########################
IDs in batch 1: tensor([1551, 3030, 3658,  207, 1869, 3843,  818, 1794, 2124,  284, 3338, 2772,
         200,  511,  825,  892])
Epoch: 530, Training Loss: 0.60, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 531 - Batch 1 ########################
IDs in batch 1: tensor([ 849, 3841, 2986, 1720,  613, 3132, 3016, 1532, 2016, 1846, 2195, 2660,
        4025, 2066, 3424, 2097])
Epoch: 531, Training Loss: 0.61, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 532 - Batch 1 ########################
IDs in batch 1: tensor([2250, 3494,  606, 1180, 2839, 1445, 1232, 3397, 1780,  391, 3014, 1196,
        3181,  891, 3647,  907])
Epoch: 532, Training Loss: 0.53, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 533 - Batch 1 ########################
IDs in batch 1: tensor([3470, 1748, 1855, 2087, 1502, 2442, 1429, 1570, 3980, 1737, 1740,  822,
        2109,    5, 1885, 2780])
Epoch: 533, Training Loss: 0.59, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 534 - Batch 1 ########################
IDs in batch 1: tensor([ 857,  541, 2772, 3539, 2446, 3742, 1796, 1885, 1279,  786, 1648, 3532,
        3997, 3981, 1022, 4056])
Epoch: 534, Training Loss: 0.55, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 535 - Batch 1 ########################
IDs in batch 1: tensor([1596, 3675,  665, 2492, 2435, 2539, 3278, 3688,  959, 2776,  603, 3087,
         244, 2959, 3459, 1756])
Epoch: 535, Training Loss: 0.61, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 536 - Batch 1 ########################
IDs in batch 1: tensor([3787,  622, 4035,  954,  320,  350, 2182, 2193, 1223, 1681, 3802, 4143,
        4096, 3264, 1305, 1159])
Epoch: 536, Training Loss: 0.82, Validation Loss: 0.75, accuracy = 0.67
######################## Epoch 537 - Batch 1 ########################
IDs in batch 1: tensor([1589, 1336, 1220, 2805,  391, 1509, 3030, 2437, 3588, 3793, 2517, 2659,
        4195, 4264, 1232, 3252])
Epoch: 537, Training Loss: 0.74, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 538 - Batch 1 ########################
IDs in batch 1: tensor([2604, 2521, 3598, 3166,  833, 1600, 1519, 4086, 3290, 2731, 2742, 1315,
        2710, 3200, 2581,  282])
Epoch: 538, Training Loss: 0.56, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 539 - Batch 1 ########################
IDs in batch 1: tensor([1406, 2727, 3387, 3146,  726, 1786,  747, 4124,  556, 3113, 3378, 3514,
          42, 1507,  914, 1986])
Epoch: 539, Training Loss: 0.35, Validation Loss: 0.74, accuracy = 0.67
######################## Epoch 540 - Batch 1 ########################
IDs in batch 1: tensor([ 914, 2851, 4188, 2244, 1264, 4139,  320, 3397, 2218, 2984, 3582,  308,
        1855, 1237, 4218,  236])
Epoch: 540, Training Loss: 0.67, Validation Loss: 0.74, accuracy = 0.67
######################## Epoch 541 - Batch 1 ########################
IDs in batch 1: tensor([2171,  594, 3384, 4032, 1723, 1988,  496,  378, 1655, 3704,  717, 1009,
        3865, 2298, 1980, 4141])
Epoch: 541, Training Loss: 0.70, Validation Loss: 0.74, accuracy = 0.67
######################## Epoch 542 - Batch 1 ########################
IDs in batch 1: tensor([1053, 2783, 2645, 4068, 2974, 3360, 1724,  774, 4005,  452, 3647,  779,
        2561, 2519, 2885, 3480])
Epoch: 542, Training Loss: 0.67, Validation Loss: 0.74, accuracy = 0.67
######################## Epoch 543 - Batch 1 ########################
IDs in batch 1: tensor([2171,  340, 4003, 1020, 2444, 2442, 2341,  733, 2383, 1116, 2678, 3597,
         452,  786, 2452,   88])
Epoch: 543, Training Loss: 0.51, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 544 - Batch 1 ########################
IDs in batch 1: tensor([4036, 3767, 1070, 1727, 3176, 4049, 1968,  182, 1381, 1291, 1638, 2418,
        2870,  678, 3329, 3827])
Epoch: 544, Training Loss: 0.66, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 545 - Batch 1 ########################
IDs in batch 1: tensor([2073, 3917, 3543, 3644,  507, 2027, 3053, 2653, 1152,  993, 1181, 2880,
         577, 2965, 2102,  575])
Epoch: 545, Training Loss: 0.62, Validation Loss: 0.73, accuracy = 0.68
######################## Epoch 546 - Batch 1 ########################
IDs in batch 1: tensor([ 587, 1341, 4095, 2682, 2220, 2348, 3897,  917, 2894,  919, 1982, 1896,
        2841,  601, 3087, 3964])
Epoch: 546, Training Loss: 0.56, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 547 - Batch 1 ########################
IDs in batch 1: tensor([4172, 1218, 2331, 1896, 1321, 4016, 2691, 4242, 4094, 2371, 3689, 2796,
        1502, 3507, 4127, 4131])
Epoch: 547, Training Loss: 0.95, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 548 - Batch 1 ########################
IDs in batch 1: tensor([ 448, 2773, 1140, 4184, 3132, 2579, 1956, 1282, 3778, 2099,  777, 2798,
        2257,  823, 3542, 3577])
Epoch: 548, Training Loss: 0.66, Validation Loss: 0.71, accuracy = 0.68
######################## Epoch 549 - Batch 1 ########################
IDs in batch 1: tensor([2119,  435,  109, 4058, 1110, 2591, 1001, 1182, 1020, 1766, 3873, 2019,
        1571, 2606, 4128,  258])
Epoch: 549, Training Loss: 0.70, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 550 - Batch 1 ########################
IDs in batch 1: tensor([4267, 4097, 1824, 4125, 1511, 3475, 3988, 1551, 2248, 2260, 2688, 3478,
        2802, 2839,  657,  234])
Epoch: 550, Training Loss: 0.62, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 551 - Batch 1 ########################
IDs in batch 1: tensor([2403, 1588, 3425, 2934,  344, 1285, 3099, 1671, 3985, 2015, 1110,  874,
         682, 2817, 3503, 1419])
Epoch: 551, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 552 - Batch 1 ########################
IDs in batch 1: tensor([1158, 2412, 1897, 1639, 3156,  373, 3984, 2050,  738, 2746,  316, 1633,
        1962, 2819, 1111,  234])
Epoch: 552, Training Loss: 0.53, Validation Loss: 0.70, accuracy = 0.71
Save best Model_1 @ epoch 552 acc: 0.7069167643610785
######################## Epoch 553 - Batch 1 ########################
IDs in batch 1: tensor([3264, 1676, 3964, 3421, 1728, 3660, 3340, 1899, 3244, 1146, 2789, 3922,
        1632, 2859, 1863, 1154])
Epoch: 553, Training Loss: 0.65, Validation Loss: 0.70, accuracy = 0.71
Save best Model_1 @ epoch 553 acc: 0.7092614302461899
######################## Epoch 554 - Batch 1 ########################
IDs in batch 1: tensor([2847, 3963, 1178, 2640, 2017, 2968, 4139,  376, 3935, 1665, 1612, 2883,
        3749, 1154, 2559, 3313])
Epoch: 554, Training Loss: 0.75, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 555 - Batch 1 ########################
IDs in batch 1: tensor([2023, 1383, 4236, 1094, 2052, 2280, 3133, 1851, 2112, 3772,  919,  494,
        4187,  547, 1380, 1840])
Epoch: 555, Training Loss: 0.48, Validation Loss: 0.70, accuracy = 0.71
Save best Model_1 @ epoch 555 acc: 0.7104337631887456
######################## Epoch 556 - Batch 1 ########################
IDs in batch 1: tensor([1218, 2013, 3476, 1193,  805, 1336,  494,  398, 1376,   52,  203, 2539,
        2451, 3479, 2199, 2442])
Epoch: 556, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 557 - Batch 1 ########################
IDs in batch 1: tensor([ 140, 1333, 1904, 1986, 2051, 2441, 2031, 2088,  631, 3942, 3590,  863,
        2599, 3108, 2730, 3853])
Epoch: 557, Training Loss: 0.51, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 558 - Batch 1 ########################
IDs in batch 1: tensor([4015,  523, 2344, 1414, 2860, 4163, 3499, 1825, 2905,  769, 4197,  983,
        2511,  120, 4146, 2559])
Epoch: 558, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 559 - Batch 1 ########################
IDs in batch 1: tensor([1417, 3545,  709, 3459, 1197, 1272,  803, 3460,  476, 3142, 3531, 1770,
        1375,  409, 3217, 2789])
Epoch: 559, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 560 - Batch 1 ########################
IDs in batch 1: tensor([1405, 2309, 3253, 1923,  808, 3130, 3782, 2829, 3932, 3647, 2485,  785,
         312,  578, 3178, 1405])
Epoch: 560, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 561 - Batch 1 ########################
IDs in batch 1: tensor([3217,  140, 2282, 1397, 1863, 2730,  262, 2761, 2822, 2440,  954, 3337,
        4093, 3795, 2523, 3279])
Epoch: 561, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 562 - Batch 1 ########################
IDs in batch 1: tensor([3111, 1372,  846, 1974,  258,  200, 3632, 4134,  335, 2953, 2591, 3472,
        1748, 1476, 3544, 2854])
Epoch: 562, Training Loss: 0.35, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 563 - Batch 1 ########################
IDs in batch 1: tensor([3516, 4144, 3982, 2176, 2080, 2372, 4046, 2579, 2574, 1502, 4139, 2373,
         796, 2620, 3534, 3310])
Epoch: 563, Training Loss: 1.07, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 564 - Batch 1 ########################
IDs in batch 1: tensor([1231, 3815, 1647, 2225, 2804, 1760, 1634, 3936, 3190,  714, 3533,  108,
        1821, 3144, 1583,  945])
Epoch: 564, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 565 - Batch 1 ########################
IDs in batch 1: tensor([4108, 1276, 1006, 2902, 3552, 1409,  265, 1812,  161,  967, 1482, 4128,
        3783,   11,  855, 2476])
Epoch: 565, Training Loss: 0.80, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 566 - Batch 1 ########################
IDs in batch 1: tensor([ 556, 2478, 2322, 4212, 2234, 4226,  882, 4253, 1934, 2342, 3220, 3743,
        1502, 3533,  954,  292])
Epoch: 566, Training Loss: 0.73, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 567 - Batch 1 ########################
IDs in batch 1: tensor([2601, 1037, 2712, 2870, 1445,  657,  212,  250, 2107,  952, 3364,  610,
        1249,  400,  950, 2851])
Epoch: 567, Training Loss: 0.65, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 568 - Batch 1 ########################
IDs in batch 1: tensor([2102, 3488, 1588, 1405, 3056, 2718, 2732, 2457,  350, 3113, 1308, 2943,
        3526, 4175,  900, 1625])
Epoch: 568, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 569 - Batch 1 ########################
IDs in batch 1: tensor([3609,  257, 3479,  444, 2729, 4166, 2620,  177, 3763,  536,  251,   32,
        3806, 2942, 2080, 2804])
Epoch: 569, Training Loss: 0.64, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 570 - Batch 1 ########################
IDs in batch 1: tensor([3841, 1877, 2669,  491, 2819, 3098,  921, 2927, 1174,  437, 2500,  693,
        4004, 3881, 2709, 2099])
Epoch: 570, Training Loss: 0.67, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 571 - Batch 1 ########################
IDs in batch 1: tensor([3839,  790,  170, 1945, 2046, 1756, 4065,  871, 3826, 2091, 3425, 1034,
        1178,  842, 2931, 2738])
Epoch: 571, Training Loss: 0.62, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 572 - Batch 1 ########################
IDs in batch 1: tensor([1139, 2751, 2005, 1579, 3032, 2642, 3021, 2458, 2050, 1613, 1484,   84,
        1583, 3667, 2313, 3537])
Epoch: 572, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.72
Save best Model_1 @ epoch 572 acc: 0.7151230949589683
######################## Epoch 573 - Batch 1 ########################
IDs in batch 1: tensor([1955, 2667,  987, 2390, 2329, 3535,  527, 3480, 1760,  186,  807, 1579,
         888, 1488, 2111, 1925])
Epoch: 573, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 574 - Batch 1 ########################
IDs in batch 1: tensor([ 477, 3660, 3199, 1877, 2035, 2198,  725,  774,  456, 1763,  803,  910,
        3509, 2870,  217,  519])
Epoch: 574, Training Loss: 0.66, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 575 - Batch 1 ########################
IDs in batch 1: tensor([1419, 1294, 1248, 2451, 2522,   95, 2989,  505, 3219, 1214, 2956, 1429,
        1496, 3459,  672,  689])
Epoch: 575, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 576 - Batch 1 ########################
IDs in batch 1: tensor([3999, 1583,  149, 1647, 1367, 3327,  645, 1340, 2080, 3787,  945,   32,
        4245, 3471, 2110,  359])
Epoch: 576, Training Loss: 0.70, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 577 - Batch 1 ########################
IDs in batch 1: tensor([2894, 3251, 1490, 1933,  140, 2931,  127, 1195, 1044,  864,  807, 2276,
          77, 1787, 2968,  547])
Epoch: 577, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 578 - Batch 1 ########################
IDs in batch 1: tensor([3747, 1772, 3072, 1183, 3374, 3386, 2567, 2812, 4007, 1325, 1012, 1767,
        3674, 1760,  862, 1830])
Epoch: 578, Training Loss: 0.63, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 579 - Batch 1 ########################
IDs in batch 1: tensor([1249, 1754, 3771, 2126, 2035, 1977, 2405, 2232,  287, 3458,   44, 1237,
        3485, 1099, 4265, 2092])
Epoch: 579, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 580 - Batch 1 ########################
IDs in batch 1: tensor([3514, 1624, 3078, 1258,  205, 1684, 2394, 1575, 2444, 4078,  135, 1310,
        3874, 1698, 4197, 2822])
Epoch: 580, Training Loss: 0.70, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 581 - Batch 1 ########################
IDs in batch 1: tensor([3913, 3660,  532,  202, 1081,  387, 2590, 3709, 2285, 2689, 2277, 3539,
        1764, 2255, 1343,  439])
Epoch: 581, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 582 - Batch 1 ########################
IDs in batch 1: tensor([1022,  628, 2934, 3938, 2305, 1734,  547, 1857, 3448,  835, 1858, 4076,
        2348, 3996, 4225, 3084])
Epoch: 582, Training Loss: 0.98, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 583 - Batch 1 ########################
IDs in batch 1: tensor([1676, 1508,   93,  380, 2224, 2011, 1178, 1299,   42, 2337, 1675, 4154,
         281, 4077, 1271, 3144])
Epoch: 583, Training Loss: 0.53, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 584 - Batch 1 ########################
IDs in batch 1: tensor([2584, 3964, 1266,  819, 2035, 3148, 2362, 2359, 2857, 3374, 1887, 2690,
        2823, 4088, 1772,  882])
Epoch: 584, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 585 - Batch 1 ########################
IDs in batch 1: tensor([2970, 2574, 2656, 2498,  139, 4238,  640,  673,  499, 3496, 3587, 1499,
        2035, 1985,  774,  355])
Epoch: 585, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 586 - Batch 1 ########################
IDs in batch 1: tensor([3206,   60,  779, 4038,  755, 2763, 3570, 2016, 1810, 1787, 1641, 1976,
          15,  605,  515, 1088])
Epoch: 586, Training Loss: 0.74, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 587 - Batch 1 ########################
IDs in batch 1: tensor([ 312, 2177, 4227, 1736, 4189,  843,  777, 2278,  924, 3023,  228,  332,
        3049, 1103, 1408, 2487])
Epoch: 587, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 588 - Batch 1 ########################
IDs in batch 1: tensor([1137, 2090,  602,  260,   88, 3951, 2730, 3707, 3960, 1108, 1022, 1181,
         965, 2812, 3998, 3593])
Epoch: 588, Training Loss: 0.66, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 589 - Batch 1 ########################
IDs in batch 1: tensor([ 441, 1580,  610, 1746,  434, 3922, 1954, 4116,   38, 1543,  687, 3760,
        1957, 2905,   22,  125])
Epoch: 589, Training Loss: 0.79, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 590 - Batch 1 ########################
IDs in batch 1: tensor([2405,  789,  727,  787,  522, 3538, 3127, 3935, 3951, 1509, 1882, 2339,
        2238,  401, 3932, 1599])
Epoch: 590, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 591 - Batch 1 ########################
IDs in batch 1: tensor([  47, 3698, 4115,  173, 3528, 2936, 1633, 3451,  284, 3364, 1208, 1986,
         510, 3407,  747, 3719])
Epoch: 591, Training Loss: 0.55, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 592 - Batch 1 ########################
IDs in batch 1: tensor([ 701,  539, 3130, 3989, 3643, 3057,  982,  523,  257, 3588, 1426, 1158,
        1373,  214, 2188, 1234])
Epoch: 592, Training Loss: 0.65, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 593 - Batch 1 ########################
IDs in batch 1: tensor([3228, 3246, 3938,  820, 3751, 4148, 2587,  350, 2764, 1306, 2041,  942,
        3387,  164, 1351, 3845])
Epoch: 593, Training Loss: 0.83, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 594 - Batch 1 ########################
IDs in batch 1: tensor([3942, 1281, 2564, 2682, 3179, 3785, 1686, 3952, 3473, 3902,   73, 3630,
        3531,  970, 1934, 3706])
Epoch: 594, Training Loss: 0.86, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 595 - Batch 1 ########################
IDs in batch 1: tensor([2997, 2425, 1892,  613, 3960,  441, 1883, 3914, 3148, 2347, 2641, 4179,
        3900, 1866, 3538,   96])
Epoch: 595, Training Loss: 0.65, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 596 - Batch 1 ########################
IDs in batch 1: tensor([1120, 2690, 2373,  736, 4166, 2182,  582, 1252, 3833, 1055,  483, 2711,
        2212, 3581, 2983, 3329])
Epoch: 596, Training Loss: 0.60, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 597 - Batch 1 ########################
IDs in batch 1: tensor([1038, 1885, 2891, 1231, 4013, 3847, 3570, 1727, 3404, 3439, 3831,  662,
        4168, 4011, 1296, 3789])
Epoch: 597, Training Loss: 1.08, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 598 - Batch 1 ########################
IDs in batch 1: tensor([2466,  503, 3988, 2550, 3142, 1726, 3527, 2464, 2529, 2870, 2709, 1611,
        1271, 3340,  164, 3977])
Epoch: 598, Training Loss: 0.50, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 599 - Batch 1 ########################
IDs in batch 1: tensor([3289, 2558, 2196,  825, 2004, 1239, 3367, 1938, 3255, 1231, 4002, 2309,
        3357, 3654, 2664,  816])
Epoch: 599, Training Loss: 0.46, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 600 - Batch 1 ########################
IDs in batch 1: tensor([1326, 1767, 1647, 2497, 1273, 2564, 4009, 3511,  575, 3424,  844, 3299,
        3723, 1175, 1833,  106])
Epoch: 600, Training Loss: 0.82, Validation Loss: 0.71, accuracy = 0.68
######################## Epoch 601 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 1168, 2041, 2729,  630, 2650, 1765, 1128,  456, 3257, 1181, 3427,
        3832, 2997, 4172, 4012])
Epoch: 601, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 602 - Batch 1 ########################
IDs in batch 1: tensor([3126, 3421, 3829, 3003, 2305, 1639, 2398, 3056, 1283, 1808, 1955, 2291,
        2478, 3751, 1077, 2298])
Epoch: 602, Training Loss: 0.81, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 603 - Batch 1 ########################
IDs in batch 1: tensor([1354,  558, 3101, 1144,  623,  104, 3289, 2053, 1770, 3030, 1571, 4229,
        2014, 2641, 4159, 2040])
Epoch: 603, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 604 - Batch 1 ########################
IDs in batch 1: tensor([1442, 3277,  432, 2795,  323, 2323, 1395,  682, 3771,  164, 3637, 3548,
         914, 2237, 2305, 4139])
Epoch: 604, Training Loss: 0.53, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 605 - Batch 1 ########################
IDs in batch 1: tensor([2437,  900, 1022, 1231,  555, 3037, 3031, 1372, 4128, 3042, 1147, 1990,
        4009, 1559, 3905, 1723])
Epoch: 605, Training Loss: 0.60, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 606 - Batch 1 ########################
IDs in batch 1: tensor([1152, 2202, 1870, 2285, 1784, 3058, 3926, 2863, 3184, 1014,  736, 2451,
        2590, 2080, 3220,   62])
Epoch: 606, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 607 - Batch 1 ########################
IDs in batch 1: tensor([2355, 1162, 2844, 3168,  396,  108, 4062, 1128, 3055, 2339, 3975, 3996,
        2823, 2030,  713,  513])
Epoch: 607, Training Loss: 0.76, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 608 - Batch 1 ########################
IDs in batch 1: tensor([ 762, 2407,  172, 2391, 3286, 3321, 3381, 2586, 2914, 4187, 1073, 3152,
        1001, 3925,  365, 4022])
Epoch: 608, Training Loss: 0.41, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 609 - Batch 1 ########################
IDs in batch 1: tensor([1471, 1126, 2326, 2798, 3022,  403, 3235, 4264, 2667, 2010,  937, 1718,
        3511, 2447, 3308, 2099])
Epoch: 609, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 610 - Batch 1 ########################
IDs in batch 1: tensor([1601, 2126, 3738, 1341, 4012,  134, 2691, 1134,  595,  150,  435, 2324,
          52, 4076, 2206,  646])
Epoch: 610, Training Loss: 0.57, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 611 - Batch 1 ########################
IDs in batch 1: tensor([3692, 1438, 2883, 2949, 3603, 1685,  426, 2776,  516, 3729,  656, 4032,
         789,  418, 2827,  113])
Epoch: 611, Training Loss: 0.79, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 612 - Batch 1 ########################
IDs in batch 1: tensor([3308, 1600, 2235,   57, 2235, 2606,  368, 1562, 3976,  357, 3051, 2796,
         186, 1822, 2764, 3640])
Epoch: 612, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 613 - Batch 1 ########################
IDs in batch 1: tensor([4146, 2423, 2733,  348, 3634, 2815, 1965, 1672, 1583, 3030, 2124, 3533,
        3475, 3334,  835,  667])
Epoch: 613, Training Loss: 0.79, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 614 - Batch 1 ########################
IDs in batch 1: tensor([1596,  550, 3152, 1379, 3423,  536,  333, 4061,  212, 2638, 3456, 1193,
         365, 2506, 2429,  251])
Epoch: 614, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 615 - Batch 1 ########################
IDs in batch 1: tensor([2821, 2522, 2188, 3381,  127, 1160, 2614, 2898, 3009, 1302, 2964, 3981,
        3298,  284, 2132, 1914])
Epoch: 615, Training Loss: 0.48, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 616 - Batch 1 ########################
IDs in batch 1: tensor([ 243,  496, 1693,  959, 2024, 2060, 1636, 4227, 4062, 3883, 2819, 1097,
         776, 3963, 3897, 4266])
Epoch: 616, Training Loss: 0.71, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 617 - Batch 1 ########################
IDs in batch 1: tensor([ 953, 3740, 1951, 2009, 2053,  653,  659, 3888, 4048,  960, 3540,   82,
        2179,  402, 2373,  590])
Epoch: 617, Training Loss: 0.62, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 618 - Batch 1 ########################
IDs in batch 1: tensor([2765, 2880, 3528, 2921, 2377, 3734, 3582, 3615, 2355, 1767, 3251,  415,
        2601, 3312,   11,  143])
Epoch: 618, Training Loss: 0.71, Validation Loss: 0.71, accuracy = 0.72
Save best Model_1 @ epoch 618 acc: 0.7174677608440797
######################## Epoch 619 - Batch 1 ########################
IDs in batch 1: tensor([1980, 1755,  127,  617, 1956, 3342,  617,  202,  536, 2183, 2246, 1213,
         808, 1311, 2891, 1787])
Epoch: 619, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.72
Save best Model_1 @ epoch 619 acc: 0.7186400937866354
######################## Epoch 620 - Batch 1 ########################
IDs in batch 1: tensor([3865, 1275, 1770, 3912, 2745,  408, 2754, 1309, 2386,  833, 3060,  396,
        1853, 3942, 1635, 1007])
Epoch: 620, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 621 - Batch 1 ########################
IDs in batch 1: tensor([2011, 2052, 3017,  343, 1980, 4048, 1836, 1747, 2605,  229, 3192, 3391,
        2159, 1360, 3907, 1712])
Epoch: 621, Training Loss: 0.61, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 622 - Batch 1 ########################
IDs in batch 1: tensor([4107,  963, 3634, 1335,  148,  545, 1076, 3455, 3099, 3793, 3587, 3386,
        2098, 2835, 3751, 2819])
Epoch: 622, Training Loss: 0.57, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 623 - Batch 1 ########################
IDs in batch 1: tensor([2529, 2360, 3680, 2664, 2949, 4013, 2967,  274, 3950, 3338, 4097,  884,
        2327, 3573, 1361,   32])
Epoch: 623, Training Loss: 0.62, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 624 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 2354, 1062, 3387,  425, 3771,  797, 2983, 3031,  812, 2204,  913,
        2998, 1498, 2295, 3973])
Epoch: 624, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.72
Save best Model_1 @ epoch 624 acc: 0.7209847596717468
######################## Epoch 625 - Batch 1 ########################
IDs in batch 1: tensor([2725,  573,  603, 4227, 3879, 1171,  276,  470,  400,  223, 3642, 2973,
        2781, 2408, 2777, 3938])
Epoch: 625, Training Loss: 0.68, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 626 - Batch 1 ########################
IDs in batch 1: tensor([2018, 2229, 2587, 3950,  758, 2146, 2049, 2787, 2863,  554, 1546,  639,
        2383, 1042, 1624, 1693])
Epoch: 626, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 627 - Batch 1 ########################
IDs in batch 1: tensor([ 104, 2358, 2428, 1781, 3917, 3600, 3032, 4126, 1845, 3570, 4108,  577,
        1332, 1294, 3466, 2743])
Epoch: 627, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 628 - Batch 1 ########################
IDs in batch 1: tensor([1159, 3132, 1156, 2299, 2040, 2891, 2485, 1661, 2066,  595,  788, 3162,
        4013,  615, 1754, 1001])
Epoch: 628, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 629 - Batch 1 ########################
IDs in batch 1: tensor([  81, 2127,  964, 2934,  813, 3197, 3969, 2428, 3312, 2350,  278, 2845,
        1614, 3127, 2789, 1158])
Epoch: 629, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 630 - Batch 1 ########################
IDs in batch 1: tensor([1755, 4017, 2847,  545, 1484, 2610, 3135, 2553, 3449,   85, 3829, 3207,
        2825,  704, 3443, 3254])
Epoch: 630, Training Loss: 0.59, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 631 - Batch 1 ########################
IDs in batch 1: tensor([  81, 1852,  615, 3964, 2777,  662, 3676, 2120, 2986,  991, 3277,  284,
        1782, 2595, 2298, 3927])
Epoch: 631, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 632 - Batch 1 ########################
IDs in batch 1: tensor([3259,  776, 3507, 4032, 1845, 1852, 2247, 3109, 1325, 3870, 3787,  219,
        1141,  832, 3865, 1624])
Epoch: 632, Training Loss: 0.64, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 633 - Batch 1 ########################
IDs in batch 1: tensor([1337, 2387, 2957, 3418, 2719,  558, 3202, 3905, 2052, 3891, 1470, 3151,
         767, 3525, 4199,   57])
Epoch: 633, Training Loss: 0.45, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 634 - Batch 1 ########################
IDs in batch 1: tensor([2880, 3810, 1698, 2167, 3516,  779, 3815, 1747, 2696, 4251, 4165, 3484,
        3802, 3130, 3382,  866])
Epoch: 634, Training Loss: 0.78, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 635 - Batch 1 ########################
IDs in batch 1: tensor([ 812,  201, 1369,  763, 4214,   28, 1588, 2590, 1722, 1057, 1128,   56,
        3101, 2492,  960, 1984])
Epoch: 635, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 636 - Batch 1 ########################
IDs in batch 1: tensor([ 145, 1712, 1796, 3399, 1728,  295, 3501, 1108, 2348, 3002,  335, 3328,
         436, 1196, 3197, 3044])
Epoch: 636, Training Loss: 0.40, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 637 - Batch 1 ########################
IDs in batch 1: tensor([3345,  151, 3953,  335, 2367, 2575, 2604, 2074, 2500,  191,  824, 1872,
        4158,  442, 4185, 2590])
Epoch: 637, Training Loss: 0.68, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 638 - Batch 1 ########################
IDs in batch 1: tensor([2590, 4095, 3056, 2451, 2784, 3499, 2695, 2127, 3934, 2826, 2013,  727,
        1860, 2112, 2095, 1733])
Epoch: 638, Training Loss: 0.67, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 639 - Batch 1 ########################
IDs in batch 1: tensor([3428, 2305, 3162, 4061, 3881, 2478, 2582, 2090, 1698, 2098, 1624, 2390,
        3310, 2693, 3591, 2013])
Epoch: 639, Training Loss: 0.55, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 640 - Batch 1 ########################
IDs in batch 1: tensor([3243, 2279, 3483, 3259, 1507, 3368, 2645, 2342, 2924, 2485,  873, 2439,
        3291, 4006, 1699, 2198])
Epoch: 640, Training Loss: 0.69, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 641 - Batch 1 ########################
IDs in batch 1: tensor([1168, 4190, 1292,  849, 3582, 3532,  804,  316, 1296,  476, 4015, 3242,
         968, 3533,   41, 3777])
Epoch: 641, Training Loss: 0.85, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 642 - Batch 1 ########################
IDs in batch 1: tensor([1123,  807, 1938, 3610,  512, 3271, 2764,  303, 1499, 4196, 2219, 2483,
        1509,  332, 3340, 3640])
Epoch: 642, Training Loss: 0.53, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 643 - Batch 1 ########################
IDs in batch 1: tensor([ 471, 3022, 3109,  305, 2800, 3439, 3028, 3702, 3539,  390, 4246, 3144,
        4127, 3610, 2701, 3349])
Epoch: 643, Training Loss: 0.53, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 644 - Batch 1 ########################
IDs in batch 1: tensor([2087, 1271, 4189, 1482, 2230, 4229, 3710, 2741,   20, 2064, 1566,  214,
        2621,  583, 2011, 1625])
Epoch: 644, Training Loss: 0.41, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 645 - Batch 1 ########################
IDs in batch 1: tensor([2806, 1266, 2796, 1032,   70, 2823,  593, 2752, 1895, 3197, 1986, 3938,
        1216, 2520, 3333, 3751])
Epoch: 645, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 646 - Batch 1 ########################
IDs in batch 1: tensor([4249, 2188, 3544, 2040, 2405, 2997, 3078, 3194, 3998, 1704, 2236,  839,
        3277, 2377,  250, 2154])
Epoch: 646, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 647 - Batch 1 ########################
IDs in batch 1: tensor([1793, 1904, 3141, 1679, 3627, 4204,  135, 1960, 4110, 3552, 2755, 3672,
        4254, 3017, 1315, 1023])
Epoch: 647, Training Loss: 0.72, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 648 - Batch 1 ########################
IDs in batch 1: tensor([3994, 4234,  659,  683,  387,  997, 1728, 2250, 2586, 1684,  277,  372,
        2516, 2121, 2712, 4253])
Epoch: 648, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 649 - Batch 1 ########################
IDs in batch 1: tensor([2366, 1204, 1420, 2488,  395, 1681, 1364, 3615,  408, 3423, 2642, 2945,
        3765, 3382, 2063,  770])
Epoch: 649, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 650 - Batch 1 ########################
IDs in batch 1: tensor([4115, 1944, 3921, 3731,  476, 1682,  469, 3807, 4080, 1934, 1481, 1988,
        2157,  854, 4127,  202])
Epoch: 650, Training Loss: 0.73, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 651 - Batch 1 ########################
IDs in batch 1: tensor([  85, 1216,  469,  980,  657, 1934, 1566,  223,  302,  442, 2292, 2468,
         751, 2925, 3216, 2142])
Epoch: 651, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 652 - Batch 1 ########################
IDs in batch 1: tensor([ 665, 1630, 1092, 1734, 1501,  881, 3599,    5, 3743, 3448, 3284,  971,
        3537, 1420, 3088, 4158])
Epoch: 652, Training Loss: 0.62, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 653 - Batch 1 ########################
IDs in batch 1: tensor([2968, 2234,  358, 1737, 2458, 2805, 4093, 1630, 3999, 2341, 2425, 2369,
        1555,  844, 1563, 1189])
Epoch: 653, Training Loss: 0.61, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 654 - Batch 1 ########################
IDs in batch 1: tensor([2116,  228, 3279,  531, 3839, 1700,  752, 1665, 2279, 1491, 3099, 2452,
        4011, 3954,  358, 2317])
Epoch: 654, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 655 - Batch 1 ########################
IDs in batch 1: tensor([2642,   62, 1571, 3696, 2275,  775, 2324,  436,  639,  762, 1938, 2255,
        3423, 1884, 2477, 3031])
Epoch: 655, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.72
Save best Model_1 @ epoch 655 acc: 0.7245017584994138
######################## Epoch 656 - Batch 1 ########################
IDs in batch 1: tensor([1708, 1921, 3523, 4094,  214,  322, 2880, 3339, 1237, 2051, 3549, 2355,
        2661, 2324, 2464, 1568])
Epoch: 656, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 657 - Batch 1 ########################
IDs in batch 1: tensor([2111, 1432, 2996, 1009, 4027, 3701,  710, 1440, 1024, 2205, 1347,  662,
        2559, 2943, 3079, 3311])
Epoch: 657, Training Loss: 0.72, Validation Loss: 0.69, accuracy = 0.73
Save best Model_1 @ epoch 657 acc: 0.7256740914419695
######################## Epoch 658 - Batch 1 ########################
IDs in batch 1: tensor([ 170,  498, 1206, 4031, 3197, 1275, 1945,  234, 1351, 1302, 1556, 3738,
        3074, 2153, 2752,  689])
Epoch: 658, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.73
Save best Model_1 @ epoch 658 acc: 0.7280187573270809
######################## Epoch 659 - Batch 1 ########################
IDs in batch 1: tensor([ 278, 4172, 2296, 3532, 2167,  108, 2755, 1154, 1470, 1967, 1120,  752,
        1174, 2476, 3039,  131])
Epoch: 659, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.74
Save best Model_1 @ epoch 659 acc: 0.735052754982415
######################## Epoch 660 - Batch 1 ########################
IDs in batch 1: tensor([1799, 1639, 1770, 4015, 3098, 4200, 3798, 1780, 3311, 1373, 3536, 1255,
        1206, 3604, 3216, 3101])
Epoch: 660, Training Loss: 0.64, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 661 - Batch 1 ########################
IDs in batch 1: tensor([1436, 3652, 2690, 1510,  857,  879, 4263, 4156, 1761, 2426, 3958, 2359,
         892, 4026, 1859, 4212])
Epoch: 661, Training Loss: 0.68, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 662 - Batch 1 ########################
IDs in batch 1: tensor([1177, 3705, 3744, 1310, 2636, 1963, 2292, 3166, 2535, 4012, 2108, 1484,
        2219, 1957, 1911, 2025])
Epoch: 662, Training Loss: 0.80, Validation Loss: 0.68, accuracy = 0.74
Save best Model_1 @ epoch 662 acc: 0.7409144196951934
######################## Epoch 663 - Batch 1 ########################
IDs in batch 1: tensor([2640,  568, 1060, 1588,  575, 3437, 2181, 2364, 2493, 2674,  635,  338,
        2737, 4013, 1247,  133])
Epoch: 663, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 664 - Batch 1 ########################
IDs in batch 1: tensor([2406, 1832, 2217, 2902,  356, 2478, 2297, 2624, 2188, 4255, 2925, 3732,
        3440, 2435, 2403,  201])
Epoch: 664, Training Loss: 0.82, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 665 - Batch 1 ########################
IDs in batch 1: tensor([2406, 1971, 2552, 1332, 1361,  864,  478, 3078, 3541, 1315, 1380, 1287,
        1330, 2262, 3157, 3489])
Epoch: 665, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 666 - Batch 1 ########################
IDs in batch 1: tensor([2080, 3607, 1916, 3479, 3177, 2127, 1782, 1244, 1789, 2880, 3300,  890,
        2787, 2789,  478, 3010])
Epoch: 666, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 667 - Batch 1 ########################
IDs in batch 1: tensor([3583, 2104,  407, 4051, 2063, 2787, 2245,  252, 4199, 3329, 4213, 2015,
        1107, 3338,  444, 1011])
Epoch: 667, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 668 - Batch 1 ########################
IDs in batch 1: tensor([3072, 3652, 2960,  733, 1102, 3148, 1767, 3313, 2732,  747, 1393, 2701,
        3183,  721, 1585, 3643])
Epoch: 668, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 669 - Batch 1 ########################
IDs in batch 1: tensor([2644, 1851, 1911,  921,  602, 2794, 4012, 2754,  775, 3621,  519, 1901,
        2827, 1835, 1379, 2133])
Epoch: 669, Training Loss: 0.71, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 670 - Batch 1 ########################
IDs in batch 1: tensor([1014,  295, 1117, 4204, 1756, 1124, 1626, 2382, 1630, 1152, 3992, 2748,
        1570, 3025, 3822, 1258])
Epoch: 670, Training Loss: 0.66, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 671 - Batch 1 ########################
IDs in batch 1: tensor([2356, 4157, 2711, 1024, 3369, 1391, 4006, 2050, 3473, 2271, 2901, 1470,
         259, 1271, 4149, 3206])
Epoch: 671, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 672 - Batch 1 ########################
IDs in batch 1: tensor([1041, 2828, 3190, 1944, 1643,  646, 3254,  752, 2697, 1693, 1511, 3511,
        1556, 2648, 1349, 1061])
Epoch: 672, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 673 - Batch 1 ########################
IDs in batch 1: tensor([ 497, 3338, 2966, 1632, 3256,  257, 2957, 2868,  529, 1760, 3401, 1432,
        2732,  758, 1681, 2447])
Epoch: 673, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 674 - Batch 1 ########################
IDs in batch 1: tensor([1824, 1789,  990, 4149,   31, 3151, 3933, 2738, 1360, 2859, 4075,  842,
        3219, 3513,  727, 1830])
Epoch: 674, Training Loss: 0.53, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 675 - Batch 1 ########################
IDs in batch 1: tensor([3015, 2831, 3934, 2895,  524, 3597, 2306, 1082, 3536, 4056, 2450, 1266,
         450,   81, 2075, 1419])
Epoch: 675, Training Loss: 0.45, Validation Loss: 0.76, accuracy = 0.67
######################## Epoch 676 - Batch 1 ########################
IDs in batch 1: tensor([4005, 2088, 1162, 3872, 3874, 3789,   59, 4088, 3836, 3166, 2040, 2457,
        4016, 3862, 1005, 3845])
Epoch: 676, Training Loss: 1.16, Validation Loss: 0.77, accuracy = 0.67
######################## Epoch 677 - Batch 1 ########################
IDs in batch 1: tensor([3541, 1381, 3922, 1409, 1651,  182,  640, 2153,  214, 2664, 1117, 3964,
         822,  813, 1680, 4009])
Epoch: 677, Training Loss: 0.67, Validation Loss: 0.79, accuracy = 0.65
######################## Epoch 678 - Batch 1 ########################
IDs in batch 1: tensor([ 411,  866, 2754, 1104, 3982, 2668, 1124, 2036, 3783, 1343, 2070, 2742,
        3544, 3384, 3501, 1953])
Epoch: 678, Training Loss: 0.46, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 679 - Batch 1 ########################
IDs in batch 1: tensor([3472, 3847, 1340, 2388, 2880,  816,  808, 2387, 1826, 3610, 3352, 3016,
        1180, 2169,  315, 4133])
Epoch: 679, Training Loss: 0.57, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 680 - Batch 1 ########################
IDs in batch 1: tensor([3601,  238, 1438, 2828, 3499,  111, 3874, 1780, 2643, 3850, 2173, 1665,
        2839, 2804, 1275, 4036])
Epoch: 680, Training Loss: 0.41, Validation Loss: 0.79, accuracy = 0.66
######################## Epoch 681 - Batch 1 ########################
IDs in batch 1: tensor([1032, 4030, 2539, 2871, 1509, 1222, 1437, 2044, 1524,  822,  373, 3583,
        1536,  427, 1974,  184])
Epoch: 681, Training Loss: 0.53, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 682 - Batch 1 ########################
IDs in batch 1: tensor([3753,  266, 1120,  537, 2718, 3734,  327, 1221,  244, 1976, 2919, 1960,
         795, 1668,   99, 4222])
Epoch: 682, Training Loss: 0.73, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 683 - Batch 1 ########################
IDs in batch 1: tensor([2382, 2913, 3780, 4179, 2463,   63, 3624, 1830, 3760,  497, 4051, 3903,
        2030, 4179, 3072, 3469])
Epoch: 683, Training Loss: 0.79, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 684 - Batch 1 ########################
IDs in batch 1: tensor([3262,  177, 2977, 2957, 2563, 4146, 2225, 3604, 3823, 3688, 2794, 2449,
        3552, 2901,  637, 2765])
Epoch: 684, Training Loss: 0.81, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 685 - Batch 1 ########################
IDs in batch 1: tensor([1111,  557,  519, 1371, 2874,  572, 1318, 2840, 2344, 4080,  546, 3339,
        1999,  150, 1081, 2583])
Epoch: 685, Training Loss: 0.48, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 686 - Batch 1 ########################
IDs in batch 1: tensor([2609, 4227, 2448, 3239, 1863, 2010, 2237, 3121, 1685,  788,  967, 1405,
         312,  981, 1193, 2229])
Epoch: 686, Training Loss: 0.40, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 687 - Batch 1 ########################
IDs in batch 1: tensor([ 893,  306, 1182, 2736, 3793, 1178, 1605, 4006, 1324,  839, 2921,  980,
        3132, 2433, 2185, 2320])
Epoch: 687, Training Loss: 0.43, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 688 - Batch 1 ########################
IDs in batch 1: tensor([3648, 1755,  507, 3271, 2459, 3660,  515, 3540,  926,  397,  481, 2406,
         550, 3535, 3930, 3755])
Epoch: 688, Training Loss: 0.52, Validation Loss: 0.74, accuracy = 0.68
######################## Epoch 689 - Batch 1 ########################
IDs in batch 1: tensor([2210,  724, 2996,   20, 3037, 3185, 1931, 1878,  111,  917, 3917, 1842,
        2653, 3082,  586, 2469])
Epoch: 689, Training Loss: 0.52, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 690 - Batch 1 ########################
IDs in batch 1: tensor([1287, 3200,  159, 3781, 4196, 1185, 3668, 3642,  229, 4004, 3337, 1753,
        2760, 2577,   42, 3255])
Epoch: 690, Training Loss: 0.69, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 691 - Batch 1 ########################
IDs in batch 1: tensor([3017, 3268,  642, 1920, 1982, 4073, 1932, 1397, 1326,  964,  594,  290,
        1972, 2236,  469, 2131])
Epoch: 691, Training Loss: 0.36, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 692 - Batch 1 ########################
IDs in batch 1: tensor([3196,  356, 4212, 1760, 2544, 1442,  955, 2640, 3022, 1332, 2377, 4025,
        2509,  255,  400, 2252])
Epoch: 692, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 693 - Batch 1 ########################
IDs in batch 1: tensor([2334,  991, 1317, 3760, 1786, 1574, 4027, 2598, 4013, 1877, 3593,  986,
        3253, 2085, 4110, 3289])
Epoch: 693, Training Loss: 0.66, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 694 - Batch 1 ########################
IDs in batch 1: tensor([ 790,  537,  829, 3308,  954,  482, 1098, 1510, 3907, 2458, 3831, 2991,
        2229, 1155, 3279,  982])
Epoch: 694, Training Loss: 0.46, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 695 - Batch 1 ########################
IDs in batch 1: tensor([ 516, 3147, 3671,  823, 2206, 3336,  789, 3136, 3475, 1059,  660, 1604,
        3689, 3160, 3177, 1707])
Epoch: 695, Training Loss: 0.56, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 696 - Batch 1 ########################
IDs in batch 1: tensor([2456,  990,   49, 2487, 1704,  795,  409,  338,  651, 2247, 1625, 3258,
        2170,  888, 1059, 2466])
Epoch: 696, Training Loss: 0.48, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 697 - Batch 1 ########################
IDs in batch 1: tensor([ 743, 3283,  557, 1798,  244,  139, 3016,  279, 3852, 1087,  873, 3023,
          98, 1037, 3475, 1517])
Epoch: 697, Training Loss: 0.65, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 698 - Batch 1 ########################
IDs in batch 1: tensor([3695, 3552,  436, 2123, 1836, 2104, 2229,  830, 3098, 3272, 4138, 3754,
         130, 1681,  988,  656])
Epoch: 698, Training Loss: 0.60, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 699 - Batch 1 ########################
IDs in batch 1: tensor([4173, 1804,  809, 2671, 2499,  395, 1434, 1320, 3585, 2231, 4135, 2418,
         724,  963, 2770,  430])
Epoch: 699, Training Loss: 0.61, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 700 - Batch 1 ########################
IDs in batch 1: tensor([1920, 2462, 2466,  936,   43, 2390, 1596, 3027, 1388, 3618,  323,  577,
        3139, 2587,  284, 2945])
Epoch: 700, Training Loss: 0.39, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 701 - Batch 1 ########################
IDs in batch 1: tensor([4229,  316, 3904, 1927, 3181, 4232,  949, 3806,  553, 1733, 4199, 1428,
         154, 3233, 3147, 3123])
Epoch: 701, Training Loss: 0.57, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 702 - Batch 1 ########################
IDs in batch 1: tensor([2493, 1996, 2017,  373, 3235, 1159,  396, 3780, 1139, 3751, 1661, 3123,
         785,  488, 1231,  463])
Epoch: 702, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 703 - Batch 1 ########################
IDs in batch 1: tensor([  99, 3492, 2352,  133, 1850, 3873,  978,  928,  102, 1376, 4204, 4190,
        2280, 3023, 2819, 3414])
Epoch: 703, Training Loss: 0.49, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 704 - Batch 1 ########################
IDs in batch 1: tensor([   5, 2603, 4072, 3384, 2841,  219, 2355, 1647, 1456, 2044,  530,  342,
        2641,  767, 2235, 2106])
Epoch: 704, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 705 - Batch 1 ########################
IDs in batch 1: tensor([3935, 1448,  277, 2978, 2003, 3337, 1125, 1281, 3511,  866,  733, 1956,
        2080, 1588, 1734, 3235])
Epoch: 705, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 706 - Batch 1 ########################
IDs in batch 1: tensor([2349, 3668, 3306, 1371,  965, 2457, 1428,   27, 3387, 2075, 1157, 3147,
        1176,  315, 1413, 1704])
Epoch: 706, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 707 - Batch 1 ########################
IDs in batch 1: tensor([3002, 3525, 2644,  976, 1428,  756, 2538,  202,  606, 2022, 1747, 3936,
        2272,  602, 3493, 3568])
Epoch: 707, Training Loss: 0.79, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 708 - Batch 1 ########################
IDs in batch 1: tensor([1006,  954, 3017, 1859,  966, 1413, 4003,  550, 1962, 1174, 3650, 3826,
        1208, 3812, 4124, 1600])
Epoch: 708, Training Loss: 0.59, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 709 - Batch 1 ########################
IDs in batch 1: tensor([ 637, 3818, 1986,  763,  657, 1764, 4050,  376, 2142, 2964, 2193,  517,
        2098, 3049, 2295,  536])
Epoch: 709, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 710 - Batch 1 ########################
IDs in batch 1: tensor([ 825, 3692, 1054,  736,   14,  709, 3252, 1278, 1408,  955,  878, 1281,
         140, 1452, 4214, 3949])
Epoch: 710, Training Loss: 1.07, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 711 - Batch 1 ########################
IDs in batch 1: tensor([3983, 2070,   95, 3478,  427,   82, 1931, 3042, 3437, 3614,  672, 1935,
        3746, 2894, 1736,  130])
Epoch: 711, Training Loss: 0.61, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 712 - Batch 1 ########################
IDs in batch 1: tensor([3326, 1934, 2341, 2376, 2236, 3425,  947, 4163, 1419, 2894, 3082, 1132,
        3572, 2506, 1804, 4204])
Epoch: 712, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 713 - Batch 1 ########################
IDs in batch 1: tensor([ 138, 3762,  850, 2170, 3030,  752, 1825, 1899,   77, 1098, 1787, 3643,
        1196, 3873, 2078,  341])
Epoch: 713, Training Loss: 0.48, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 714 - Batch 1 ########################
IDs in batch 1: tensor([3338, 2741, 2550, 1627, 1789, 1076, 1720, 4124, 1913, 2545, 3932, 3882,
        1438, 1399,  687,  445])
Epoch: 714, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 715 - Batch 1 ########################
IDs in batch 1: tensor([1271,  743, 3749, 2696, 2733, 1540,  302, 3290, 3693, 2897,  450, 1017,
        4165, 2823,  942,  348])
Epoch: 715, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 716 - Batch 1 ########################
IDs in batch 1: tensor([3368, 4148,  195,  830, 1388, 2382, 1242, 2075, 2028, 3541, 4187, 4121,
        2125, 2369, 1090, 1681])
Epoch: 716, Training Loss: 0.70, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 717 - Batch 1 ########################
IDs in batch 1: tensor([ 134,   71, 2185, 1386, 3886, 3453, 1361, 1767,  563,  292,  534, 3587,
         718, 4119, 3478, 1977])
Epoch: 717, Training Loss: 0.58, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 718 - Batch 1 ########################
IDs in batch 1: tensor([ 674, 3081, 1162, 3723, 2146, 2949, 2417, 3492,  656, 3252, 1185,  910,
        2482, 2439,  732, 4226])
Epoch: 718, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 719 - Batch 1 ########################
IDs in batch 1: tensor([2986,  102,  615,   28, 1559, 3505, 1157, 3886, 2316, 1787, 2258, 1201,
        1146,  688,  527, 3798])
Epoch: 719, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 720 - Batch 1 ########################
IDs in batch 1: tensor([2898,  237, 1171, 1497, 3440, 1727, 3527, 3055, 2170, 3208, 1107, 3853,
         928,  809,  147, 4078])
Epoch: 720, Training Loss: 0.80, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 721 - Batch 1 ########################
IDs in batch 1: tensor([1599, 3255,  334, 1383, 2868, 1289,  704, 2133,  101,  244, 1006, 2159,
        3253,  302, 4070,  432])
Epoch: 721, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 722 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 4075, 1267, 1663,  751, 3700,  766,  263, 3334, 2661, 2312,  239,
         779, 1605, 2276,  667])
Epoch: 722, Training Loss: 0.76, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 723 - Batch 1 ########################
IDs in batch 1: tensor([2980, 1590, 3044, 3975, 1092, 3970, 1491, 4136, 3357, 1055, 1756,  379,
         164, 3540, 1567, 2456])
Epoch: 723, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 724 - Batch 1 ########################
IDs in batch 1: tensor([2936, 3847, 1971, 2192, 1472, 3091,  358, 1007, 3277,  960, 1923, 1594,
        1417, 1665, 2149,  202])
Epoch: 724, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 725 - Batch 1 ########################
IDs in batch 1: tensor([2418,  183, 2902, 1185, 2359, 1038,  409, 1041, 1589, 2143, 1648,  403,
        2649, 1567, 1059, 2230])
Epoch: 725, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 726 - Batch 1 ########################
IDs in batch 1: tensor([1132, 2606, 1753, 3851, 3465, 3226, 1085,  666, 1094, 2002, 3221,  183,
        1360, 3745, 2733, 1038])
Epoch: 726, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 727 - Batch 1 ########################
IDs in batch 1: tensor([2798,   71, 3535, 3410, 4179,  194,  472,  785,  448,  154, 3092, 2938,
        3101,  287, 1082, 3803])
Epoch: 727, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 728 - Batch 1 ########################
IDs in batch 1: tensor([3058, 1157,  407, 2697, 3206,  684, 1332, 2670, 1063, 3833,  274, 2108,
        2873, 2610, 1786,  343])
Epoch: 728, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 729 - Batch 1 ########################
IDs in batch 1: tensor([2385, 1204,  992, 3282,  699, 1226, 1185,  430, 3539, 1080, 1671, 1089,
        4236, 4022, 1432, 2406])
Epoch: 729, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 730 - Batch 1 ########################
IDs in batch 1: tensor([3673, 4138, 2761,   71, 3827, 2496,  778, 2583, 2837,  965, 3588, 3499,
        1331, 3998, 3434, 3642])
Epoch: 730, Training Loss: 0.62, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 731 - Batch 1 ########################
IDs in batch 1: tensor([3241,  357, 1594,  594, 3492,  930,  582, 3831, 1454, 3499, 3327, 2209,
        1585, 3999, 1325, 2189])
Epoch: 731, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 732 - Batch 1 ########################
IDs in batch 1: tensor([4053,  622, 3829,  957, 3764,  796, 3536, 3567, 2363,  681, 4267, 1786,
        1914, 3563, 1024, 1626])
Epoch: 732, Training Loss: 1.09, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 733 - Batch 1 ########################
IDs in batch 1: tensor([4188,  645,   92, 2119, 3593, 2069, 2479, 4016, 2836,  534, 4158, 2978,
        3143, 1306, 2355,  275])
Epoch: 733, Training Loss: 0.40, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 734 - Batch 1 ########################
IDs in batch 1: tensor([ 832,  337,  786, 4264, 1136, 1128, 1076, 3051, 1718, 2253, 1049, 2419,
        1819, 1543,  672, 1945])
Epoch: 734, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 735 - Batch 1 ########################
IDs in batch 1: tensor([2390, 2799,  277, 1344, 1852,  736, 2621, 2419,  148, 2150, 3032, 4122,
        2970, 2224, 3539, 2418])
Epoch: 735, Training Loss: 0.62, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 736 - Batch 1 ########################
IDs in batch 1: tensor([  39, 4024, 3624,  952, 4128, 3486,  838, 4143,  164, 3151, 3990, 2849,
        1098, 3458, 2795, 2393])
Epoch: 736, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 737 - Batch 1 ########################
IDs in batch 1: tensor([ 887,  512, 3476, 2529, 3755, 1555, 1408, 3787,  575, 3693, 2489,  359,
        3797, 1082, 1693,  100])
Epoch: 737, Training Loss: 0.61, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 738 - Batch 1 ########################
IDs in batch 1: tensor([2287, 2301, 2250, 2489,  462,  769, 1798, 3813, 1102, 2176, 4267, 2840,
        2872, 3738, 4240, 2137])
Epoch: 738, Training Loss: 0.76, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 739 - Batch 1 ########################
IDs in batch 1: tensor([3904, 2213, 2248, 2102, 1780, 4068, 2908, 3921, 3211, 3219, 1299, 1904,
        3487,  586, 2046, 2237])
Epoch: 739, Training Loss: 0.75, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 740 - Batch 1 ########################
IDs in batch 1: tensor([4187, 1578, 2382, 1632, 3663, 1391, 3219, 2688, 2025,  320, 1899, 4099,
        2018, 4032, 2870, 1283])
Epoch: 740, Training Loss: 0.57, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 741 - Batch 1 ########################
IDs in batch 1: tensor([3023, 1693, 3952,  756, 3723, 3258, 3379, 2991, 1221, 2229, 1543,   57,
        3456, 4121, 3499, 3543])
Epoch: 741, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 742 - Batch 1 ########################
IDs in batch 1: tensor([3886, 3022, 3661, 4199, 2671,  143, 3672, 2844, 2555, 1751, 1556, 3484,
        2143, 4187, 2329, 2919])
Epoch: 742, Training Loss: 0.69, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 743 - Batch 1 ########################
IDs in batch 1: tensor([3943,  578, 3251, 2688, 2760, 1767,  278, 2141, 4253, 3044, 1949, 2541,
         577,  691,  515, 1863])
Epoch: 743, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 744 - Batch 1 ########################
IDs in batch 1: tensor([2807, 3936, 2539, 3638, 3031, 1869,  363, 1182,  792, 1599,  438, 2828,
        4036,  874, 1025,   38])
Epoch: 744, Training Loss: 0.70, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 745 - Batch 1 ########################
IDs in batch 1: tensor([1518, 3866, 1121, 2897, 3239, 1803, 1442, 3843, 3035,   73, 2754, 1405,
        2860, 3990, 4011, 3821])
Epoch: 745, Training Loss: 0.79, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 746 - Batch 1 ########################
IDs in batch 1: tensor([4234,   98, 2046, 3303,  455, 2494, 1673, 3692,  537, 2724,  674,  890,
        1882, 3357, 3440,  837])
Epoch: 746, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 747 - Batch 1 ########################
IDs in batch 1: tensor([ 568,  568, 3732, 2030, 2863, 3147, 2458, 3707, 3427, 2452,  282, 1676,
        1385,  129, 1937, 2090])
Epoch: 747, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 748 - Batch 1 ########################
IDs in batch 1: tensor([1107, 1123, 2624,  858, 2137,   15,  632, 3603, 3021,  276,  825,  949,
        2482, 1037, 3514, 1663])
Epoch: 748, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 749 - Batch 1 ########################
IDs in batch 1: tensor([2342, 3746, 1256, 1896, 3568, 1885, 2277, 2425,  590, 1178,  167, 3334,
        1723, 1163, 2159,  518])
Epoch: 749, Training Loss: 0.70, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 750 - Batch 1 ########################
IDs in batch 1: tensor([1670, 1627, 4157, 2583,  538,  554, 3717, 3079, 1624, 3973, 1963, 2660,
         756, 2008, 1952, 1626])
Epoch: 750, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 751 - Batch 1 ########################
IDs in batch 1: tensor([1276,  893, 1519, 1558,  964, 2410, 3920,  545, 2196, 3994, 1159, 1167,
        3369, 3270, 1241, 1913])
Epoch: 751, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 752 - Batch 1 ########################
IDs in batch 1: tensor([2292, 4190, 1157, 2470,  977, 2358, 1234, 2274,  651, 3397, 3729,  778,
        2712,   70, 1391, 1423])
Epoch: 752, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 753 - Batch 1 ########################
IDs in batch 1: tensor([  49, 1784, 2478,  747, 2151, 2206, 4099,  609, 3787, 3836, 2413,  804,
        2856, 3810,  595, 3487])
Epoch: 753, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 754 - Batch 1 ########################
IDs in batch 1: tensor([2463,  362, 3714, 1345, 1181, 2764,  160, 2589,  565, 3236, 1850, 1220,
        4031, 1442, 1134, 2132])
Epoch: 754, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 755 - Batch 1 ########################
IDs in batch 1: tensor([2498, 1324, 4080, 1730,  391, 3208, 1271, 1459, 2624, 2154,   97,  993,
         991, 2885, 1980,  642])
Epoch: 755, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 756 - Batch 1 ########################
IDs in batch 1: tensor([2030, 3426, 2420, 3528,  112, 4238, 1747, 2615, 2103,  236, 2736, 4025,
        2772,  103, 1892,  202])
Epoch: 756, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 757 - Batch 1 ########################
IDs in batch 1: tensor([3057, 3161, 1423, 3919, 1624, 2993, 2235, 2897, 1680, 3990, 2751, 2334,
        2796, 1061, 2367, 2763])
Epoch: 757, Training Loss: 0.42, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 758 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 3015, 3667, 4253,   38, 2894,  151, 3832, 1102, 2176, 1087,  465,
        3421,  887, 2646,  195])
Epoch: 758, Training Loss: 0.32, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 759 - Batch 1 ########################
IDs in batch 1: tensor([2320,  257, 3029, 2248, 2781, 2370, 1196,  902, 3921, 1501, 2754,   13,
        4124, 4245, 2468, 2832])
Epoch: 759, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 760 - Batch 1 ########################
IDs in batch 1: tensor([2624, 2433, 1083, 1176, 3806,   21, 3718, 2328, 3860, 2343, 4245,  323,
        2155, 1821, 1007, 3299])
Epoch: 760, Training Loss: 0.78, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 761 - Batch 1 ########################
IDs in batch 1: tensor([1408,   78, 3664, 4157, 1976, 1158,  376, 1096, 2832, 3370, 2418,  467,
        1118,   31,  362,  964])
Epoch: 761, Training Loss: 0.56, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 762 - Batch 1 ########################
IDs in batch 1: tensor([1393, 3371, 1764,  662, 3711, 1497, 3995,  685, 1476, 3327, 2353, 4058,
        3088, 2529, 3908, 2258])
Epoch: 762, Training Loss: 0.65, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 763 - Batch 1 ########################
IDs in batch 1: tensor([1576, 2107, 3075, 1710, 3603,  538, 1402, 4225, 4131, 3501,  659, 1035,
        3903, 2313, 3996,  201])
Epoch: 763, Training Loss: 0.94, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 764 - Batch 1 ########################
IDs in batch 1: tensor([3727, 3879,  402,  963, 2884, 2776, 3705, 1321, 2660, 3692, 2880, 2642,
        3789, 2478, 2131, 2453])
Epoch: 764, Training Loss: 0.81, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 765 - Batch 1 ########################
IDs in batch 1: tensor([2166, 1128, 1960, 1404, 2575, 3339, 3042, 4204, 1119, 2746, 4027, 1809,
         425, 2271, 1445, 2154])
Epoch: 765, Training Loss: 0.64, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 766 - Batch 1 ########################
IDs in batch 1: tensor([3016, 4144, 3793, 3672, 3838, 3958, 2065, 3343, 1168, 2465, 4227,  356,
        2299, 2444, 3949, 4230])
Epoch: 766, Training Loss: 0.79, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 767 - Batch 1 ########################
IDs in batch 1: tensor([2072, 3793, 4181,  427, 3518, 3290, 1469,  411,  605, 3052, 4100, 1060,
        3373, 1693, 2798,   43])
Epoch: 767, Training Loss: 0.77, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 768 - Batch 1 ########################
IDs in batch 1: tensor([1870, 2241,  278, 3352,   28, 1025, 2506, 2097,  949, 1886, 1085,  325,
         572, 1706, 2367, 2978])
Epoch: 768, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 769 - Batch 1 ########################
IDs in batch 1: tensor([ 425, 2480,  805,  976,  680, 3830, 3188,  259, 2676, 2230, 3079,  582,
        2487, 2524, 3108, 2970])
Epoch: 769, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 770 - Batch 1 ########################
IDs in batch 1: tensor([1626,  202, 2974, 1275, 3151, 4251,  544, 3275, 3503, 3692, 1371, 2291,
        2248, 2255, 2606,  346])
Epoch: 770, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 771 - Batch 1 ########################
IDs in batch 1: tensor([ 133, 1640,  854, 3277, 3862,  827, 1242, 1934, 3057, 1679,  591, 1444,
        3771,  264, 3734, 2217])
Epoch: 771, Training Loss: 0.73, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 772 - Batch 1 ########################
IDs in batch 1: tensor([1794,  232, 1273, 2863, 3037, 1633, 2561,  921, 1405, 3869,  332, 2425,
        3092,  967, 1575, 1859])
Epoch: 772, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 773 - Batch 1 ########################
IDs in batch 1: tensor([ 100,  550, 2402, 3220, 4146,  928,  904,  691, 1082, 2951, 3505,  826,
        2095, 2586, 1050, 3300])
Epoch: 773, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 774 - Batch 1 ########################
IDs in batch 1: tensor([3650, 1043, 3739, 1365, 1425,  809,  350, 4120,  945, 2674,  807,   35,
        1341, 3642, 3564, 1624])
Epoch: 774, Training Loss: 0.93, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 775 - Batch 1 ########################
IDs in batch 1: tensor([3782, 3362, 4245, 1056, 1080,  897, 2442, 3554,  726, 2537, 4263, 2166,
        3845, 2736, 2959, 2849])
Epoch: 775, Training Loss: 0.69, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 776 - Batch 1 ########################
IDs in batch 1: tensor([3465,   96, 3489,  344, 1043, 3415, 2678, 3187,  959, 2950,  455, 3818,
        3943, 2800, 1333, 3342])
Epoch: 776, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 777 - Batch 1 ########################
IDs in batch 1: tensor([3826, 1276, 2322,   15,  811, 1571, 2742, 1143, 3882, 1835, 2632, 2891,
         681, 3718,  573, 4089])
Epoch: 777, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 778 - Batch 1 ########################
IDs in batch 1: tensor([2416, 3850,  841, 3664, 1781, 1704, 1611, 1469, 3246, 1571, 4035, 3374,
        2447, 3458, 3977, 3518])
Epoch: 778, Training Loss: 0.71, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 779 - Batch 1 ########################
IDs in batch 1: tensor([ 165, 3859, 2256,  644,  451, 1706, 3286, 3723, 2127, 3136,  942, 4076,
        1740, 2207,  444, 1132])
Epoch: 779, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 780 - Batch 1 ########################
IDs in batch 1: tensor([ 183,  615, 2729, 3345, 3661, 1196, 3860,  575, 1056, 3886, 4068,  880,
        1419, 3203, 4267, 1470])
Epoch: 780, Training Loss: 0.77, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 781 - Batch 1 ########################
IDs in batch 1: tensor([ 206,  596, 3284, 3815,  335, 1122, 2110, 2213, 1065, 3830, 3779, 2973,
         656, 1386, 2102, 2038])
Epoch: 781, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 782 - Batch 1 ########################
IDs in batch 1: tensor([2470,  610, 1840, 1931,   21,  128, 1317, 1119, 1498, 2328, 2081, 1075,
        3395,  757, 2145, 3897])
Epoch: 782, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 783 - Batch 1 ########################
IDs in batch 1: tensor([1108, 1122,   28,  863, 1700, 4105,  899, 1870, 3672, 3808,  978, 2782,
        3023, 2886, 3753, 2053])
Epoch: 783, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 784 - Batch 1 ########################
IDs in batch 1: tensor([4235,  430,  969, 3863, 2487, 2410,  454, 3919, 2504, 3718, 3592,   88,
        3632, 2050,  786, 3410])
Epoch: 784, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 785 - Batch 1 ########################
IDs in batch 1: tensor([4010,  612, 1555, 2866, 2172, 3589, 2045, 3658,  376, 3719, 2060, 1752,
        3401, 1600,   86, 2544])
Epoch: 785, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 786 - Batch 1 ########################
IDs in batch 1: tensor([4119, 3920, 1619, 3074,  876,    7, 1956, 3118, 2252, 1959, 3927, 1841,
         594,  365, 4251, 3647])
Epoch: 786, Training Loss: 0.50, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 787 - Batch 1 ########################
IDs in batch 1: tensor([1120,  632, 2710,  438, 4125, 4055, 1009,  369, 4166,  497, 2398, 4196,
         997, 1909,  318, 3567])
Epoch: 787, Training Loss: 0.69, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 788 - Batch 1 ########################
IDs in batch 1: tensor([3875, 3032, 3250, 1853, 2796, 2155,  601, 2643, 2024, 2627, 2620, 1260,
        2456, 3615, 2440, 3534])
Epoch: 788, Training Loss: 0.77, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 789 - Batch 1 ########################
IDs in batch 1: tensor([1639, 2721,  678, 2368, 2667, 3000, 3982, 2166,  398, 1445, 3634, 3166,
        4230, 3969, 2372, 4122])
Epoch: 789, Training Loss: 0.68, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 790 - Batch 1 ########################
IDs in batch 1: tensor([1469,   27,  534, 2652, 1977, 2727,  340, 2444, 2924, 3714,  316,   74,
         766, 3105, 1346, 2170])
Epoch: 790, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 791 - Batch 1 ########################
IDs in batch 1: tensor([1642,  797,  915,  434, 3492, 3478,  821, 1610, 2563,  340, 2133, 4175,
        4263, 3538, 3729, 2980])
Epoch: 791, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 792 - Batch 1 ########################
IDs in batch 1: tensor([2854, 3300, 1650, 2113, 2425, 1282, 3587, 2765, 2880, 1623, 2112, 3513,
        2943,  797, 1733, 3810])
Epoch: 792, Training Loss: 0.45, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 793 - Batch 1 ########################
IDs in batch 1: tensor([3858, 2849, 2535, 4120, 3972,  395, 2025, 2217, 1199, 2040, 1043, 1502,
        2050,  962,  846, 3449])
Epoch: 793, Training Loss: 0.54, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 794 - Batch 1 ########################
IDs in batch 1: tensor([2640, 1200, 1198,  422, 3797, 2375, 2350, 2551, 3376, 2431, 2691, 3529,
         292,  730,  631, 3246])
Epoch: 794, Training Loss: 0.73, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 795 - Batch 1 ########################
IDs in batch 1: tensor([3789, 1651, 1612, 3695, 1047,  517,  104, 1850, 3178, 2405, 2717, 4188,
        2179,  553, 3486,   30])
Epoch: 795, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 796 - Batch 1 ########################
IDs in batch 1: tensor([3003, 1623, 1171, 1209, 4012, 3836, 2776, 1753, 2730, 2998, 4094,  743,
         152, 4181, 4157, 1501])
Epoch: 796, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 797 - Batch 1 ########################
IDs in batch 1: tensor([2190, 2144, 3343, 2331, 4228,  866,    4, 2040, 3000, 2281, 3601, 2195,
        3727,  591, 3914, 3823])
Epoch: 797, Training Loss: 0.62, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 798 - Batch 1 ########################
IDs in batch 1: tensor([ 762, 3610,  787, 2636, 1658, 1720, 3495,  683, 3258, 2743, 4179,  505,
        1065, 2191, 1558, 3829])
Epoch: 798, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 799 - Batch 1 ########################
IDs in batch 1: tensor([2370, 3723, 3841, 3772,  874,  530, 1193, 2108, 1570, 3390, 2334, 3948,
        1107,  523, 3637,  269])
Epoch: 799, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 800 - Batch 1 ########################
IDs in batch 1: tensor([ 514, 3207,  545,  337, 3084,  490, 3105, 2980, 3246, 1823, 1456,  943,
        3614, 4261, 2517, 2111])
Epoch: 800, Training Loss: 0.67, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 801 - Batch 1 ########################
IDs in batch 1: tensor([1320,  630, 1537, 3458,  219, 3436, 3478, 1070, 2963, 1916, 3797, 1672,
        3757, 3298, 3036, 2682])
Epoch: 801, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 802 - Batch 1 ########################
IDs in batch 1: tensor([1083, 1959, 1665,  827, 1610,  444, 2558, 3480, 3926, 1647,  135, 1887,
         822,   86, 3917, 2038])
Epoch: 802, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 803 - Batch 1 ########################
IDs in batch 1: tensor([2670, 2004, 4173, 2572, 3421, 1700,  900, 3573, 2228, 2090, 1365, 1712,
        2984, 1991, 2539, 1444])
Epoch: 803, Training Loss: 0.68, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 804 - Batch 1 ########################
IDs in batch 1: tensor([3699, 3032, 1882, 3214, 1623, 2551, 3994, 2238, 2109, 4264, 2718, 3713,
         967, 3599,  132, 3265])
Epoch: 804, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 805 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 2848,  184, 3928, 2013,  340, 1092, 3328, 2551,  375, 2649, 3092,
        2672, 3178,  455, 2446])
Epoch: 805, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 806 - Batch 1 ########################
IDs in batch 1: tensor([3414, 4046, 4005, 2610, 2984, 3997,  355, 4093,  893,  976, 1862, 3135,
        2670, 2772, 3366, 3005])
Epoch: 806, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 807 - Batch 1 ########################
IDs in batch 1: tensor([3110, 2546,  849, 1970, 3016, 1784, 3004,  223,  265, 2484, 1126, 2271,
         776,   30, 3994, 1224])
Epoch: 807, Training Loss: 0.49, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 808 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 1916, 2350, 2688, 3900, 3168, 4088, 2094, 2088,  205, 2618, 1612,
        3387, 2181, 3591, 2794])
Epoch: 808, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 809 - Batch 1 ########################
IDs in batch 1: tensor([ 864,  129, 1027, 3139,  807,  530, 2467, 3323,   22, 4253,   74, 2108,
        3816, 1632, 2182, 4033])
Epoch: 809, Training Loss: 0.73, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 810 - Batch 1 ########################
IDs in batch 1: tensor([1467, 1181, 2172, 1219, 2317, 3057, 1553,  830,  617, 4220, 2488, 1770,
        1796, 4014, 2784, 1951])
Epoch: 810, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 811 - Batch 1 ########################
IDs in batch 1: tensor([2947, 2511, 1089,   59, 1575,  854, 3608,  152, 3094,  427,  398, 1819,
        2056,  348, 1517, 1269])
Epoch: 811, Training Loss: 0.49, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 812 - Batch 1 ########################
IDs in batch 1: tensor([1811, 3069, 2118, 2478, 2793,  855, 2462, 2379, 2114, 1104, 1976, 1545,
         212, 4146, 1882, 4152])
Epoch: 812, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 813 - Batch 1 ########################
IDs in batch 1: tensor([3726, 3601, 2122, 3500, 3180, 2125, 3984, 1617,  919, 1860, 3531, 1103,
        1949, 4187, 3542,  439])
Epoch: 813, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 814 - Batch 1 ########################
IDs in batch 1: tensor([1360, 1223,  730, 3729, 3330, 3975, 3037, 3369, 1381, 1110, 3938,  790,
        1393, 3993, 1047,  661])
Epoch: 814, Training Loss: 0.64, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 815 - Batch 1 ########################
IDs in batch 1: tensor([   7, 3074,  324, 1226, 1146, 1434, 2106, 3664, 3764, 2297, 2209, 2450,
        3440, 2780,  534,  393])
Epoch: 815, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 816 - Batch 1 ########################
IDs in batch 1: tensor([3389, 2449, 3732, 1558, 3452, 3746, 3028, 1384, 1113, 1371, 2827,  483,
        3648,  732, 3545, 1502])
Epoch: 816, Training Loss: 0.62, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 817 - Batch 1 ########################
IDs in batch 1: tensor([2285, 3461, 1543, 2717, 1212, 1990, 1310, 3016,  182, 3942, 2960,  714,
        2456, 4131, 1418, 3065])
Epoch: 817, Training Loss: 0.54, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 818 - Batch 1 ########################
IDs in batch 1: tensor([4203, 4015,  699, 1553,  662, 2950, 4190, 1918, 1745,  685,  262, 2758,
        1302, 3055,  785, 1083])
Epoch: 818, Training Loss: 0.59, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 819 - Batch 1 ########################
IDs in batch 1: tensor([1249, 3531, 3329, 2458, 3071,  323, 2967, 1267,  604, 2375, 1999, 2362,
        2908,  212, 4095, 1330])
Epoch: 819, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 820 - Batch 1 ########################
IDs in batch 1: tensor([4189, 1478, 3638, 2492, 1812, 2741,  407,  220,  117, 3409,  259, 1512,
        3342, 2402, 1231, 3516])
Epoch: 820, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 821 - Batch 1 ########################
IDs in batch 1: tensor([2125, 4225, 2682, 3856, 1635,  244,  623, 2257,  622,  769, 3989, 3615,
        3604, 4009, 3526, 2217])
Epoch: 821, Training Loss: 0.80, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 822 - Batch 1 ########################
IDs in batch 1: tensor([4061,  303,  988,  165, 1993, 3358, 3018, 2347, 2897,  558, 1157, 2291,
        2238,  794, 2610, 3590])
Epoch: 822, Training Loss: 0.64, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 823 - Batch 1 ########################
IDs in batch 1: tensor([2839, 4185, 2582, 2419, 2857, 3401, 1380, 3638, 1809, 3533, 2616, 2034,
        2717, 1287, 4240,  851])
Epoch: 823, Training Loss: 0.79, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 824 - Batch 1 ########################
IDs in batch 1: tensor([3439, 1784, 3841,  379, 3802,  568, 3995, 3497, 2957, 3235, 2110,  488,
        1753, 1125,  250, 3907])
Epoch: 824, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 825 - Batch 1 ########################
IDs in batch 1: tensor([3503, 3289, 1159, 1745,   61, 2733,  960, 1765,  191,  792,  140, 2824,
        3845, 1136, 1181, 1870])
Epoch: 825, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 826 - Batch 1 ########################
IDs in batch 1: tensor([1345, 4253, 1373, 3154,  977,   97,  613, 2041, 2354, 3202, 3677, 1842,
          96, 1885, 3688, 1077])
Epoch: 826, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 827 - Batch 1 ########################
IDs in batch 1: tensor([2339,  228, 1060, 3954, 2002, 2108, 1360, 3885, 2149, 3461,  324, 1385,
        4082, 3545, 4181,  994])
Epoch: 827, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 828 - Batch 1 ########################
IDs in batch 1: tensor([1257,  546, 2346, 1256, 2117, 2086,  923, 3704, 3754, 1920,   14, 1297,
        2652, 4238, 1263, 2866])
Epoch: 828, Training Loss: 0.49, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 829 - Batch 1 ########################
IDs in batch 1: tensor([4163, 2207,  721, 2670, 3993, 2166, 4078, 2736, 4222, 3200, 2034, 3124,
        1417, 1951,  412, 1605])
Epoch: 829, Training Loss: 0.55, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 830 - Batch 1 ########################
IDs in batch 1: tensor([ 483, 2097, 3882, 3180, 4238,  897, 1455,  476, 3051, 3071, 3738, 2391,
        1324, 3433,  127, 3310])
Epoch: 830, Training Loss: 0.46, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 831 - Batch 1 ########################
IDs in batch 1: tensor([1347, 1340, 4033, 3593, 1003, 2153, 3440, 4084, 3178,  478, 2154,   47,
         674, 4258, 1381, 1260])
Epoch: 831, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 832 - Batch 1 ########################
IDs in batch 1: tensor([1208, 3114, 1722,   84,  390, 2157, 2629,  767,  968, 1594, 2203, 1277,
        4156, 1626,  620,  623])
Epoch: 832, Training Loss: 0.62, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 833 - Batch 1 ########################
IDs in batch 1: tensor([3921, 3568, 1619, 4017,  541, 1440,  610, 3449, 3483, 3647,  485, 2402,
        2915, 1269, 2603, 1316])
Epoch: 833, Training Loss: 0.70, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 834 - Batch 1 ########################
IDs in batch 1: tensor([1289, 2708,  507, 1361,  217,  924, 3656,  635, 1755, 3113, 4033, 2542,
         324, 3963, 2500,  367])
Epoch: 834, Training Loss: 0.53, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 835 - Batch 1 ########################
IDs in batch 1: tensor([3663, 2860, 2696,  219, 3404,  862,  105,  937,   37, 2500,  496, 1119,
        3822,  201, 4251, 1708])
Epoch: 835, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 836 - Batch 1 ########################
IDs in batch 1: tensor([ 280,  185,  601, 2457, 1270,  547, 3211, 4163, 3446, 2391, 1499, 1380,
        3016, 4011, 1962, 1728])
Epoch: 836, Training Loss: 0.42, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 837 - Batch 1 ########################
IDs in batch 1: tensor([1208, 1410, 2087, 1167,  302, 3821,  108, 3701, 1086, 2108, 1417, 4038,
        1011,  289, 1177, 2028])
Epoch: 837, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 838 - Batch 1 ########################
IDs in batch 1: tensor([3971, 2238,   46,  622, 1093, 3091, 3418, 1649,  717,  947, 1218, 1168,
         159, 3962, 3960,  143])
Epoch: 838, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 839 - Batch 1 ########################
IDs in batch 1: tensor([3873,  593, 1985, 2475,   30, 3818, 1277, 2541,  952, 2841,  894, 3258,
        3446, 3418, 3755, 1104])
Epoch: 839, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 840 - Batch 1 ########################
IDs in batch 1: tensor([2870, 2134,  636, 3991, 2023,  419, 3914, 2242, 2256, 2701, 4168, 2615,
        4017, 1702, 3723, 2824])
Epoch: 840, Training Loss: 0.71, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 841 - Batch 1 ########################
IDs in batch 1: tensor([3404, 2749, 2375, 3351, 1413,  436, 1193, 3299,  606, 3888, 3544,  277,
        1308, 2812, 3926, 4013])
Epoch: 841, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 842 - Batch 1 ########################
IDs in batch 1: tensor([ 408, 1471, 3200,  582, 3812,  516, 1972,  815,  987,  566, 3743, 2008,
        2382, 3500, 2377, 3871])
Epoch: 842, Training Loss: 0.48, Validation Loss: 0.71, accuracy = 0.68
######################## Epoch 843 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 1762,  887, 3245, 3193, 3271,  656, 1236,  790,  351, 1185,  557,
        2519, 3178, 1636,  862])
Epoch: 843, Training Loss: 0.48, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 844 - Batch 1 ########################
IDs in batch 1: tensor([2730,  195, 1008, 3246, 1592, 1897, 2492, 3192,   96, 1551, 1910, 2619,
         942, 2505, 2028,  199])
Epoch: 844, Training Loss: 0.50, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 845 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 1980, 1660, 2640, 2671, 2248,  884,  834, 2044,  635, 3911, 1347,
        1108, 2581, 1954,  536])
Epoch: 845, Training Loss: 0.50, Validation Loss: 0.71, accuracy = 0.68
######################## Epoch 846 - Batch 1 ########################
IDs in batch 1: tensor([3543, 2809, 3647, 1496, 1317, 2894, 3427,  807, 1404,   47, 3417, 1417,
        2914,  825,  131,  131])
Epoch: 846, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 847 - Batch 1 ########################
IDs in batch 1: tensor([ 281,  225, 3418, 3760, 1034, 1817,  774, 4018, 4198,  470, 1763, 1552,
        2376, 3250, 3516,  606])
Epoch: 847, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.69
######################## Epoch 848 - Batch 1 ########################
IDs in batch 1: tensor([1373, 3734, 4061, 2383, 3509,   34, 3926,  425,  214, 2092, 1101, 2346,
        1286, 1434,  660, 3187])
Epoch: 848, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.69
######################## Epoch 849 - Batch 1 ########################
IDs in batch 1: tensor([1780,  110, 1656,  900, 1799, 1377, 2745,  300,  359, 1832, 4015, 3534,
        1991, 1804, 1453, 3630])
Epoch: 849, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 850 - Batch 1 ########################
IDs in batch 1: tensor([1180, 2797, 2429, 1340, 4110,  120, 2198, 1132, 2708, 1084, 2780, 3509,
         497, 2271,   78, 1222])
Epoch: 850, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 851 - Batch 1 ########################
IDs in batch 1: tensor([3885, 1316,  196,  651, 2999, 1073, 3114, 3635,  295,  947, 2287, 2049,
        3401, 3483, 2143, 4087])
Epoch: 851, Training Loss: 0.52, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 852 - Batch 1 ########################
IDs in batch 1: tensor([3898,  879, 2703, 2721, 3827, 1216, 3214, 2760, 2506, 4040, 2086, 1938,
        2292, 1480, 3971, 3697])
Epoch: 852, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 853 - Batch 1 ########################
IDs in batch 1: tensor([1039, 3057, 3112, 3192, 1591,  846,  730, 3755, 2815,  773, 1467, 2655,
        3436, 1830, 1012, 1182])
Epoch: 853, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 854 - Batch 1 ########################
IDs in batch 1: tensor([1010,  788, 1846, 2810, 3647, 3846, 2442, 1798, 3930, 2205, 1034, 2246,
        2161, 3025, 3245,  507])
Epoch: 854, Training Loss: 0.42, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 855 - Batch 1 ########################
IDs in batch 1: tensor([1681,  941,  181, 3102, 3368, 3863, 2819, 2334, 1067, 2529,  481, 1249,
         553,  234, 4115,  444])
Epoch: 855, Training Loss: 0.68, Validation Loss: 0.69, accuracy = 0.69
######################## Epoch 856 - Batch 1 ########################
IDs in batch 1: tensor([1269, 3594, 4246, 2649, 2655, 1499,  942, 4053, 2749, 2408, 3188, 1862,
         628, 2563, 4012, 3193])
Epoch: 856, Training Loss: 0.64, Validation Loss: 0.69, accuracy = 0.69
######################## Epoch 857 - Batch 1 ########################
IDs in batch 1: tensor([3743,  983, 3829, 3373,  507, 3914,  539, 1988, 2228,  376, 3261,  491,
        1173, 1824,  332,  465])
Epoch: 857, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 858 - Batch 1 ########################
IDs in batch 1: tensor([4038, 3486, 4263, 4226,   35, 2579, 2789,  128, 1453, 3587, 1051, 1121,
        3298, 1388, 3934, 1536])
Epoch: 858, Training Loss: 0.49, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 859 - Batch 1 ########################
IDs in batch 1: tensor([3650, 1213, 3379, 1193,  503, 2292,  687,  517, 4037, 3495,  996,  482,
        2092, 3157,  704, 1884])
Epoch: 859, Training Loss: 0.60, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 860 - Batch 1 ########################
IDs in batch 1: tensor([2362, 2551, 1982,  763, 4049,  980, 1158, 3473, 2553, 4127, 1488, 4009,
        2822, 2039, 1116,  402])
Epoch: 860, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 861 - Batch 1 ########################
IDs in batch 1: tensor([3608, 2604,  797, 2849,  666, 3950,  344,  987, 2161, 1702, 1024, 3377,
        1156,  198, 1716, 1575])
Epoch: 861, Training Loss: 0.59, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 862 - Batch 1 ########################
IDs in batch 1: tensor([3414, 1199, 4067, 2059,   73, 4159, 4113, 2118, 2122,  316, 3094,  866,
         161,   93, 2035, 4173])
Epoch: 862, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 863 - Batch 1 ########################
IDs in batch 1: tensor([1076, 1247,  990,  444, 1450, 1959,  264, 2500,  448,  718, 3035, 2309,
        3863, 1635, 1828,  786])
Epoch: 863, Training Loss: 0.53, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 864 - Batch 1 ########################
IDs in batch 1: tensor([ 896, 3386, 2053, 3926, 3535, 2798, 2840, 2382, 2070, 1736, 2109, 2337,
         278,  232, 2157, 2598])
Epoch: 864, Training Loss: 0.47, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 865 - Batch 1 ########################
IDs in batch 1: tensor([ 109, 3652, 1388, 1730, 2715, 3187, 2870, 2595, 1361, 3529,  699,  182,
        3157, 2094, 2352, 3833])
Epoch: 865, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 866 - Batch 1 ########################
IDs in batch 1: tensor([ 167, 3418, 1658, 1487, 1844, 1119,  730, 3190, 2052, 3192, 1414,  449,
        2990, 3234,    4, 3391])
Epoch: 866, Training Loss: 0.48, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 867 - Batch 1 ########################
IDs in batch 1: tensor([3386, 2832, 3509, 3718, 2522, 3936, 2157, 2796, 3570, 1413, 2358,  943,
        3871, 2183, 3268, 2437])
Epoch: 867, Training Loss: 0.66, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 868 - Batch 1 ########################
IDs in batch 1: tensor([ 454, 1181,  739, 3914, 1034, 2600,   96, 2646, 1144, 2124, 3162, 3183,
         595,  335, 2388,  318])
Epoch: 868, Training Loss: 0.30, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 869 - Batch 1 ########################
IDs in batch 1: tensor([1271, 2429, 4082, 1171, 3656, 3339, 1851, 1136,  757, 3821, 1168, 2584,
        2473, 4050,   52, 3922])
Epoch: 869, Training Loss: 0.82, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 870 - Batch 1 ########################
IDs in batch 1: tensor([1745,  517, 3406, 2304, 1198, 3999,  942, 1551,  808, 2701, 3473, 2758,
        2151, 3479, 2281,  262])
Epoch: 870, Training Loss: 0.42, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 871 - Batch 1 ########################
IDs in batch 1: tensor([ 622,  136,  892,  601, 3983,  960,  622,  395, 2629, 3604, 2256, 2795,
        2244, 2412, 1008, 1972])
Epoch: 871, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 872 - Batch 1 ########################
IDs in batch 1: tensor([4013, 1218, 2996,  262,  966, 3600, 3479, 2072, 1396, 2650,  226,  492,
        2195, 1734, 3721, 3785])
Epoch: 872, Training Loss: 0.65, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 873 - Batch 1 ########################
IDs in batch 1: tensor([ 553, 3102,  489,  183, 3391, 3185, 2620, 3037,  225, 4119, 1718, 1910,
        3436, 2895, 3456, 2726])
Epoch: 873, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 874 - Batch 1 ########################
IDs in batch 1: tensor([3105, 1530, 2891, 4065,    5, 3133, 4077,  714, 2650, 2455,  776, 3111,
         482, 3831, 2400, 3287])
Epoch: 874, Training Loss: 0.44, Validation Loss: 0.65, accuracy = 0.74
Save best Model_1 @ epoch 874 acc: 0.7432590855803048
######################## Epoch 875 - Batch 1 ########################
IDs in batch 1: tensor([1762, 3227, 2727, 3948,  407, 1139, 3891, 3813, 2228,  236, 3390, 1186,
        3701,  134,  149, 1292])
Epoch: 875, Training Loss: 0.74, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 876 - Batch 1 ########################
IDs in batch 1: tensor([1250, 4061, 1364, 3047,  950, 1566, 2844, 1823, 4105, 1789, 3204,  490,
        1128, 1384,  921, 1999])
Epoch: 876, Training Loss: 0.71, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 877 - Batch 1 ########################
IDs in batch 1: tensor([2180, 2014,  785, 1501, 2649, 1225, 1611, 1023,  265,  553, 3261, 1840,
        3982,  738, 2435, 4131])
Epoch: 877, Training Loss: 0.61, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 878 - Batch 1 ########################
IDs in batch 1: tensor([2984,   27, 3044, 2238, 2546,  926, 3572,  100, 1909,   37, 1860, 3257,
         117, 1258, 3453, 1551])
Epoch: 878, Training Loss: 0.39, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 879 - Batch 1 ########################
IDs in batch 1: tensor([ 335, 2839, 2366, 2328, 3256, 2182,  808,  904, 1506, 4089,  572, 3385,
        2937,  474, 1968, 1960])
Epoch: 879, Training Loss: 0.26, Validation Loss: 0.65, accuracy = 0.74
Save best Model_1 @ epoch 879 acc: 0.7444314185228605
######################## Epoch 880 - Batch 1 ########################
IDs in batch 1: tensor([ 795,  200,  376,  684, 1470, 2653,  681, 2354, 3199, 3804,  966, 2414,
        1578,  211, 3270, 3490])
Epoch: 880, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 881 - Batch 1 ########################
IDs in batch 1: tensor([4261, 1633, 2536, 2237, 2739,  337, 2993, 2796, 1084,  258, 1086, 3987,
        1817, 2788, 2453,  966])
Epoch: 881, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 882 - Batch 1 ########################
IDs in batch 1: tensor([1346, 3723,  921, 1186, 1173, 1452,  975, 1599, 3601,  394, 1548, 2417,
        1710, 3895, 2366, 2337])
Epoch: 882, Training Loss: 0.66, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 883 - Batch 1 ########################
IDs in batch 1: tensor([3754,   49,  219, 1089, 1588,  346, 3381,  727,  663, 3734, 3498, 2410,
        1296,  519, 2108,  278])
Epoch: 883, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 884 - Batch 1 ########################
IDs in batch 1: tensor([4163, 1297,  384, 3262,  992, 4235, 1842, 2497, 3468, 3290, 2443, 3677,
         536, 3744, 2505, 3423])
Epoch: 884, Training Loss: 0.70, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 885 - Batch 1 ########################
IDs in batch 1: tensor([ 735, 2141,  435, 1651, 3545, 2482, 1502, 3432, 4024,  225, 1266, 3399,
         513, 4122, 1166, 2809])
Epoch: 885, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 886 - Batch 1 ########################
IDs in batch 1: tensor([1895, 1949,  517, 2075, 3446, 4268,  330,   99, 2995, 1137,  201,  531,
        2788, 4061,  895,  921])
Epoch: 886, Training Loss: 0.48, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 887 - Batch 1 ########################
IDs in batch 1: tensor([1993, 1575, 1661, 1154,  726, 3369, 1229,  452, 3176, 1224, 4266, 3654,
        3954, 2603,  987, 1706])
Epoch: 887, Training Loss: 0.54, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 888 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 3204, 2256, 3547, 1933, 2485,  892, 3014,  644, 1496, 1845, 1970,
        2046, 1630, 1214,  321])
Epoch: 888, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 889 - Batch 1 ########################
IDs in batch 1: tensor([1118, 1341, 1455, 2680, 1747, 3973, 1772, 1685,  789, 4263, 4242, 1657,
         515,  395,  261,  485])
Epoch: 889, Training Loss: 0.82, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 890 - Batch 1 ########################
IDs in batch 1: tensor([3414,  408, 3429, 1618, 1491, 4144, 3718, 2568, 2938, 4156, 3474, 2524,
        3241, 4077,  558, 3780])
Epoch: 890, Training Loss: 0.67, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 891 - Batch 1 ########################
IDs in batch 1: tensor([3494, 2640, 3311, 3176, 2996,  159, 2847, 3360, 3259, 2697, 1247,  438,
        3038,  886, 3667, 4050])
Epoch: 891, Training Loss: 0.41, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 892 - Batch 1 ########################
IDs in batch 1: tensor([ 195, 1024,  126, 2316, 1753,  335, 2772, 3368, 1409,  483, 2497,  212,
        3530, 1497, 2598, 2610])
Epoch: 892, Training Loss: 0.41, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 893 - Batch 1 ########################
IDs in batch 1: tensor([2339, 1326,  651, 2853, 2519, 1099, 1467, 3713,  221, 1467,  893, 2583,
         252,  672, 3284,   88])
Epoch: 893, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 894 - Batch 1 ########################
IDs in batch 1: tensor([1509, 3834, 4004, 2400, 1331, 2605, 4175,  397, 1845, 4196, 3557, 2519,
        1530,  626, 1284, 3951])
Epoch: 894, Training Loss: 0.85, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 895 - Batch 1 ########################
IDs in batch 1: tensor([1004,  751, 1328, 3148, 4099,  371, 3369, 3006, 2961, 1641,  300, 1826,
        2399, 1923, 2773, 3772])
Epoch: 895, Training Loss: 0.53, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 896 - Batch 1 ########################
IDs in batch 1: tensor([2676,  477, 1722, 1214, 1428, 2600, 3425, 3472, 2885, 1592,  606, 2467,
        1208, 1363, 3816,  694])
Epoch: 896, Training Loss: 0.37, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 897 - Batch 1 ########################
IDs in batch 1: tensor([3160, 2458, 1962, 2986, 1291, 3020,  792,  610, 2461, 4037, 2627, 2178,
         198,  181, 1910, 1090])
Epoch: 897, Training Loss: 0.38, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 898 - Batch 1 ########################
IDs in batch 1: tensor([ 875,  736,  372, 1747, 2484, 4253, 3194,  513, 3718,  832,  607, 2418,
        1954,  949,   22, 3624])
Epoch: 898, Training Loss: 0.50, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 899 - Batch 1 ########################
IDs in batch 1: tensor([1158, 4180, 1655, 3753, 3452,  672, 3058,  138, 1959, 1285,  755,  278,
        4253, 3460, 3650, 1409])
Epoch: 899, Training Loss: 0.62, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 900 - Batch 1 ########################
IDs in batch 1: tensor([ 352, 1684, 3598, 2154, 1297, 1840, 2107, 1073, 2234,  969, 3875,  450,
        2035, 4212, 2666,  950])
Epoch: 900, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 901 - Batch 1 ########################
IDs in batch 1: tensor([3000, 1496, 2511, 2749, 2095, 2619, 1321, 2443,  199,  338,  394, 1075,
         985, 3954, 1030, 1525])
Epoch: 901, Training Loss: 0.52, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 902 - Batch 1 ########################
IDs in batch 1: tensor([ 691,  684, 3587,  213,  308,  946,  957, 2464, 3537, 2561,  220,  926,
        3898, 1774, 3790,  519])
Epoch: 902, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 903 - Batch 1 ########################
IDs in batch 1: tensor([ 649, 2005, 2874, 3964, 2879, 1795, 4185,  417, 3558, 1673, 1134, 2976,
        1509, 1518, 3428,  262])
Epoch: 903, Training Loss: 0.41, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 904 - Batch 1 ########################
IDs in batch 1: tensor([1548, 2660,  132, 2241, 2492, 2632, 1456, 2478, 3308, 3037,  691, 1088,
         977, 3299, 2835, 4067])
Epoch: 904, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 905 - Batch 1 ########################
IDs in batch 1: tensor([2666, 2260, 1887, 3245, 3755, 3808, 1179, 2676, 2472, 1069, 3990, 1092,
        1349, 1624,   97,   11])
Epoch: 905, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 906 - Batch 1 ########################
IDs in batch 1: tensor([1798, 3317, 2470, 3589, 1555,   11,  517, 4015,  139, 3672, 1088, 1880,
         205, 1624, 3441, 1944])
Epoch: 906, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 907 - Batch 1 ########################
IDs in batch 1: tensor([1052, 2537, 3298,  425, 1474,   30, 3126, 4174, 3729, 3240, 2563, 2458,
        2323, 2189,  985, 1453])
Epoch: 907, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 908 - Batch 1 ########################
IDs in batch 1: tensor([3031, 1367, 1426, 2968,  771,   95, 2091, 2107, 2951, 3025, 3655,  184,
        1419, 3328,  733,  890])
Epoch: 908, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 909 - Batch 1 ########################
IDs in batch 1: tensor([1718, 2449,  652, 3914,  338, 2365, 1087, 2292,  673, 2388, 1454, 2870,
        1671, 2364, 1233, 3729])
Epoch: 909, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 910 - Batch 1 ########################
IDs in batch 1: tensor([1558, 3168, 1360,  691, 2290, 1706, 2034, 1005, 2963, 1073,  628, 3573,
        4131, 2379, 2148, 1206])
Epoch: 910, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 911 - Batch 1 ########################
IDs in batch 1: tensor([ 610, 1291,  135, 3323, 3162, 3789,  788,  193, 4009, 1381, 1947, 1355,
        2620,  531, 3647, 1710])
Epoch: 911, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 912 - Batch 1 ########################
IDs in batch 1: tensor([3963, 4136, 4253, 2299,  996, 2291, 1264, 3704, 4254, 3120, 4046, 2011,
         127, 3928, 3044, 2402])
Epoch: 912, Training Loss: 0.91, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 913 - Batch 1 ########################
IDs in batch 1: tensor([ 337, 3564,  450, 2819, 3675, 2159,  997, 3417, 3114, 1731, 2260, 1984,
        3863, 2247, 1200, 2726])
Epoch: 913, Training Loss: 0.36, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 914 - Batch 1 ########################
IDs in batch 1: tensor([1458, 1385, 1352, 2859,  141, 2034, 4032, 2719, 2969,  974, 1569, 1911,
         714,  302, 3190, 1775])
Epoch: 914, Training Loss: 0.35, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 915 - Batch 1 ########################
IDs in batch 1: tensor([4097,  767,  257,   15, 2157,  869, 2401, 3369, 2858, 2171, 1472,  818,
        2179,  740,  829, 3671])
Epoch: 915, Training Loss: 0.33, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 916 - Batch 1 ########################
IDs in batch 1: tensor([3154, 1043,  895,  277, 3851, 3949, 1220, 1945, 2237,  223, 3120, 1665,
        3702, 1438,  360,  137])
Epoch: 916, Training Loss: 0.47, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 917 - Batch 1 ########################
IDs in batch 1: tensor([3621, 1496,  961, 2034, 3239, 2402, 1894, 1655, 2074, 1030, 2237, 2107,
        2731,  177,  346, 3573])
Epoch: 917, Training Loss: 0.81, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 918 - Batch 1 ########################
IDs in batch 1: tensor([1310, 1798, 2764,  866,  636, 1583, 3156, 1841, 3100, 4088, 3847,  996,
         897, 2615, 1467,  260])
Epoch: 918, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 919 - Batch 1 ########################
IDs in batch 1: tensor([1567, 1605, 3459, 3323, 2798, 3094, 3756, 1274, 1728,  352, 3366, 1988,
        1182, 3142, 2718, 1881])
Epoch: 919, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 920 - Batch 1 ########################
IDs in batch 1: tensor([  44, 1948, 2172, 2538,  105, 3409,  721, 4084,  180,  444, 1612, 2748,
         779, 2719, 2494, 3710])
Epoch: 920, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 921 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 2087,  527,  122,  214, 3308, 2426, 1811, 2477, 3999, 4131, 2117,
        2627, 2277, 3484, 3248])
Epoch: 921, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 922 - Batch 1 ########################
IDs in batch 1: tensor([ 995, 2521,  382, 3272, 2748, 2362, 1828,  342,  980, 3228, 2247, 1727,
        3505, 1872, 1065, 3391])
Epoch: 922, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 923 - Batch 1 ########################
IDs in batch 1: tensor([2582,  890,  356, 3585, 2572, 2537,  909, 1126,  306, 1751, 3485, 3206,
        4038,  316, 3451, 2951])
Epoch: 923, Training Loss: 0.55, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 924 - Batch 1 ########################
IDs in batch 1: tensor([3429, 3530, 3983, 3952, 1345, 2986,  681, 3178, 3949, 3822,  425, 2693,
        2749, 3651, 3199, 3922])
Epoch: 924, Training Loss: 0.80, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 925 - Batch 1 ########################
IDs in batch 1: tensor([2755, 1938,  651, 3465, 1072, 1419, 1121, 1390, 2775, 3211,  757,  649,
         134, 2109,   74, 3772])
Epoch: 925, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 926 - Batch 1 ########################
IDs in batch 1: tensor([ 200,  538, 1080, 4011, 1937, 1575,  666, 1990, 1198, 3504, 2669, 2117,
        1570,   82, 3333,  894])
Epoch: 926, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 927 - Batch 1 ########################
IDs in batch 1: tensor([ 223, 1643, 2656, 2026, 3993, 2739, 1256, 1779, 1222, 3286,  355, 2407,
        3797, 3370,  154,  391])
Epoch: 927, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 928 - Batch 1 ########################
IDs in batch 1: tensor([4267, 2604, 1730, 3391, 1921, 2156, 2410,  781,  946, 2832,  981,  848,
        1193, 3079,  899, 4251])
Epoch: 928, Training Loss: 0.74, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 929 - Batch 1 ########################
IDs in batch 1: tensor([2791,  181, 3597, 2476,  354, 1570, 4228, 2452, 1445, 3545, 1436, 1866,
        1080, 2726, 3920,  475])
Epoch: 929, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 930 - Batch 1 ########################
IDs in batch 1: tensor([2278, 1698, 4036, 2051, 1914, 3783, 2729, 2926, 3240,   19, 1877, 3115,
        2640, 4175, 2092, 3400])
Epoch: 930, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 931 - Batch 1 ########################
IDs in batch 1: tensor([4156,  628, 3219, 1222, 2708, 3712, 1765, 2441, 1436, 2553, 2860, 2425,
         234, 3327,   70, 1832])
Epoch: 931, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 932 - Batch 1 ########################
IDs in batch 1: tensor([3591,  573, 3950,  811,  928,  658, 3058,  815,  159, 1132, 2028,  757,
        3261,  578,  591,  282])
Epoch: 932, Training Loss: 0.49, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 933 - Batch 1 ########################
IDs in batch 1: tensor([ 640, 1037, 1177, 3875, 3208,  122, 3958, 1386, 4105, 4093, 3058, 4055,
        2246, 2934, 1372, 3813])
Epoch: 933, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 934 - Batch 1 ########################
IDs in batch 1: tensor([1432, 3252, 2629, 3267, 3592,  917, 3846,  985, 1233,  981, 3483,  531,
         582,  596, 1575, 3531])
Epoch: 934, Training Loss: 0.36, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 935 - Batch 1 ########################
IDs in batch 1: tensor([3648, 2740,  201, 1761, 1895,  112, 1490,  119, 2483, 1879, 3014, 2582,
        3558, 3982, 3767, 4172])
Epoch: 935, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 936 - Batch 1 ########################
IDs in batch 1: tensor([2279, 2703, 2836, 3488,  275, 1236, 3185,   68,  260, 1122, 1042, 2772,
        3885,  673, 3408, 3974])
Epoch: 936, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 937 - Batch 1 ########################
IDs in batch 1: tensor([ 213, 2688, 1754, 2567, 3139, 3983, 1141, 2017, 1119,   13, 2437,   68,
        1472,  494,  776, 1132])
Epoch: 937, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 938 - Batch 1 ########################
IDs in batch 1: tensor([ 980, 2541, 1484, 2908, 3084,  482, 2934,  899, 1934, 2415,  147,  324,
        4246, 1639, 2135,  887])
Epoch: 938, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 939 - Batch 1 ########################
IDs in batch 1: tensor([ 134,  129, 1518,  644, 1702, 3154, 1573, 1173, 2897, 1397, 2615, 1632,
         213, 2110, 3136, 4002])
Epoch: 939, Training Loss: 0.39, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 940 - Batch 1 ########################
IDs in batch 1: tensor([1753,  265,  151, 1455, 2056, 3790,  101, 4224, 1900, 1195, 1967,  613,
         928, 2892, 2837,  882])
Epoch: 940, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 941 - Batch 1 ########################
IDs in batch 1: tensor([ 281, 3378, 2314, 2884, 2506, 4116,   70,  181,   37,  448, 2578, 1511,
        3787, 2324, 3950,  251])
Epoch: 941, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 942 - Batch 1 ########################
IDs in batch 1: tensor([4254, 1499, 2198, 3934, 1553, 2272, 3902,  280, 1858, 3483, 3156, 4175,
        1012, 3664, 2516, 2015])
Epoch: 942, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 943 - Batch 1 ########################
IDs in batch 1: tensor([2364, 2453, 1278, 4005, 1453, 2405,  626, 3792, 1968, 4258, 3188, 2715,
        1986, 2217, 2656, 1600])
Epoch: 943, Training Loss: 0.63, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 944 - Batch 1 ########################
IDs in batch 1: tensor([2605,  213,  121, 4024,  537,  688, 1182,  427, 1851,  640, 1491, 2014,
        2548, 1083,  632, 3637])
Epoch: 944, Training Loss: 0.56, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 945 - Batch 1 ########################
IDs in batch 1: tensor([3541, 3473, 1794, 3507, 3727,  106, 3922, 3223, 2632, 3500, 3418, 2937,
        1351,  333, 3469, 3706])
Epoch: 945, Training Loss: 0.84, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 946 - Batch 1 ########################
IDs in batch 1: tensor([1387,   84, 2090,  244, 3542, 1220, 1552, 1588, 2290, 2347, 2297, 1833,
        1444, 2688, 3428,  850])
Epoch: 946, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 947 - Batch 1 ########################
IDs in batch 1: tensor([3658, 2835, 3607,  132, 4181, 1060, 1026,  260, 2894, 4013, 2291, 2942,
        2732, 3069, 4120, 2428])
Epoch: 947, Training Loss: 0.52, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 948 - Batch 1 ########################
IDs in batch 1: tensor([3357, 1574, 2369,  753,  407, 4199,  693, 3110,  220, 1487, 3802, 2031,
        2829, 2069,  639, 2945])
Epoch: 948, Training Loss: 0.43, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 949 - Batch 1 ########################
IDs in batch 1: tensor([2767, 3308, 2826, 1146,  971, 2423, 2352,  851, 4154,  804, 3885, 1786,
         237,  587,  747, 4077])
Epoch: 949, Training Loss: 0.55, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 950 - Batch 1 ########################
IDs in batch 1: tensor([1408, 2123, 1673, 3652, 4255, 2724, 3535, 3180, 1963,  372,  869, 1594,
        3300,  565, 2312,  642])
Epoch: 950, Training Loss: 0.30, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 951 - Batch 1 ########################
IDs in batch 1: tensor([1819, 3664,  261,   32, 1023, 1364, 1239, 4073, 1102, 1336,  526,  357,
        2615, 2329, 2836, 3495])
Epoch: 951, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 952 - Batch 1 ########################
IDs in batch 1: tensor([1842,  680, 2371, 1556, 1504, 2292, 2868, 1612, 2386, 2156, 3663, 3357,
        1351,  710, 2973,  986])
Epoch: 952, Training Loss: 0.51, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 953 - Batch 1 ########################
IDs in batch 1: tensor([1748, 1708, 1502, 3958, 1756, 1752,  516,  762, 2712, 1395, 1030, 3767,
         993,  141, 3762, 2176])
Epoch: 953, Training Loss: 0.65, Validation Loss: 0.64, accuracy = 0.72
######################## Epoch 954 - Batch 1 ########################
IDs in batch 1: tensor([ 978, 4105,  228, 3793,  487, 3802, 2649,  255, 2842, 3211,  875, 2996,
        3049, 2137, 2322, 3092])
Epoch: 954, Training Loss: 0.33, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 955 - Batch 1 ########################
IDs in batch 1: tensor([ 777, 3323,   26,  852, 4222, 3812, 2524, 3876, 4149, 1913, 3472, 2578,
        2966, 1284, 4076,  809])
Epoch: 955, Training Loss: 0.64, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 956 - Batch 1 ########################
IDs in batch 1: tensor([3700, 2367,  330, 1925, 1965, 2356, 2540, 2826,  714, 2327, 1633,  842,
        2857, 3688, 2087, 3120])
Epoch: 956, Training Loss: 0.73, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 957 - Batch 1 ########################
IDs in batch 1: tensor([3328, 1591, 3969, 2915,  332, 4095, 3600, 3764, 2645, 3351, 2413, 2860,
        1267, 3204,   61, 1043])
Epoch: 957, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 958 - Batch 1 ########################
IDs in batch 1: tensor([2508, 3291, 4115, 2387, 3980, 3523, 1693, 1123, 2518, 1355, 2621, 2522,
         376, 1904,   15, 1452])
Epoch: 958, Training Loss: 0.44, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 959 - Batch 1 ########################
IDs in batch 1: tensor([1264,  733, 4009, 3853, 1224,  554, 2689, 2487, 2871,  206, 3897,  419,
        2356, 3590, 3997, 2400])
Epoch: 959, Training Loss: 0.63, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 960 - Batch 1 ########################
IDs in batch 1: tensor([2827, 2461, 3548, 3760, 3185, 1601, 2406, 3667, 2951, 3358, 2605, 3688,
        2416, 1795, 3728, 3371])
Epoch: 960, Training Loss: 0.98, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 961 - Batch 1 ########################
IDs in batch 1: tensor([1176, 2589, 1315, 2873,  172, 1315,   32, 3178, 3459,  714, 3220, 2013,
        3071, 3367, 2344, 1548])
Epoch: 961, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 962 - Batch 1 ########################
IDs in batch 1: tensor([ 947, 2991, 2291, 3534, 3465, 1291, 2853, 2260,  111, 3200,  967, 1569,
        2656, 4257,  434, 1733])
Epoch: 962, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 963 - Batch 1 ########################
IDs in batch 1: tensor([3528,  135, 3744, 2924, 3434, 2391, 3018, 2765, 1118, 1594, 4157, 2819,
         701, 4175, 3483, 1089])
Epoch: 963, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 964 - Batch 1 ########################
IDs in batch 1: tensor([3372, 1595, 1097,  631, 2653, 3677, 3938, 2193, 3914, 3898,  578, 2793,
        3950, 3709,  591,  284])
Epoch: 964, Training Loss: 0.38, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 965 - Batch 1 ########################
IDs in batch 1: tensor([3117, 4061, 3143, 2856,  541, 1007, 3160, 3970, 1546, 1938, 3676, 1957,
        3488, 3705, 1428,  256])
Epoch: 965, Training Loss: 0.51, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 966 - Batch 1 ########################
IDs in batch 1: tensor([ 723, 3150, 3265, 3968, 1844,  356, 4194, 1285, 3583, 3037, 2579, 4038,
        4227,  596,  880,  219])
Epoch: 966, Training Loss: 0.62, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 967 - Batch 1 ########################
IDs in batch 1: tensor([3948, 4141,  245, 2067,  947, 2236, 2483, 2118, 1365, 2134, 1319, 3719,
        3389, 4036, 4236, 2344])
Epoch: 967, Training Loss: 0.51, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 968 - Batch 1 ########################
IDs in batch 1: tensor([3996, 4026, 1413,  213,  260, 1397,    7, 2005, 3278, 2344, 2095, 1640,
        1886, 4105, 2671, 3352])
Epoch: 968, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 969 - Batch 1 ########################
IDs in batch 1: tensor([ 653, 2575, 1001, 1163,  126, 2937, 1798,  330, 2244,  590, 1438, 1022,
        1009,  886,   15, 2391])
Epoch: 969, Training Loss: 0.33, Validation Loss: 0.65, accuracy = 0.75
Save best Model_1 @ epoch 969 acc: 0.7456037514654161
######################## Epoch 970 - Batch 1 ########################
IDs in batch 1: tensor([1991, 2845, 3180, 1116, 3588, 1278, 2178, 1367, 1083, 2751, 1716, 3947,
        1540, 1642,  341, 1596])
Epoch: 970, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 971 - Batch 1 ########################
IDs in batch 1: tensor([3052,  670, 2250, 4232, 3069, 3345, 3364, 4215,  377, 2559, 2794, 2218,
        1685,  672, 1130, 2770])
Epoch: 971, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 972 - Batch 1 ########################
IDs in batch 1: tensor([2013, 1120, 1779, 1812,  529, 3718, 1610, 1518, 1599, 3078, 1391,  894,
         563,   63, 1823, 1423])
Epoch: 972, Training Loss: 0.51, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 973 - Batch 1 ########################
IDs in batch 1: tensor([ 165,  985, 1852, 2957, 1862,  519, 1545, 1796, 2056, 1597, 3243,  387,
        3278, 3659,  376, 1200])
Epoch: 973, Training Loss: 0.24, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 974 - Batch 1 ########################
IDs in batch 1: tensor([ 409, 3837, 3460, 4002, 2582, 2251,  679,  451,  106,  351, 1755, 1458,
         930, 4172, 3729, 3357])
Epoch: 974, Training Loss: 0.53, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 975 - Batch 1 ########################
IDs in batch 1: tensor([4025, 3583, 2661, 2964,  320, 2262, 2825,  148,  883, 2983, 3952, 2306,
         670, 2341, 3874, 4103])
Epoch: 975, Training Loss: 0.42, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 976 - Batch 1 ########################
IDs in batch 1: tensor([3995, 1031, 2045, 2921, 1835,  348, 2462, 2822, 1530, 1870, 2379, 4251,
        1844, 2265,  198, 1857])
Epoch: 976, Training Loss: 0.62, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 977 - Batch 1 ########################
IDs in batch 1: tensor([3389,  660, 1167, 3002, 2496,  982, 3190,  990,  113,  747, 2653, 1428,
         258, 1016, 3444, 2691])
Epoch: 977, Training Loss: 0.62, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 978 - Batch 1 ########################
IDs in batch 1: tensor([ 160, 2413,  314, 4061, 3132, 1385, 4148,  646, 2417, 3746, 3785,  496,
        1266, 1716,  485, 3100])
Epoch: 978, Training Loss: 0.39, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 979 - Batch 1 ########################
IDs in batch 1: tensor([2153, 1878, 2316, 3610, 3433, 3339, 3423, 1727, 2738,  993, 2210, 4194,
        3810, 2681,  904, 2674])
Epoch: 979, Training Loss: 0.55, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 980 - Batch 1 ########################
IDs in batch 1: tensor([2689, 2603, 1658, 2280, 4039, 3654, 2441,  211,  324,  143, 1638, 3000,
        1819, 1028,  950, 3532])
Epoch: 980, Training Loss: 0.37, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 981 - Batch 1 ########################
IDs in batch 1: tensor([1526, 2655,  820, 4234, 3898, 3582,  947, 3628,  822, 4254, 2770, 2014,
        1942, 1576, 2963, 3706])
Epoch: 981, Training Loss: 0.55, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 982 - Batch 1 ########################
IDs in batch 1: tensor([1214, 4264, 2018, 2794, 3364,  435, 3328, 3879,  251, 4058, 2931, 2827,
        1083, 4134, 1779, 3211])
Epoch: 982, Training Loss: 0.50, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 983 - Batch 1 ########################
IDs in batch 1: tensor([3389, 1656, 1548, 3268, 4093, 3286, 1999, 1059, 1751,  432, 3193, 4003,
        2372, 3847, 2297, 3358])
Epoch: 983, Training Loss: 0.56, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 984 - Batch 1 ########################
IDs in batch 1: tensor([2190, 3698, 2218, 2784, 3259, 1335, 1937, 1914, 4166,  417, 2719, 1646,
        4158, 1126,  591, 2023])
Epoch: 984, Training Loss: 0.51, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 985 - Batch 1 ########################
IDs in batch 1: tensor([2245, 1130, 2410, 3180, 4234, 4086, 2851, 1324, 2352, 1128, 3885, 3004,
        2249, 4212, 1024,  795])
Epoch: 985, Training Loss: 0.39, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 986 - Batch 1 ########################
IDs in batch 1: tensor([  30, 3156, 4217, 4141, 4159, 2799, 3847, 2793,  469, 3894, 1641, 2099,
        1318, 2382, 3683, 1530])
Epoch: 986, Training Loss: 0.49, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 987 - Batch 1 ########################
IDs in batch 1: tensor([2973, 4236, 2015, 3516, 3465, 2892, 2469, 3634, 4086, 3648, 2752,  804,
        2023, 2098, 4030,  481])
Epoch: 987, Training Loss: 0.65, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 988 - Batch 1 ########################
IDs in batch 1: tensor([ 949, 3843, 3283, 2284, 4007, 1024, 1157,  623, 4033, 1097, 2804, 3992,
        3474, 2455, 2252, 1131])
Epoch: 988, Training Loss: 0.56, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 989 - Batch 1 ########################
IDs in batch 1: tensor([2232, 2337, 4094, 2641, 2446, 1502, 2805, 2510,   49, 1272, 1218, 4226,
        2075,  657, 1885,  121])
Epoch: 989, Training Loss: 0.47, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 990 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 1206,  131, 3568,  360, 1896,  813, 1156, 2575, 3912, 1671, 1006,
         921,  522, 3702, 3621])
Epoch: 990, Training Loss: 0.64, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 991 - Batch 1 ########################
IDs in batch 1: tensor([1060, 3548, 1974, 3375,  971,  975, 1273, 2199, 3485, 2924,  126,  127,
        1962, 2636, 1887, 2118])
Epoch: 991, Training Loss: 0.52, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 992 - Batch 1 ########################
IDs in batch 1: tensor([1526, 3527, 3245,  955, 2696, 2276, 1011, 4163, 1751, 1302, 1862, 4224,
        1166, 1887,  823, 2600])
Epoch: 992, Training Loss: 0.35, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 993 - Batch 1 ########################
IDs in batch 1: tensor([3427, 2118,  870, 3128, 4044, 2040, 2359, 3474, 4232,  547, 2207, 1134,
        3591, 1803, 4002, 3970])
Epoch: 993, Training Loss: 0.56, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 994 - Batch 1 ########################
IDs in batch 1: tensor([ 777, 3428, 3872,   44, 1517, 3635, 2312, 1511, 2592, 2717, 2004, 3489,
         730, 1332, 1310, 3826])
Epoch: 994, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 995 - Batch 1 ########################
IDs in batch 1: tensor([1289, 2459,  701, 3006, 2133,  590, 3314, 2189,  841,  335, 2142,  391,
        2126,  572,  834, 2650])
Epoch: 995, Training Loss: 0.39, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 996 - Batch 1 ########################
IDs in batch 1: tensor([2030,  636, 3493, 2771, 2326, 3767, 2023, 2870, 1345, 3250, 1041, 2231,
        3318,  959, 2592,  689])
Epoch: 996, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.75
Save best Model_1 @ epoch 996 acc: 0.7467760844079718
######################## Epoch 997 - Batch 1 ########################
IDs in batch 1: tensor([3891, 3334, 1525,  604, 3161, 1614, 3338, 1724, 3826,  811,  401,   56,
        3244,  523,  729, 2059])
Epoch: 997, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 998 - Batch 1 ########################
IDs in batch 1: tensor([4124, 3972, 2280, 4065, 1263, 1825, 3245, 1702, 3573, 3438, 1506, 1812,
        3888,  674, 1665, 2094])
Epoch: 998, Training Loss: 0.81, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 999 - Batch 1 ########################
IDs in batch 1: tensor([ 804, 3779,  804, 3243,  917, 1260, 3358, 3740, 1357, 2017,  243, 2099,
        1698, 2742, 2118, 2640])
Epoch: 999, Training Loss: 0.38, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1000 - Batch 1 ########################
IDs in batch 1: tensor([ 136, 3870, 2990, 2726, 1825, 2619,  530, 2765,  726, 1239, 2365, 4238,
        2167, 1782, 1951,  463])
Epoch: 1000, Training Loss: 0.50, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1001 - Batch 1 ########################
IDs in batch 1: tensor([3552,  639, 2480, 1284,  555, 1118,  456, 3178, 1638, 2721, 1219, 2369,
        3056, 2167, 2504, 3655])
Epoch: 1001, Training Loss: 0.28, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1002 - Batch 1 ########################
IDs in batch 1: tensor([4158, 3382, 1450, 3594, 3038, 2936,  324, 2026, 3697, 2371, 3823, 2385,
        1472, 3872, 2334, 2901])
Epoch: 1002, Training Loss: 0.51, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1003 - Batch 1 ########################
IDs in batch 1: tensor([1351,  950,  762,  956,  966, 1069, 3494, 3056,   10, 2892,  532, 3154,
        2943, 2523, 1231, 1773])
Epoch: 1003, Training Loss: 0.52, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1004 - Batch 1 ########################
IDs in batch 1: tensor([2060, 1866,  875, 3177,   63, 1450, 3441,   84, 2546, 2562,  109, 4175,
        3466, 3806, 2231, 2176])
Epoch: 1004, Training Loss: 0.28, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1005 - Batch 1 ########################
IDs in batch 1: tensor([2606, 2691, 1638, 3031, 1700, 2890, 3675, 3261,  893, 3306, 2880, 3985,
        1803, 2752,   20,  400])
Epoch: 1005, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1006 - Batch 1 ########################
IDs in batch 1: tensor([3075, 2736, 2674, 3498, 3262, 3693, 1140,  968, 2804, 2492, 1624, 2970,
        1892, 2432, 3375, 4146])
Epoch: 1006, Training Loss: 0.50, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1007 - Batch 1 ########################
IDs in batch 1: tensor([3771, 2537,  790, 1385, 3252,  334, 1679, 1356, 3943, 2989, 3047, 3317,
        2799, 4228, 2961,  419])
Epoch: 1007, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1008 - Batch 1 ########################
IDs in batch 1: tensor([3630, 2667,  508, 4110, 1862,  584, 4246,  247,   70, 3410,  276, 1242,
         275, 1030, 3731, 2603])
Epoch: 1008, Training Loss: 0.46, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1009 - Batch 1 ########################
IDs in batch 1: tensor([1566, 2899, 1567, 2995, 2824, 3635,  657, 1559, 2011, 3017,  632, 3833,
        4217, 2564, 3021, 1852])
Epoch: 1009, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1010 - Batch 1 ########################
IDs in batch 1: tensor([1766, 1244, 3683,  852, 3439, 2579,  259, 2727, 1157,  352,  770, 1391,
        3073, 2237, 2652, 2018])
Epoch: 1010, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1011 - Batch 1 ########################
IDs in batch 1: tensor([1512, 2493,  255,  247, 2894, 1786, 1868, 1364, 4080,  289, 2231, 3111,
        1862, 3002, 1812, 2841])
Epoch: 1011, Training Loss: 0.25, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1012 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2914, 2706, 4256, 3152, 2787,  214, 3130, 1176, 2052, 2764,  811,
        1959, 2011, 1121, 1103])
Epoch: 1012, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1013 - Batch 1 ########################
IDs in batch 1: tensor([1185, 2349,  825, 1131, 3303,  736, 4103, 2856, 2676, 1643,  333, 3744,
        3806, 1232, 1737, 2003])
Epoch: 1013, Training Loss: 0.38, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1014 - Batch 1 ########################
IDs in batch 1: tensor([3196, 2331, 2467, 3060, 3308, 3311,  812, 3557, 3467, 3017, 2313, 3585,
        1399,  816, 1956,  550])
Epoch: 1014, Training Loss: 0.50, Validation Loss: 0.64, accuracy = 0.75
Save best Model_1 @ epoch 1014 acc: 0.7479484173505275
######################## Epoch 1015 - Batch 1 ########################
IDs in batch 1: tensor([ 880, 3648, 3272, 1882,  883, 2511, 1387, 2028, 1025, 2150, 2291, 2989,
        3810, 3563, 3995,  968])
Epoch: 1015, Training Loss: 0.33, Validation Loss: 0.64, accuracy = 0.75
Save best Model_1 @ epoch 1015 acc: 0.7502930832356389
######################## Epoch 1016 - Batch 1 ########################
IDs in batch 1: tensor([1220, 2235, 2641, 2198, 3395, 2086, 4128, 3203,  892, 3886,   52, 2689,
        1886,  355,  663, 3827])
Epoch: 1016, Training Loss: 0.39, Validation Loss: 0.64, accuracy = 0.75
Save best Model_1 @ epoch 1016 acc: 0.7514654161781946
######################## Epoch 1017 - Batch 1 ########################
IDs in batch 1: tensor([ 941,   25, 1623, 3208, 3456, 2855,  606,  530,  846, 2828,  825, 2151,
        2436, 3372, 2800, 4144])
Epoch: 1017, Training Loss: 0.35, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1018 - Batch 1 ########################
IDs in batch 1: tensor([2601,  448, 3456, 2773, 3767, 1116, 1030, 3540, 3654, 3985, 3183, 1001,
        2253, 1954, 1583, 2022])
Epoch: 1018, Training Loss: 0.48, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1019 - Batch 1 ########################
IDs in batch 1: tensor([2777,  568, 4215, 3831, 2812, 2470, 4121, 3326, 3187, 3244,  515, 2363,
        3862, 1189, 3734, 2732])
Epoch: 1019, Training Loss: 0.46, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1020 - Batch 1 ########################
IDs in batch 1: tensor([3276, 2051, 2144, 1331, 2693, 3992, 1967, 2856, 3456, 3549,  424, 2760,
        2571,   95, 2681, 4166])
Epoch: 1020, Training Loss: 0.48, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1021 - Batch 1 ########################
IDs in batch 1: tensor([2390,  750,   47, 2439, 3514, 2871,  558, 3962, 3822, 3704,  250, 3705,
        4046,  588, 1190,  795])
Epoch: 1021, Training Loss: 0.78, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1022 - Batch 1 ########################
IDs in batch 1: tensor([2167, 3866, 2188, 4009, 1883, 1063, 3713,  496, 3757, 2103, 2838, 2253,
         812, 1445, 1672, 3321])
Epoch: 1022, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1023 - Batch 1 ########################
IDs in batch 1: tensor([ 362, 3879, 1404, 3020, 4046, 2709, 1410, 1495, 3214, 4222, 2545, 3364,
        1642,  515, 3598, 3636])
Epoch: 1023, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1024 - Batch 1 ########################
IDs in batch 1: tensor([1005,  218, 3157, 2198, 2934, 3499, 3082,  269, 3534, 2884, 1155, 2009,
        3829, 2571, 2564, 1519])
Epoch: 1024, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1025 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 3371,  362, 2371, 1419,  896, 3669, 2157, 3644, 1070, 1005, 1506,
        2238, 1934, 3507, 2895])
Epoch: 1025, Training Loss: 0.48, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1026 - Batch 1 ########################
IDs in batch 1: tensor([1481, 1185, 2155, 3866,  151, 4046, 1341, 1050, 3132, 2354,  508, 1185,
        1482, 1993, 1004,  147])
Epoch: 1026, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1027 - Batch 1 ########################
IDs in batch 1: tensor([1578,  537, 3275, 1822, 2710, 2148, 2393, 1204, 1499, 1022,  138, 1920,
        1553, 2313, 1345,  284])
Epoch: 1027, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1028 - Batch 1 ########################
IDs in batch 1: tensor([2505,  320, 2727, 3660,  269, 2831, 2028,  946, 3587, 2425,  263, 4195,
        2993, 1660, 1857, 4068])
Epoch: 1028, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1029 - Batch 1 ########################
IDs in batch 1: tensor([3114, 2459,  832,   46, 1870,  422, 2924, 4159, 3907,  155, 3015,  790,
        1761, 1263, 1736, 2498])
Epoch: 1029, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1030 - Batch 1 ########################
IDs in batch 1: tensor([2822, 1199, 3228, 3920, 1337, 2244, 1901, 3996, 4146, 4080, 3600,  388,
        1892,  574, 1004, 1247])
Epoch: 1030, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1031 - Batch 1 ########################
IDs in batch 1: tensor([3527, 3533, 3368,  139, 3858, 2855, 2806, 2482, 3472,  674, 4076, 3349,
        1088, 1296, 3763, 2343])
Epoch: 1031, Training Loss: 0.53, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1032 - Batch 1 ########################
IDs in batch 1: tensor([2989, 1065,  992,  511, 4118, 1841, 3558, 3534,  971, 2565,  482, 1282,
        3088, 1119, 1213, 2167])
Epoch: 1032, Training Loss: 0.40, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1033 - Batch 1 ########################
IDs in batch 1: tensor([4061, 2432, 3354,  729, 1320, 4223,  928, 3976, 2350,  846,  672, 4163,
        3876, 3558,  173, 3664])
Epoch: 1033, Training Loss: 0.56, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1034 - Batch 1 ########################
IDs in batch 1: tensor([2151, 1817, 2825, 4056, 2023,  290, 1711, 3970, 2784, 3693, 3938, 3496,
        2788, 1005, 1891,  359])
Epoch: 1034, Training Loss: 0.48, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1035 - Batch 1 ########################
IDs in batch 1: tensor([3650,  637, 4126, 1570,  816, 3279, 3448,  890, 2179, 3020, 3982, 4062,
        3355, 3739,  300,  558])
Epoch: 1035, Training Loss: 0.56, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1036 - Batch 1 ########################
IDs in batch 1: tensor([2051, 1812, 3351, 1678, 1028, 1143, 3357, 4086, 1568,  779, 1244, 1756,
        4025, 2550, 3875, 2615])
Epoch: 1036, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1037 - Batch 1 ########################
IDs in batch 1: tensor([2223, 3239,  150,  534, 4261, 1010, 3913, 1180, 4096, 1059,  915, 1081,
         971, 1428,  985, 2183])
Epoch: 1037, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1038 - Batch 1 ########################
IDs in batch 1: tensor([3113,   73, 1239, 1711,   37, 3715, 3304,  577, 3246,  913, 2044,  739,
         717, 1417, 2065, 2281])
Epoch: 1038, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1039 - Batch 1 ########################
IDs in batch 1: tensor([4242,  604, 1727, 3227,  670, 1496, 1189, 2199, 2244, 3481, 1276, 2709,
        1045, 1044, 3719, 2232])
Epoch: 1039, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1040 - Batch 1 ########################
IDs in batch 1: tensor([3381, 3200, 4258, 1655, 3312, 3521,  928, 3637, 1168, 1279, 3236, 1183,
        3832, 2137, 3303, 2601])
Epoch: 1040, Training Loss: 0.43, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1041 - Batch 1 ########################
IDs in batch 1: tensor([  64, 1641,  679, 2362, 2261,  660, 1119, 1999,  858, 2063,  682,  642,
        1390, 1836,  354, 1092])
Epoch: 1041, Training Loss: 0.63, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1042 - Batch 1 ########################
IDs in batch 1: tensor([2360, 1698, 2050,  369, 3282, 3903, 3109, 1126, 4008, 2748, 2648, 2993,
        4030,  835, 4085, 1047])
Epoch: 1042, Training Loss: 0.50, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1043 - Batch 1 ########################
IDs in batch 1: tensor([1636, 2674,  372,  659, 4214, 3846,  289,  830, 1555, 1389, 4050,  405,
        2509, 2480, 3343,  375])
Epoch: 1043, Training Loss: 0.59, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1044 - Batch 1 ########################
IDs in batch 1: tensor([1782,  587, 1219, 2681, 3432, 1868,  741, 2927, 1870, 2393, 3017, 3490,
        1914, 2480, 2858, 1451])
Epoch: 1044, Training Loss: 0.39, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1045 - Batch 1 ########################
IDs in batch 1: tensor([2661, 1646, 2784, 3728, 3417,  625, 1745,  305, 2789, 4203, 1676, 3389,
        2485, 2432, 3202, 1016])
Epoch: 1045, Training Loss: 0.46, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1046 - Batch 1 ########################
IDs in batch 1: tensor([3513, 2832, 2249, 2418, 3151, 2771, 2621,  936, 3607, 3310,  483,   81,
        4165,  956, 3424, 4033])
Epoch: 1046, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1047 - Batch 1 ########################
IDs in batch 1: tensor([4086,  631, 2565, 1076, 3218, 1832, 1536, 3015, 2748, 3706, 3907, 1134,
        3642,  415, 1902, 3696])
Epoch: 1047, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1048 - Batch 1 ########################
IDs in batch 1: tensor([1395, 3135, 3238, 2999, 1233, 2114, 4163, 2855, 1828, 1858, 1990, 2143,
        2661,  547,  659, 1894])
Epoch: 1048, Training Loss: 0.77, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1049 - Batch 1 ########################
IDs in batch 1: tensor([ 604,  949, 2390, 3399, 1589, 3261, 2151, 3088, 3432,   47, 1419, 1833,
        3333,  228, 3094, 2360])
Epoch: 1049, Training Loss: 0.36, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1050 - Batch 1 ########################
IDs in batch 1: tensor([2081,  566, 3538, 3016, 3853,  982,  393, 3798,  132, 1081,  109, 3123,
         555, 2603, 1789, 1367])
Epoch: 1050, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1051 - Batch 1 ########################
IDs in batch 1: tensor([1296, 1417,  120, 1047,  919, 3689, 2601, 1030, 3408, 1960, 1341, 3394,
        3928, 1066,  604, 2483])
Epoch: 1051, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1052 - Batch 1 ########################
IDs in batch 1: tensor([2176, 2891, 2346, 2838, 1916, 2874,  796, 3415, 2489,  670, 3282, 4096,
        3608, 3816,   62, 3988])
Epoch: 1052, Training Loss: 0.77, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1053 - Batch 1 ########################
IDs in batch 1: tensor([3618, 2605, 1960, 3312, 3771, 3272, 1751, 3833, 1891, 2322,  418, 1639,
        1480, 3739,  357, 1879])
Epoch: 1053, Training Loss: 0.43, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1054 - Batch 1 ########################
IDs in batch 1: tensor([  35, 4096, 1291, 2565,  356,  102,  769, 3692, 3109,  977, 2642, 4004,
        2572,  229, 1748, 1351])
Epoch: 1054, Training Loss: 0.37, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1055 - Batch 1 ########################
IDs in batch 1: tensor([3597, 1122, 1994, 1124, 2788, 3077,  259, 2866, 2115,  908,  325, 2784,
        2695,  250, 1031, 2171])
Epoch: 1055, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1056 - Batch 1 ########################
IDs in batch 1: tensor([3745,  582, 3469, 2010,   10, 3983, 2833, 3618, 4186, 1226,  154,  470,
        3474, 1204, 2011,  687])
Epoch: 1056, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1057 - Batch 1 ########################
IDs in batch 1: tensor([2578,  454, 1881, 2690, 2629, 3284,  750,  112, 2366, 3497, 3846,  185,
        1140, 1063, 4175,  936])
Epoch: 1057, Training Loss: 0.42, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1058 - Batch 1 ########################
IDs in batch 1: tensor([3593, 3441, 4266, 4242, 3536, 3856,   71, 1284, 1025, 3234,  312, 1748,
        1042,  346,  295,  497])
Epoch: 1058, Training Loss: 0.88, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1059 - Batch 1 ########################
IDs in batch 1: tensor([3262,  739, 1979, 1825, 3345, 1026,  133,   21, 2915, 1299, 2008,  617,
         322, 1760, 2812, 3495])
Epoch: 1059, Training Loss: 0.38, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1060 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 3334, 2872, 2415,  555, 1387, 3543,  490, 2400,  226, 3128,  120,
        3088,  881, 4119, 2257])
Epoch: 1060, Training Loss: 0.60, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1061 - Batch 1 ########################
IDs in batch 1: tensor([2847, 2137, 2697,  105, 3084,  412, 4180, 2804, 3851, 1450, 4003, 3738,
        4085, 1316,  343, 2371])
Epoch: 1061, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1062 - Batch 1 ########################
IDs in batch 1: tensor([3492, 3554,  833, 2655,  626, 3525, 3838, 3993, 2148,  554,  684, 1130,
        3495, 2858, 1252,  411])
Epoch: 1062, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1063 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 2601, 4002, 2274, 3902, 2696, 1166,   46, 1543, 3789, 2190, 3487,
        2223, 3453, 3417, 3345])
Epoch: 1063, Training Loss: 0.31, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1064 - Batch 1 ########################
IDs in batch 1: tensor([ 203,  813, 3088,  681, 2727, 3328, 3407, 2368,  275, 1345, 2457, 1157,
        1272, 3908, 3726, 3441])
Epoch: 1064, Training Loss: 0.16, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1065 - Batch 1 ########################
IDs in batch 1: tensor([ 843,   95, 1822, 2195, 2036, 2039, 3313, 2398, 3982, 1920,  781, 2109,
        3934, 3360, 2488, 2066])
Epoch: 1065, Training Loss: 0.50, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1066 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 1868,  776, 1627,  395, 3804, 3473, 1723,  401, 1473,  412, 1045,
        1275,  977, 2913, 2099])
Epoch: 1066, Training Loss: 0.59, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1067 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 2701, 2250, 3988, 1180, 2144,  522, 3751, 3968, 3642, 1423, 3150,
        1420,  259,  151, 3030])
Epoch: 1067, Training Loss: 0.40, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1068 - Batch 1 ########################
IDs in batch 1: tensor([1315, 2631, 1627, 3226, 1473, 3221, 3447, 3769,  857, 3994, 2375, 2763,
        4062, 2809, 1537, 2181])
Epoch: 1068, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1069 - Batch 1 ########################
IDs in batch 1: tensor([ 960,   37, 3017, 3570, 2618, 1781, 3950, 2802, 1075, 1247,  121, 3091,
        3272, 2581, 3461, 2156])
Epoch: 1069, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1070 - Batch 1 ########################
IDs in batch 1: tensor([3453, 1798, 1954, 2886, 3317, 1154, 3785, 1196, 2905, 1731,  236,  995,
         776, 2577, 4037, 1970])
Epoch: 1070, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1071 - Batch 1 ########################
IDs in batch 1: tensor([4258,  995, 4089, 3990, 2228,   14, 2681, 1846, 2002,  586,  733,  612,
        3627, 2120, 1031, 3676])
Epoch: 1071, Training Loss: 0.55, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1072 - Batch 1 ########################
IDs in batch 1: tensor([1396, 2161, 4017, 2348, 3220, 3711, 3693, 2166, 3461, 1959, 1459, 3185,
        2638, 1432, 1633, 1958])
Epoch: 1072, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1073 - Batch 1 ########################
IDs in batch 1: tensor([2552, 2202, 4229, 2127, 3181,  787, 3912, 3298,  766, 3014, 3183, 1604,
        2567, 2026, 3473, 2098])
Epoch: 1073, Training Loss: 0.58, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1074 - Batch 1 ########################
IDs in batch 1: tensor([ 198, 1804, 1784, 2212, 3756,  127, 2169,  827, 1841, 3391, 1704, 1275,
         965, 3410, 2822, 2172])
Epoch: 1074, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1075 - Batch 1 ########################
IDs in batch 1: tensor([3976, 2488, 3680, 3415, 2456, 3435, 1855, 3524, 1914, 4168,  351, 2590,
         959, 3060, 1755, 1842])
Epoch: 1075, Training Loss: 0.59, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1076 - Batch 1 ########################
IDs in batch 1: tensor([1952, 1736, 1250, 1373, 2709,  797, 2703,  127, 1947, 3178, 1141, 2019,
          86, 3037, 2087, 3250])
Epoch: 1076, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1077 - Batch 1 ########################
IDs in batch 1: tensor([2791, 3424, 1012, 2659, 1756,  949, 1287, 4140, 2748, 1110, 1657, 4060,
        1830, 3304, 2462,  280])
Epoch: 1077, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1078 - Batch 1 ########################
IDs in batch 1: tensor([3200, 1402, 3771,  763, 2046, 3057,  626, 1588, 3031, 1384,  279, 3407,
        2287, 4140, 1088, 2102])
Epoch: 1078, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1079 - Batch 1 ########################
IDs in batch 1: tensor([ 610, 4218, 3812, 2884, 2526, 2290,  424, 4005, 1961, 1868, 2441, 2316,
        1213, 2256, 4100, 1344])
Epoch: 1079, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1080 - Batch 1 ########################
IDs in batch 1: tensor([2908,   73, 3638, 3490, 4115, 3500,  977,  137, 2185, 4089, 2487, 3139,
        4196, 1225,  350, 1500])
Epoch: 1080, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1081 - Batch 1 ########################
IDs in batch 1: tensor([2954, 3822, 1899, 3660,  106, 3537,  593, 3545, 3807,   21, 1809, 4025,
        3406,  955, 3099,  320])
Epoch: 1081, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1082 - Batch 1 ########################
IDs in batch 1: tensor([ 649, 3904, 4140, 3652, 3802, 2134, 1682, 3227, 2431, 3394, 3907,  284,
        1498, 4131,  678, 1107])
Epoch: 1082, Training Loss: 0.54, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1083 - Batch 1 ########################
IDs in batch 1: tensor([3147,  530, 1548, 1214, 2696, 1125, 3945, 3084, 1404, 4217,  949, 1330,
        2260, 3436,  266, 3120])
Epoch: 1083, Training Loss: 0.58, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1084 - Batch 1 ########################
IDs in batch 1: tensor([3397, 2953,   85,  398, 1497, 2456, 1821, 3376,  673,  946, 3533, 3952,
        3159, 2236, 2280, 1008])
Epoch: 1084, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1085 - Batch 1 ########################
IDs in batch 1: tensor([2854,  218, 3494, 2821, 3084, 4121, 4264, 1870, 2791, 1578, 2826, 2663,
        2052, 3627, 4048, 1090])
Epoch: 1085, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1086 - Batch 1 ########################
IDs in batch 1: tensor([2416, 3548,  498, 1569, 1704, 4266,   84, 2193, 3787, 1967, 2689, 1397,
        2793, 2224, 3180, 2772])
Epoch: 1086, Training Loss: 0.39, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1087 - Batch 1 ########################
IDs in batch 1: tensor([1089, 2784, 3379, 2255,   70, 1154,  358, 3236,  243, 1489, 2541, 3505,
        2986, 1851, 1144, 3888])
Epoch: 1087, Training Loss: 0.34, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 1088 - Batch 1 ########################
IDs in batch 1: tensor([1708, 4078,  424,  623, 1222, 1627, 1663,  693, 2453, 1707,  971, 2856,
        1049,  378,  795,  662])
Epoch: 1088, Training Loss: 1.03, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1089 - Batch 1 ########################
IDs in batch 1: tensor([4223, 1578,  934, 1052, 1189, 2831, 3883, 3847, 1231,  335, 2386, 3851,
          34,   77,  786, 2664])
Epoch: 1089, Training Loss: 0.57, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1090 - Batch 1 ########################
IDs in batch 1: tensor([1949, 2851, 2183, 2982, 2456, 3996, 2144,  382, 1024,   41, 3453, 1866,
         688,  971, 3039, 3860])
Epoch: 1090, Training Loss: 0.50, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1091 - Batch 1 ########################
IDs in batch 1: tensor([2983,  907, 3287, 3928, 2487, 3484, 2743, 4176, 2476,  644, 3354,  568,
        1778, 2315, 3386, 2869])
Epoch: 1091, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1092 - Batch 1 ########################
IDs in batch 1: tensor([4062, 2895, 2809,  732, 3109,  243,  839, 3127,  573,  982, 3159, 3597,
        2936, 2577, 3895, 4044])
Epoch: 1092, Training Loss: 0.52, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1093 - Batch 1 ########################
IDs in batch 1: tensor([1103, 1627,  308,  996, 2024, 2375, 3847, 1257, 3771,  164,  393,  886,
        2999,  662, 1034, 1979])
Epoch: 1093, Training Loss: 0.51, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1094 - Batch 1 ########################
IDs in batch 1: tensor([3603, 1818, 2091, 3635,  834,  501, 3767, 4115, 2973,  852, 1756, 3081,
        2475,  826, 3829, 3763])
Epoch: 1094, Training Loss: 0.74, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1095 - Batch 1 ########################
IDs in batch 1: tensor([2615, 3895, 2185, 1183,   14,  102, 1530, 3495,  193, 1361, 3278, 2548,
        2398, 3552,  704, 1405])
Epoch: 1095, Training Loss: 0.26, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1096 - Batch 1 ########################
IDs in batch 1: tensor([2579, 2627, 3181, 2701, 1623, 2825, 3239, 3236, 1795, 3304, 3958, 3353,
        4133, 2470, 3614, 3435])
Epoch: 1096, Training Loss: 0.69, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1097 - Batch 1 ########################
IDs in batch 1: tensor([1039, 3028, 1103,  945, 2666, 3276, 2579,  824,   77, 1731, 2014, 2738,
        1204, 1794,  459, 3972])
Epoch: 1097, Training Loss: 0.46, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1098 - Batch 1 ########################
IDs in batch 1: tensor([1825, 2551, 3071, 1895, 3501, 1065, 3618,  122, 1390, 1558, 1576, 2322,
         926, 2712, 4060, 1965])
Epoch: 1098, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1099 - Batch 1 ########################
IDs in batch 1: tensor([3617, 2143,  510,  498, 2876,  426, 2022, 3279, 2494,  849, 1137,  427,
        3372, 1231, 2687, 2316])
Epoch: 1099, Training Loss: 0.59, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1100 - Batch 1 ########################
IDs in batch 1: tensor([  37, 1720, 1111, 1255, 1686, 1117, 2149,  530, 3474, 1834,  921, 3135,
        3600,  335, 1931,  143])
Epoch: 1100, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1101 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 1628, 1310,   32, 1506, 4214, 2278, 3765, 2484,  622, 2466, 2894,
        3349, 2832, 3497, 2788])
Epoch: 1101, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1102 - Batch 1 ########################
IDs in batch 1: tensor([3821, 2161, 3627, 1555, 3388, 1302,  778, 1421, 3182, 1267,   88,  321,
        3023, 1081, 4009, 2363])
Epoch: 1102, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1103 - Batch 1 ########################
IDs in batch 1: tensor([1204,  749, 4003,  247,  342, 1274, 4057, 4194, 3505, 3688, 2177, 4038,
        3369,  143, 4217, 4256])
Epoch: 1103, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1104 - Batch 1 ########################
IDs in batch 1: tensor([  98, 3256, 2663, 3463, 2605, 1935, 2609,  193, 2982, 1563, 2358, 3244,
        2632, 1884, 3644, 4217])
Epoch: 1104, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1105 - Batch 1 ########################
IDs in batch 1: tensor([1868, 1574,  949, 3480,  779, 2887, 4114, 4099, 3154, 2355, 2863, 2595,
         588,  375, 3327, 2949])
Epoch: 1105, Training Loss: 0.46, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1106 - Batch 1 ########################
IDs in batch 1: tensor([3241, 1257,  811,  399, 3616, 2134,  537, 2143,  954, 2027, 1841, 3598,
        2444,  501,  739, 2413])
Epoch: 1106, Training Loss: 0.48, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1107 - Batch 1 ########################
IDs in batch 1: tensor([1131, 2915, 1189, 1849, 3188, 3907, 3206, 1092,  232,  666,  851, 2464,
          47,  578, 2199, 2316])
Epoch: 1107, Training Loss: 0.30, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1108 - Batch 1 ########################
IDs in batch 1: tensor([3257, 1927,  704,  300, 3088, 2070, 1096, 1990, 3364,  890, 2703,   72,
        3692, 3279, 3109,  854])
Epoch: 1108, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1109 - Batch 1 ########################
IDs in batch 1: tensor([ 920,  565, 1585,  786, 3921, 2873, 3964, 1933, 3878, 2431, 3663,  205,
        1740, 3917, 2414, 3423])
Epoch: 1109, Training Loss: 0.51, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1110 - Batch 1 ########################
IDs in batch 1: tensor([2028, 2131,  555, 2761, 3199, 1345, 3358, 1779, 1693, 2672, 1405, 2262,
        2472, 2036, 3088, 2973])
Epoch: 1110, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1111 - Batch 1 ########################
IDs in batch 1: tensor([3552,   68, 3399, 2074,  484, 2458, 3751, 1038,  292, 2135, 2879, 3789,
        2245, 2965, 3098,  732])
Epoch: 1111, Training Loss: 0.28, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1112 - Batch 1 ########################
IDs in batch 1: tensor([2526, 2126, 3862, 2157,  607, 3428, 3029,   34, 4053,  171, 2591,  440,
         348, 2565, 3577,  312])
Epoch: 1112, Training Loss: 0.60, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1113 - Batch 1 ########################
IDs in batch 1: tensor([3497, 1200, 1954, 3265, 1404, 2999, 3577, 3030,  986, 1266, 4097, 2802,
        1090, 3921, 2447, 2537])
Epoch: 1113, Training Loss: 0.54, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1114 - Batch 1 ########################
IDs in batch 1: tensor([ 104, 4255, 1371, 3822, 1244, 2461,  252,  172, 3885, 2668, 3922, 1463,
        3713,  945, 1233, 4119])
Epoch: 1114, Training Loss: 0.90, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1115 - Batch 1 ########################
IDs in batch 1: tensor([2784, 3738, 2291, 3216, 3060,  627, 1610, 2254, 1882, 3755, 2741, 2667,
        1025, 2879, 3490,  262])
Epoch: 1115, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1116 - Batch 1 ########################
IDs in batch 1: tensor([2772, 1125, 4115,  467, 2394, 1383, 1208, 1160, 2924,  724, 3154,  455,
         904,  449, 1153, 1302])
Epoch: 1116, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1117 - Batch 1 ########################
IDs in batch 1: tensor([1828,  448, 3176, 3664,  842, 2002, 4242, 1410, 1573, 1634,  449, 2719,
         602, 3236,  778, 1010])
Epoch: 1117, Training Loss: 0.44, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1118 - Batch 1 ########################
IDs in batch 1: tensor([2363,  818, 1626,  205, 1818, 3872, 3707, 1684,  160, 1745,  834, 2247,
        3689, 1147, 3821,  678])
Epoch: 1118, Training Loss: 0.35, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1119 - Batch 1 ########################
IDs in batch 1: tensor([  59, 3270, 2966,  228, 2479, 2025, 3042,  462,  989, 3100, 4203, 1053,
        1088, 3836, 2121, 3710])
Epoch: 1119, Training Loss: 0.31, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1120 - Batch 1 ########################
IDs in batch 1: tensor([1309, 3505, 1005, 2287, 2870, 2210, 2646, 2821, 1962,  769, 1214, 1016,
        2053, 4188,  498, 1882])
Epoch: 1120, Training Loss: 0.25, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1121 - Batch 1 ########################
IDs in batch 1: tensor([3543, 1134, 2591, 3939, 2167, 4242, 1497, 3265, 1812, 1740, 1986, 1935,
        3706,  214, 1098, 1344])
Epoch: 1121, Training Loss: 0.26, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1122 - Batch 1 ########################
IDs in batch 1: tensor([3079, 1143, 4072, 1103, 1484, 3351,  333,  345,  362, 1385,  305, 3564,
        1331, 3700, 3732, 2016])
Epoch: 1122, Training Loss: 0.50, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1123 - Batch 1 ########################
IDs in batch 1: tensor([3539, 3640, 2661, 2655, 1490, 2772, 1530, 2339, 4186,  960, 1310,  102,
        2264, 4196,  738,  211])
Epoch: 1123, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1124 - Batch 1 ########################
IDs in batch 1: tensor([3723,  876, 3710, 2276, 3992, 1592,  968, 2457, 2246, 1054, 2550, 4230,
         826, 3246,  449, 3677])
Epoch: 1124, Training Loss: 0.72, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1125 - Batch 1 ########################
IDs in batch 1: tensor([1224, 1712, 1556,  723, 2137, 3926, 2412, 3845, 1386, 3632, 3675,  165,
        3436,  332, 1627, 3772])
Epoch: 1125, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1126 - Batch 1 ########################
IDs in batch 1: tensor([1364, 2098, 4144,  880, 2035, 2782, 1902, 3082, 1457,  155, 1826, 4009,
        1405, 3091,   46, 3187])
Epoch: 1126, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1127 - Batch 1 ########################
IDs in batch 1: tensor([2653, 3279, 3536, 3418, 2238, 1530, 2189, 1724, 3856, 3387, 1075, 4238,
        3495, 1373, 2499, 1220])
Epoch: 1127, Training Loss: 0.21, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1128 - Batch 1 ########################
IDs in batch 1: tensor([2546, 2371, 3557, 3049, 3342, 1306,  269,  482, 2835, 3651,  435, 2107,
        2231,   84,  681, 3952])
Epoch: 1128, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1129 - Batch 1 ########################
IDs in batch 1: tensor([ 591, 2734,  678, 4009, 1716, 1610, 3970, 1767,  481, 3907, 3933, 3282,
         790, 1552, 2538, 2290])
Epoch: 1129, Training Loss: 0.53, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1130 - Batch 1 ########################
IDs in batch 1: tensor([ 821,  590, 3743, 4172, 1330, 3387, 3832, 3271,  823, 3838, 2225, 2644,
        2114, 1517, 2253, 1272])
Epoch: 1130, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1131 - Batch 1 ########################
IDs in batch 1: tensor([ 497, 2937, 2016, 1836, 1139,  354, 3914, 3148, 3744, 3473, 2153, 2235,
        1897, 4186, 2964,  652])
Epoch: 1131, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1132 - Batch 1 ########################
IDs in batch 1: tensor([1183,   72,  225, 3505, 3525, 2498, 3994,  837, 2542, 4033, 3816, 3833,
        3749, 3837, 2995, 2265])
Epoch: 1132, Training Loss: 0.68, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1133 - Batch 1 ########################
IDs in batch 1: tensor([ 187, 1661, 1786, 3632,  574, 2737, 4002, 2969,  769,  224, 2646, 2997,
         332, 4018, 2473, 1231])
Epoch: 1133, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1134 - Batch 1 ########################
IDs in batch 1: tensor([2732,  367, 2022,  363, 2014,  463, 3475, 1024, 3993,   86, 2582, 1159,
        1665, 3554, 3509,   18])
Epoch: 1134, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1135 - Batch 1 ########################
IDs in batch 1: tensor([3208,  566,  520, 3235, 1044, 3471, 2733, 4057, 2577, 3524, 1284,  474,
        1171, 1279, 1384, 3262])
Epoch: 1135, Training Loss: 0.42, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1136 - Batch 1 ########################
IDs in batch 1: tensor([3590, 2425, 3538, 4174, 3998,  287, 1802, 2217, 1896, 3658,  946, 1481,
         913, 1798, 2650, 3377])
Epoch: 1136, Training Loss: 0.44, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1137 - Batch 1 ########################
IDs in batch 1: tensor([1704, 3600,  185, 3031, 1160, 1970, 1602, 1472, 3789, 2274,  961,  880,
        2869,  213, 3478, 2887])
Epoch: 1137, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1138 - Batch 1 ########################
IDs in batch 1: tensor([1020, 4095, 1878,  918, 2914,  617, 2300,  913, 2729, 2610, 1870, 2809,
        1702, 2741, 2116, 2605])
Epoch: 1138, Training Loss: 0.47, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1139 - Batch 1 ########################
IDs in batch 1: tensor([2624, 1225, 3378, 3028, 3661, 3846, 1319,  640,   38, 3483, 3846, 2805,
        1331, 3495,  747, 2075])
Epoch: 1139, Training Loss: 0.49, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1140 - Batch 1 ########################
IDs in batch 1: tensor([3342, 3286, 1879,  660, 3141, 1347, 2203, 3587,  469,   41, 1062, 1661,
        2016, 3757,  848, 2661])
Epoch: 1140, Training Loss: 0.48, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1141 - Batch 1 ########################
IDs in batch 1: tensor([4095,  796, 4100, 1015, 3374, 3406, 2603,  378, 1309, 2126, 1795, 1885,
        2690, 3656, 2974, 2709])
Epoch: 1141, Training Loss: 0.46, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1142 - Batch 1 ########################
IDs in batch 1: tensor([2809, 3669, 4077, 2493, 1841, 4105, 2019, 1518, 1955,  626, 4024, 2462,
        3406,  149,  214, 3162])
Epoch: 1142, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1143 - Batch 1 ########################
IDs in batch 1: tensor([3199, 2618, 3942, 2603, 2564, 1551, 1945, 1341,  649,  303,   62, 1337,
        2659, 2575, 4093, 2943])
Epoch: 1143, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1144 - Batch 1 ########################
IDs in batch 1: tensor([ 280, 1451, 1686, 3554, 2681, 4060, 2763, 3527, 1437, 2173,  779, 3608,
         879, 2203, 1414, 3984])
Epoch: 1144, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1145 - Batch 1 ########################
IDs in batch 1: tensor([ 822, 3663,  649, 1578, 2262, 3154, 3179, 1286, 3683, 3558, 2973, 1982,
        2687, 2907, 1961, 2504])
Epoch: 1145, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1146 - Batch 1 ########################
IDs in batch 1: tensor([3426, 2989,  620, 3587, 2721, 3545, 4189, 2414, 3760,   26,  921, 1772,
        1474, 3410, 3642, 2936])
Epoch: 1146, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1147 - Batch 1 ########################
IDs in batch 1: tensor([  37, 1057,  963,  161, 2827,  190, 1102, 2278,  763, 2692, 3424,  119,
        1138,  822,   34,  357])
Epoch: 1147, Training Loss: 0.47, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1148 - Batch 1 ########################
IDs in batch 1: tensor([2355, 1526, 3516, 4110, 3860, 1196, 3343,  986, 3220, 1651,  909, 2574,
         902,  484, 1766,  354])
Epoch: 1148, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1149 - Batch 1 ########################
IDs in batch 1: tensor([1760,  332, 1824, 3272, 1182, 1437, 1519,  368, 2691, 3558, 1778, 1399,
        2343, 3692, 2013, 3004])
Epoch: 1149, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1150 - Batch 1 ########################
IDs in batch 1: tensor([2358, 3995,  390, 4135, 4159, 3628, 2301, 4222, 3499, 2821, 4161, 3507,
        3357,  205, 3987, 3353])
Epoch: 1150, Training Loss: 0.73, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1151 - Batch 1 ########################
IDs in batch 1: tensor([1289, 2777, 2472,  980, 3816,   71, 3368, 2344, 2156, 2284, 2133,   27,
         245, 2286, 3463, 3493])
Epoch: 1151, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1152 - Batch 1 ########################
IDs in batch 1: tensor([2523,  100,  881, 1088, 2137, 3499,  556, 2230,  884, 1464, 3749, 3693,
         402, 2371, 3912, 2189])
Epoch: 1152, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1153 - Batch 1 ########################
IDs in batch 1: tensor([3726,  710, 1206, 1247, 1195, 3121, 1318, 3353, 2965, 4117, 2483,  523,
        4212, 2775, 2256, 1553])
Epoch: 1153, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1154 - Batch 1 ########################
IDs in batch 1: tensor([1802, 1020, 2166, 3853,  340,  426, 1175, 1440, 3810, 2951,  345, 2885,
        1469, 2797, 3831, 2824])
Epoch: 1154, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1155 - Batch 1 ########################
IDs in batch 1: tensor([ 122, 4143,  202, 1418, 3521, 2181, 3391, 1628, 1017, 3935, 3676, 3675,
        2796,  730, 1415, 3208])
Epoch: 1155, Training Loss: 0.40, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1156 - Batch 1 ########################
IDs in batch 1: tensor([3853, 2346,  346,  108,  752, 2951,  842, 3021, 3797, 3669, 1799, 1326,
        2195, 1938, 1597,   51])
Epoch: 1156, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1157 - Batch 1 ########################
IDs in batch 1: tensor([ 482, 1809, 1959, 3433, 2036,  113,  926,  732, 1157, 2927, 3235,  604,
        1495,  804,  360,    7])
Epoch: 1157, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1158 - Batch 1 ########################
IDs in batch 1: tensor([3150, 4089, 1199, 1374, 1325, 2523, 2838,  602, 2124, 1200, 1916,  503,
        3371, 3599, 2874, 2616])
Epoch: 1158, Training Loss: 0.31, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1159 - Batch 1 ########################
IDs in batch 1: tensor([3812, 3262, 1090,  456, 3345, 2793,  152, 1849, 1334, 1585, 2783, 2245,
        4157, 3656, 3567, 1155])
Epoch: 1159, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1160 - Batch 1 ########################
IDs in batch 1: tensor([1545, 2299, 1952, 1781, 2372, 4230, 3265, 4148, 2034, 1322,  252, 2400,
        1200,  631, 1628, 3399])
Epoch: 1160, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1161 - Batch 1 ########################
IDs in batch 1: tensor([1231, 3572, 2080, 1700,  852, 1699,  531, 2555, 3989, 4195,  139, 3407,
        1283,  822, 3466, 4149])
Epoch: 1161, Training Loss: 0.50, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1162 - Batch 1 ########################
IDs in batch 1: tensor([4080, 1267,  281,  300, 2536, 2271,  660, 4024,  456,  160,   37,  359,
        3075, 1591, 3494, 3042])
Epoch: 1162, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 1163 - Batch 1 ########################
IDs in batch 1: tensor([2494, 3648, 1921, 1009,  968, 3267, 3339, 3473,   11, 4228,   96,  488,
        1092, 2030,  995, 2244])
Epoch: 1163, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1164 - Batch 1 ########################
IDs in batch 1: tensor([  27, 4078,   98,  371, 2973, 1156, 1200, 2480, 2272, 2954, 2493,  494,
        2050,  732,  660, 1512])
Epoch: 1164, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1165 - Batch 1 ########################
IDs in batch 1: tensor([1763, 2966, 2836, 1784, 2027,  232, 2484, 2636, 1746, 4046, 3501, 1755,
        3707, 3144,  102, 2915])
Epoch: 1165, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1166 - Batch 1 ########################
IDs in batch 1: tensor([2601, 3753, 3091, 3386, 2368, 3513, 1573, 1212, 2546, 4110, 3118,  236,
        1590, 1600,  463, 3120])
Epoch: 1166, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1167 - Batch 1 ########################
IDs in batch 1: tensor([4117, 1166, 4096, 2332, 1224,  219,  919, 1639, 2031, 1103, 3925, 3732,
        2703,  515, 1817,  646])
Epoch: 1167, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1168 - Batch 1 ########################
IDs in batch 1: tensor([3654, 1569, 2758,  507, 1650, 2794, 2575, 4110, 1614, 2151, 2090, 1312,
         644,  306, 2046, 2606])
Epoch: 1168, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1169 - Batch 1 ########################
IDs in batch 1: tensor([2447, 1982,  651, 1007, 2940, 2176, 2643,  787, 2284, 3728, 2925, 2598,
        2773, 3728, 1406, 3719])
Epoch: 1169, Training Loss: 0.49, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1170 - Batch 1 ########################
IDs in batch 1: tensor([3764, 1047, 3002, 1429,  969, 3391, 2060,  797, 2520, 2320, 2919, 3681,
        3386, 4203, 2606, 3376])
Epoch: 1170, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1171 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 1885, 3321, 1231, 1464, 3843, 2300, 2780,  333, 2504,  555, 2771,
         367, 1247, 1845, 2805])
Epoch: 1171, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1172 - Batch 1 ########################
IDs in batch 1: tensor([3732,  631, 2477, 3538, 1458,  529, 2081, 2171, 3374, 1548,  603, 4025,
        1155, 3762, 1201, 1633])
Epoch: 1172, Training Loss: 0.53, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1173 - Batch 1 ########################
IDs in batch 1: tensor([1491, 3496,  622, 3465, 2697, 1336, 2356, 1970, 1481, 1157,  335, 2386,
        2322, 2451,  511,  926])
Epoch: 1173, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1174 - Batch 1 ########################
IDs in batch 1: tensor([ 816, 3803, 2112,  982, 2375, 4005,  788, 1320,  828, 1075, 4240, 3123,
         749, 1251, 2748, 3351])
Epoch: 1174, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1175 - Batch 1 ########################
IDs in batch 1: tensor([2367, 2664,  452, 2008, 1381, 2192, 1325, 3113, 2840, 1365, 4110, 2945,
         357, 2205, 3644, 1406])
Epoch: 1175, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1176 - Batch 1 ########################
IDs in batch 1: tensor([2426, 1526, 2545, 2604, 3746, 1195, 3469, 3554,  947, 2536, 2709, 4230,
        3337, 3337, 1737, 1291])
Epoch: 1176, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1177 - Batch 1 ########################
IDs in batch 1: tensor([2936, 3652, 1025,   25,  261, 3114, 2316, 3073, 2555, 2824, 3902, 3283,
        1764, 3021, 3718, 1130])
Epoch: 1177, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1178 - Batch 1 ########################
IDs in batch 1: tensor([2838, 1774,  221,  137, 1159,  202, 4203,  405,  522, 2540, 2235, 1677,
        3713, 1824, 2228, 2342])
Epoch: 1178, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1179 - Batch 1 ########################
IDs in batch 1: tensor([2238, 1437, 2278,  126,  680, 4069, 2414,  678, 2876, 2907, 2036, 1083,
        2545,  295, 3569, 1119])
Epoch: 1179, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1180 - Batch 1 ########################
IDs in batch 1: tensor([2847, 1434, 4181, 3483, 2282,  758, 2203, 3667, 1711, 2666, 1045, 1810,
        3255, 2337,  913, 4014])
Epoch: 1180, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1181 - Batch 1 ########################
IDs in batch 1: tensor([3764, 2767,  771, 2763, 2297,  919, 3187, 1956,  991,  511, 4236,  160,
        1559,  405,  747, 1439])
Epoch: 1181, Training Loss: 0.37, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1182 - Batch 1 ########################
IDs in batch 1: tensor([4089, 2926, 2473, 1773, 3456, 2539, 2980, 3060, 1536, 3960, 2193, 1373,
        2863, 1737,  284, 1938])
Epoch: 1182, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1183 - Batch 1 ########################
IDs in batch 1: tensor([2301,  615, 2192,  225, 1932, 1828, 2805, 2238, 1737, 2126, 3723, 2156,
         918, 2678, 2357,  910])
Epoch: 1183, Training Loss: 0.39, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1184 - Batch 1 ########################
IDs in batch 1: tensor([1118, 3010, 3345, 4114, 2842, 1620,  262, 1578, 1591, 2548, 2880, 1404,
        4184, 2178, 2173, 3733])
Epoch: 1184, Training Loss: 0.33, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1185 - Batch 1 ########################
IDs in batch 1: tensor([1463, 2118, 2044,  978, 3702, 3017, 3039, 1540, 1993, 3451,  264,  187,
        1975, 1576,  523, 4115])
Epoch: 1185, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1186 - Batch 1 ########################
IDs in batch 1: tensor([2499, 3056, 1786, 2902, 1015,   43, 2652, 3640, 2049,  985, 3726, 4258,
         401, 1512, 2986, 1904])
Epoch: 1186, Training Loss: 0.23, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1187 - Batch 1 ########################
IDs in batch 1: tensor([2809, 3311, 1660,  555, 3073, 1860, 2075, 2212, 2018, 1198, 2053,  789,
         239, 1660, 3123, 3960])
Epoch: 1187, Training Loss: 0.46, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1188 - Batch 1 ########################
IDs in batch 1: tensor([3731, 1274, 3949, 2717, 2648, 2652, 2193, 1641, 1419, 3253, 4136, 2579,
        1183,  661,   44, 3982])
Epoch: 1188, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1189 - Batch 1 ########################
IDs in batch 1: tensor([3160, 3552, 2133, 3234, 3071, 3099, 2819, 4046, 1551, 1699, 1204,  992,
        1648, 3973, 1634, 1263])
Epoch: 1189, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1190 - Batch 1 ########################
IDs in batch 1: tensor([2419, 1005, 1070, 2466,  590, 1971, 4105, 3056,  305, 4017, 3081,  967,
         352, 1882, 2339, 3430])
Epoch: 1190, Training Loss: 0.31, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1191 - Batch 1 ########################
IDs in batch 1: tensor([3950,  839, 4073,   50, 2476, 1179,  256, 1756, 3992,  214, 2446, 3081,
        2583, 1861, 2299, 3474])
Epoch: 1191, Training Loss: 0.29, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1192 - Batch 1 ########################
IDs in batch 1: tensor([3961, 1102, 3368,  375, 1089, 3588, 3527, 3683,  424, 2794,  814, 2103,
        3905, 3226, 1270, 1736])
Epoch: 1192, Training Loss: 0.52, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1193 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 1803, 3823,  572, 3557, 1763, 3126, 2745,  527, 3333, 1953, 1552,
        3102, 3516,  127,  259])
Epoch: 1193, Training Loss: 0.19, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1194 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 4103, 3373, 1453, 4121, 3119, 3142, 3124,  855, 1199, 4078, 2845,
         623, 3951, 3658, 3499])
Epoch: 1194, Training Loss: 0.59, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1195 - Batch 1 ########################
IDs in batch 1: tensor([2120, 1090, 2018, 1356, 4188,   52, 3261, 4038,  147, 3148, 2715, 1951,
         961, 1223, 2842, 2155])
Epoch: 1195, Training Loss: 0.19, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1196 - Batch 1 ########################
IDs in batch 1: tensor([2191, 3711, 3144, 3934, 3338,    4, 1334, 2526, 1748,  315, 3337, 1716,
        3091, 1706, 2945, 1448])
Epoch: 1196, Training Loss: 0.16, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1197 - Batch 1 ########################
IDs in batch 1: tensor([1866, 2739, 1570, 4050, 2749, 1442, 2228, 1132,  892, 3658, 1818, 1959,
        2614, 1178, 2860, 3120])
Epoch: 1197, Training Loss: 0.31, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1198 - Batch 1 ########################
IDs in batch 1: tensor([2789, 1201, 1849, 1234, 1821, 3151,  140, 1921,  265, 1044, 2328, 2537,
        1290,  733,  971, 2488])
Epoch: 1198, Training Loss: 0.27, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1199 - Batch 1 ########################
IDs in batch 1: tensor([ 483, 1996, 1498, 4033, 2347, 2052, 2488,  145,  337,  260, 3885, 1700,
         848, 2709, 3912, 3739])
Epoch: 1199, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1200 - Batch 1 ########################
IDs in batch 1: tensor([3962, 1595,  674, 2090, 4218, 3060,  620, 2505, 3162, 2231, 1680, 4255,
        2506, 2236, 3418, 3161])
Epoch: 1200, Training Loss: 0.48, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1201 - Batch 1 ########################
IDs in batch 1: tensor([  93, 1080, 2976, 1596,  583, 3933, 1182, 1120, 3102, 3391, 3496, 2973,
        4158, 1355, 1933, 1711])
Epoch: 1201, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1202 - Batch 1 ########################
IDs in batch 1: tensor([2761,  317, 1782, 2783,  888, 2229,  180,  419, 2597, 1415,  172, 2367,
         324,    7, 2436, 4048])
Epoch: 1202, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1203 - Batch 1 ########################
IDs in batch 1: tensor([2181, 3040,  393, 1294, 3907,  820,  796,  778,  767, 2313,  573,  274,
        3914, 1415,  211, 3406])
Epoch: 1203, Training Loss: 0.48, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1204 - Batch 1 ########################
IDs in batch 1: tensor([3423, 1551, 4249, 3894, 1474, 4033, 2949,  413, 2523, 3072, 4037, 1632,
         945,  523,  774, 2670])
Epoch: 1204, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1205 - Batch 1 ########################
IDs in batch 1: tensor([1562, 1276, 2045, 2360, 4038, 2771,  937, 2510, 2059,  687, 1054,  767,
        1751, 1958,  756, 2546])
Epoch: 1205, Training Loss: 0.57, Validation Loss: 0.65, accuracy = 0.72
######################## Epoch 1206 - Batch 1 ########################
IDs in batch 1: tensor([3597, 3977, 2097, 3827, 1962, 2838, 1728, 2013, 4228,  835,  150,  237,
        1015, 2508, 2739, 3908])
Epoch: 1206, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1207 - Batch 1 ########################
IDs in batch 1: tensor([3168, 1186, 3998, 2466, 2838, 2583, 1802, 3498, 3862, 2709, 1984,  805,
         357,  113, 1322, 3509])
Epoch: 1207, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1208 - Batch 1 ########################
IDs in batch 1: tensor([1335, 2046, 1351, 3124, 1682, 1395, 1087,  330, 2866,  122, 3936, 1287,
        2550, 3119, 1039, 1041])
Epoch: 1208, Training Loss: 0.28, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1209 - Batch 1 ########################
IDs in batch 1: tensor([1764,  822, 1132, 1894,  627, 2207, 3554, 1780,  161, 3577,  732, 3926,
         550, 3241, 4238, 2133])
Epoch: 1209, Training Loss: 0.39, Validation Loss: 0.64, accuracy = 0.72
######################## Epoch 1210 - Batch 1 ########################
IDs in batch 1: tensor([4086, 2228, 3340, 1970, 3371, 3052,  167,  640, 3264,   71,  879, 1754,
        3699, 3262,  590, 2217])
Epoch: 1210, Training Loss: 0.27, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1211 - Batch 1 ########################
IDs in batch 1: tensor([3058, 2616,  193,  456, 1057,  874, 3448,   82,  871, 3306, 3449, 3371,
        2709, 1573,  434, 2218])
Epoch: 1211, Training Loss: 0.29, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1212 - Batch 1 ########################
IDs in batch 1: tensor([1371, 3399, 3434,  900, 1311, 3652, 1387, 2582,   27, 2379, 2151, 4014,
        2108,  605, 4166, 3069])
Epoch: 1212, Training Loss: 0.37, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1213 - Batch 1 ########################
IDs in batch 1: tensor([3712, 1846, 3327,  132, 1402, 1916, 2855, 2550, 1911, 4135, 1756, 1474,
        2476, 2912, 3318, 4000])
Epoch: 1213, Training Loss: 0.54, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1214 - Batch 1 ########################
IDs in batch 1: tensor([  98, 1139, 1294, 1672,  813, 1439,  109, 2286,  936,   39, 1670,   27,
        1977, 1228, 4032, 2717])
Epoch: 1214, Training Loss: 0.62, Validation Loss: 0.63, accuracy = 0.73
######################## Epoch 1215 - Batch 1 ########################
IDs in batch 1: tensor([3763,  252,   39, 1869, 1082, 3387, 3428, 3637, 1404, 3843, 2332,  890,
         275, 2117,  128, 2577])
Epoch: 1215, Training Loss: 0.34, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1216 - Batch 1 ########################
IDs in batch 1: tensor([3471, 3235, 3253, 2783, 1469, 4072, 1279, 1345, 3785, 2232, 1774, 1832,
         949, 3370,  258,  338])
Epoch: 1216, Training Loss: 0.25, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1217 - Batch 1 ########################
IDs in batch 1: tensor([2536,  805, 3313, 1038, 1352, 2453, 2461, 2195, 1343, 2510, 3428,  337,
         944, 2309, 3036,  975])
Epoch: 1217, Training Loss: 0.41, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1218 - Batch 1 ########################
IDs in batch 1: tensor([1852, 4204, 1651, 2177,   18, 2883,  926,  258, 2764, 2584, 4082, 2258,
         265,  284, 1665,   74])
Epoch: 1218, Training Loss: 0.20, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1219 - Batch 1 ########################
IDs in batch 1: tensor([3532, 2891, 2067, 3630,  774, 3755, 1497,  258,  879,  172, 3253, 1996,
        1710,  582, 2559,  588])
Epoch: 1219, Training Loss: 0.38, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1220 - Batch 1 ########################
IDs in batch 1: tensor([2711, 1208, 1899, 1568, 1780, 1733,  103, 1313, 4000, 3073, 1062, 3739,
         147, 1707, 3298, 3870])
Epoch: 1220, Training Loss: 0.40, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1221 - Batch 1 ########################
IDs in batch 1: tensor([2059, 4122, 1665, 3727, 2121, 3949, 1781, 1457, 3943, 1670, 1310, 1218,
        1436, 3379, 2245,  526])
Epoch: 1221, Training Loss: 0.51, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1222 - Batch 1 ########################
IDs in batch 1: tensor([3872, 4075,  277,  378, 2726, 3410, 3277, 1537, 1277, 1681, 3503,  899,
        1276, 2641, 2188, 1312])
Epoch: 1222, Training Loss: 0.37, Validation Loss: 0.63, accuracy = 0.73
######################## Epoch 1223 - Batch 1 ########################
IDs in batch 1: tensor([ 851, 2399, 1985, 2258, 1250,  515, 1632, 2367,  888, 2285, 2823, 1887,
        1083, 2703, 3381, 2031])
Epoch: 1223, Training Loss: 0.20, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1224 - Batch 1 ########################
IDs in batch 1: tensor([1861,  584,  827, 4240, 4032,  977, 1137,  332,  372, 2708, 4267, 1994,
        1128, 1415,   31,  467])
Epoch: 1224, Training Loss: 0.32, Validation Loss: 0.64, accuracy = 0.72
######################## Epoch 1225 - Batch 1 ########################
IDs in batch 1: tensor([2203, 3309,  510, 3304,  573, 3352, 3060, 2980, 3922, 1047, 1551, 1030,
        2052, 1752, 1974, 2524])
Epoch: 1225, Training Loss: 0.45, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1226 - Batch 1 ########################
IDs in batch 1: tensor([1209, 3196, 2849, 2583, 2334, 2652, 1283,  539, 3573, 4141, 1996,  678,
        1766, 1080,  403,  356])
Epoch: 1226, Training Loss: 0.28, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1227 - Batch 1 ########################
IDs in batch 1: tensor([2011,  466,  635, 1657, 2760,  855, 1640, 1296, 1891, 2049, 4002, 2301,
        3950, 1736, 1508,  902])
Epoch: 1227, Training Loss: 0.22, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1228 - Batch 1 ########################
IDs in batch 1: tensor([1367, 2731, 4236, 2770, 1961, 1487,  820, 3357, 2449, 2028, 2432,  776,
        1540,  965, 2219, 1881])
Epoch: 1228, Training Loss: 0.29, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1229 - Batch 1 ########################
IDs in batch 1: tensor([1734, 2858, 2645, 3621, 3473, 2655,  487,  766, 3780,  341, 1335, 2529,
        2960, 3219, 1408, 2644])
Epoch: 1229, Training Loss: 0.43, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1230 - Batch 1 ########################
IDs in batch 1: tensor([3219, 1532, 1899,  456, 2353, 1507, 1263, 3603, 2880,  989,  170, 1765,
          10, 3493, 2369, 2886])
Epoch: 1230, Training Loss: 0.17, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1231 - Batch 1 ########################
IDs in batch 1: tensor([ 351, 1610, 1087,  535, 4267, 3896, 3255, 3444,  132, 4033, 1410, 1947,
        4031, 4016, 1222,  511])
Epoch: 1231, Training Loss: 0.70, Validation Loss: 0.64, accuracy = 0.73
######################## Epoch 1232 - Batch 1 ########################
IDs in batch 1: tensor([1787,  899, 2383, 1485, 1429, 1052, 2346,  224, 2357,  228, 3082, 2817,
        2052, 3151,  283, 3739])
Epoch: 1232, Training Loss: 0.23, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1233 - Batch 1 ########################
IDs in batch 1: tensor([ 375,  465, 1724,  245, 2664, 1755, 3911, 4200, 2991, 3114,  900, 2706,
        2407, 3912, 1990, 2375])
Epoch: 1233, Training Loss: 0.28, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1234 - Batch 1 ########################
IDs in batch 1: tensor([2482, 2480, 3807, 3829,  302, 3697, 1008,  823, 3414,  213, 1130,  656,
        1638,  924, 4199, 3060])
Epoch: 1234, Training Loss: 0.56, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1235 - Batch 1 ########################
IDs in batch 1: tensor([ 637, 2261, 1740, 2385,  442,  472,  593, 1961, 4181, 3374, 1485, 1647,
        4094, 2356, 3804, 3594])
Epoch: 1235, Training Loss: 0.66, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1236 - Batch 1 ########################
IDs in batch 1: tensor([2700, 4022, 1954, 1309, 1037, 3196, 2226, 3156, 1083,  430, 2787, 4173,
        3810, 3600,  171,   43])
Epoch: 1236, Training Loss: 0.38, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1237 - Batch 1 ########################
IDs in batch 1: tensor([1089, 2286, 1073,  875, 1497, 1104, 1617, 1067, 3184, 3084,  511, 2039,
        3439, 2934, 4077,  649])
Epoch: 1237, Training Loss: 0.19, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1238 - Batch 1 ########################
IDs in batch 1: tensor([1111, 2522, 3943, 3617,  914, 2375, 2276, 2085, 3092, 4055, 1110, 1985,
        3006, 3604, 2246, 3668])
Epoch: 1238, Training Loss: 0.43, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1239 - Batch 1 ########################
IDs in batch 1: tensor([  41,  826, 2332, 1782, 3936, 3468, 3954, 1846,  753,  993, 1349, 1812,
        1434, 3582, 3789, 2901])
Epoch: 1239, Training Loss: 0.44, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1240 - Batch 1 ########################
IDs in batch 1: tensor([2192, 1122, 1863,  842, 2207, 1361, 3607, 2835,  949, 1566, 1782,  980,
          86,  400, 4124, 2228])
Epoch: 1240, Training Loss: 0.21, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1241 - Batch 1 ########################
IDs in batch 1: tensor([2644, 3485, 2671,  674, 2857, 3767, 3680, 4036, 2099, 3903, 1267, 1297,
        1556, 3069, 4097,  303])
Epoch: 1241, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1242 - Batch 1 ########################
IDs in batch 1: tensor([2387, 1185,  289, 3284, 1193,  701, 2913, 3525,   28, 2224, 2314,  497,
        4133, 2419, 2357, 1641])
Epoch: 1242, Training Loss: 0.19, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1243 - Batch 1 ########################
IDs in batch 1: tensor([1802, 3264, 2412, 1618, 3998, 1089, 1025, 4189, 3948, 3130, 2559,    4,
         133, 1090, 4049, 2627])
Epoch: 1243, Training Loss: 0.37, Validation Loss: 0.65, accuracy = 0.73
######################## Epoch 1244 - Batch 1 ########################
IDs in batch 1: tensor([1399, 1794, 1054,  262, 2067, 2443, 4011, 2406, 1636,   63,  193,   22,
        3289,  583, 2027,   34])
Epoch: 1244, Training Loss: 0.52, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1245 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 1880,  243, 2838, 3314, 1225, 3830, 1510,  426, 3151, 1306, 2789,
        1878, 2646, 4088, 2171])
Epoch: 1245, Training Loss: 0.25, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1246 - Batch 1 ########################
IDs in batch 1: tensor([1458, 4101, 1671, 2277,  491,  199, 2337,  986, 1627, 1951, 3688,  786,
         953, 1798, 2899, 4246])
Epoch: 1246, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1247 - Batch 1 ########################
IDs in batch 1: tensor([2132, 3118, 1611, 1201, 1158, 2191, 3451,  529, 3734, 2290, 1421, 1852,
        3996, 1740, 3498,   44])
Epoch: 1247, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1248 - Batch 1 ########################
IDs in batch 1: tensor([2718, 1110, 3994,  672, 1031, 1369,  411, 1125, 2870, 3099, 2894, 1121,
          73, 1509, 1199, 2111])
Epoch: 1248, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1249 - Batch 1 ########################
IDs in batch 1: tensor([1347, 1118, 4113, 3680, 3650,  221, 2524, 3233, 3933,  816, 3521, 2497,
        2819,  122, 3379, 3433])
Epoch: 1249, Training Loss: 0.60, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1250 - Batch 1 ########################
IDs in batch 1: tensor([ 864, 3592, 3113,  260,  910, 3599, 2229,  661,  139, 2173, 1059, 2461,
         753, 2358,   18, 2772])
Epoch: 1250, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1251 - Batch 1 ########################
IDs in batch 1: tensor([1312, 2966, 2973, 3484,  606, 1076, 3810, 3017, 1563, 2648, 2836,   20,
        4012, 2516, 2863, 3627])
Epoch: 1251, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1252 - Batch 1 ########################
IDs in batch 1: tensor([2723, 3351, 3077, 4154,  225, 2819,  812,  577, 2025, 2025, 1214, 1626,
        2444, 3049, 3756,  933])
Epoch: 1252, Training Loss: 0.41, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1253 - Batch 1 ########################
IDs in batch 1: tensor([4225, 2484, 3780, 1321, 2842, 1326, 1271,  133, 1225, 1439, 4008, 3283,
        3778,  547, 4097, 3336])
Epoch: 1253, Training Loss: 0.68, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1254 - Batch 1 ########################
IDs in batch 1: tensor([3395, 1376,  603, 1965,  902, 3312,  988,  662, 3379, 1484, 2143, 2499,
        2940,  858, 2366, 2358])
Epoch: 1254, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1255 - Batch 1 ########################
IDs in batch 1: tensor([2789, 3907, 1047, 1853, 3777, 2305, 3100,  321, 2234, 3252, 3746, 2097,
        1624, 2443, 3831,  900])
Epoch: 1255, Training Loss: 0.66, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1256 - Batch 1 ########################
IDs in batch 1: tensor([ 667, 1289, 1501, 2412, 4031, 3490, 3506, 3863, 4185,  944, 3860, 1474,
        1942,  876, 2899,  226])
Epoch: 1256, Training Loss: 0.59, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1257 - Batch 1 ########################
IDs in batch 1: tensor([2371, 1733, 3397, 1734, 1130, 1404,  944, 1291, 3729, 1133, 3000, 1894,
        2969, 3588,  937, 3675])
Epoch: 1257, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1258 - Batch 1 ########################
IDs in batch 1: tensor([2742, 1733, 2780, 4156, 2688,  184,  628,   86,  361, 1994, 2457, 3806,
        1524, 2331, 1712, 2898])
Epoch: 1258, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1259 - Batch 1 ########################
IDs in batch 1: tensor([4046, 2723, 2153,  348,  789, 1499, 3697, 2091,  631, 3718, 1482, 2124,
        2014, 3495,  225, 1573])
Epoch: 1259, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1260 - Batch 1 ########################
IDs in batch 1: tensor([ 941, 3557, 3278, 2937,  685, 1160, 3627,  741, 3334, 3407, 4006, 3516,
        2908, 2693, 1956,  582])
Epoch: 1260, Training Loss: 0.25, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1261 - Batch 1 ########################
IDs in batch 1: tensor([1177, 3081,  725, 3808, 2039, 2805,  221,  112,  508, 1671, 3390, 3729,
        3729, 2966,  302,  539])
Epoch: 1261, Training Loss: 0.28, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 1262 - Batch 1 ########################
IDs in batch 1: tensor([2465,  766, 3842, 2621, 3942, 3397,  159,  389, 1632,   64, 2891, 3028,
        1043, 2019, 2051, 3253])
Epoch: 1262, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 1263 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 3323, 1676,  375, 4136, 4245,  676, 3836,   24, 3014,  419, 1155,
         274, 1236, 1287, 2993])
Epoch: 1263, Training Loss: 0.51, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1264 - Batch 1 ########################
IDs in batch 1: tensor([ 591, 1763, 2041,  333, 2653,  425, 2730,  154, 1082, 3554, 1639, 3333,
        2991, 2781, 2400, 3723])
Epoch: 1264, Training Loss: 0.21, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1265 - Batch 1 ########################
IDs in batch 1: tensor([1488,   64, 2550,  747,  437, 1751, 3866, 1267,  921,  511, 2479, 1558,
        1080,  478,   59, 3160])
Epoch: 1265, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1266 - Batch 1 ########################
IDs in batch 1: tensor([3390, 3300, 3262,  280,  125, 2320,  407, 3744,  583,  781,  646, 2191,
        2145, 3996, 3952, 1971])
Epoch: 1266, Training Loss: 0.29, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1267 - Batch 1 ########################
IDs in batch 1: tensor([1354, 2382, 2842, 2542,  265, 1333, 1057, 3870, 1698, 2793, 3680, 4022,
        3376, 3082, 3651, 3973])
Epoch: 1267, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1268 - Batch 1 ########################
IDs in batch 1: tensor([1328, 3425, 3594, 2511, 3151, 2441, 3353, 2123,   51, 3039,  858, 1001,
        1415, 1787, 3590, 2247])
Epoch: 1268, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1269 - Batch 1 ########################
IDs in batch 1: tensor([3577, 1780,  218,  368, 2726,  676, 2149, 3528, 3926, 2115,  770, 2631,
        2074, 3604, 1138, 3663])
Epoch: 1269, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1270 - Batch 1 ########################
IDs in batch 1: tensor([  93, 1459, 2450, 2849, 2050, 2179, 2167,  701, 3042, 3974, 2740,  217,
        1472, 1375, 2250, 3938])
Epoch: 1270, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1271 - Batch 1 ########################
IDs in batch 1: tensor([4194, 1321, 1601, 1434, 3630, 3190, 3300, 1271, 2478, 2285, 2417, 2362,
        2523, 1489,  830, 1872])
Epoch: 1271, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1272 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 3469, 4005, 2780, 3872, 4127, 2604, 2401,  214, 2616, 4033, 2115,
        1975,  891, 1808, 3101])
Epoch: 1272, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1273 - Batch 1 ########################
IDs in batch 1: tensor([1294, 3558,  750,  533, 1116,  797,  318,  512, 3176, 4024, 2053, 4060,
        1796, 2982, 2355,  605])
Epoch: 1273, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1274 - Batch 1 ########################
IDs in batch 1: tensor([  61, 1698, 1862, 1811, 3839, 3211, 1950, 1960, 1647, 3236, 3755, 3373,
        2142,  673, 2252, 3659])
Epoch: 1274, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1275 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 2261, 1780, 3598, 2931, 3778, 3858, 3885,  452, 3298,  605,  573,
        1082, 3415, 2016, 4101])
Epoch: 1275, Training Loss: 0.46, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1276 - Batch 1 ########################
IDs in batch 1: tensor([1884, 3308, 4227,  159, 1061, 2954, 1773, 3516, 3429,  467,  635, 4044,
        3500,  507, 1319, 2978])
Epoch: 1276, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1277 - Batch 1 ########################
IDs in batch 1: tensor([3115, 2290, 3919, 2375, 1160, 1883,  930, 2758, 3604, 1138,  825, 2170,
        1953, 2244,  685, 2715])
Epoch: 1277, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1278 - Batch 1 ########################
IDs in batch 1: tensor([3548, 2696,  182, 3300, 2615, 2632, 2334, 3329, 1130,  413, 1846, 1476,
        4100, 2727,  899, 1578])
Epoch: 1278, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1279 - Batch 1 ########################
IDs in batch 1: tensor([2937, 1633, 1011,  519, 3838, 4039, 2676, 1249, 3430, 3927, 1258, 2250,
         797, 1537,  488, 4253])
Epoch: 1279, Training Loss: 0.50, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1280 - Batch 1 ########################
IDs in batch 1: tensor([1760, 1444,   26, 2614,  137, 2143,  472,  219, 2296, 2537, 2372, 2582,
        3400, 2432, 2376, 1286])
Epoch: 1280, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1281 - Batch 1 ########################
IDs in batch 1: tensor([3764, 3029,  290,   30, 1571, 2150, 3866, 2300, 3846, 3951, 1482, 3847,
        2347,   84, 3447, 1686])
Epoch: 1281, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1282 - Batch 1 ########################
IDs in batch 1: tensor([ 937,  689, 2232, 2120, 3733, 2056, 3870, 3121, 2765, 2209, 1132, 2472,
         588, 1011, 2292, 1371])
Epoch: 1282, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1283 - Batch 1 ########################
IDs in batch 1: tensor([1309, 1067, 1137, 1236, 2578,  637, 2957, 1337, 3961, 1841, 3286, 4008,
         602, 1061, 3614, 3536])
Epoch: 1283, Training Loss: 0.44, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1284 - Batch 1 ########################
IDs in batch 1: tensor([3728, 2142,  266, 2540, 1439, 3569, 1340, 1061, 3267, 1017, 1767, 1708,
        1305, 2131, 2618,  408])
Epoch: 1284, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1285 - Batch 1 ########################
IDs in batch 1: tensor([3298, 3688, 3367, 3146,  424, 3115, 1569, 2742, 2405, 1817,  128,  701,
        3432, 3493, 3490, 3527])
Epoch: 1285, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1286 - Batch 1 ########################
IDs in batch 1: tensor([3108,  729,   52, 1675, 3092,  514, 3985, 3879,   95, 1316, 1985, 2520,
        2564,  709, 3839, 4000])
Epoch: 1286, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1287 - Batch 1 ########################
IDs in batch 1: tensor([1670, 1849,  440, 4268, 2094, 2190,   47, 3291, 3913, 1429,  425, 1450,
        4268, 2241, 1361, 3521])
Epoch: 1287, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1288 - Batch 1 ########################
IDs in batch 1: tensor([2591, 2618, 1707,  126, 3839, 1569,  727, 3265,  557, 4220, 4236, 1660,
         219,  323, 3354, 1764])
Epoch: 1288, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1289 - Batch 1 ########################
IDs in batch 1: tensor([4157, 3178, 2182,  797, 1284, 2535,  545, 2921, 2857, 1595,  851, 3367,
         612, 4268, 2118, 3503])
Epoch: 1289, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1290 - Batch 1 ########################
IDs in batch 1: tensor([2030,  527, 1123, 1708, 2723, 4068, 3652, 1863, 1275, 2415, 2368, 4114,
        3895, 3190, 2202, 2526])
Epoch: 1290, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1291 - Batch 1 ########################
IDs in batch 1: tensor([2489, 1753, 3181, 1496,  595,  945,  405, 3940, 3010, 3933,  785, 2837,
        1932,  733, 1218, 2636])
Epoch: 1291, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1292 - Batch 1 ########################
IDs in batch 1: tensor([2802,  872, 1116, 3675, 2476,   51, 3246,  747, 3845, 4174,  904, 3099,
         256, 2721,  749, 1543])
Epoch: 1292, Training Loss: 0.38, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1293 - Batch 1 ########################
IDs in batch 1: tensor([1131,  637, 1935, 1543, 1284, 3746,  172, 2932, 2974,  199, 4264, 2332,
        3197,  187, 1084, 4268])
Epoch: 1293, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1294 - Batch 1 ########################
IDs in batch 1: tensor([3426, 1237, 2016, 1857,  535, 2366, 2393,  164, 2655, 3593, 2589, 2469,
        3672, 1283, 2934, 1209])
Epoch: 1294, Training Loss: 0.60, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1295 - Batch 1 ########################
IDs in batch 1: tensor([2151, 2982, 2739, 2102, 1108, 2241,  223, 2499, 3386, 1274,  586, 4117,
         987, 1255, 1803, 2789])
Epoch: 1295, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1296 - Batch 1 ########################
IDs in batch 1: tensor([2732, 1567,  390, 3636, 3234, 3451, 2467,  435, 3783, 1324, 4065,  756,
        2426, 2225, 2432, 1718])
Epoch: 1296, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1297 - Batch 1 ########################
IDs in batch 1: tensor([1248, 2401,  755, 2346,  476, 1413, 2131, 1340, 2540, 2949, 2440, 3532,
         492, 2867,  956, 4044])
Epoch: 1297, Training Loss: 0.57, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1298 - Batch 1 ########################
IDs in batch 1: tensor([2378, 1260, 3751, 3053,  681,  221, 2098, 3053,  605,  515, 3329, 3707,
        4198, 4014, 3270, 3373])
Epoch: 1298, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1299 - Batch 1 ########################
IDs in batch 1: tensor([2627, 1340, 1099, 4166, 1642, 2432, 1883,    4, 1144, 1442, 4227, 1809,
        2589, 3516, 1707, 2661])
Epoch: 1299, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1300 - Batch 1 ########################
IDs in batch 1: tensor([4264, 1250, 1846, 1591, 2905, 3432, 3511, 4261, 4003, 3985, 1902,  814,
        3711, 1023,  781, 3115])
Epoch: 1300, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1301 - Batch 1 ########################
IDs in batch 1: tensor([3372, 1263, 1171,  846,  314,  201,  382, 2655, 4088,  718,  191, 3921,
        1852, 1502,  653, 2344])
Epoch: 1301, Training Loss: 0.46, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1302 - Batch 1 ########################
IDs in batch 1: tensor([ 869, 2338, 3009, 3438,  524, 2159, 1883, 4048, 2375, 3344, 1958, 2339,
         593, 3284, 3983, 1056])
Epoch: 1302, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1303 - Batch 1 ########################
IDs in batch 1: tensor([1789, 3753, 2449,  492, 3527,   95, 2839, 3705, 1120, 2664,  465, 2378,
        2118, 3536, 3733, 1034])
Epoch: 1303, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1304 - Batch 1 ########################
IDs in batch 1: tensor([3963,  710, 1803, 2821, 3376,   13, 3235, 1423, 3745, 3197, 1255,   50,
        2812, 2018, 2416, 3426])
Epoch: 1304, Training Loss: 0.47, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1305 - Batch 1 ########################
IDs in batch 1: tensor([1256, 3583, 2782, 3537, 1166, 1985,  552, 3196, 2393, 2748, 1747, 2536,
        3052, 2011, 1913, 3245])
Epoch: 1305, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1306 - Batch 1 ########################
IDs in batch 1: tensor([1054, 3603, 2117, 4187, 3343, 3542, 3494, 1201, 1558, 2236,  826, 2448,
        3117,   92,  180, 2014])
Epoch: 1306, Training Loss: 0.39, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1307 - Batch 1 ########################
IDs in batch 1: tensor([4119, 2195,  221, 2272,   27, 3839, 1862, 3275, 2286, 1038,  187, 3949,
         417, 1628, 3469, 2370])
Epoch: 1307, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1308 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 3549, 2176, 3334, 4038,  408, 1559,  106, 2718, 2646, 3873, 2456,
        4266, 2967, 1057, 1296])
Epoch: 1308, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1309 - Batch 1 ########################
IDs in batch 1: tensor([1809, 4024, 2506,   28, 2232, 2537, 2493, 1452, 3992, 1902,  953,  993,
        1656, 2125, 1385, 2250])
Epoch: 1309, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1310 - Batch 1 ########################
IDs in batch 1: tensor([ 751, 3567, 1567, 2456, 1166,  388,  824, 2821,  221, 1624, 1133, 1308,
         662, 3458,  785,  342])
Epoch: 1310, Training Loss: 0.69, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1311 - Batch 1 ########################
IDs in batch 1: tensor([1126, 4148, 1097, 2991, 1525, 2523,  986,  422, 3467,  481, 3117,  544,
        1786,   99, 1555,  723])
Epoch: 1311, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1312 - Batch 1 ########################
IDs in batch 1: tensor([ 113, 2915, 3135, 1345, 1016, 1778, 3553, 3394, 2645, 2741, 1266, 3731,
        3792, 1812, 1532,  314])
Epoch: 1312, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1313 - Batch 1 ########################
IDs in batch 1: tensor([4114, 2148, 1882, 1660,  891,  718,  243, 2500,  191, 2969, 1173, 1096,
         684,  418,  483,   20])
Epoch: 1313, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1314 - Batch 1 ########################
IDs in batch 1: tensor([2085, 2358, 1576, 2809,  255, 3793, 1044, 1720, 3683, 1679, 1981,  809,
         631, 1117, 1067,  992])
Epoch: 1314, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1315 - Batch 1 ########################
IDs in batch 1: tensor([ 159, 1113, 1405, 2249, 1085, 4261, 2180,   93, 1698, 2969,  244, 1575,
        2014, 1397, 3905,  538])
Epoch: 1315, Training Loss: 0.18, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1316 - Batch 1 ########################
IDs in batch 1: tensor([2306,   15, 3837, 2249, 1305, 3160, 3497,  913,  639, 1311, 2765, 1880,
         741, 3102, 3049, 3851])
Epoch: 1316, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1317 - Batch 1 ########################
IDs in batch 1: tensor([1536, 1296, 4257, 2185, 2797, 1076, 2752, 2284, 2367,  623, 3841, 3655,
          57, 3094, 1634, 1625])
Epoch: 1317, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1318 - Batch 1 ########################
IDs in batch 1: tensor([2783, 4261,  978, 2051, 1341,  334, 2487, 3650, 3326,  777,  886, 2640,
        2809, 2590, 3474, 2056])
Epoch: 1318, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1319 - Batch 1 ########################
IDs in batch 1: tensor([2783, 3252,  556, 2721, 2848, 3842, 2568, 4060, 2156, 1734, 1001, 1748,
        2192, 4116, 1901, 3771])
Epoch: 1319, Training Loss: 0.70, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1320 - Batch 1 ########################
IDs in batch 1: tensor([3303, 4148, 1092, 3587, 1223, 2295,  552, 4186,  876, 2880, 3428, 3797,
        2329, 2090, 2550,  818])
Epoch: 1320, Training Loss: 0.37, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1321 - Batch 1 ########################
IDs in batch 1: tensor([3858,  873,  841, 1846, 3436, 3651, 1140, 3499, 3607,  487,  684,  603,
        1108,  639, 1681, 2206])
Epoch: 1321, Training Loss: 0.51, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1322 - Batch 1 ########################
IDs in batch 1: tensor([1645,  402,  451, 1779, 3786, 1198, 2732, 2741, 2461, 2418, 4018, 2171,
        2872, 3569, 1524,  143])
Epoch: 1322, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1323 - Batch 1 ########################
IDs in batch 1: tensor([ 635, 1740, 1014,  207,  726, 2832, 2493, 2120, 2116,  943, 3985, 2066,
        3947,  456, 2323, 3150])
Epoch: 1323, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1324 - Batch 1 ########################
IDs in batch 1: tensor([2898, 3027, 1869, 1934, 3587, 2693, 1955, 2777, 1886, 4100, 1321, 2536,
        3360, 2015, 4173,  264])
Epoch: 1324, Training Loss: 0.59, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1325 - Batch 1 ########################
IDs in batch 1: tensor([1075, 3176,  952, 2483,  726,   50, 1208, 2306, 1216, 1895, 2155, 3705,
        3821, 2102, 4161, 3430])
Epoch: 1325, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1326 - Batch 1 ########################
IDs in batch 1: tensor([1497, 3222, 3533,  199, 3051, 1354, 3608, 3676, 2329, 1880,  244, 2529,
        2440, 2369, 2942, 3506])
Epoch: 1326, Training Loss: 0.45, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1327 - Batch 1 ########################
IDs in batch 1: tensor([2399, 3932, 3196, 2121, 3308, 2545, 2648, 4235, 3236, 1568, 2369,  350,
        3963, 3621, 3334, 3882])
Epoch: 1327, Training Loss: 0.61, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1328 - Batch 1 ########################
IDs in batch 1: tensor([1318, 1126, 1655, 4186, 3355, 2610, 1935, 2734,  275, 1835,   74, 1684,
         330, 3523, 2107, 1218])
Epoch: 1328, Training Loss: 0.35, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1329 - Batch 1 ########################
IDs in batch 1: tensor([ 401, 1767, 1562,  848, 4254, 3570, 2435, 1737, 4226,  284, 1404, 3922,
        2990, 2873, 3081,  327])
Epoch: 1329, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1330 - Batch 1 ########################
IDs in batch 1: tensor([1525, 1918, 4215, 3723, 2693, 2358,  959, 2238, 2123, 3701, 3197, 3804,
        1899, 2475,  196, 2953])
Epoch: 1330, Training Loss: 0.51, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1331 - Batch 1 ########################
IDs in batch 1: tensor([3947, 1236, 3992, 1626, 1315, 3453, 1393,  314, 1168, 1075, 2839, 1257,
         155, 1643, 1263, 4013])
Epoch: 1331, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1332 - Batch 1 ########################
IDs in batch 1: tensor([2346, 3182, 3005, 3599,  943, 1302, 2680, 4027, 3721, 2356, 2358, 2954,
        1614, 3394, 2867, 1537])
Epoch: 1332, Training Loss: 0.52, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1333 - Batch 1 ########################
IDs in batch 1: tensor([3142, 1641,  316,   38, 1272, 1605,  544, 1712, 2572, 2028,  717, 2110,
        4025, 4229,  155,  494])
Epoch: 1333, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1334 - Batch 1 ########################
IDs in batch 1: tensor([2798, 1133, 2739, 1686, 1456,  899,  876, 1511, 2245, 1445, 3765, 3943,
        3425,  755, 1093, 1960])
Epoch: 1334, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1335 - Batch 1 ########################
IDs in batch 1: tensor([ 283, 2193, 1646, 1317, 2125, 2894, 2571,  335, 3907, 4258, 2142, 3530,
        1250, 4212,  890, 2887])
Epoch: 1335, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1336 - Batch 1 ########################
IDs in batch 1: tensor([1332,  472, 2154, 2856,  876, 3038, 1971, 2041, 3729, 1157, 2461, 2913,
        2541, 2781,  318, 2295])
Epoch: 1336, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1337 - Batch 1 ########################
IDs in batch 1: tensor([1693, 1880, 3057,  992, 2783, 1299, 2383, 1530, 1970, 3900,  193, 4085,
        3265,  149, 4163, 3792])
Epoch: 1337, Training Loss: 0.21, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1338 - Batch 1 ########################
IDs in batch 1: tensor([2115, 3644, 4148,  612,  583, 2851,  256,  751, 3287, 2309, 2964, 1377,
         873, 1365, 3632, 1471])
Epoch: 1338, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1339 - Batch 1 ########################
IDs in batch 1: tensor([3308, 2730,  640, 1918, 4240, 3997, 3333,  826, 1731, 1566, 3873,  604,
        3221, 2851,   20,  891])
Epoch: 1339, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1340 - Batch 1 ########################
IDs in batch 1: tensor([1770,  135, 2368, 1931, 2086,  689, 2655, 3936, 3795,  568, 4135, 2183,
        1193, 3342,  584, 1571])
Epoch: 1340, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1341 - Batch 1 ########################
IDs in batch 1: tensor([1073, 2248, 4103, 4263, 3131, 3658,  320, 2332,  721, 1974, 3185, 2767,
        3401, 3003, 1086, 3706])
Epoch: 1341, Training Loss: 0.51, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1342 - Batch 1 ########################
IDs in batch 1: tensor([2313, 2833, 3275, 3060, 3921, 2285, 2182, 1657, 3664,  787, 1601, 3366,
        1707,  260, 2407,  730])
Epoch: 1342, Training Loss: 0.44, Validation Loss: 0.69, accuracy = 0.70
######################## Epoch 1343 - Batch 1 ########################
IDs in batch 1: tensor([ 960,  983, 1116, 4133,    7, 3976, 3530, 3265,  165, 1981, 4180, 1575,
          74, 1440, 2740, 3920])
Epoch: 1343, Training Loss: 0.44, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1344 - Batch 1 ########################
IDs in batch 1: tensor([ 993,  770, 2996,  511, 3455, 3660, 2709, 1830,   37, 2038, 1747,  498,
        3184, 1121, 2415, 3374])
Epoch: 1344, Training Loss: 0.43, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1345 - Batch 1 ########################
IDs in batch 1: tensor([3721, 1063,  357, 3838, 1060, 1487, 3282, 1283, 3617, 3838, 2590, 1612,
        2448,  777,  752, 1863])
Epoch: 1345, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1346 - Batch 1 ########################
IDs in batch 1: tensor([ 109, 2860, 3240, 1748, 2505,  292, 3912, 3874, 2188,   21, 1073, 2660,
        4095, 2917, 2144, 1836])
Epoch: 1346, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1347 - Batch 1 ########################
IDs in batch 1: tensor([1340, 1376, 1214, 3406,  475, 1361, 4018, 2934, 1060, 2682, 2849, 2402,
        1896, 1767,  994, 3009])
Epoch: 1347, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1348 - Batch 1 ########################
IDs in batch 1: tensor([  62,  184, 2840, 3942, 1290, 1229, 2682, 2005, 1861, 3911, 3769, 2276,
        1170, 3642, 4110,  485])
Epoch: 1348, Training Loss: 0.42, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1349 - Batch 1 ########################
IDs in batch 1: tensor([3583,  857, 1600, 1143, 2386, 1130,  673, 2876, 2995, 1481,  535, 2823,
        2156, 1062,  743, 3436])
Epoch: 1349, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1350 - Batch 1 ########################
IDs in batch 1: tensor([  18,  842,  637, 3024, 2842,   74, 3373, 3362, 3994, 3488, 2329, 1594,
        1209, 2467,  485,  155])
Epoch: 1350, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1351 - Batch 1 ########################
IDs in batch 1: tensor([1819, 4200,   25, 1635, 3531, 2636, 3471, 2780,  283,   31,  735, 3254,
        4058,    5, 1312,  712])
Epoch: 1351, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1352 - Batch 1 ########################
IDs in batch 1: tensor([4124, 3648, 1740, 2842, 2510,   70,  302, 3052, 2161,  947, 3072,   50,
        1225, 3058, 3408, 3199])
Epoch: 1352, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1353 - Batch 1 ########################
IDs in batch 1: tensor([3234, 2839, 1894,  704, 3660, 3081,  752, 1655,  538, 3869, 4264, 4126,
        2156, 2102,  338, 2700])
Epoch: 1353, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1354 - Batch 1 ########################
IDs in batch 1: tensor([3270, 2894, 1252,  573, 3516, 2943, 3199, 2349, 2717, 4078, 2610, 3958,
        3499, 3905, 2598,   95])
Epoch: 1354, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1355 - Batch 1 ########################
IDs in batch 1: tensor([ 206, 3133, 2031, 3461, 1981, 1136, 4187,  303, 1386, 1113, 1585, 1567,
        3101, 2196, 2917, 2741])
Epoch: 1355, Training Loss: 0.25, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1356 - Batch 1 ########################
IDs in batch 1: tensor([ 109, 1614, 2936, 2692, 1499, 1179,  133, 3954, 1673, 1994,  295, 4061,
        1899, 2667, 2204,  397])
Epoch: 1356, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1357 - Batch 1 ########################
IDs in batch 1: tensor([3842, 1055, 3850, 2202, 2544,  362,  894, 1310, 1755,  220, 2567,  317,
        3745, 2751, 1133, 3793])
Epoch: 1357, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1358 - Batch 1 ########################
IDs in batch 1: tensor([2982, 2868, 2505, 1340, 1355,  517, 3779,  415, 2393, 3328, 3749, 4067,
        1656, 2195, 3697, 1896])
Epoch: 1358, Training Loss: 0.33, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1359 - Batch 1 ########################
IDs in batch 1: tensor([  52, 1685, 1284, 1286, 2446, 1808, 4139, 2279,  838, 3883, 4082, 1233,
        1231,  907, 3990, 4012])
Epoch: 1359, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1360 - Batch 1 ########################
IDs in batch 1: tensor([2171, 3476, 4161,  886, 3352, 3688,  372,  537, 3495, 1086, 1747, 3907,
         740, 1272, 1844, 3254])
Epoch: 1360, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1361 - Batch 1 ########################
IDs in batch 1: tensor([1189,  256, 2680, 3980,  874, 2601,  452, 1273,  873, 2993,  119,  610,
        2771,    4, 3368, 2125])
Epoch: 1361, Training Loss: 0.35, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1362 - Batch 1 ########################
IDs in batch 1: tensor([2836, 3607,  445, 3970, 2363, 1999, 4055, 2359, 3822,  665, 2767, 1574,
        3487, 1511, 3527, 2097])
Epoch: 1362, Training Loss: 0.29, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1363 - Batch 1 ########################
IDs in batch 1: tensor([1287, 3999, 1731, 2890, 1228, 1404, 1143, 3837, 3585, 1761,  394,  871,
         199, 1945, 3279, 2376])
Epoch: 1363, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1364 - Batch 1 ########################
IDs in batch 1: tensor([ 666,  953, 1175,  346, 1275, 2287,  439,  236,  970, 3000, 1132,  890,
        2352, 1463, 1853, 3303])
Epoch: 1364, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1365 - Batch 1 ########################
IDs in batch 1: tensor([2821, 3527, 1274, 1639, 4149, 2898, 2924, 2060, 1614, 4053, 2678, 4170,
        2937, 2179,  110,   56])
Epoch: 1365, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1366 - Batch 1 ########################
IDs in batch 1: tensor([3998,  213, 2610,  279, 3226, 3740, 1745, 1860, 1024, 2638, 2153, 3354,
        3114, 1052,   32, 4266])
Epoch: 1366, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1367 - Batch 1 ########################
IDs in batch 1: tensor([3278, 3092, 3483, 4128, 3927,  620,  508, 4055, 1452, 3900, 2115,  821,
        2275,   74, 1952, 4126])
Epoch: 1367, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1368 - Batch 1 ########################
IDs in batch 1: tensor([2109, 2401, 3446, 2371, 1326, 1310, 3188,  997, 4116, 3144, 1315, 1895,
        3071,  738,  171, 1346])
Epoch: 1368, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1369 - Batch 1 ########################
IDs in batch 1: tensor([1195,   14, 2483,  815,  740, 2591,   13,  781, 2258, 3650, 1668, 2258,
        2854, 3984,  487, 2498])
Epoch: 1369, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1370 - Batch 1 ########################
IDs in batch 1: tensor([4121, 1130,  769, 1337, 3387,  400, 3022,  379,   32, 1920, 1354, 3654,
         199, 4050, 4213, 3242])
Epoch: 1370, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1371 - Batch 1 ########################
IDs in batch 1: tensor([1060,  126, 3354, 1328,  303,  578, 3072, 3523, 1810, 3526, 2599, 1383,
        3995,  119, 4011, 2252])
Epoch: 1371, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1372 - Batch 1 ########################
IDs in batch 1: tensor([ 663,  980,  699, 3117, 3883, 1530, 3987, 1271, 1097, 1310, 1700, 3100,
         546, 2663, 3358, 3656])
Epoch: 1372, Training Loss: 0.46, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1373 - Batch 1 ########################
IDs in batch 1: tensor([3943, 1923, 3634, 3176, 2748, 4170, 1858,  862, 2417, 3014, 4246,  883,
        1426,  530, 1178, 2441])
Epoch: 1373, Training Loss: 0.43, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1374 - Batch 1 ########################
IDs in batch 1: tensor([1585,  277,  532, 4158, 3852, 1566, 4236, 4096,  338,  129, 3369, 2749,
        3997, 1302, 3882, 1755])
Epoch: 1374, Training Loss: 0.53, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1375 - Batch 1 ########################
IDs in batch 1: tensor([2133, 4085, 1975, 2072,  934, 1120, 3663, 1817, 2982, 1602, 2788, 2810,
        3389, 3475, 2119, 3444])
Epoch: 1375, Training Loss: 0.72, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1376 - Batch 1 ########################
IDs in batch 1: tensor([2897, 2723, 3251, 3395, 3373,  514, 3196, 3262, 2879, 2090,  672, 3992,
        2902,  753, 2518,  747])
Epoch: 1376, Training Loss: 0.43, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1377 - Batch 1 ########################
IDs in batch 1: tensor([1754,  533, 3658, 2668, 3178, 1426, 2773, 1510, 1613, 3435, 1146, 1490,
         448,  962, 1767, 1156])
Epoch: 1377, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1378 - Batch 1 ########################
IDs in batch 1: tensor([4134, 2410, 2945,  165,  471,  814, 1870, 1999, 2462, 1098, 1102, 1601,
        3734, 2815,  523, 4031])
Epoch: 1378, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1379 - Batch 1 ########################
IDs in batch 1: tensor([ 289,  829, 2274, 3438, 2977, 1147, 1281, 1902,  202, 1663,   88, 4141,
         411,  389, 3727, 3962])
Epoch: 1379, Training Loss: 0.46, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1380 - Batch 1 ########################
IDs in batch 1: tensor([3272, 3688, 2804, 2924,  572,  794, 3545, 1233, 2863, 3183, 1746,  550,
        1467, 1264, 2073, 4128])
Epoch: 1380, Training Loss: 0.36, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1381 - Batch 1 ########################
IDs in batch 1: tensor([3516, 4050,  422, 3407, 2908, 3640, 1610, 4032,  962, 4008, 2331,   26,
        1656, 3693,  976,  439])
Epoch: 1381, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1382 - Batch 1 ########################
IDs in batch 1: tensor([2151, 2402, 3278, 2317, 2420,  213, 3143,   32, 2154, 2109, 3894,  441,
        4110, 2121, 1913, 1308])
Epoch: 1382, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1383 - Batch 1 ########################
IDs in batch 1: tensor([3234, 2703, 3592, 1177, 3144,  788, 1773, 1555, 3130,  739, 2198, 2229,
         870,   63, 2339, 3554])
Epoch: 1383, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1384 - Batch 1 ########################
IDs in batch 1: tensor([1318,   21, 1437,  437,  491,  345, 1337, 4267, 2870, 2254, 2605, 1333,
        2907, 2553, 2247, 3692])
Epoch: 1384, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1385 - Batch 1 ########################
IDs in batch 1: tensor([3418, 1346,  920,  923, 2456, 3968, 2453, 3056, 2420,  427, 2807,  117,
        1003, 1575, 3342, 2729])
Epoch: 1385, Training Loss: 0.32, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1386 - Batch 1 ########################
IDs in batch 1: tensor([1732, 1222,  322, 2423, 2505, 1278, 3135, 1237,  694, 3701, 3072,  950,
        3743, 3444, 2044, 4072])
Epoch: 1386, Training Loss: 0.44, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1387 - Batch 1 ########################
IDs in batch 1: tensor([ 145, 1686, 3942, 1250, 1826, 2730,  430, 3484, 3912, 3749, 2579,  862,
        2468,  376, 3053, 2770])
Epoch: 1387, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1388 - Batch 1 ########################
IDs in batch 1: tensor([2480,  389, 2067,  530, 2034, 2316, 1023,  835, 3098,  952,  926, 2476,
        1123, 2796, 4135,  689])
Epoch: 1388, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1389 - Batch 1 ########################
IDs in batch 1: tensor([2838, 2115, 4009, 1383, 2382,  893, 2346, 3650, 2212,  190, 3123, 2415,
        1611, 2545, 2347, 1028])
Epoch: 1389, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1390 - Batch 1 ########################
IDs in batch 1: tensor([1056, 1459, 2741, 2412, 1269, 4267, 3180, 3181, 2217,  918, 3654, 3226,
        3878, 2218, 3806, 3343])
Epoch: 1390, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1391 - Batch 1 ########################
IDs in batch 1: tensor([1419,  591,  260, 3436, 1957, 2667, 3928,  587, 3371, 1580,  125, 1189,
        1009, 2959,  167, 1602])
Epoch: 1391, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1392 - Batch 1 ########################
IDs in batch 1: tensor([2367, 2700, 2869, 2416, 3695, 2969, 2618, 1369,   50, 3168,  682, 1204,
        1010,  838,  139, 3858])
Epoch: 1392, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1393 - Batch 1 ########################
IDs in batch 1: tensor([1500, 1383, 2841, 3051,  200,  211,   71, 3905,  229, 2589, 2807,  895,
         960, 1251,   20,  657])
Epoch: 1393, Training Loss: 0.54, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1394 - Batch 1 ########################
IDs in batch 1: tensor([1198, 3743,  226, 2963, 2540, 1467, 3018,  804,   27,  843, 1895, 2141,
         399, 3731, 2053,  350])
Epoch: 1394, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1395 - Batch 1 ########################
IDs in batch 1: tensor([3529, 3711, 4022, 1672, 3688, 3476, 4256, 1552, 2683,   35, 1248,  896,
         314,  183, 1044, 1340])
Epoch: 1395, Training Loss: 0.56, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1396 - Batch 1 ########################
IDs in batch 1: tensor([1250, 3121, 4115,  960, 2291,  161, 1546, 1042, 1634,  875, 1437,  533,
         896,  444, 2103, 4062])
Epoch: 1396, Training Loss: 0.61, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1397 - Batch 1 ########################
IDs in batch 1: tensor([2400, 3879,  418,  910, 1053, 2462, 1491, 3299, 1625,  918,  487, 4005,
        3313, 4159, 4179, 4188])
Epoch: 1397, Training Loss: 0.55, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1398 - Batch 1 ########################
IDs in batch 1: tensor([1346, 3042, 1369,  851, 1218, 1611, 2540, 1510, 1341,  407, 2666,  975,
         103,  968, 1271, 3015])
Epoch: 1398, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1399 - Batch 1 ########################
IDs in batch 1: tensor([2391, 1818, 3885, 1910, 3182, 4215, 3881, 4218, 3321, 2949, 3121,  593,
        1524, 4124, 2040, 2070])
Epoch: 1399, Training Loss: 0.72, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1400 - Batch 1 ########################
IDs in batch 1: tensor([4051, 4146, 3356, 1611, 3917, 1553, 1270, 1650, 1255, 1232, 3660,  514,
         990, 3126, 2437, 1167])
Epoch: 1400, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1401 - Batch 1 ########################
IDs in batch 1: tensor([ 108,  886, 2493, 2349, 3159, 1218, 3304,  218,  811, 1718, 3030, 2373,
        2880,  112, 3473, 3311])
Epoch: 1401, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 1402 - Batch 1 ########################
IDs in batch 1: tensor([1897,   77,  854, 2112,   73, 1133, 3196, 1491, 3468, 1645, 3410,  345,
        2826,   14,  434,  357])
Epoch: 1402, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1403 - Batch 1 ########################
IDs in batch 1: tensor([2601, 2674, 2030,  524,  109, 2591,  566,  804,  212, 2205, 1656,  891,
        4266, 1258, 1573, 3483])
Epoch: 1403, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1404 - Batch 1 ########################
IDs in batch 1: tensor([ 327,  781, 1728, 2277, 3731,  206, 3661, 2760, 3541, 1228, 1124, 2441,
        2151, 1101, 3458, 1723])
Epoch: 1404, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1405 - Batch 1 ########################
IDs in batch 1: tensor([ 946, 3699, 3228, 3243, 3199,  828,  658, 2493, 1131, 1120, 3879, 2589,
        4067, 3003, 2989, 3652])
Epoch: 1405, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1406 - Batch 1 ########################
IDs in batch 1: tensor([ 399,  852, 3537, 2369, 3992, 1840, 1722, 2087, 2366, 3529, 1761, 2247,
        3428, 1877, 2605, 2443])
Epoch: 1406, Training Loss: 0.37, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1407 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 2025, 1977, 3362, 1770,  165, 1137, 1440, 1311,  334, 1760,  108,
        2793, 2356, 3705,  770])
Epoch: 1407, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1408 - Batch 1 ########################
IDs in batch 1: tensor([ 854,  603,  382, 4242, 2316, 2260,  106, 4263, 2836, 2247, 1752, 1678,
        1896, 1196, 3883, 3681])
Epoch: 1408, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1409 - Batch 1 ########################
IDs in batch 1: tensor([1341,  660, 2708, 3084, 1120, 2442, 1982, 3998, 3996,   18, 2510, 3765,
        1319, 2745, 3858,  193])
Epoch: 1409, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1410 - Batch 1 ########################
IDs in batch 1: tensor([3262, 2624, 2170, 2835,  723, 2798, 3306, 3673, 1668, 3240, 3168, 2339,
        3614, 3762, 2416, 1877])
Epoch: 1410, Training Loss: 0.46, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1411 - Batch 1 ########################
IDs in batch 1: tensor([1536, 2934, 2851, 2433, 3021,  362,   63, 1119,  138, 2598, 3218, 2353,
        3111, 2883,  823, 2369])
Epoch: 1411, Training Loss: 0.43, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1412 - Batch 1 ########################
IDs in batch 1: tensor([3111,  462, 3467, 1263, 3933, 1511, 3023, 2133, 3199, 4126, 4196, 3345,
        2719, 3533, 3570, 3926])
Epoch: 1412, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1413 - Batch 1 ########################
IDs in batch 1: tensor([2225, 1934, 2620, 2086, 2917, 4026, 3199, 3395,  104,  826, 3913,  832,
        3326,  701, 1574, 3369])
Epoch: 1413, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1414 - Batch 1 ########################
IDs in batch 1: tensor([1413, 4267, 1991, 2350, 3328, 4068,  554,  476, 3397,  207, 1955, 2300,
        2505, 1453, 2453, 3248])
Epoch: 1414, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1415 - Batch 1 ########################
IDs in batch 1: tensor([2171, 1886, 2885, 1050, 2913, 1045, 3976, 1072, 3245, 2641, 1292, 1220,
        4058, 1909, 1432, 1910])
Epoch: 1415, Training Loss: 0.40, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1416 - Batch 1 ########################
IDs in batch 1: tensor([ 515,  173, 2231, 2908, 4078, 1195, 1859, 1821, 4242, 3624, 2087, 2931,
        3321, 2681,  741, 1518])
Epoch: 1416, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1417 - Batch 1 ########################
IDs in batch 1: tensor([3632,  397, 2681, 3693,   61, 3902,  289,  455, 3529,  604,  785, 1440,
        3753, 4010, 2462,  403])
Epoch: 1417, Training Loss: 0.54, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1418 - Batch 1 ########################
IDs in batch 1: tensor([3995, 2954, 3024, 1955, 3506, 2802, 1391, 4125, 1724, 3074,    4, 3226,
        1316, 2189,   92, 3458])
Epoch: 1418, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1419 - Batch 1 ########################
IDs in batch 1: tensor([1892, 2060,  252,  255,  596, 3873, 1066, 4188, 1042, 3928, 2810, 1901,
        2247, 3751, 3534, 1490])
Epoch: 1419, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1420 - Batch 1 ########################
IDs in batch 1: tensor([2074,  876, 1284, 2276,  418, 3504, 1160, 1376, 1545, 1361, 3357, 1308,
        2849, 1377,  787, 2488])
Epoch: 1420, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1421 - Batch 1 ########################
IDs in batch 1: tensor([2235, 1796, 2135,  870,  425, 3792, 3092, 2210, 3003, 3713,  950,  674,
         348, 4058, 2095, 2118])
Epoch: 1421, Training Loss: 0.58, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1422 - Batch 1 ########################
IDs in batch 1: tensor([1556,  470, 1082, 1684, 2122, 1661,  747, 1690, 4220,  659,  524, 1354,
        3337, 2368, 2141, 3547])
Epoch: 1422, Training Loss: 0.32, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1423 - Batch 1 ########################
IDs in batch 1: tensor([2604, 1039, 1470, 1737, 1170,  401, 4257, 1189, 3866, 2467, 2005, 3423,
        3647, 1139, 3466, 3671])
Epoch: 1423, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1424 - Batch 1 ########################
IDs in batch 1: tensor([1723, 2150, 4026, 1870, 1957, 1617, 2577, 3530, 3256, 2405, 3719,  322,
         346, 2942, 1781, 1849])
Epoch: 1424, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1425 - Batch 1 ########################
IDs in batch 1: tensor([1269, 3002, 4116, 1651, 3476, 1031, 4230, 1660,  211, 3218, 1034,  196,
        1075, 2614, 3447, 1340])
Epoch: 1425, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1426 - Batch 1 ########################
IDs in batch 1: tensor([3704,  417,  196, 1397, 3984,  813, 2134, 3284, 2655, 1393, 2845,  747,
        2859,  289,  926, 1836])
Epoch: 1426, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1427 - Batch 1 ########################
IDs in batch 1: tensor([1698, 1949, 3303,  640,  626, 3496,  143, 2250, 4026, 3839, 1834, 2407,
        1275, 1828, 3146, 2688])
Epoch: 1427, Training Loss: 0.24, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1428 - Batch 1 ########################
IDs in batch 1: tensor([1846,  883, 1574,  980, 3101, 3087, 3539, 3071,  803, 2552, 1200, 3804,
        3945, 3588, 1555, 1671])
Epoch: 1428, Training Loss: 0.30, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1429 - Batch 1 ########################
IDs in batch 1: tensor([3526,  974,  284, 1558,  368, 2666,   88, 2833, 1232, 1417, 1195, 2643,
        2109, 3091, 2567, 2506])
Epoch: 1429, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1430 - Batch 1 ########################
IDs in batch 1: tensor([1155, 2051, 1454, 3992, 2371,  934,  425, 1870, 1681, 2721,  369,  989,
         890, 3663, 3671, 3962])
Epoch: 1430, Training Loss: 0.41, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1431 - Batch 1 ########################
IDs in batch 1: tensor([2723,  985,   99, 1015, 3549, 1015,  539, 1130, 3161, 4139,  211,  936,
        1883, 3446, 3184, 1369])
Epoch: 1431, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1432 - Batch 1 ########################
IDs in batch 1: tensor([3453, 1440, 2151, 1344, 3644, 2256, 4189, 3905, 3640, 2005, 1886, 2617,
        2416, 4161, 1546,   18])
Epoch: 1432, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1433 - Batch 1 ########################
IDs in batch 1: tensor([2743, 1799, 1271,  290, 2039,  850,  413, 1630, 2132, 3355, 2670, 2966,
         913, 4148, 1057, 2997])
Epoch: 1433, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1434 - Batch 1 ########################
IDs in batch 1: tensor([1432, 2937,   18,  604, 3161,  545,   27,  348, 3935, 3092, 2284, 3705,
        4195,  455, 1904, 1920])
Epoch: 1434, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1435 - Batch 1 ########################
IDs in batch 1: tensor([  34,  389, 3533,  259,  237, 1391, 2365, 3872, 2789, 3152, 2317,  788,
         426, 3905, 3542, 2025])
Epoch: 1435, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1436 - Batch 1 ########################
IDs in batch 1: tensor([3787, 2934, 2737,  752, 3570, 3438, 2719, 2950, 3548, 2800, 1670, 3466,
        2597, 3938, 1345, 2170])
Epoch: 1436, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1437 - Batch 1 ########################
IDs in batch 1: tensor([2300, 1656,  955, 3384, 1727, 4067, 3101, 3542,  949, 2582,  198, 3475,
        2784, 3211, 3747, 1766])
Epoch: 1437, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1438 - Batch 1 ########################
IDs in batch 1: tensor([2223,  474, 3668, 1934,  993, 3771, 3521, 2921, 1042,  237,  135, 1568,
        2192,  862,   31,  302])
Epoch: 1438, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1439 - Batch 1 ########################
IDs in batch 1: tensor([3277, 1476, 3275, 1113, 1239, 2110,  143, 1274, 2772, 4008, 4144,  510,
        3022, 2027, 1702,  133])
Epoch: 1439, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1440 - Batch 1 ########################
IDs in batch 1: tensor([3379,  950, 3151, 2650, 2253, 1636,  610, 1258, 3056, 3587, 4100,   62,
        2540, 2204, 1901, 1883])
Epoch: 1440, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1441 - Batch 1 ########################
IDs in batch 1: tensor([4128, 3656, 2598, 3897, 1007,  120, 3088, 1834, 3394,  375, 3300, 4056,
        2241, 3738, 3777,  607])
Epoch: 1441, Training Loss: 0.29, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1442 - Batch 1 ########################
IDs in batch 1: tensor([2718, 1063, 3151, 3977, 4265, 1770, 2524, 1161, 1290, 2120, 4141, 4224,
         201, 2111, 2927, 2291])
Epoch: 1442, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1443 - Batch 1 ########################
IDs in batch 1: tensor([1276, 2436, 4033, 2522, 1963,  874, 3371, 3885, 2022,  111, 2804, 3472,
        2587, 1834, 3871, 1445])
Epoch: 1443, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1444 - Batch 1 ########################
IDs in batch 1: tensor([2711, 3443, 2760, 1367, 3218,  119, 4184, 1255, 3354, 1818,  694, 2835,
        1558, 2480, 1723, 2743])
Epoch: 1444, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1445 - Batch 1 ########################
IDs in batch 1: tensor([1367, 1986, 1599, 1830, 2839, 3582, 3306, 3277,  190, 1959,  276,   64,
        2518,  824, 1601, 3700])
Epoch: 1445, Training Loss: 0.24, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1446 - Batch 1 ########################
IDs in batch 1: tensor([2209, 1945, 3481, 2362,  351,  276, 3952, 2463, 2870, 2763, 2011,  164,
        1971, 3996,   30, 1760])
Epoch: 1446, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1447 - Batch 1 ########################
IDs in batch 1: tensor([1052, 1510, 3956, 2963, 1212, 3798, 2597, 1793, 2265, 3727, 1787, 3182,
          56, 2337, 2135, 2968])
Epoch: 1447, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1448 - Batch 1 ########################
IDs in batch 1: tensor([ 909, 3858, 3094, 2315, 2659, 4234, 2183, 1986,  264,  987,  750,  665,
        3372, 4121,  694,  594])
Epoch: 1448, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1449 - Batch 1 ########################
IDs in batch 1: tensor([2529, 3842, 1574, 1081,  130, 2913, 1996,  498, 3922,  892, 3677,  263,
         821,  343, 3993, 1521])
Epoch: 1449, Training Loss: 0.53, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1450 - Batch 1 ########################
IDs in batch 1: tensor([ 274, 2247,  536, 2322,  558, 2597, 1292,  747,  490,  132,   77, 2272,
        2676,  456, 4212, 2469])
Epoch: 1450, Training Loss: 0.32, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1451 - Batch 1 ########################
IDs in batch 1: tensor([1868, 2511,   28, 3897, 3207,   41, 4267, 3160, 1351, 2189,   98, 1255,
        3459, 1975, 1543, 2681])
Epoch: 1451, Training Loss: 0.16, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1452 - Batch 1 ########################
IDs in batch 1: tensor([ 558, 2998,  171, 1121, 2739, 3860, 2991, 1080, 2284,  989, 2016, 2226,
        1328, 3600, 3268, 2391])
Epoch: 1452, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1453 - Batch 1 ########################
IDs in batch 1: tensor([3951, 3710, 1974, 3526,  417, 2011, 2226,  133, 1025, 3177, 2364, 3199,
        2615,  119, 2966, 2619])
Epoch: 1453, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1454 - Batch 1 ########################
IDs in batch 1: tensor([1330, 2348,  398, 1710,  217, 1335,  389, 2937, 2108, 3240, 1962, 3375,
        1510, 2976,  818, 2352])
Epoch: 1454, Training Loss: 0.30, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1455 - Batch 1 ########################
IDs in batch 1: tensor([3326, 2423, 2159, 1599, 1935, 1676, 2947,  492,  269, 1438, 1495,  625,
        3495, 2030, 1120, 3663])
Epoch: 1455, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1456 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 1644, 3992, 1879, 1716, 3099, 1007,  687, 3187, 4097, 1812, 2568,
        1793,  672, 1024,  572])
Epoch: 1456, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1457 - Batch 1 ########################
IDs in batch 1: tensor([2526, 4236, 2754, 3021,  910, 1014, 4002, 2777, 1711,  819,  332, 1061,
        1237, 3911, 4234, 4256])
Epoch: 1457, Training Loss: 0.41, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1458 - Batch 1 ########################
IDs in batch 1: tensor([2387, 4121, 3897, 2185, 3154, 1747,  511, 1835, 3049, 1599, 2317, 1367,
        1740, 3146,  172,  667])
Epoch: 1458, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1459 - Batch 1 ########################
IDs in batch 1: tensor([3895, 1158, 2441,  518, 1496, 1152, 3409, 2022, 1474, 1292, 3919, 1156,
         332, 2452, 3604,  930])
Epoch: 1459, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1460 - Batch 1 ########################
IDs in batch 1: tensor([2313, 1425, 1663, 3479, 4099, 2349,   93, 1050,  165,  821, 3492, 1269,
        3042, 3279, 4082, 2879])
Epoch: 1460, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1461 - Batch 1 ########################
IDs in batch 1: tensor([3507, 2663, 4121,  988, 2196, 1154, 1037, 3655, 3873, 2290, 1677, 1076,
          21, 1181, 3853, 4046])
Epoch: 1461, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1462 - Batch 1 ########################
IDs in batch 1: tensor([ 612,  844, 4203, 3900, 1519, 3728, 2063, 3389, 2252,  962, 2854,  723,
         846,  701,  305,  850])
Epoch: 1462, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1463 - Batch 1 ########################
IDs in batch 1: tensor([2112,  369, 3672, 1118, 2857, 1957,  344,  639,  569, 1005, 3461, 1094,
        1944,  430, 1144,   32])
Epoch: 1463, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1464 - Batch 1 ########################
IDs in batch 1: tensor([1248, 2656, 1372, 4200, 1324, 4000,  418, 2209, 2317,  141, 2973, 3778,
        3834,  554, 3551, 1450])
Epoch: 1464, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1465 - Batch 1 ########################
IDs in batch 1: tensor([1944, 2926, 1884,  362, 1341, 3795, 2755, 3483, 3996, 2983, 1748, 3939,
        2028, 2727,  167, 1257])
Epoch: 1465, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1466 - Batch 1 ########################
IDs in batch 1: tensor([3917, 2366, 3528, 3950, 2065,  390,  152, 3680, 1235, 2581,  713, 1220,
        2154,  908, 1022, 2866])
Epoch: 1466, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1467 - Batch 1 ########################
IDs in batch 1: tensor([ 829, 3144, 3747,  539, 2362, 1076, 1809, 3496, 3763, 1914, 3692,  532,
         356, 1517, 1315,  140])
Epoch: 1467, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1468 - Batch 1 ########################
IDs in batch 1: tensor([2868, 2788,  693, 1126, 3532,  196, 4097,  368, 3845,  228, 2402, 2261,
        3577, 3480,  893, 3367])
Epoch: 1468, Training Loss: 0.43, Validation Loss: 0.67, accuracy = 0.71
######################## Epoch 1469 - Batch 1 ########################
IDs in batch 1: tensor([1063, 3823, 1385, 3100, 4093, 3516, 2448,  950, 2297,  283, 4126, 1913,
        2742, 2467, 2323, 4200])
Epoch: 1469, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1470 - Batch 1 ########################
IDs in batch 1: tensor([3318,  899, 3734, 3834, 3710, 4215, 1596, 4010, 3252, 3644, 3177, 2418,
        3927, 1949, 4166, 2348])
Epoch: 1470, Training Loss: 0.85, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1471 - Batch 1 ########################
IDs in batch 1: tensor([3009,  615, 3071, 3199, 2041, 3710, 1489,   41, 1909, 2300, 1096,  572,
        2505,  659, 1518,  568])
Epoch: 1471, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1472 - Batch 1 ########################
IDs in batch 1: tensor([2161, 3496, 3927, 3603,  547,  256,  547, 1224,  824, 3214, 1668, 1712,
        2804, 1039, 3037,  807])
Epoch: 1472, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1473 - Batch 1 ########################
IDs in batch 1: tensor([ 161, 3903,  483, 2894, 2758, 1762, 4010, 2499, 1546, 2872, 1269,  967,
        3802,  517, 2746,  990])
Epoch: 1473, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1474 - Batch 1 ########################
IDs in batch 1: tensor([2344,  352, 2038, 2348, 3437,  490, 4114, 2775, 1234, 3903, 1624, 1802,
        1559, 1119, 2464,   61])
Epoch: 1474, Training Loss: 0.31, Validation Loss: 0.68, accuracy = 0.71
######################## Epoch 1475 - Batch 1 ########################
IDs in batch 1: tensor([3353, 3333, 2090, 3948, 2376, 1147, 1156, 3795, 2545, 2819,  152, 1493,
        1532, 3139,  397, 1951])
Epoch: 1475, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1476 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 1731, 3112, 3707, 1035, 1099, 3583, 1458,  344, 4078, 3306, 1650,
        1107, 2173, 1747,  992])
Epoch: 1476, Training Loss: 0.32, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1477 - Batch 1 ########################
IDs in batch 1: tensor([ 380, 2466, 2772, 3342, 2455, 2034, 1297, 2132, 1117, 1159, 2356, 1723,
        4088, 4024, 3207, 3818])
Epoch: 1477, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1478 - Batch 1 ########################
IDs in batch 1: tensor([2638, 3804, 2961, 3593, 2882,  762,  184,  266,  812,  280, 2134, 2965,
        2825, 1027, 2537,   27])
Epoch: 1478, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1479 - Batch 1 ########################
IDs in batch 1: tensor([1661, 1718, 1500,  485, 1239,  358,  436,  883, 3866, 3551, 1672, 1017,
        3091, 3364, 2017, 3948])
Epoch: 1479, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1480 - Batch 1 ########################
IDs in batch 1: tensor([ 283, 3467,  909, 3958, 2652, 1178,  787,  485, 2354, 3304, 3241, 4185,
        3707,  626, 4025, 2537])
Epoch: 1480, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1481 - Batch 1 ########################
IDs in batch 1: tensor([1364, 3842, 4232, 2452,  632, 2135, 3790, 3010, 1043, 3689,  103, 1569,
        2497, 2271, 2326, 3182])
Epoch: 1481, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1482 - Batch 1 ########################
IDs in batch 1: tensor([2497, 3326,  140,  508, 2791,  554,  804, 3368,    4, 2437, 1321,   93,
        1642, 1219, 1061,   82])
Epoch: 1482, Training Loss: 0.42, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1483 - Batch 1 ########################
IDs in batch 1: tensor([4180,  159, 3451, 2385, 3647, 1352, 3883, 1333,  959, 2305, 2876,   57,
        1432, 1088, 3253, 3744])
Epoch: 1483, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1484 - Batch 1 ########################
IDs in batch 1: tensor([2998, 1927, 2730, 4075, 2738, 2539, 2844, 3821, 1235, 1574, 4179, 2860,
        2550, 2599, 3408,  670])
Epoch: 1484, Training Loss: 0.54, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1485 - Batch 1 ########################
IDs in batch 1: tensor([1354, 2478,  427, 1796, 3920, 2145, 1825, 2982,  258, 2760, 2760, 3370,
        1050, 1693, 1153, 3218])
Epoch: 1485, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1486 - Batch 1 ########################
IDs in batch 1: tensor([2060,   38,  753,  844, 1166, 1471, 2805, 2761, 2155,  343, 2046, 3829,
        2223, 2506,  740, 2199])
Epoch: 1486, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1487 - Batch 1 ########################
IDs in batch 1: tensor([2499, 3036, 2982, 3087, 2505, 2075, 2603, 3421, 2431,  770, 3417, 1755,
         539, 1949, 2917,   11])
Epoch: 1487, Training Loss: 0.43, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1488 - Batch 1 ########################
IDs in batch 1: tensor([2605,  651, 1900, 1884, 1970, 2974, 1727, 1960, 3954, 4196,  120,  942,
        3448, 1086,  682, 2522])
Epoch: 1488, Training Loss: 0.48, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1489 - Batch 1 ########################
IDs in batch 1: tensor([3084, 2708,  405,  893, 1384, 4188, 3290, 1855,  832, 3446, 4264, 3410,
        3133, 1331, 1745, 3734])
Epoch: 1489, Training Loss: 0.69, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1490 - Batch 1 ########################
IDs in batch 1: tensor([2124, 1467, 1567, 1982, 3392, 3248,  380, 3830, 4013, 2463, 3035,  203,
        1110, 2998, 3126, 2354])
Epoch: 1490, Training Loss: 0.46, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1491 - Batch 1 ########################
IDs in batch 1: tensor([ 362, 3588, 1810, 2984,  526, 1641, 1853, 3581, 3456, 2103, 2681, 2553,
        1201, 1495,  333, 4133])
Epoch: 1491, Training Loss: 0.50, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1492 - Batch 1 ########################
IDs in batch 1: tensor([1367, 1881, 2357, 2479, 1232, 3178, 3958, 2892, 3336, 2542, 3102, 2344,
        1131, 3960, 1999,  993])
Epoch: 1492, Training Loss: 0.32, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 1493 - Batch 1 ########################
IDs in batch 1: tensor([1379, 2016, 2832,  110, 2441,  574, 4188, 2226, 3968,  108, 2230, 3276,
        2921,    4,  196,  513])
Epoch: 1493, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.69
######################## Epoch 1494 - Batch 1 ########################
IDs in batch 1: tensor([1277, 3671, 2797, 3891, 2038, 1426, 3793, 1110,   44, 2432, 3866,   85,
         946, 2824, 1644, 3465])
Epoch: 1494, Training Loss: 0.39, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1495 - Batch 1 ########################
IDs in batch 1: tensor([2060, 3714, 1628, 1882,  653, 2192, 3072,  968, 2842, 2301,  371, 3894,
        3753, 3246, 1818,  807])
Epoch: 1495, Training Loss: 0.30, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1496 - Batch 1 ########################
IDs in batch 1: tensor([ 237, 4186, 3384, 1117, 1963,  342, 2496,  224, 1657, 1090, 3782, 3528,
         732, 3144,  454, 2604])
Epoch: 1496, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1497 - Batch 1 ########################
IDs in batch 1: tensor([1722,  943,  908, 1777, 3144, 4212,  104, 3949, 2597, 2558, 2587, 1823,
        3618, 1266, 2648,  855])
Epoch: 1497, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1498 - Batch 1 ########################
IDs in batch 1: tensor([ 822, 2960,  437,  305, 2552, 4249, 2815, 2063,  682,  603,  891,  160,
        3065, 3850,  280,  694])
Epoch: 1498, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1499 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 3368, 2931, 4049, 1752, 2690, 1464, 1861, 1017,  871, 1158, 4110,
         807, 2228,  755,  252])
Epoch: 1499, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1500 - Batch 1 ########################
IDs in batch 1: tensor([1765, 1335, 2947,  356, 2455, 2724, 1340, 1676, 2150, 1841,  890, 4246,
         415, 1931, 3907, 2912])
Epoch: 1500, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1501 - Batch 1 ########################
IDs in batch 1: tensor([4085,  411, 1355, 1891, 3117, 1555, 2483, 1163, 3728, 2144, 2457, 1657,
         923, 3632, 4168,  519])
Epoch: 1501, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1502 - Batch 1 ########################
IDs in batch 1: tensor([1053, 2229, 2441, 1508, 3336, 3507, 3862,   60, 3614, 3208,  797, 2346,
         526, 3483,  218,  202])
Epoch: 1502, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1503 - Batch 1 ########################
IDs in batch 1: tensor([1970, 1798, 3183,  584, 2262,  247,  790,  478, 3299, 2609, 4203,  276,
        1648, 1553,  203, 1996])
Epoch: 1503, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1504 - Batch 1 ########################
IDs in batch 1: tensor([2553,  494, 3238, 2831, 1346,  526, 3478, 1199, 2052, 2326, 1493, 1601,
        2005, 2119, 4068,  205])
Epoch: 1504, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1505 - Batch 1 ########################
IDs in batch 1: tensor([4144, 1389, 2584, 3495, 1931, 1429,  833, 2544, 1610, 2986, 1977,  344,
        1347, 2386,  950, 1001])
Epoch: 1505, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1506 - Batch 1 ########################
IDs in batch 1: tensor([3053,  518, 3738,  839, 1559, 1613, 1913, 4099, 1247, 4032, 2275, 1552,
        1559, 1324, 2849, 1967])
Epoch: 1506, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1507 - Batch 1 ########################
IDs in batch 1: tensor([2453, 1183, 2854, 3853,  139, 2075, 2008, 2177, 1426, 3813,  936, 1942,
        2758, 1174, 2149, 1473])
Epoch: 1507, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1508 - Batch 1 ########################
IDs in batch 1: tensor([ 474, 3146, 2794, 3583, 2724, 3942, 4061, 2498,  842, 2341, 4213, 2789,
         184,   59, 3933,  503])
Epoch: 1508, Training Loss: 0.26, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1509 - Batch 1 ########################
IDs in batch 1: tensor([2510, 2328, 3591, 1255, 2350, 1655, 4186, 2271, 3943, 3395, 3675, 4254,
        2274, 2226, 4256, 3504])
Epoch: 1509, Training Loss: 0.54, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1510 - Batch 1 ########################
IDs in batch 1: tensor([1495, 2925, 3060, 1798, 2401,  826, 3650, 1464, 2645,  220,   82, 3570,
        3142, 1413,  251, 4226])
Epoch: 1510, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1511 - Batch 1 ########################
IDs in batch 1: tensor([  32, 2365, 2331, 3199, 2181, 3409, 1391, 2535, 1711, 3006, 3573, 1916,
         387, 2599, 2111, 1212])
Epoch: 1511, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1512 - Batch 1 ########################
IDs in batch 1: tensor([4031, 1894,  804, 3290, 1163, 2359, 2217, 1321,  556,  131, 1590, 4268,
        3500, 2353,  687, 2892])
Epoch: 1512, Training Loss: 0.34, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1513 - Batch 1 ########################
IDs in batch 1: tensor([1041, 4086,  662,  565,  513, 3098,  966,    7,  593, 2873,   37, 1234,
        2324, 4108,   47,  211])
Epoch: 1513, Training Loss: 0.64, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1514 - Batch 1 ########################
IDs in batch 1: tensor([1962,  730, 3760, 3765, 3533, 2954,  854,  821, 2494, 2418,  244, 2218,
        2018, 1331, 1804, 3837])
Epoch: 1514, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1515 - Batch 1 ########################
IDs in batch 1: tensor([2063, 1921, 1175, 3455, 1390, 2075, 4005,  520,  427, 3532,  876,  680,
         792, 2465, 1463, 3585])
Epoch: 1515, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1516 - Batch 1 ########################
IDs in batch 1: tensor([3921, 3936,  733,  980,  685, 1434,  393, 1704, 3914, 2828, 3618, 2605,
        3197, 2536, 3850, 1828])
Epoch: 1516, Training Loss: 0.46, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1517 - Batch 1 ########################
IDs in batch 1: tensor([3194, 1967, 2835, 2806, 2936, 2669, 1140, 2616, 3930, 2399, 2317, 3094,
         712, 1125, 2372, 2627])
Epoch: 1517, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1518 - Batch 1 ########################
IDs in batch 1: tensor([1934,  112, 1851, 2726, 1386, 1510, 3812,  809, 3243, 3038, 2408, 2508,
        1144, 1234, 2661, 1498])
Epoch: 1518, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1519 - Batch 1 ########################
IDs in batch 1: tensor([ 194, 2262, 4217, 2347, 2046,  644, 4121,  219, 3591, 2309, 1352, 3934,
        3968,  545, 2046, 3217])
Epoch: 1519, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1520 - Batch 1 ########################
IDs in batch 1: tensor([2567, 3902, 3908, 2772,  789, 3384, 3037, 1384, 2457, 1421, 1326,  960,
         469, 2118,  733, 3455])
Epoch: 1520, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1521 - Batch 1 ########################
IDs in batch 1: tensor([2847,  834, 3310, 2969, 2667, 4122,  813,  390, 2234, 3035,  626, 2799,
        2583,  491, 3911, 1501])
Epoch: 1521, Training Loss: 0.45, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1522 - Batch 1 ########################
IDs in batch 1: tensor([3765, 1536,  851, 1032, 3651, 2567, 2026, 1457, 3017, 4058, 3382, 2228,
        1963, 1312, 3747, 1375])
Epoch: 1522, Training Loss: 0.66, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1523 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 3181, 1661, 4013, 1502, 1352, 2800,  109,  819, 3374,  924, 2953,
        2578, 4056, 1409, 1053])
Epoch: 1523, Training Loss: 0.54, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1524 - Batch 1 ########################
IDs in batch 1: tensor([1971, 3621, 2401, 4055, 2236, 2154, 3484, 3340,  785, 2372, 3729, 3977,
         965, 3345, 1866,  603])
Epoch: 1524, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1525 - Batch 1 ########################
IDs in batch 1: tensor([ 160,  942, 1089,  701, 3306, 4222, 1601,  891, 3239, 2965, 4246,  491,
        2059, 3075,  501,  314])
Epoch: 1525, Training Loss: 0.33, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1526 - Batch 1 ########################
IDs in batch 1: tensor([3839,   46, 3699, 4016, 2500, 3423, 3879, 4163, 2106, 2028, 2117,  384,
        2429, 1321, 2407, 2328])
Epoch: 1526, Training Loss: 0.27, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1527 - Batch 1 ########################
IDs in batch 1: tensor([3255, 1464, 2733, 2969,  876, 1423, 3769, 3283, 2746,  467, 3432, 2671,
        4101, 1963, 3475, 2632])
Epoch: 1527, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1528 - Batch 1 ########################
IDs in batch 1: tensor([1635,  725, 3375, 1273, 2990, 1258, 3114, 1474, 1030,  792, 1111, 4227,
        2823, 2464, 2343, 2772])
Epoch: 1528, Training Loss: 0.39, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1529 - Batch 1 ########################
IDs in batch 1: tensor([ 188, 3183, 2869, 2687, 1335, 2095, 2489, 3640, 3838, 3540, 1425, 2963,
        3162, 2489,  212, 3179])
Epoch: 1529, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1530 - Batch 1 ########################
IDs in batch 1: tensor([ 217,  430, 2127, 3221, 3128,  918, 2305,  934, 3739, 2064,  188, 3818,
        2831, 2254, 2860,  220])
Epoch: 1530, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1531 - Batch 1 ########################
IDs in batch 1: tensor([3860, 1321, 2279, 2899, 2264, 2453, 1526, 4154, 4068,  612, 1413, 4003,
        1530, 1158, 1702, 1751])
Epoch: 1531, Training Loss: 0.36, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1532 - Batch 1 ########################
IDs in batch 1: tensor([1384, 3744,  507, 2949, 2053, 3617, 3680, 1199,  637, 1237, 2352, 4082,
        3863, 3367, 2535, 2982])
Epoch: 1532, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1533 - Batch 1 ########################
IDs in batch 1: tensor([1552,  399, 3196, 2894,  954,  529,  326, 2108, 2548,  869, 1668, 3130,
        1996, 2767,  471,  915])
Epoch: 1533, Training Loss: 0.38, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1534 - Batch 1 ########################
IDs in batch 1: tensor([ 341,  870,  803, 3157,  659, 1841, 2984, 2760, 4186, 2853, 2529, 3310,
        4251, 1256,  284, 1213])
Epoch: 1534, Training Loss: 0.32, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1535 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2598, 3894, 1180, 2520,  315,  986,  557, 1641, 4251, 3511, 4086,
        1352,  636, 3154,  484])
Epoch: 1535, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.72
######################## Epoch 1536 - Batch 1 ########################
IDs in batch 1: tensor([ 395, 2050,  955, 2193, 2815,  165, 3744, 1198, 3577, 4222,   72,  712,
         919, 3395, 4015,  723])
Epoch: 1536, Training Loss: 0.35, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1537 - Batch 1 ########################
IDs in batch 1: tensor([3553, 3017,  902, 3780,  256, 4253, 3525, 4024,  323, 2721,  128, 2476,
         733,  887, 2334, 4217])
Epoch: 1537, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1538 - Batch 1 ########################
IDs in batch 1: tensor([2264,  269, 2755, 1499,  323, 2853, 2967, 1927, 2188, 3879, 1031, 3009,
        2668, 4226, 2874, 4143])
Epoch: 1538, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1539 - Batch 1 ########################
IDs in batch 1: tensor([3161, 2682, 3178,  947,  757,  199, 1882, 3378, 2945, 3862, 4176, 3143,
         724, 2841,  465, 4136])
Epoch: 1539, Training Loss: 0.42, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1540 - Batch 1 ########################
IDs in batch 1: tensor([4095, 1569, 2257, 1861, 1134, 1899, 2111, 1613, 1555, 3364, 1364, 1096,
        3355, 1014, 2141, 4011])
Epoch: 1540, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1541 - Batch 1 ########################
IDs in batch 1: tensor([3362,  262, 2343, 4010, 2228,  159, 3004,  642, 3223, 2772, 3843,  148,
         228,   41,  812, 3398])
Epoch: 1541, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1542 - Batch 1 ########################
IDs in batch 1: tensor([2413, 2496, 2170, 1395, 3921, 1972, 2721,  326, 1556,  276, 2388, 3084,
        3406, 1724, 4161, 3539])
Epoch: 1542, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1543 - Batch 1 ########################
IDs in batch 1: tensor([2915, 2312, 2249, 4108, 2671,  343,  491, 3132, 1249,  896, 3196,  198,
        1344,  771, 3812,  804])
Epoch: 1543, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1544 - Batch 1 ########################
IDs in batch 1: tensor([1633, 4007, 2219, 3908, 3587, 3110, 1086, 2016, 1155, 3598, 1954, 3728,
        4125, 3098,   42, 2016])
Epoch: 1544, Training Loss: 0.47, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1545 - Batch 1 ########################
IDs in batch 1: tensor([ 530,  324,  811,  195, 3638,  863, 1417, 3200, 1417, 3303, 1317, 2943,
          82, 1356, 3369, 1087])
Epoch: 1545, Training Loss: 0.28, Validation Loss: 0.68, accuracy = 0.73
######################## Epoch 1546 - Batch 1 ########################
IDs in batch 1: tensor([1956, 3618, 3968, 2407, 2649, 2749, 2583, 3143, 3004, 1862, 4258, 3152,
        2251,  196, 2733, 1434])
Epoch: 1546, Training Loss: 0.72, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1547 - Batch 1 ########################
IDs in batch 1: tensor([3953, 1981, 2670, 1155, 1291, 4200, 2876, 2022, 2511, 3883, 3689, 2886,
        3592, 2376,  928, 1266])
Epoch: 1547, Training Loss: 0.45, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1548 - Batch 1 ########################
IDs in batch 1: tensor([3763, 2919,  819, 3660,  469, 2582,  140, 2280, 1786, 1872, 1754, 1648,
        4258, 1458,    5, 2019])
Epoch: 1548, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1549 - Batch 1 ########################
IDs in batch 1: tensor([2035, 3525, 2171, 2915, 1200, 3077, 1708,  264, 1559,  393, 2509, 1487,
        2641, 1745, 1617, 2189])
Epoch: 1549, Training Loss: 0.16, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1550 - Batch 1 ########################
IDs in batch 1: tensor([3928, 3226, 3179,  226, 2787, 1495, 1235, 3779, 1762, 2350, 1134, 1372,
        3609, 2496, 3376, 1748])
Epoch: 1550, Training Loss: 0.26, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1551 - Batch 1 ########################
IDs in batch 1: tensor([2996, 3152, 3060, 3928, 3421, 1763, 1212, 1061,  412, 2499, 4013, 3465,
         590, 1011, 2346, 1651])
Epoch: 1551, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1552 - Batch 1 ########################
IDs in batch 1: tensor([2789, 3049, 3434, 3469, 4188,  523, 1155, 3284, 1075, 2784, 4140, 1732,
        2806, 1841, 1632, 1450])
Epoch: 1552, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1553 - Batch 1 ########################
IDs in batch 1: tensor([3130,  552, 3516, 1673, 2220,  862, 1673,  154,  709,  682,  395, 1895,
        2890, 1679, 3616, 1690])
Epoch: 1553, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1554 - Batch 1 ########################
IDs in batch 1: tensor([2917, 3876, 3960, 1219, 2444, 3334, 2120, 2696,  491, 3108, 2711,  182,
        1618, 1661, 1556,   10])
Epoch: 1554, Training Loss: 0.26, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1555 - Batch 1 ########################
IDs in batch 1: tensor([4199,  321,  263, 2348, 3436, 1760, 1804, 3238,  858,  161, 3507, 3020,
        2098, 3980, 2784, 3410])
Epoch: 1555, Training Loss: 0.40, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1556 - Batch 1 ########################
IDs in batch 1: tensor([1495, 2439, 4037, 2306, 2262, 1319, 2984,  730, 2092, 3485, 3148, 3087,
        2724, 2199, 3545, 4107])
Epoch: 1556, Training Loss: 0.61, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1557 - Batch 1 ########################
IDs in batch 1: tensor([ 857, 2226, 3130, 2480, 1133, 3368, 4016, 2150,   60,  183, 2242, 1024,
         886, 3264, 3358,  489])
Epoch: 1557, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1558 - Batch 1 ########################
IDs in batch 1: tensor([2603, 3950, 4225, 3695, 3525, 2832, 2749, 3990, 3196, 1501, 4026, 2378,
        3921, 2250, 1372, 1233])
Epoch: 1558, Training Loss: 0.61, Validation Loss: 0.68, accuracy = 0.72
######################## Epoch 1559 - Batch 1 ########################
IDs in batch 1: tensor([2457, 2703, 3524, 4003, 3608, 1134,  777,  213, 1333, 2018, 2496, 2370,
        1852, 1571, 4082, 1206])
Epoch: 1559, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1560 - Batch 1 ########################
IDs in batch 1: tensor([3879, 4254,  292, 3084, 1640, 3554, 3911, 1414, 2478, 1833, 3038, 3500,
        1387,   44, 2734, 3500])
Epoch: 1560, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1561 - Batch 1 ########################
IDs in batch 1: tensor([ 637,  701, 3808, 3480, 2295,  266, 3261, 2463, 4061, 3488, 1756, 3223,
        1574, 2529, 3310, 1311])
Epoch: 1561, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.72
######################## Epoch 1562 - Batch 1 ########################
IDs in batch 1: tensor([1354, 1472,  330,  356, 2477,  498, 1418, 2463, 2568, 2276, 2925, 4195,
        2758,  625, 1823, 1583])
Epoch: 1562, Training Loss: 0.14, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1563 - Batch 1 ########################
IDs in batch 1: tensor([3264, 2046,  741, 2571, 3467, 2475,  484, 1310, 3436, 1241,  300, 1710,
        2606, 3330, 2954, 3400])
Epoch: 1563, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1564 - Batch 1 ########################
IDs in batch 1: tensor([2090, 2854, 4163, 2290, 3831, 2002, 3956, 1927,  252, 1628, 3130, 1734,
        4240, 1956, 1863, 3323])
Epoch: 1564, Training Loss: 0.31, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1565 - Batch 1 ########################
IDs in batch 1: tensor([ 498, 2403, 2458, 2306, 3298,  287,  137,   74,  279, 2173, 3077, 3472,
        3715, 1730, 1085, 2746])
Epoch: 1565, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1566 - Batch 1 ########################
IDs in batch 1: tensor([3037,  322, 3706,   92, 2379,  365, 1410, 1102, 1786,  109, 3632, 1780,
         134, 2457, 2836, 2365])
Epoch: 1566, Training Loss: 0.42, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1567 - Batch 1 ########################
IDs in batch 1: tensor([3740, 1311,  139, 3463,  826, 1344,  340, 2784, 3000, 2464, 3780,  747,
        2137, 2541, 3713, 2645])
Epoch: 1567, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1568 - Batch 1 ########################
IDs in batch 1: tensor([2931,  752, 2247, 2618, 4089, 2253,  300, 3354, 4068, 3648, 3535, 2300,
        2451, 4026,  646, 3815])
Epoch: 1568, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1569 - Batch 1 ########################
IDs in batch 1: tensor([  64, 2842, 3970,  891, 1321, 1952, 3956,  478, 2687,  936,  263, 2645,
        3513, 1456, 3567, 2132])
Epoch: 1569, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1570 - Batch 1 ########################
IDs in batch 1: tensor([ 330,   63, 3321,  203, 3339, 1499, 3255, 2418, 1363, 2367, 1849, 2870,
        1038,  582, 1252, 2688])
Epoch: 1570, Training Loss: 0.27, Validation Loss: 0.66, accuracy = 0.73
######################## Epoch 1571 - Batch 1 ########################
IDs in batch 1: tensor([3300, 2298, 3250, 1845,  409,   68, 2405,  334,  712,  963, 2741, 1025,
        2203, 2155, 3333,  470])
Epoch: 1571, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1572 - Batch 1 ########################
IDs in batch 1: tensor([1154, 1089, 1974, 3408, 1309,  243, 3160,  505, 1668,  923, 2812, 1975,
        1892,  141,  832,  418])
Epoch: 1572, Training Loss: 0.28, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1573 - Batch 1 ########################
IDs in batch 1: tensor([2261, 1990,  341, 1900,   60, 3188, 2407, 2538, 3176, 2783, 3950, 1312,
        2125,  699, 4242, 1628])
Epoch: 1573, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1574 - Batch 1 ########################
IDs in batch 1: tensor([2510, 3718, 2025, 1334, 4194, 2629, 1552, 1600,  104, 2226, 3644, 3073,
        2193,  190, 2410, 2886])
Epoch: 1574, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1575 - Batch 1 ########################
IDs in batch 1: tensor([ 982, 3399,  434, 3721, 3711, 1252, 3437, 1521, 3353, 2917, 3265, 1521,
        2437, 3443,  140,  779])
Epoch: 1575, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1576 - Batch 1 ########################
IDs in batch 1: tensor([1206, 2703, 1953, 3745, 3476,  890, 4010, 1779, 2636,  303, 1610,  741,
        2867, 1336, 2703, 2052])
Epoch: 1576, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1577 - Batch 1 ########################
IDs in batch 1: tensor([1088, 4115, 2244, 2458, 3385, 2118, 1977, 3112, 2986, 3002, 2606,  820,
          51,  884, 4117, 3995])
Epoch: 1577, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.73
######################## Epoch 1578 - Batch 1 ########################
IDs in batch 1: tensor([ 152, 3473, 3049,  257, 1223, 2968, 3763,  530, 1546, 3536, 2905, 3142,
        3031, 1480, 1218, 3583])
Epoch: 1578, Training Loss: 0.20, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1579 - Batch 1 ########################
IDs in batch 1: tensor([3268,  492, 3738,  662, 1818,  601, 3729, 2300, 4057,  848, 2582, 1385,
        2290, 3822, 1661, 2563])
Epoch: 1579, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.74
######################## Epoch 1580 - Batch 1 ########################
IDs in batch 1: tensor([3264, 1270, 1556, 1784, 1553, 2364, 1760,   99, 3283, 3552, 2193, 2953,
        2849,  145,  437, 4180])
Epoch: 1580, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1581 - Batch 1 ########################
IDs in batch 1: tensor([4084,  545, 3846, 3370, 1341,  944, 2624,  682, 3786, 2587,  886, 1252,
        3417,  434,  513, 2511])
Epoch: 1581, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1582 - Batch 1 ########################
IDs in batch 1: tensor([2838,   85, 3913, 1506, 4114,  809, 4048, 2390,   18, 2470, 1599, 2408,
          42, 3739, 2193, 2752])
Epoch: 1582, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1583 - Batch 1 ########################
IDs in batch 1: tensor([3557,  134,  261, 3873, 1501, 2600,  930, 4010, 4016, 4000, 3211, 2708,
        2041,  440, 2564,  897])
Epoch: 1583, Training Loss: 0.39, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1584 - Batch 1 ########################
IDs in batch 1: tensor([1665,  184, 1315,  181,  778, 2281, 3681, 1024, 3006, 2519, 2859, 1313,
        3763, 3638, 3121,  438])
Epoch: 1584, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1585 - Batch 1 ########################
IDs in batch 1: tensor([1971, 3227, 1166, 2202, 2285,  997, 2314,  141, 4133,   11, 3939, 2950,
         322, 2135, 3197, 1281])
Epoch: 1585, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1586 - Batch 1 ########################
IDs in batch 1: tensor([ 274,  789, 1108, 1098,  904, 2578,  630, 4133,  993, 1166, 1082, 4084,
        1585, 2056, 2974, 3425])
Epoch: 1586, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1587 - Batch 1 ########################
IDs in batch 1: tensor([2181, 1968, 4143, 3701,  766, 3183, 1981, 1886, 1602, 2969, 3493,  358,
        3421,  830, 2145, 4122])
Epoch: 1587, Training Loss: 0.37, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1588 - Batch 1 ########################
IDs in batch 1: tensor([ 658,  871,  830, 1485, 1147, 2660, 2189, 3707,  218, 1784, 1625, 2002,
         225, 3177, 2480, 1178])
Epoch: 1588, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1589 - Batch 1 ########################
IDs in batch 1: tensor([1345, 1635, 3549, 2578, 1289,  527, 1154, 3498, 1344, 3495, 3715, 1376,
         646,   97, 4117, 3459])
Epoch: 1589, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1590 - Batch 1 ########################
IDs in batch 1: tensor([ 137, 2171, 2976, 3038, 1312, 1406, 3554, 1601,  818, 4242, 1016,  198,
         360, 2797, 3706, 2494])
Epoch: 1590, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1591 - Batch 1 ########################
IDs in batch 1: tensor([ 333, 4176, 4049, 1698, 3499,  890, 1331,  376, 3351, 2052, 1296, 2734,
        2403, 3304, 2414,  334])
Epoch: 1591, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1592 - Batch 1 ########################
IDs in batch 1: tensor([ 644, 1996, 2796, 3495, 2689, 2551,  555, 2726, 3526, 1356, 3908, 2683,
        1938, 2517, 1508, 1955])
Epoch: 1592, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1593 - Batch 1 ########################
IDs in batch 1: tensor([ 795,  244, 1640, 3498,   77, 2191, 3351, 3751, 3822,  833, 2182, 1287,
        1440, 3638, 1249,  440])
Epoch: 1593, Training Loss: 0.29, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1594 - Batch 1 ########################
IDs in batch 1: tensor([1333, 1472, 1781, 1464, 3767, 4039,  280, 1162, 1575, 1859, 1042, 2347,
         996, 2028, 3291, 2365])
Epoch: 1594, Training Loss: 0.41, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1595 - Batch 1 ########################
IDs in batch 1: tensor([ 565, 3427, 2435,  983,  988,  991, 4069,  517, 3308, 1292, 1855, 2272,
        3500,  928, 2772, 4058])
Epoch: 1595, Training Loss: 0.38, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1596 - Batch 1 ########################
IDs in batch 1: tensor([1841, 3853,  642, 3654, 3972,  595, 1881, 1163,  195, 3495, 2545, 2854,
        3364, 2806, 3669, 1099])
Epoch: 1596, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1597 - Batch 1 ########################
IDs in batch 1: tensor([3922, 1576, 1583, 2498,  342,  308, 3018, 2108, 2708, 1088, 1123, 1566,
        2869, 3932, 2064,  635])
Epoch: 1597, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1598 - Batch 1 ########################
IDs in batch 1: tensor([2419,  183, 2539,  814,  112,  880, 1297,  520, 1133, 3111, 2819, 3528,
        2725, 3439, 1365, 3882])
Epoch: 1598, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1599 - Batch 1 ########################
IDs in batch 1: tensor([1902, 3977, 1161, 3648, 1803, 2721, 1223, 1988, 3461, 2883, 3621,  133,
        2636, 3982, 1496,  161])
Epoch: 1599, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1600 - Batch 1 ########################
IDs in batch 1: tensor([2821,  623, 2646, 2235, 2346,  541, 3440, 2144, 3216, 3539, 3423,  303,
         681, 2689, 3663, 1310])
Epoch: 1600, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1601 - Batch 1 ########################
IDs in batch 1: tensor([ 649, 3920,  202, 3563, 1260, 3992, 4050, 1321, 1370, 1179,  193,  205,
        1087, 4056, 1306, 2202])
Epoch: 1601, Training Loss: 0.86, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1602 - Batch 1 ########################
IDs in batch 1: tensor([2858,  338, 3739,  625, 3370, 3593, 3461, 1736, 3532, 3564, 2506, 2181,
        3360, 2770, 1614, 2514])
Epoch: 1602, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1603 - Batch 1 ########################
IDs in batch 1: tensor([3518, 3713, 1009, 3376, 4158, 1052, 1007,  378, 4220, 1752, 1059, 1031,
        3958, 3010, 3246, 3781])
Epoch: 1603, Training Loss: 0.72, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1604 - Batch 1 ########################
IDs in batch 1: tensor([2844, 2312, 3693, 1809, 3542, 2327, 3852,  143, 3362, 1138, 1126, 2499,
        1972, 1597, 3873, 3914])
Epoch: 1604, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1605 - Batch 1 ########################
IDs in batch 1: tensor([4180, 1676, 3421, 3028, 1610, 3184,  617, 1319, 2362,  375, 3235, 1840,
        2575, 2301,  651, 4213])
Epoch: 1605, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1606 - Batch 1 ########################
IDs in batch 1: tensor([2465,   98, 3719, 3795, 1291,  221,   31, 1846, 2894, 2370, 1034,   59,
        1062, 3360, 4044, 3389])
Epoch: 1606, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1607 - Batch 1 ########################
IDs in batch 1: tensor([ 823, 3940, 1287, 2022, 3053,  155, 4128, 1862,  425,  538, 2752, 3455,
        2993, 3148, 1956, 2940])
Epoch: 1607, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1608 - Batch 1 ########################
IDs in batch 1: tensor([ 292, 1596,  105, 1763, 2346, 2249, 1810, 2886,  701, 1285, 4204,  574,
        2568,  970,  862, 3912])
Epoch: 1608, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1609 - Batch 1 ########################
IDs in batch 1: tensor([1682, 3509, 2400, 2901, 1331, 1490, 3439, 2219, 2616, 4174, 2284, 2383,
        2476, 2661,  280, 3734])
Epoch: 1609, Training Loss: 0.37, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1610 - Batch 1 ########################
IDs in batch 1: tensor([ 835, 4131, 1402, 3950, 1499, 1062, 3615, 2085, 1894,  726, 1467, 3299,
        2927, 2689, 1617, 2537])
Epoch: 1610, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1611 - Batch 1 ########################
IDs in batch 1: tensor([1588, 2005,  875, 3983,  752, 2190, 3950, 2771,  132, 2220, 3398, 3099,
        1573, 3747, 1680, 2723])
Epoch: 1611, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1612 - Batch 1 ########################
IDs in batch 1: tensor([1562, 1681, 2008, 3673, 3487, 3806, 1098, 3961,  193, 2224, 4117, 1379,
        1611,  785, 3087, 1084])
Epoch: 1612, Training Loss: 0.49, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1613 - Batch 1 ########################
IDs in batch 1: tensor([  38, 3453,  315, 3749, 1720, 3246, 1464, 1093, 2807, 3549, 1199, 1755,
        3951, 1030, 4000, 1821])
Epoch: 1613, Training Loss: 0.48, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1614 - Batch 1 ########################
IDs in batch 1: tensor([1756, 2045,  427,  470, 3248,  300, 1799, 2548, 3980, 2406, 3547,   59,
        1984,  389, 1723, 3900])
Epoch: 1614, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1615 - Batch 1 ########################
IDs in batch 1: tensor([1812, 3760, 2213, 3829, 3182,   95,  960,  819,  620, 3597, 2787, 2337,
        3318,  884, 1305, 3601])
Epoch: 1615, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1616 - Batch 1 ########################
IDs in batch 1: tensor([3394, 3618, 2127, 3499, 2617, 3999, 3818, 1728,  455, 3199,  709, 2332,
        3449, 1976, 2442, 1746])
Epoch: 1616, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1617 - Batch 1 ########################
IDs in batch 1: tensor([1958, 3313, 4157, 3223,  741, 1178, 4161, 1498, 3588, 3836, 2964, 2373,
        1104,  191, 3656, 2314])
Epoch: 1617, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1618 - Batch 1 ########################
IDs in batch 1: tensor([1026,  455,  205, 1671,  578, 1349, 3767, 2465, 1278,  779,  129, 3707,
        1567, 1075, 1101,  676])
Epoch: 1618, Training Loss: 0.70, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1619 - Batch 1 ########################
IDs in batch 1: tensor([3409,  762, 2065, 2514,  864,  456, 1562, 3202, 2636, 2746, 3234, 1117,
         185,  769, 1861, 3443])
Epoch: 1619, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1620 - Batch 1 ########################
IDs in batch 1: tensor([1439,  945,  269, 2246, 3795, 2697, 2095, 1756,  519, 3238,  606, 3945,
        1651, 3990, 3485, 4101])
Epoch: 1620, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1621 - Batch 1 ########################
IDs in batch 1: tensor([ 260, 2836, 1672, 2907, 1051, 3516, 2161, 3577, 1860, 2885, 3386,   25,
        2004, 2423,  371,  920])
Epoch: 1621, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1622 - Batch 1 ########################
IDs in batch 1: tensor([ 435, 3904, 1497,   56,  842,  818, 3714,  409, 2518, 3395, 1711,  622,
        3327, 1027, 3372, 1740])
Epoch: 1622, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1623 - Batch 1 ########################
IDs in batch 1: tensor([3300, 2344,  771, 1745, 1583,  110,  276, 2793,  808, 1853, 1883,  960,
        2053,  710, 1569, 2131])
Epoch: 1623, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1624 - Batch 1 ########################
IDs in batch 1: tensor([ 673,  130,  907, 1861,  833, 3496, 2858, 1434, 3954, 1850, 4254, 1994,
        3501, 2696, 1844, 1138])
Epoch: 1624, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1625 - Batch 1 ########################
IDs in batch 1: tensor([4124, 3781, 2150,  111, 3072,  991, 2921, 1045, 2970, 2552,  863, 4117,
         914,   98, 2435, 1269])
Epoch: 1625, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1626 - Batch 1 ########################
IDs in batch 1: tensor([2734, 1134, 4205, 3677, 2470, 3583,  807,  463, 4062, 1808, 2793,  710,
        1375,  323, 3000, 1330])
Epoch: 1626, Training Loss: 0.76, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1627 - Batch 1 ########################
IDs in batch 1: tensor([1163, 1007, 3434, 1566, 3806, 2019, 2831, 2868, 1944, 2103, 2855, 2712,
        4268, 3496, 3235, 2721])
Epoch: 1627, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1628 - Batch 1 ########################
IDs in batch 1: tensor([2254, 3950,  213,  547,  563, 1295, 3250, 4186, 2583, 2599, 1377, 3014,
        4139, 2721, 2373,  953])
Epoch: 1628, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.71
######################## Epoch 1629 - Batch 1 ########################
IDs in batch 1: tensor([2067, 3098, 1994, 3446, 4148,  413,  819,  243, 2696, 1171, 2195, 3851,
        3351, 3610, 4072, 3127])
Epoch: 1629, Training Loss: 0.31, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1630 - Batch 1 ########################
IDs in batch 1: tensor([1733,  788, 2827, 2304,  557, 4139, 1156, 1266, 3479,  512,   22, 3410,
         259, 3313, 3185, 2219])
Epoch: 1630, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1631 - Batch 1 ########################
IDs in batch 1: tensor([4061, 2252,  980,   18,  324, 3251, 1057, 2882,  472, 3509, 2247, 1118,
        3006,  511, 3841, 2765])
Epoch: 1631, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1632 - Batch 1 ########################
IDs in batch 1: tensor([2415, 2505,  450, 3718, 1724, 2764, 3786, 3492,  653, 4044, 2853, 2883,
        1162, 3211, 3336, 2701])
Epoch: 1632, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1633 - Batch 1 ########################
IDs in batch 1: tensor([2640,  137,  635, 3418, 2732,  237, 1589, 2204, 1632,  814, 2244, 1334,
        3664, 2558, 3276, 3432])
Epoch: 1633, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.70
######################## Epoch 1634 - Batch 1 ########################
IDs in batch 1: tensor([ 350, 3133, 2646,  968, 4253,  946, 2977,  365, 1671, 3692, 3337, 2230,
        2010, 2521,  173, 2123])
Epoch: 1634, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1635 - Batch 1 ########################
IDs in batch 1: tensor([ 346, 1381, 1722,  774, 1247, 3948, 3235, 1630, 3919, 2232,  565, 3400,
        3581, 3714,  357,  322])
Epoch: 1635, Training Loss: 0.49, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1636 - Batch 1 ########################
IDs in batch 1: tensor([4230,  985, 3841, 2558, 3466, 4036, 2536, 3289, 1832, 1317, 1180, 1450,
        2329, 4033, 2316, 2615])
Epoch: 1636, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1637 - Batch 1 ########################
IDs in batch 1: tensor([ 343,  767, 3636, 1037, 3616, 3352, 3456, 3135, 1573, 1525, 4251, 1423,
        3381, 1251, 1804, 1521])
Epoch: 1637, Training Loss: 0.47, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1638 - Batch 1 ########################
IDs in batch 1: tensor([3834, 3493, 1956,  993, 2401, 1767,  888, 3668, 3524, 3746,  718, 2505,
         498,  395, 1290, 3028])
Epoch: 1638, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1639 - Batch 1 ########################
IDs in batch 1: tensor([3456, 4125, 2145, 3300,  455, 2795,  303, 2258, 1711, 2028, 2179, 2620,
        1524, 2171, 4086, 1590])
Epoch: 1639, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1640 - Batch 1 ########################
IDs in batch 1: tensor([3960,  846,  111, 2217,  395, 2629,  937, 2495, 1574, 1136,   99, 2600,
        1055, 3505, 3700, 1736])
Epoch: 1640, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1641 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 2010, 2764,  360,  380, 3743, 2823,  970, 4008,   73,  612, 1107,
        2065, 4038, 2581, 3372])
Epoch: 1641, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1642 - Batch 1 ########################
IDs in batch 1: tensor([1324,  808,  171, 3187, 3958, 1954, 3492, 1932, 2350, 4121,  454, 2027,
         122,  442, 3133, 2938])
Epoch: 1642, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1643 - Batch 1 ########################
IDs in batch 1: tensor([ 119, 1226, 1370, 1585, 3834, 3542, 3235,  914, 4033, 1296,  952, 3996,
        2783, 1458, 3364, 4050])
Epoch: 1643, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1644 - Batch 1 ########################
IDs in batch 1: tensor([2754, 1290, 2969,  870, 3037, 3369, 1281, 3267,  717, 1312, 4033, 1702,
        2641, 3581, 1495, 3358])
Epoch: 1644, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1645 - Batch 1 ########################
IDs in batch 1: tensor([3927,  135,  795, 2565, 2464, 4103, 1383, 2356, 3746, 4004, 3192, 2745,
        1840,  332, 2736, 2793])
Epoch: 1645, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1646 - Batch 1 ########################
IDs in batch 1: tensor([ 547, 1920, 4195,  959, 2251, 2151, 3610, 3311, 3193,  134, 1579, 4197,
        1302, 1984, 4085, 3760])
Epoch: 1646, Training Loss: 0.64, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1647 - Batch 1 ########################
IDs in batch 1: tensor([1249,  721,  954, 2320, 3218,  803, 3898, 2660,  921, 2770, 1746, 2797,
          86, 3608, 1049, 3904])
Epoch: 1647, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1648 - Batch 1 ########################
IDs in batch 1: tensor([3364,  966, 1755, 3954, 3143,  752, 1195, 1920, 1802, 1861, 1345,  427,
        1795, 1752, 2840, 1960])
Epoch: 1648, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1649 - Batch 1 ########################
IDs in batch 1: tensor([ 187,  449,  113, 3408,  663,   77, 1680, 2783, 2517, 1623, 1745,  474,
        1042, 1925, 3009, 2253])
Epoch: 1649, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1650 - Batch 1 ########################
IDs in batch 1: tensor([2344, 2178, 4057, 1286, 4170,  632, 3778, 2892, 2026,  354, 1226,  953,
        3858, 1179, 2870,  835])
Epoch: 1650, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1651 - Batch 1 ########################
IDs in batch 1: tensor([2383, 1756, 2866, 2092, 2671, 3309,  350, 3003, 3950, 2869, 1830,  657,
        2188,  150, 1228, 2795])
Epoch: 1651, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1652 - Batch 1 ########################
IDs in batch 1: tensor([1677, 3528, 1500, 2356, 1624, 1482, 1009,  323,    5, 4168, 1061,  886,
         803, 3238, 2804, 2354])
Epoch: 1652, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1653 - Batch 1 ########################
IDs in batch 1: tensor([3110, 2921,  653,  991, 1375, 1630, 1859,  432, 3772, 3738,  250, 1093,
        2322, 3465, 3414, 2976])
Epoch: 1653, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1654 - Batch 1 ########################
IDs in batch 1: tensor([2848, 2616, 4011, 1761, 4050, 3356, 4245,  988, 1384,  382,  822,   85,
        2815, 1007, 4048,  890])
Epoch: 1654, Training Loss: 0.43, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1655 - Batch 1 ########################
IDs in batch 1: tensor([2177, 3544,  724, 3400, 2112, 2871, 2681, 1229, 2663, 3528, 1676, 1271,
        1178,  140, 3697, 4204])
Epoch: 1655, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 1656 - Batch 1 ########################
IDs in batch 1: tensor([1904, 2890, 2399, 2477,  812, 1496, 1602, 1315, 1137, 1146, 2724,  371,
          77, 1789, 2770, 1509])
Epoch: 1656, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1657 - Batch 1 ########################
IDs in batch 1: tensor([1102, 3587, 1239, 3598, 2982, 3992, 4135, 3911, 3500, 2053,  305, 2223,
        2407, 2664, 3060,   64])
Epoch: 1657, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1658 - Batch 1 ########################
IDs in batch 1: tensor([1563, 1325,  354, 3290, 1775,  284, 2004, 2053, 2666, 2477,  463,  751,
         557,  357,  343, 3363])
Epoch: 1658, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1659 - Batch 1 ########################
IDs in batch 1: tensor([4070, 2324, 3300, 3152, 1156, 3427,  442, 4061,  135, 1097,  188, 3763,
        2390, 3911, 3746, 3397])
Epoch: 1659, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1660 - Batch 1 ########################
IDs in batch 1: tensor([1999,  923, 3053, 4093,  769, 1665,  512, 2376, 1803, 1818, 2238, 1677,
        3711, 2478, 1504, 3538])
Epoch: 1660, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1661 - Batch 1 ########################
IDs in batch 1: tensor([1009, 2764, 4113, 3810, 4222, 4214,   41,   30, 3439, 1351,  626, 2358,
          59, 2182, 1241, 1414])
Epoch: 1661, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1662 - Batch 1 ########################
IDs in batch 1: tensor([3615,  494, 1379,  827, 3714, 3726,   31,  250, 2449, 3188, 2775, 3553,
        2326, 1085, 3439, 2099])
Epoch: 1662, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1663 - Batch 1 ########################
IDs in batch 1: tensor([1073, 1206,  794, 4035, 1057,  839, 1885, 1138, 4065,  659, 3055, 1755,
         198, 3071, 2462,  795])
Epoch: 1663, Training Loss: 0.33, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1664 - Batch 1 ########################
IDs in batch 1: tensor([3591, 2659, 3370, 2414, 3238,   32, 2660, 1380, 2833, 3072,  644, 1619,
        1960, 2119, 1754,  135])
Epoch: 1664, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1665 - Batch 1 ########################
IDs in batch 1: tensor([3479, 1886, 2649, 1052,  894, 4018,  345,  274,  470, 2292, 3255,  518,
        2529, 4168, 1396, 1332])
Epoch: 1665, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 1666 - Batch 1 ########################
IDs in batch 1: tensor([2551, 3190, 3453, 4089, 2789, 2344, 3638, 2177, 2751,   37, 3668, 1171,
        2463, 3447, 4255, 1098])
Epoch: 1666, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1667 - Batch 1 ########################
IDs in batch 1: tensor([3496, 2405,  471,  913,  149, 3484,  915, 3010, 3298,  425,  546, 4186,
        2655, 1767,  129, 1284])
Epoch: 1667, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1668 - Batch 1 ########################
IDs in batch 1: tensor([2425, 2505, 1636, 1237, 1618,  718, 3371, 1958, 1032,  566, 2838,  409,
         959, 3311, 1131, 3845])
Epoch: 1668, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1669 - Batch 1 ########################
IDs in batch 1: tensor([ 401, 2463, 1266, 2452, 3936,  950, 1247, 1252, 4120, 1305,  129, 1793,
        2119, 2788, 2819, 2884])
Epoch: 1669, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1670 - Batch 1 ########################
IDs in batch 1: tensor([1899, 4103, 2433, 2810, 3130, 1436, 1766, 2123, 1067, 3427, 3446,   56,
        3423, 3176,   52,  913])
Epoch: 1670, Training Loss: 0.25, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1671 - Batch 1 ########################
IDs in batch 1: tensor([2827, 3130, 1553, 1034, 3573, 3769, 2668, 2598, 1050,  640, 1488, 2917,
        3102, 1702, 4010, 2145])
Epoch: 1671, Training Loss: 0.22, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1672 - Batch 1 ########################
IDs in batch 1: tensor([1395, 3882, 1880, 3872, 1961, 3052,  135, 4065, 1213,  752,  200, 4255,
        2777, 3558, 2577, 2859])
Epoch: 1672, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1673 - Batch 1 ########################
IDs in batch 1: tensor([3975,  709, 3859, 1174, 3908,  727,  896, 1849, 3429, 3220, 1845, 1676,
        4200, 3147,  106, 3832])
Epoch: 1673, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1674 - Batch 1 ########################
IDs in batch 1: tensor([2359,  776,  699, 3214, 2721, 3166, 3300, 1764, 1134, 2317,  725, 2355,
        2563, 3006,  892,  312])
Epoch: 1674, Training Loss: 0.33, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1675 - Batch 1 ########################
IDs in batch 1: tensor([1263,  991,  863,  513,  741,   86, 3764, 4226,  904, 1158, 3234, 2008,
        3930, 3638, 2366,  172])
Epoch: 1675, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1676 - Batch 1 ########################
IDs in batch 1: tensor([2478,  936, 1023, 2845,  182,   51, 2008, 3700, 2449,   14,  854, 1524,
        1369, 1257, 3214, 3754])
Epoch: 1676, Training Loss: 0.33, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1677 - Batch 1 ########################
IDs in batch 1: tensor([3253, 1361,  320,  644, 3286, 2436, 2542, 1658, 2109, 3553, 2198, 1517,
         544, 3105,  538,  145])
Epoch: 1677, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1678 - Batch 1 ########################
IDs in batch 1: tensor([3974,  485, 1512,  263,  411, 1263, 3919, 2947, 1096,  809,  854, 3399,
         808, 3326, 2546, 2620])
Epoch: 1678, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1679 - Batch 1 ########################
IDs in batch 1: tensor([3564, 1517, 1693, 2287, 3908, 3321, 3581, 4033,  186, 1945,  556,  470,
         363, 1488, 1625, 2143])
Epoch: 1679, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1680 - Batch 1 ########################
IDs in batch 1: tensor([2051, 4179, 4266, 1525,  652, 3253, 1282, 3976,  125, 3859, 3127, 2854,
        2627, 2126, 1740, 3342])
Epoch: 1680, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1681 - Batch 1 ########################
IDs in batch 1: tensor([1379, 3974, 2367, 3338, 1011,  345, 1726, 1733, 3262,  649,  899, 1761,
        3251, 3398, 2732, 3386])
Epoch: 1681, Training Loss: 0.08, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1682 - Batch 1 ########################
IDs in batch 1: tensor([3647,  978, 1204, 3636, 3779, 2464, 2989, 2825,  524,  890, 1592, 2400,
        2170,  996, 1279, 3970])
Epoch: 1682, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1683 - Batch 1 ########################
IDs in batch 1: tensor([3911, 2892, 4025, 3496, 1144,  988, 2133,  914, 1413,  835, 2787,  325,
         630,  741, 3945, 3441])
Epoch: 1683, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1684 - Batch 1 ########################
IDs in batch 1: tensor([2244, 1999, 4200, 1672, 3235, 1913, 1399, 4180, 1042, 3896,  747, 4002,
        3675, 2478, 2678, 1297])
Epoch: 1684, Training Loss: 0.30, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1685 - Batch 1 ########################
IDs in batch 1: tensor([2178, 2667,  459, 1097, 2371, 2974, 2511,  778,  639, 3028,   42,  396,
        2802, 2317, 1737, 1682])
Epoch: 1685, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1686 - Batch 1 ########################
IDs in batch 1: tensor([2408, 3973,  909,  726, 1426, 2627, 2967, 1955, 3074,  883, 1333, 3797,
        2026,  129, 1681, 2807])
Epoch: 1686, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1687 - Batch 1 ########################
IDs in batch 1: tensor([1006, 3908, 3634,  140, 4175,  988,  497, 1858, 3872,  469,  320, 2485,
        1707, 2761, 3161, 3934])
Epoch: 1687, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1688 - Batch 1 ########################
IDs in batch 1: tensor([1061, 1028, 2378,  275, 3593, 3423, 3222,  699, 3552,  371, 3211, 2487,
         477, 3693, 2844, 3543])
Epoch: 1688, Training Loss: 0.56, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1689 - Batch 1 ########################
IDs in batch 1: tensor([3344, 2765, 1900, 3920, 1823, 4235, 1375, 2209,   74,  704, 3111, 2251,
        1065, 2363,   34, 2193])
Epoch: 1689, Training Loss: 0.59, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1690 - Batch 1 ########################
IDs in batch 1: tensor([2688, 3948, 2150, 4166,  886, 4154, 3507, 4053, 1364, 3514, 2092,  154,
         826, 3588, 3047, 1747])
Epoch: 1690, Training Loss: 0.27, Validation Loss: 0.69, accuracy = 0.73
######################## Epoch 1691 - Batch 1 ########################
IDs in batch 1: tensor([3276, 3989,  776,  188,  517, 3593, 2886, 4077, 3731, 2026, 1988, 1872,
        4085,  538, 3025,  361])
Epoch: 1691, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1692 - Batch 1 ########################
IDs in batch 1: tensor([3921, 2715, 1157,  626, 2320, 2390,  483, 1455,  207, 2028, 2485, 1379,
        3540, 3109,  821, 2234])
Epoch: 1692, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1693 - Batch 1 ########################
IDs in batch 1: tensor([2802, 1066,  415, 3312, 2040, 3876, 3627,  578, 3881,  490, 1640, 3258,
        2999, 1346, 3234, 1116])
Epoch: 1693, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1694 - Batch 1 ########################
IDs in batch 1: tensor([1819, 1994, 3834, 3217,  824, 1159,  626, 1179, 3312, 2002, 1478, 2717,
        2497,  596, 3681, 3004])
Epoch: 1694, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1695 - Batch 1 ########################
IDs in batch 1: tensor([3634, 3406, 3058,  245, 1976, 2912, 3238, 1126, 1823, 1497,  422, 4051,
         558, 1646, 1186, 3590])
Epoch: 1695, Training Loss: 0.49, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1696 - Batch 1 ########################
IDs in batch 1: tensor([3878, 1487,  471, 1224, 2265,  194, 2387, 2650,  375, 3807, 4185, 3528,
        2956, 2156, 1198, 3501])
Epoch: 1696, Training Loss: 0.39, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1697 - Batch 1 ########################
IDs in batch 1: tensor([3268, 3031, 1676, 2494, 2347, 3895, 2124,  111, 1716, 3983,  854, 1137,
        2326,  282, 3392,  756])
Epoch: 1697, Training Loss: 0.56, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1698 - Batch 1 ########################
IDs in batch 1: tensor([ 966, 3108, 1916, 2579, 3353, 2743, 4075, 3370, 1134,  128, 1990, 3459,
        2241, 4234, 3572, 2282])
Epoch: 1698, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1699 - Batch 1 ########################
IDs in batch 1: tensor([4065, 2226, 3290, 1158,   43, 3888,  269, 1421, 3778,   62, 4032, 3356,
        1878, 4103, 2448, 2081])
Epoch: 1699, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1700 - Batch 1 ########################
IDs in batch 1: tensor([2261, 3176, 2316, 2065,  563,  520, 2499, 1519, 3208,  426, 3823, 2406,
        1510,  455, 1393,  345])
Epoch: 1700, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1701 - Batch 1 ########################
IDs in batch 1: tensor([ 681, 3831,  245, 1234, 3812, 3105, 1004, 2624, 2370, 3114, 2703,  470,
        1118,  620,   35, 4161])
Epoch: 1701, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1702 - Batch 1 ########################
IDs in batch 1: tensor([ 375, 3993, 2369,  490,   98, 2891, 2429, 3314, 3999,  346, 3449, 2242,
         213,  161, 2072, 1229])
Epoch: 1702, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1703 - Batch 1 ########################
IDs in batch 1: tensor([  88, 1302, 2597, 1834,  340, 3037,  321,  196,   96, 4084, 2286, 1996,
        2535, 2228,  394, 1787])
Epoch: 1703, Training Loss: 0.49, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 1704 - Batch 1 ########################
IDs in batch 1: tensor([3934, 4096,  236, 4234,  128,  257, 1256, 2521, 4213, 3356, 1313, 4156,
        2771,  896, 4264, 3640])
Epoch: 1704, Training Loss: 0.56, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1705 - Batch 1 ########################
IDs in batch 1: tensor([ 223, 3398, 1574,   34, 1357, 2489, 1841,  777, 4185, 2840, 1393, 1904,
        1120,  317, 2070,  136])
Epoch: 1705, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1706 - Batch 1 ########################
IDs in batch 1: tensor([  59,  372,  989, 2456, 2548, 1635, 1860, 2324, 1508, 1414, 2934, 3643,
        3002, 4038, 1198,   82])
Epoch: 1706, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1707 - Batch 1 ########################
IDs in batch 1: tensor([4027,  422, 2842, 1035,   82,  405, 1634, 2480, 1681, 2375, 1810, 2899,
        2799, 2970, 1075, 4008])
Epoch: 1707, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1708 - Batch 1 ########################
IDs in batch 1: tensor([3227, 3869, 2656, 2660, 1250,  292, 1605, 2251, 2538, 2091, 3994, 1284,
         980, 2522,  667,  996])
Epoch: 1708, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 1709 - Batch 1 ########################
IDs in batch 1: tensor([3483, 2777,  305, 3704, 4122,  444, 1724,  649,   39, 2008, 3564, 2706,
         546,  997, 1846, 3798])
Epoch: 1709, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1710 - Batch 1 ########################
IDs in batch 1: tensor([3309, 1562, 3843, 1321, 1570, 3833, 3839,  978, 4061, 2706, 3516, 1700,
        2950, 3873, 4238, 2443])
Epoch: 1710, Training Loss: 0.44, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 1711 - Batch 1 ########################
IDs in batch 1: tensor([4013, 4117, 1601, 2826,  503, 3658, 3283,  920, 3392, 2526, 3833, 2498,
        2760, 3503, 1706, 3971])
Epoch: 1711, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1712 - Batch 1 ########################
IDs in batch 1: tensor([2793, 3078,  792, 1281, 3753, 3180, 3954,  130, 4038, 2984, 4031, 1473,
        3023, 2192, 1279, 2280])
Epoch: 1712, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1713 - Batch 1 ########################
IDs in batch 1: tensor([2458, 1812,   14, 1859, 3702, 1090,  138,  279,  448, 3912,  108,  683,
        3936, 2851,  529, 2883])
Epoch: 1713, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1714 - Batch 1 ########################
IDs in batch 1: tensor([1185, 2858,  463, 3250, 2587,  466, 1641, 3727,  470,  962,   92, 1870,
        3234, 3962, 3262, 2379])
Epoch: 1714, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1715 - Batch 1 ########################
IDs in batch 1: tensor([4097,  630,  644, 2271, 2183,  119, 1399, 3529, 2516,  243, 4048, 3591,
        3837, 2316,  531,   51])
Epoch: 1715, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1716 - Batch 1 ########################
IDs in batch 1: tensor([3133,  264,  338, 2575, 3713, 3607, 3500, 1356, 1404, 1076, 3789, 2571,
        2518, 3423,  714, 1552])
Epoch: 1716, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1717 - Batch 1 ########################
IDs in batch 1: tensor([3968,  610,  818, 2696, 3311, 3100, 3481, 2672, 1173,  730,  401, 3272,
        1096, 4264,  263, 4215])
Epoch: 1717, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1718 - Batch 1 ########################
IDs in batch 1: tensor([1682,  874,  983, 3282, 1219, 2697, 3220, 1153,  212, 1678,  295, 3692,
        1067, 2053,   61,  147])
Epoch: 1718, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1719 - Batch 1 ########################
IDs in batch 1: tensor([2297,  282, 3542, 1976, 2034, 4190, 1429,  147, 3132, 2953, 1786,  490,
         808,  843, 1630, 2606])
Epoch: 1719, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1720 - Batch 1 ########################
IDs in batch 1: tensor([4055, 2604, 1402, 2431, 1470, 1517, 1543, 1296, 3573, 2986, 2479, 2970,
        3366, 2692, 2172, 3465])
Epoch: 1720, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1721 - Batch 1 ########################
IDs in batch 1: tensor([2090, 3501, 4185, 2403, 2176, 3783, 2508, 1132, 3311,  346,  448,  725,
        3989,  949,  511, 1500])
Epoch: 1721, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1722 - Batch 1 ########################
IDs in batch 1: tensor([ 390, 3911, 2218, 1195,  767, 2209, 3258, 2350, 3650,  148, 1080, 2592,
         324, 3513, 4146, 4135])
Epoch: 1722, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1723 - Batch 1 ########################
IDs in batch 1: tensor([3143,  280,  363, 1370, 1032, 3185, 3875, 1082,   44, 3888, 1569,  138,
        1927, 1206,  400, 1612])
Epoch: 1723, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1724 - Batch 1 ########################
IDs in batch 1: tensor([3954,  991, 4163, 2551, 1069,  219, 3968, 2656, 1069,  620, 1977,  448,
        3268, 3404, 1414,  308])
Epoch: 1724, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1725 - Batch 1 ########################
IDs in batch 1: tensor([2332, 2521, 2982, 3642,  574, 2124, 2763, 3251, 1119, 1740,  527, 2373,
        3908,  325, 3114, 3636])
Epoch: 1725, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1726 - Batch 1 ########################
IDs in batch 1: tensor([1948, 3354, 2730,  971, 2095, 2244,  419, 1369, 1638, 3999,  975,  434,
        2418, 2997, 1578, 2780])
Epoch: 1726, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1727 - Batch 1 ########################
IDs in batch 1: tensor([ 863, 3660, 2509, 2688,  743, 2947, 4173, 2953, 1315,  266, 1680,   62,
        2069, 1680, 2451, 3004])
Epoch: 1727, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1728 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 2931, 4044,  959, 2144, 1182, 2370, 2282, 2099,  651, 3936, 1485,
        2905, 3590, 1573, 3313])
Epoch: 1728, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1729 - Batch 1 ########################
IDs in batch 1: tensor([3997, 3338, 1576, 1726,  953, 3572, 2018,  436, 3217, 3933,   73, 2151,
         830, 2035, 2141,  674])
Epoch: 1729, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1730 - Batch 1 ########################
IDs in batch 1: tensor([1355,  302, 1923,  338, 1067, 2519, 2743, 1181, 2796, 3404,  535, 2653,
        2028, 3938, 1828, 1796])
Epoch: 1730, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1731 - Batch 1 ########################
IDs in batch 1: tensor([4256, 4006, 1404, 3262, 3675, 2568, 2317, 3718, 1532, 2823, 1201, 1375,
         407, 3196,  730,  733])
Epoch: 1731, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1732 - Batch 1 ########################
IDs in batch 1: tensor([3259,  121, 2540,   78, 2317, 1638, 3675, 3092, 2536, 2791, 3031, 1567,
        1772, 1639, 2668,  308])
Epoch: 1732, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1733 - Batch 1 ########################
IDs in batch 1: tensor([2229, 3135,  553,   32,  769, 4185,  300, 1700,  691, 2516, 2755, 1204,
         997, 2791, 2500, 2272])
Epoch: 1733, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1734 - Batch 1 ########################
IDs in batch 1: tensor([3203, 1809,  476,  435, 1310, 1949,  393, 4108, 2470, 2018, 1823, 1263,
         545, 1316, 2038, 2934])
Epoch: 1734, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1735 - Batch 1 ########################
IDs in batch 1: tensor([3027, 2787, 1546, 1737, 1060, 4256, 2316, 1404, 3933, 1276, 1053, 2440,
        1706, 4050, 1517, 1286])
Epoch: 1735, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1736 - Batch 1 ########################
IDs in batch 1: tensor([2523, 2989,  152, 1897, 2339, 3052, 1282, 1057, 3746, 2232, 2610, 2155,
        3021, 1258, 2514, 2882])
Epoch: 1736, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1737 - Batch 1 ########################
IDs in batch 1: tensor([1272,  732, 1536, 3597, 3435,  327, 2545,  804, 4022, 1355, 1747, 1027,
        2190, 2202, 3961, 1179])
Epoch: 1737, Training Loss: 0.53, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1738 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 3739, 1841, 2180, 3472, 2848,  340, 1396, 3392, 3806, 1948, 1012,
        1214, 1868, 3920, 3886])
Epoch: 1738, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1739 - Batch 1 ########################
IDs in batch 1: tensor([1895, 2177, 3917, 2350, 1166,  946, 1270, 2207, 2090, 2700, 1931, 1476,
        2837, 1454,  109, 3023])
Epoch: 1739, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1740 - Batch 1 ########################
IDs in batch 1: tensor([ 857, 2798, 1782, 3223,  281, 1794, 2452, 1793, 1649, 3399, 2473, 3244,
         441, 3668, 2960, 2844])
Epoch: 1740, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1741 - Batch 1 ########################
IDs in batch 1: tensor([2575, 3329, 4152,  138, 2863, 1062, 4058, 3573, 4010,  988, 3831,  714,
         771, 3055, 1252, 3699])
Epoch: 1741, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1742 - Batch 1 ########################
IDs in batch 1: tensor([2458, 4265, 1779, 2148,  418, 3378, 3074, 3971, 2281, 2840, 2871, 2465,
         128, 3417, 1777,   57])
Epoch: 1742, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1743 - Batch 1 ########################
IDs in batch 1: tensor([1257, 1244, 3843,  232, 2905, 1938, 1675, 4222, 1056,  804, 1789, 2230,
        3185, 2425,  837, 3693])
Epoch: 1743, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1744 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 3771,  379, 2193, 3883, 3308, 1056,  749, 2504, 3338, 2092, 3448,
        3904, 2926, 3683, 4118])
Epoch: 1744, Training Loss: 0.62, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1745 - Batch 1 ########################
IDs in batch 1: tensor([ 244,  986, 2274, 2683, 3652, 2087, 2363, 3677, 3615,  508,  438, 1883,
        1774, 2274, 3651, 4015])
Epoch: 1745, Training Loss: 0.51, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1746 - Batch 1 ########################
IDs in batch 1: tensor([ 368, 3570, 3509, 1225, 2190, 3018,  646, 3032, 2558, 3521, 1658, 2387,
        2410, 1090,  894, 2553])
Epoch: 1746, Training Loss: 0.41, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1747 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 3253, 1753, 1859, 2579, 1326, 1110, 4085, 3465, 2316, 1393,  976,
        3823,  173, 3429, 3621])
Epoch: 1747, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1748 - Batch 1 ########################
IDs in batch 1: tensor([3822,  743, 2788,  369, 1887, 1736, 2237,  843, 1655,  122, 3184, 1484,
          15,  812,  904, 2718])
Epoch: 1748, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1749 - Batch 1 ########################
IDs in batch 1: tensor([2401, 1624,  413,  933, 3836, 3744, 4032, 2800,  992, 1510, 3326, 1141,
        3275, 1786, 1139, 1141])
Epoch: 1749, Training Loss: 0.55, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1750 - Batch 1 ########################
IDs in batch 1: tensor([ 855,  642, 1423, 1239, 4089,  195, 2018, 2429, 3141, 2436,  547,  942,
        2776, 2271, 2350, 3984])
Epoch: 1750, Training Loss: 0.52, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1751 - Batch 1 ########################
IDs in batch 1: tensor([2004, 1896, 2817, 2166, 3351, 1183,  236,  302, 2247, 4266, 2711,  773,
        3755,  962, 2045, 2806])
Epoch: 1751, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.71
######################## Epoch 1752 - Batch 1 ########################
IDs in batch 1: tensor([1373, 4032, 3496, 3783, 2145,  165, 3306,   95,  607, 4131, 2446, 3833,
        1825,  771, 1822, 2358])
Epoch: 1752, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1753 - Batch 1 ########################
IDs in batch 1: tensor([2984, 2886,  960,  804,  569, 3513, 3217, 3615, 3831,  512, 3154, 2796,
        2015, 4016, 3711,  993])
Epoch: 1753, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1754 - Batch 1 ########################
IDs in batch 1: tensor([3446,  219, 2807,  352,  787,  989, 1016, 3925, 1599, 1569,  960,  387,
        3998,  725,  213, 2758])
Epoch: 1754, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1755 - Batch 1 ########################
IDs in batch 1: tensor([3084, 1512, 3710, 2777,   85,  729, 1648,  103,  565, 2359, 3399, 3591,
        2109,  959,  368, 1575])
Epoch: 1755, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1756 - Batch 1 ########################
IDs in batch 1: tensor([3367, 2925,   19, 3476,   61,   43, 1107, 1525, 1469,  682, 2218,   92,
         914, 1028, 3568,  848])
Epoch: 1756, Training Loss: 0.60, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1757 - Batch 1 ########################
IDs in batch 1: tensor([3391, 4068, 3111, 3972, 3040,  605, 2298, 1404, 2793, 3357, 2219,  537,
         739, 2667, 1471, 3037])
Epoch: 1757, Training Loss: 0.39, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1758 - Batch 1 ########################
IDs in batch 1: tensor([2650, 3628, 4140, 3660, 4166,  546, 1795,  955, 1051, 3553, 3407,  358,
         484, 2350,  512, 1991])
Epoch: 1758, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1759 - Batch 1 ########################
IDs in batch 1: tensor([3680,  907, 1518, 2907,  947, 2094, 2156, 2341, 3218,  855, 2314, 4232,
         322, 1267,  317, 1853])
Epoch: 1759, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1760 - Batch 1 ########################
IDs in batch 1: tensor([  49, 4159, 3463, 1773, 3733,  290, 1824, 3052, 3340, 2636, 2183,  397,
        1825, 2207,  797, 3782])
Epoch: 1760, Training Loss: 0.41, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1761 - Batch 1 ########################
IDs in batch 1: tensor([3377, 2458,  907, 4234, 1226, 2745,  914,  870, 2309, 1306, 2914, 1733,
        1209, 2442, 4025, 3535])
Epoch: 1761, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1762 - Batch 1 ########################
IDs in batch 1: tensor([1166, 2459, 1337, 3326, 3370, 1201,  823, 2344, 1645, 3265, 1010, 2123,
         803, 3964, 1472, 1313])
Epoch: 1762, Training Loss: 0.41, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1763 - Batch 1 ########################
IDs in batch 1: tensor([4131, 1628,  838, 2913, 3827, 4060, 3859,  651, 2448,  888, 3289,  662,
         823, 2504, 2280, 2614])
Epoch: 1763, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1764 - Batch 1 ########################
IDs in batch 1: tensor([1011,  507, 1996, 3711, 3027, 1056, 3190,  320,   63,  191, 1331,  741,
        4027,  584,  497, 2092])
Epoch: 1764, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1765 - Batch 1 ########################
IDs in batch 1: tensor([ 712,  362, 3364, 2765, 1281, 1032, 3251, 4255, 2983, 1949,   46, 3711,
        4046, 3913, 2545,  962])
Epoch: 1765, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1766 - Batch 1 ########################
IDs in batch 1: tensor([ 961, 2692, 4118, 2338, 2137,  203,  255, 3554, 3456, 3211, 1290, 3243,
         508,  981, 2991, 3109])
Epoch: 1766, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1767 - Batch 1 ########################
IDs in batch 1: tensor([3211,  947, 3570, 2098,  913, 2629, 2085, 2514, 1525, 1452, 4196, 1399,
        1444, 1413, 1650, 2492])
Epoch: 1767, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1768 - Batch 1 ########################
IDs in batch 1: tensor([ 773,  305, 2934, 3192,  915, 3837, 3027,  138, 2712,  796, 3360, 1294,
        3099, 3838, 2574,  279])
Epoch: 1768, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1769 - Batch 1 ########################
IDs in batch 1: tensor([4022, 3888, 3127,  555,  373, 1642,  837,  498,  739, 2024,  138,  113,
        4158, 3997, 2342, 3917])
Epoch: 1769, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1770 - Batch 1 ########################
IDs in batch 1: tensor([2745,  723, 3998,  219, 3073,  481, 3974, 1319, 1270, 2363, 2464, 2347,
        4116, 2688, 3749, 1396])
Epoch: 1770, Training Loss: 0.31, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1771 - Batch 1 ########################
IDs in batch 1: tensor([2783,   59, 3778,  177, 2624, 1099, 1101, 2828, 3208, 3934, 2723, 2690,
        1857, 4144, 2514, 2914])
Epoch: 1771, Training Loss: 0.45, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1772 - Batch 1 ########################
IDs in batch 1: tensor([ 609, 2379,  683, 2348,  606,  712, 2154,  996, 2238, 1845, 2290, 3701,
        1706,  646,   60,  112])
Epoch: 1772, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1773 - Batch 1 ########################
IDs in batch 1: tensor([3447, 2616, 1233, 4120, 1519,  946, 1134, 1976,  459, 1633,  436,  388,
        3717, 1656, 2826, 1325])
Epoch: 1773, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1774 - Batch 1 ########################
IDs in batch 1: tensor([2309, 3459, 1882,  463, 2690, 2443, 1931, 3276,  665, 1569, 2855, 4218,
        2847,  637, 3760, 4032])
Epoch: 1774, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1775 - Batch 1 ########################
IDs in batch 1: tensor([3069,  849, 3373, 3362, 3644, 2734, 3471, 4173,  436, 2134, 1543, 1963,
        3969, 3368, 1147, 2382])
Epoch: 1775, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1776 - Batch 1 ########################
IDs in batch 1: tensor([3360, 3160, 3926,   70, 3894, 3581, 2936, 2114, 1748, 4156, 2291, 4119,
         245, 2255, 2313, 2636])
Epoch: 1776, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1777 - Batch 1 ########################
IDs in batch 1: tensor([ 610,   28, 1252, 3098, 2598,  812,  269, 3451, 2016,  150, 3035, 2873,
         356, 2950, 1612, 4200])
Epoch: 1777, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1778 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 3972, 2854, 1899, 2812, 2133, 2400,  753, 3473, 1363,  244, 4097,
        1657, 1519, 4135, 3458])
Epoch: 1778, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1779 - Batch 1 ########################
IDs in batch 1: tensor([3449,  497, 3105, 1507, 3863,   52, 1218, 4140,  747,  656, 3638, 1635,
        2996, 3813, 1410, 1328])
Epoch: 1779, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1780 - Batch 1 ########################
IDs in batch 1: tensor([ 740, 1001,  305, 3430, 1911,  980, 2250, 3119,  709,  683,  412, 2954,
        3197, 2218, 3833, 1861])
Epoch: 1780, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1781 - Batch 1 ########################
IDs in batch 1: tensor([2153, 2873, 2787, 1369, 3964, 1361, 3756, 2876, 1125, 3984,  483, 3826,
        3569, 1869, 4149, 2997])
Epoch: 1781, Training Loss: 0.32, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1782 - Batch 1 ########################
IDs in batch 1: tensor([3141, 2142, 4053, 1591, 1891, 3996,  808, 1685, 4203,  389, 1712,  409,
         766, 4261, 2150, 2937])
Epoch: 1782, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1783 - Batch 1 ########################
IDs in batch 1: tensor([1459, 1186, 3585,  995, 4217, 3100,  750, 3603, 2604,  454, 2784, 2354,
        1426,  710,  882, 1440])
Epoch: 1783, Training Loss: 0.47, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1784 - Batch 1 ########################
IDs in batch 1: tensor([2019, 4163, 3423,  265, 1871, 3738, 3816, 4136, 2797, 1817,  994, 2977,
        1613, 3349, 1198, 1163])
Epoch: 1784, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1785 - Batch 1 ########################
IDs in batch 1: tensor([1250,  864, 1634, 2078, 1365, 1849, 3872, 1201,  657, 1490, 4170, 2718,
         103,  306, 3587,   82])
Epoch: 1785, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1786 - Batch 1 ########################
IDs in batch 1: tensor([3131, 1292, 3875,  360,   77,  154, 1031, 2853, 1945, 1275, 3451, 1086,
        3833, 3547, 2726,  887])
Epoch: 1786, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1787 - Batch 1 ########################
IDs in batch 1: tensor([ 735, 3674,  967, 3473, 2060, 1163, 1518,  536,  821,  413,  317,  945,
         474, 4165, 4097, 4072])
Epoch: 1787, Training Loss: 0.67, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1788 - Batch 1 ########################
IDs in batch 1: tensor([ 135, 2092, 3521, 1320, 3723, 1562,  739, 4080, 1088, 3763, 2323,  343,
        2478, 2142,  886, 1282])
Epoch: 1788, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1789 - Batch 1 ########################
IDs in batch 1: tensor([3669, 2467, 3927, 3473, 2417, 3264,  499, 3428, 1481, 1899, 2018, 1402,
        2312, 4267, 4099, 3974])
Epoch: 1789, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1790 - Batch 1 ########################
IDs in batch 1: tensor([  72, 1379, 1625,   19,  137, 2178, 2960, 2842, 3772, 2327,  471, 1050,
        2631, 3917,  953,  956])
Epoch: 1790, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 1791 - Batch 1 ########################
IDs in batch 1: tensor([2492, 2453, 3475, 2367, 2982, 3035,  895, 4013, 1224, 2504, 1835, 2855,
        2457, 2455, 3277,  956])
Epoch: 1791, Training Loss: 0.69, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1792 - Batch 1 ########################
IDs in batch 1: tensor([1312, 1690, 2968, 2804, 3821, 3021,  390, 1556, 3592, 2960, 3447, 3120,
         987, 4053, 1958,  750])
Epoch: 1792, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1793 - Batch 1 ########################
IDs in batch 1: tensor([2589, 4067, 2334, 2986, 1237, 1811, 1213, 2065, 2484,  794, 3551, 3754,
        3532, 3709,  662, 1312])
Epoch: 1793, Training Loss: 0.51, Validation Loss: 0.77, accuracy = 0.69
######################## Epoch 1794 - Batch 1 ########################
IDs in batch 1: tensor([2195, 3984,  147, 2541,  586, 3732,  986, 2798, 3570,  740, 1913, 1005,
        1950, 2402, 1774, 3658])
Epoch: 1794, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 1795 - Batch 1 ########################
IDs in batch 1: tensor([3891, 1267, 1720, 2485, 2590, 3077, 3115, 2479, 3406, 4213, 2314, 2011,
         171, 1464, 3268, 3920])
Epoch: 1795, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 1796 - Batch 1 ########################
IDs in batch 1: tensor([1525, 2477, 1054, 1176,  863,  284, 1027, 1311, 2771, 2838, 3718, 3781,
         534,  511, 3117, 3430])
Epoch: 1796, Training Loss: 0.62, Validation Loss: 0.76, accuracy = 0.68
######################## Epoch 1797 - Batch 1 ########################
IDs in batch 1: tensor([3701,  626, 2539, 3014, 3253,  171, 1075, 3521, 1853, 3996, 2926, 1866,
        3572, 4003, 2583, 3721])
Epoch: 1797, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 1798 - Batch 1 ########################
IDs in batch 1: tensor([2244, 2649, 1537,  736,  879, 3705,  276, 2676,  819,  218, 1638, 2104,
        3865, 3990, 1077, 4087])
Epoch: 1798, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 1799 - Batch 1 ########################
IDs in batch 1: tensor([4254, 2383,  228, 1882, 1852, 2256,  183,  363, 3128, 2898, 3866, 2940,
        4073, 2999, 2359, 4185])
Epoch: 1799, Training Loss: 0.38, Validation Loss: 0.75, accuracy = 0.68
######################## Epoch 1800 - Batch 1 ########################
IDs in batch 1: tensor([3647,  777, 2895, 1415, 1043, 2247, 1766, 3783, 1267, 2204, 3593, 2719,
        3494, 2219,  781,  964])
Epoch: 1800, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 1801 - Batch 1 ########################
IDs in batch 1: tensor([ 456,  988, 3028,  405, 2394,  915, 3531, 2232,  354,  105, 1195,  219,
        2457, 3168, 1347,   95])
Epoch: 1801, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 1802 - Batch 1 ########################
IDs in batch 1: tensor([3928, 1052, 3267,  459,  195,  321,  260, 1891, 3875, 3223, 1953,  485,
        1418,  666, 2316, 2787])
Epoch: 1802, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1803 - Batch 1 ########################
IDs in batch 1: tensor([2564,  878,  862,  130, 1059, 3406, 4141, 2125, 2387, 3241, 2414, 1111,
        2206, 4245, 4213, 1642])
Epoch: 1803, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.69
######################## Epoch 1804 - Batch 1 ########################
IDs in batch 1: tensor([3568, 3972, 3161, 2492,  965, 2727, 1352, 1242, 2406, 2660,  990, 3569,
        1088,  786, 2188, 2217])
Epoch: 1804, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1805 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1241, 2251, 3343, 3764,  177, 2749, 3798,    5, 3497, 2969, 1784,
        2195, 3226, 4144, 3496])
Epoch: 1805, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1806 - Batch 1 ########################
IDs in batch 1: tensor([3190, 3179, 1916, 1157,  275, 1944, 3921, 3436, 1761,  373, 1098,  371,
         816,  214, 2921, 2867])
Epoch: 1806, Training Loss: 0.26, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1807 - Batch 1 ########################
IDs in batch 1: tensor([ 422, 2080, 4128, 3265,  821, 3859, 2206,  818,  966, 1375, 1985, 2913,
        3271, 1817, 1958,   10])
Epoch: 1807, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1808 - Batch 1 ########################
IDs in batch 1: tensor([4096, 2592, 1899,  202, 1086, 1256, 3683, 2723,  365, 1803, 1232, 3908,
        2298, 2804,  946, 3569])
Epoch: 1808, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1809 - Batch 1 ########################
IDs in batch 1: tensor([4065, 3228, 3466, 2154, 1630,  997, 4089, 2280,  403, 2371, 2754,  261,
         469, 1381, 3767,  767])
Epoch: 1809, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1810 - Batch 1 ########################
IDs in batch 1: tensor([1920, 2604, 2322,  712,   30, 1934, 3719,  102, 3540,  963, 2578, 1030,
        2271, 4134, 1519, 1302])
Epoch: 1810, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1811 - Batch 1 ########################
IDs in batch 1: tensor([1704, 1085,   20, 2016, 3055, 2253,  981, 1028, 1722,  415,  438, 1171,
         699, 2180,  135, 1065])
Epoch: 1811, Training Loss: 0.65, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1812 - Batch 1 ########################
IDs in batch 1: tensor([2455, 2019,  944, 3453, 2301, 2370, 1754, 3920,  766, 3790, 1530,  725,
        1107, 3532, 3469, 2301])
Epoch: 1812, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1813 - Batch 1 ########################
IDs in batch 1: tensor([3287, 2279, 2676,  736, 2736,  171, 1602, 3648, 4015,  103, 4173, 2210,
        2044, 4128, 4190, 2825])
Epoch: 1813, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1814 - Batch 1 ########################
IDs in batch 1: tensor([ 957, 3092, 3483, 1754, 3826, 2849, 1110, 2349,  449, 3943,  857, 1128,
        3005, 3972,  183, 1673])
Epoch: 1814, Training Loss: 0.26, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1815 - Batch 1 ########################
IDs in batch 1: tensor([1049, 1920,  640, 2436, 2869, 4187,  902, 1049,   38, 2546, 1066,  111,
         683, 2655, 2191, 3830])
Epoch: 1815, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1816 - Batch 1 ########################
IDs in batch 1: tensor([2993, 2743,  326,  762, 3504, 1022,  937, 2511, 1326, 2715, 2516, 2155,
        2740, 3636, 1855, 3483])
Epoch: 1816, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1817 - Batch 1 ########################
IDs in batch 1: tensor([  56,  892, 3749, 3159,  177,  964, 2822, 3456, 2353, 3997, 3881, 4062,
        2752, 2086, 1179, 3378])
Epoch: 1817, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1818 - Batch 1 ########################
IDs in batch 1: tensor([3518, 2074,   72,  522, 1780, 2114, 2092, 1859, 1624, 2921, 3136,  442,
        1754, 2770, 3630, 4017])
Epoch: 1818, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1819 - Batch 1 ########################
IDs in batch 1: tensor([2863,  829, 3309, 3797, 1352, 3460,  965,  855, 2695, 2327, 2207, 1196,
        2754, 3993, 2886, 3218])
Epoch: 1819, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1820 - Batch 1 ########################
IDs in batch 1: tensor([2339, 1852, 1784, 1536, 2826, 4165,  497, 1895, 3377, 1751, 1287, 1174,
        4093, 2040, 1097, 1934])
Epoch: 1820, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1821 - Batch 1 ########################
IDs in batch 1: tensor([3159,  653, 3226,  401, 3760, 3476, 4057, 1530, 2137, 2435,  915,  875,
        4099, 2091,  886, 1334])
Epoch: 1821, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1822 - Batch 1 ########################
IDs in batch 1: tensor([1981, 3539, 2455,  594, 1671, 1793,  683, 2696, 2026, 2810, 2504,  725,
        3372, 2915, 1383, 2965])
Epoch: 1822, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1823 - Batch 1 ########################
IDs in batch 1: tensor([2986,  322, 1306, 2980,   19, 3733, 1241, 2924, 2505,  430,  358, 3953,
        1066, 3384, 2112, 1436])
Epoch: 1823, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1824 - Batch 1 ########################
IDs in batch 1: tensor([2249, 3960,  851, 3756, 2529, 4061, 2122, 1835,  770, 3358, 3160, 1075,
        3250, 1487, 3407,  379])
Epoch: 1824, Training Loss: 0.37, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1825 - Batch 1 ########################
IDs in batch 1: tensor([ 758,   72,  757, 1380, 3367, 1168, 1821,  320, 2461, 2219, 2203, 3589,
         529, 1804, 3309, 3630])
Epoch: 1825, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1826 - Batch 1 ########################
IDs in batch 1: tensor([4196, 3018,  198, 3262, 3304, 1181,  890, 1063, 1005, 2798, 3548,  343,
         964, 4197, 2770, 1309])
Epoch: 1826, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1827 - Batch 1 ########################
IDs in batch 1: tensor([1458, 1732,  198, 2017, 3661,  306, 3326,  531, 3005,  133,  491, 3709,
        3995, 2627, 2592, 4222])
Epoch: 1827, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1828 - Batch 1 ########################
IDs in batch 1: tensor([3074, 3271,  449, 1208,    7, 3180, 1716, 2102, 3779,  259,  950, 2618,
         552, 3128,  322,  201])
Epoch: 1828, Training Loss: 0.34, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1829 - Batch 1 ########################
IDs in batch 1: tensor([ 397, 3108,  522,  394, 2255, 3451, 2420,   74, 2094,  980, 2343, 1737,
        2605, 3552, 1670, 1015])
Epoch: 1829, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1830 - Batch 1 ########################
IDs in batch 1: tensor([3945,  322, 3548, 3010,  710, 2056,  547, 2362, 1026, 3398, 2572, 3995,
        1736, 1614, 3132, 3616])
Epoch: 1830, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 1831 - Batch 1 ########################
IDs in batch 1: tensor([ 173, 2171,  837,  790, 3543, 3669, 2733, 1660, 1981, 3226, 2783,  326,
        3781, 1030, 2901, 2733])
Epoch: 1831, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1832 - Batch 1 ########################
IDs in batch 1: tensor([2468, 3644, 3203,  552, 2106, 4002, 3866, 1610, 1663,  952, 3908,  359,
        2860, 3159, 3434, 2394])
Epoch: 1832, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1833 - Batch 1 ########################
IDs in batch 1: tensor([1821,  173, 3397, 4068, 1228, 1559, 4107, 1746,  666, 2271,  160, 3150,
         545, 3676,   15, 4036])
Epoch: 1833, Training Loss: 0.41, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1834 - Batch 1 ########################
IDs in batch 1: tensor([4085, 4175,  266,  839, 3740, 1588,  126, 2398, 2112, 1870,  718, 4205,
        2571, 2951, 3498, 3509])
Epoch: 1834, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1835 - Batch 1 ########################
IDs in batch 1: tensor([3208, 2638,  862, 4267, 1031, 1798, 1237, 3378, 3601, 1073, 3118, 2407,
        2358,   25, 1490,  888])
Epoch: 1835, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1836 - Batch 1 ########################
IDs in batch 1: tensor([2419, 3836,  303, 1781, 2013, 3999, 3947, 3883, 3214, 4115,  962, 4157,
        2653,  188, 2284, 1463])
Epoch: 1836, Training Loss: 0.36, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1837 - Batch 1 ########################
IDs in batch 1: tensor([1294,  190, 3314, 1004, 2278, 1199, 2690, 2249, 1617, 4229, 4114,  989,
         613, 3270, 1413, 1633])
Epoch: 1837, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1838 - Batch 1 ########################
IDs in batch 1: tensor([2019, 2541, 2872, 1271, 2276,  419,  451, 3992,  752,  535, 2892, 3812,
        1166, 4120,  200, 2605])
Epoch: 1838, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1839 - Batch 1 ########################
IDs in batch 1: tensor([2464, 3108,  315,  496,  804, 2420, 1122,   57, 1720,  977, 2212, 2372,
        3113, 2226, 1283,  738])
Epoch: 1839, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1840 - Batch 1 ########################
IDs in batch 1: tensor([2095, 2347, 3006, 1950, 1162, 2854, 3488, 2099, 2822,  405, 3065,  775,
        1644,  674, 1510,  970])
Epoch: 1840, Training Loss: 0.43, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1841 - Batch 1 ########################
IDs in batch 1: tensor([ 530, 3813, 3275,  844,    5, 2383, 1086,  306, 2898, 3738, 3647,  704,
        3683, 1496,  891, 2845])
Epoch: 1841, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1842 - Batch 1 ########################
IDs in batch 1: tensor([1312, 2600,  957, 2067,  537, 1102, 3526, 2732, 2565,  470,  205, 1044,
         809, 2356, 1008, 2899])
Epoch: 1842, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1843 - Batch 1 ########################
IDs in batch 1: tensor([1501, 3136, 1224, 4228, 2773,  992, 3802, 1140, 2473,  250, 3640, 2780,
        1388, 2882, 2399, 2947])
Epoch: 1843, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1844 - Batch 1 ########################
IDs in batch 1: tensor([1633, 2348,  871, 2072,  699, 2879, 2364, 2348, 4159, 1733, 2565, 3643,
        3397, 1724, 2898, 2508])
Epoch: 1844, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1845 - Batch 1 ########################
IDs in batch 1: tensor([1532, 2492, 2553, 3479, 3392, 2841, 3900, 2292,  198, 4265, 2550, 1094,
         535, 3202, 4072,  613])
Epoch: 1845, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1846 - Batch 1 ########################
IDs in batch 1: tensor([3415, 1563, 2249, 3197, 2423, 3360, 3313, 3496,  287, 3696, 2921, 2914,
        2693,  439, 1646,  849])
Epoch: 1846, Training Loss: 0.43, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1847 - Batch 1 ########################
IDs in batch 1: tensor([3744,  536, 2193, 3498, 2489, 3640, 1374, 3506, 1781, 3486, 2917,  417,
        3609,  330, 2708,  850])
Epoch: 1847, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1848 - Batch 1 ########################
IDs in batch 1: tensor([2510, 2173, 2209,  803, 1028, 1886, 2558, 3650, 2274, 2234, 2485, 1849,
        2581,  820, 1221, 3882])
Epoch: 1848, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1849 - Batch 1 ########################
IDs in batch 1: tensor([3150, 2606, 3865, 3545, 1457, 3092,  965, 1849,  721,  360, 3671, 2468,
        1003, 2245, 1840, 1502])
Epoch: 1849, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1850 - Batch 1 ########################
IDs in batch 1: tensor([2228, 1551, 3872, 3200, 2614, 2540, 3952, 1555, 4085,  275,   77, 2504,
        1452, 3368, 1311, 1051])
Epoch: 1850, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1851 - Batch 1 ########################
IDs in batch 1: tensor([4114, 3306, 3523, 1081, 2907, 3360, 2369, 3469, 3446, 2653, 3780, 3904,
        2087, 3000, 4152, 2236])
Epoch: 1851, Training Loss: 0.86, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1852 - Batch 1 ########################
IDs in batch 1: tensor([1193, 2577, 4062, 1163, 2448, 1428, 3939, 2008,  191, 1546, 1399, 1723,
          99, 3614, 2912, 4126])
Epoch: 1852, Training Loss: 0.31, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1853 - Batch 1 ########################
IDs in batch 1: tensor([1005, 2732, 1317, 1951, 2871,  762, 2250,  198, 3336, 1980, 1310, 2254,
        1352,   32, 2787, 2287])
Epoch: 1853, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1854 - Batch 1 ########################
IDs in batch 1: tensor([ 908, 2379, 4232,  129, 3604, 3769, 3141, 1467, 4012, 1708, 1080, 2053,
        2777, 1324, 1787, 2462])
Epoch: 1854, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1855 - Batch 1 ########################
IDs in batch 1: tensor([2320, 2791, 3572,  407, 2845, 2505,  926, 2298, 2500, 1075,  547,  281,
        1302, 1672, 1455, 1317])
Epoch: 1855, Training Loss: 0.35, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1856 - Batch 1 ########################
IDs in batch 1: tensor([3902, 3551, 4212, 4170, 2857, 2690, 1317, 3290, 2718,  184, 1803,  121,
        3339, 1023, 4077, 1049])
Epoch: 1856, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1857 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 2606,   96, 2112, 2257, 3317, 1007, 2050, 1626, 2845, 2636,  152,
        3922, 3176,  269,  422])
Epoch: 1857, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1858 - Batch 1 ########################
IDs in batch 1: tensor([3934, 1678, 3991, 1872, 1850, 3729, 1495, 1627,  205, 2299,  110, 3676,
        2868, 2767, 1299, 2898])
Epoch: 1858, Training Loss: 0.33, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1859 - Batch 1 ########################
IDs in batch 1: tensor([ 952, 2405, 2599, 2046, 2354, 1141, 1931, 2097,  350,  897, 1146, 3539,
        3028, 1320, 2496, 1118])
Epoch: 1859, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 1860 - Batch 1 ########################
IDs in batch 1: tensor([3074, 1916, 2441,  151, 1934, 3958, 4125, 2157, 1255, 2791, 2835,  646,
        1613, 3813, 2257, 1322])
Epoch: 1860, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1861 - Batch 1 ########################
IDs in batch 1: tensor([ 602,  710, 1765, 1299, 1369, 1809, 1567, 1594, 2645, 2369, 1296, 3779,
         544, 3084, 1090, 3913])
Epoch: 1861, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1862 - Batch 1 ########################
IDs in batch 1: tensor([3373, 2562,  933,  494, 1337, 1737, 2969,  835,  290, 1131, 2008, 2954,
        3015, 1484, 2592, 1173])
Epoch: 1862, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1863 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 4013, 2499, 3291, 1020,  825, 1506, 2775, 2760, 1094, 2114, 3494,
        3936, 2019,  539, 1546])
Epoch: 1863, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1864 - Batch 1 ########################
IDs in batch 1: tensor([4122, 1826, 3813, 1909,   99,  750, 1229, 2555, 3286,  896, 1051, 3650,
        1916, 1136, 1168,  926])
Epoch: 1864, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1865 - Batch 1 ########################
IDs in batch 1: tensor([1077, 1016, 3362, 3495, 4010, 3538,  265, 2849, 2890, 3406,  355, 4075,
        2431, 2059, 1056, 3590])
Epoch: 1865, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1866 - Batch 1 ########################
IDs in batch 1: tensor([ 140, 1923, 3763,  262, 1891, 1546, 4026, 1212, 2264, 3569, 1055, 2708,
        3706, 3516, 1686, 2873])
Epoch: 1866, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1867 - Batch 1 ########################
IDs in batch 1: tensor([1120, 4217, 3769, 4073, 3543, 3634, 2672,  649, 3156, 2125, 1482, 1370,
        3458, 2462, 2451,   63])
Epoch: 1867, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1868 - Batch 1 ########################
IDs in batch 1: tensor([3827, 3404, 3248,  138, 1780,  256, 3433, 1009, 3110, 3610, 4084, 1448,
        3897,  238, 1043,  120])
Epoch: 1868, Training Loss: 0.35, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1869 - Batch 1 ########################
IDs in batch 1: tensor([2942,  622, 3398, 2121,  261, 2369, 3496, 1035,  491,  399, 3942, 3057,
        1386, 2045, 1089, 4039])
Epoch: 1869, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1870 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 3531,  977,  488, 2552, 3701, 2010, 1258, 1665, 1497,  786, 3447,
         113, 1161, 3199, 4174])
Epoch: 1870, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1871 - Batch 1 ########################
IDs in batch 1: tensor([2354, 1981, 3376,  425, 2410, 2315, 4116, 3460, 1624, 2978, 4236, 4044,
        3270, 3219, 1962, 3328])
Epoch: 1871, Training Loss: 0.51, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1872 - Batch 1 ########################
IDs in batch 1: tensor([1093, 4176, 2873, 1385, 2258,  558, 2868, 1413, 1383, 3772, 2106, 2499,
         563, 1101, 1509, 1380])
Epoch: 1872, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1873 - Batch 1 ########################
IDs in batch 1: tensor([3159, 2300, 1397, 3141, 3815, 3833, 3154, 1982,  470, 2360, 1445,  501,
        3408,  536, 1665,   71])
Epoch: 1873, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1874 - Batch 1 ########################
IDs in batch 1: tensor([1602, 1383, 1672, 2734, 2615, 3632, 2112, 3692,  373, 3734, 2382, 2479,
         256, 1532, 2120, 2166])
Epoch: 1874, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1875 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 3780, 1707, 1855,  942, 1628, 2246, 2053, 1276, 1500, 3942,  626,
        3151,  994,  930, 1266])
Epoch: 1875, Training Loss: 0.46, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1876 - Batch 1 ########################
IDs in batch 1: tensor([ 185, 1730, 2329, 1711, 3146, 1311, 1675, 3507, 1473, 1545, 1973, 1232,
        2841, 1032, 3935, 3756])
Epoch: 1876, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1877 - Batch 1 ########################
IDs in batch 1: tensor([3291, 1567, 1360, 1780, 3764, 3647,   64, 3567, 3973,  315, 1369, 3969,
        2179,  533,  412,  774])
Epoch: 1877, Training Loss: 0.63, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1878 - Batch 1 ########################
IDs in batch 1: tensor([1510, 3250, 4022, 1341, 1199, 1190, 3094, 2462, 2196,  555, 3779,  117,
        2837, 2167, 3987, 3069])
Epoch: 1878, Training Loss: 0.56, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1879 - Batch 1 ########################
IDs in batch 1: tensor([3767, 3663, 3896, 2953,  535, 2278, 3429, 1016, 2848, 3772, 3878,  775,
        4139,  255,  824, 4180])
Epoch: 1879, Training Loss: 0.42, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1880 - Batch 1 ########################
IDs in batch 1: tensor([2373, 3111, 2094, 2856,  658, 3988, 3099, 1356,  923, 1163, 1356, 1235,
         942, 3783, 4249, 1445])
Epoch: 1880, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1881 - Batch 1 ########################
IDs in batch 1: tensor([3032,  994, 3850, 3222, 3357,  994,  287, 1272, 1932, 2723, 3610,  659,
        2791, 2708, 3246, 2253])
Epoch: 1881, Training Loss: 0.43, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1882 - Batch 1 ########################
IDs in batch 1: tensor([1364,  494, 3377, 3969, 3132, 1644,  109,  503, 1448, 4036,  534, 3111,
        3530, 1980, 3497, 2126])
Epoch: 1882, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1883 - Batch 1 ########################
IDs in batch 1: tensor([3532, 2641, 2241, 2399, 3956, 2809,  213, 1051, 2097, 4086,  904,  997,
         651, 4204, 3278,  212])
Epoch: 1883, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1884 - Batch 1 ########################
IDs in batch 1: tensor([1260, 1256, 3505, 2859, 1958, 2915, 3072, 3259, 2620, 2535, 3717, 3740,
        3483, 2655, 1887, 2188])
Epoch: 1884, Training Loss: 0.63, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1885 - Batch 1 ########################
IDs in batch 1: tensor([2618, 3664, 3460, 2378,  244,  332, 1576,  432,  100, 1385, 2833, 2326,
        1594,  712, 1626, 1028])
Epoch: 1885, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1886 - Batch 1 ########################
IDs in batch 1: tensor([ 568, 2241, 1015, 2118, 1326, 1501, 1104, 3326,  165, 4016, 3658, 1973,
        2641, 3267, 2257, 1160])
Epoch: 1886, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1887 - Batch 1 ########################
IDs in batch 1: tensor([2212, 3214,  766, 4174, 3975,  572, 3507, 2320, 2159, 1751, 2586, 3159,
        1954, 4176, 3246, 3290])
Epoch: 1887, Training Loss: 0.42, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1888 - Batch 1 ########################
IDs in batch 1: tensor([ 732, 2690,  408, 3345, 3872, 2126, 3417, 4189, 3100, 1588, 3071, 1108,
         344, 3467, 1846, 3334])
Epoch: 1888, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 1889 - Batch 1 ########################
IDs in batch 1: tensor([2874, 2264, 3891, 1224,  320,  491, 3040,  858, 3418,  923,  437, 2610,
        1857, 2108, 1576,  260])
Epoch: 1889, Training Loss: 0.36, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1890 - Batch 1 ########################
IDs in batch 1: tensor([2945, 2703, 3108, 4144, 4031, 2616, 1123, 4113, 2127, 3430,  639,  837,
        2005, 1249,  946, 3903])
Epoch: 1890, Training Loss: 0.31, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1891 - Batch 1 ########################
IDs in batch 1: tensor([2278,  907,  223, 1007, 1506, 1819,  117,  164, 4203, 1975, 1437, 3882,
        3822, 1732, 1482, 3002])
Epoch: 1891, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1892 - Batch 1 ########################
IDs in batch 1: tensor([1858, 4046, 2246, 1493,  400, 3144, 2064, 4067, 3371, 1753, 1878, 2232,
        1107, 1219, 1970, 4128])
Epoch: 1892, Training Loss: 0.32, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1893 - Batch 1 ########################
IDs in batch 1: tensor([2535, 4002, 3729, 3881,  824, 4086, 3317, 2854, 2949,  275, 2500, 2290,
        2064, 1162, 1122, 1526])
Epoch: 1893, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1894 - Batch 1 ########################
IDs in batch 1: tensor([2537, 3309, 4070, 1154, 1264,  941, 3581, 3501, 3132, 2220,  844, 3922,
        2450, 4087,  969, 1578])
Epoch: 1894, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1895 - Batch 1 ########################
IDs in batch 1: tensor([1556, 1916, 2773,  547, 3618,  717,  330,  188,  993, 3434, 3476, 2652,
         363,  552, 2003, 3424])
Epoch: 1895, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1896 - Batch 1 ########################
IDs in batch 1: tensor([3262,   37,  348, 1274,  882, 1049, 3583, 3250, 3233, 2119,  508, 2326,
        2115, 3527, 4011, 3836])
Epoch: 1896, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1897 - Batch 1 ########################
IDs in batch 1: tensor([3343, 1404, 2103,   68, 1337, 2271, 1958, 3366, 2078, 1911, 3991, 2488,
        4146, 1476,  261, 2857])
Epoch: 1897, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1898 - Batch 1 ########################
IDs in batch 1: tensor([3003,  819, 2659, 4018, 1640, 2561,  812, 4143, 1699, 1287, 3621, 4068,
         610, 1380, 3733, 2493])
Epoch: 1898, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1899 - Batch 1 ########################
IDs in batch 1: tensor([ 225, 3409, 4194, 4267, 2484, 2495, 1222, 1161, 4232, 1730,  864, 3271,
        3406, 1519, 3950, 2151])
Epoch: 1899, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 1900 - Batch 1 ########################
IDs in batch 1: tensor([3991,  653,  620,  851, 2097, 3530, 3250, 4225,  126, 4087,  505, 3127,
        1443, 1463, 1878,  684])
Epoch: 1900, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1901 - Batch 1 ########################
IDs in batch 1: tensor([2041, 2936,  753, 2574, 2127, 3697, 3114, 2306, 1504, 3719, 2410, 2092,
        2003, 2339, 1179, 3434])
Epoch: 1901, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1902 - Batch 1 ########################
IDs in batch 1: tensor([2472, 1141, 1096,  676, 2290, 1899,   30, 1232, 1372,  967,  462, 2710,
        4254,  665, 2572,  444])
Epoch: 1902, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1903 - Batch 1 ########################
IDs in batch 1: tensor([1232,  622, 2278, 3017, 1001, 1712, 2008, 3082, 2710, 2126, 2341, 1894,
         796, 3627, 2711, 3616])
Epoch: 1903, Training Loss: 0.35, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1904 - Batch 1 ########################
IDs in batch 1: tensor([1861, 2435, 2586, 4185, 1602,  908, 3136, 4229, 4220, 3954, 1410, 2748,
        2463,   85, 2022, 3375])
Epoch: 1904, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1905 - Batch 1 ########################
IDs in batch 1: tensor([1704, 1648, 2447,  131, 3972, 1035, 1429, 2419, 1351,  141, 3461,  279,
        1308, 1555, 3787,  260])
Epoch: 1905, Training Loss: 0.41, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1906 - Batch 1 ########################
IDs in batch 1: tensor([2097,  846, 1345,  866, 1859, 2492, 1419, 1499,  154, 3052, 1901, 1869,
        2880, 1294, 1730, 1718])
Epoch: 1906, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1907 - Batch 1 ########################
IDs in batch 1: tensor([1337, 2582, 1004, 3480, 3732, 2465,  569, 2538, 4000, 3569,  878, 1852,
        2413, 2964, 2842, 1590])
Epoch: 1907, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1908 - Batch 1 ########################
IDs in batch 1: tensor([ 990,  814, 1892, 1504, 2986, 1605,  378, 3015, 1640,  529, 2400, 1232,
         448, 3398, 2998, 2663])
Epoch: 1908, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1909 - Batch 1 ########################
IDs in batch 1: tensor([ 348, 3017, 3323, 2299, 1851, 2285, 2822, 2853, 2960, 2398,  755, 3729,
         491,  676,  252,  529])
Epoch: 1909, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1910 - Batch 1 ########################
IDs in batch 1: tensor([ 182, 3733,  967, 2385,  482,  563, 2334, 3618, 3197, 1208, 3518, 2729,
        2337, 3846,   41, 2603])
Epoch: 1910, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1911 - Batch 1 ########################
IDs in batch 1: tensor([2391,  258, 1117,  343,  195, 2111, 4007, 3563,  256, 1178, 2202, 1396,
        4012,  220, 2219, 4135])
Epoch: 1911, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1912 - Batch 1 ########################
IDs in batch 1: tensor([ 436, 1723, 1755, 2777, 3409,  515, 3056, 3669, 2356,  843,  415,  182,
         632, 1884, 1098, 3704])
Epoch: 1912, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1913 - Batch 1 ########################
IDs in batch 1: tensor([4254, 4220,   38, 3321, 3545, 2519, 1065,  135,  250, 2965, 2825, 2161,
        2678, 1076, 2885, 2832])
Epoch: 1913, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1914 - Batch 1 ########################
IDs in batch 1: tensor([ 236, 2666, 2053, 2488,  826, 3618, 1363, 2447, 2945, 2327, 1045, 1671,
         466, 1478, 2614, 3554])
Epoch: 1914, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1915 - Batch 1 ########################
IDs in batch 1: tensor([2098,  993,  440,  834,  250, 2552,  612, 1171, 4105, 3257, 3321, 3056,
         807, 2644,  835,  804])
Epoch: 1915, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1916 - Batch 1 ########################
IDs in batch 1: tensor([4084, 3009, 4039, 2144, 1355,  306, 3028, 3948,  131,  316, 4057, 3120,
        4085,  262, 1443, 2373])
Epoch: 1916, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 1917 - Batch 1 ########################
IDs in batch 1: tensor([ 828, 2839, 3312, 3161, 2262, 3660, 3069, 3538, 1282,  751,  152, 1159,
        1618,  132, 1764, 1326])
Epoch: 1917, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1918 - Batch 1 ########################
IDs in batch 1: tensor([  70,  568, 3739, 1003, 1491,  185, 1618,  635,  605, 1452, 3833, 2891,
        1440, 1138, 1051, 2317])
Epoch: 1918, Training Loss: 0.38, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1919 - Batch 1 ########################
IDs in batch 1: tensor([3514,  834, 4113, 2465,  769, 1469, 3518, 2553, 4085, 2739, 3027,  605,
        1633, 3279,  819, 3974])
Epoch: 1919, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1920 - Batch 1 ########################
IDs in batch 1: tensor([1363,  229,  888, 3211, 4263, 3436, 4033,  150, 4097,  303, 3816, 3004,
        2123,  846,  483, 2234])
Epoch: 1920, Training Loss: 0.32, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1921 - Batch 1 ########################
IDs in batch 1: tensor([3073, 3914, 3532, 2742, 2485,  516,  607, 3221, 4010,  211, 3833, 1308,
        1209, 3408, 1678, 2917])
Epoch: 1921, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1922 - Batch 1 ########################
IDs in batch 1: tensor([ 573,   64,   81, 3340, 3094,  496, 2592, 1932, 1879, 2091,  211, 4174,
        3802, 4119,  635,  766])
Epoch: 1922, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 1923 - Batch 1 ########################
IDs in batch 1: tensor([ 918, 2413,  305,  753, 1605, 2418, 3023, 1429, 1223, 3253, 2104, 1617,
        2480,  113, 3357, 1008])
Epoch: 1923, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1924 - Batch 1 ########################
IDs in batch 1: tensor([2604, 2993,  100, 2237,  632, 1726, 3053, 2655, 1935, 2369, 1065, 2609,
        1317, 2522, 2402, 2271])
Epoch: 1924, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1925 - Batch 1 ########################
IDs in batch 1: tensor([1904, 2913, 3286, 3803, 4187, 2245,  550,  170, 2125, 1399, 3753, 3527,
        1132, 1624,  937, 1393])
Epoch: 1925, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 1926 - Batch 1 ########################
IDs in batch 1: tensor([2741, 4062, 4173, 1292, 3518,  626, 3863,  427, 3831, 1023, 2577, 2354,
        4168,   30, 1369, 1803])
Epoch: 1926, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1927 - Batch 1 ########################
IDs in batch 1: tensor([1340,  777, 3921,  376,  378, 1613, 2419, 2849, 3927, 2724, 1555, 2553,
        2349,  397, 3421, 3847])
Epoch: 1927, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1928 - Batch 1 ########################
IDs in batch 1: tensor([2146, 2770, 2663, 2262,  583, 2274, 3927, 1751, 1974, 1361, 1156, 2338,
        1182, 3996, 4062, 4128])
Epoch: 1928, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1929 - Batch 1 ########################
IDs in batch 1: tensor([3738, 4268, 2967,  483, 1810, 3017,  155,  954, 4134, 3738, 1472, 2505,
        2010,   18, 2572, 2676])
Epoch: 1929, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1930 - Batch 1 ########################
IDs in batch 1: tensor([3177,   25, 1882, 3283, 3842,  962, 3664,  555, 1569, 1144, 3313, 3463,
        3831,  323,  100, 4087])
Epoch: 1930, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1931 - Batch 1 ########################
IDs in batch 1: tensor([ 234, 2851, 3069,  100, 3925,  444,  340, 4032,  659, 1137, 1379,  920,
        3838, 1459, 1556,  484])
Epoch: 1931, Training Loss: 0.49, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 1932 - Batch 1 ########################
IDs in batch 1: tensor([3500, 3947,  200, 1008, 4168,  143, 3490, 3082, 3131, 2056,  829, 1571,
         263, 3194,  143, 1849])
Epoch: 1932, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1933 - Batch 1 ########################
IDs in batch 1: tensor([3049, 3656, 2148, 2845, 3181, 2041, 1043,  149, 1646, 3652, 1733, 2695,
         337, 1282, 1063, 2592])
Epoch: 1933, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1934 - Batch 1 ########################
IDs in batch 1: tensor([ 652,  496, 1880,  733, 4215, 1218,  472, 1590,  531, 2279,  205, 2305,
        1740,  928, 3925, 2690])
Epoch: 1934, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1935 - Batch 1 ########################
IDs in batch 1: tensor([2690,  941,  376, 1177, 1570,  604, 2857, 3695, 1360, 4173, 1140, 3638,
         111, 3757,  837, 3968])
Epoch: 1935, Training Loss: 0.65, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1936 - Batch 1 ########################
IDs in batch 1: tensor([2462, 3506,  660,  910, 3381, 1977, 1284, 1707, 1953, 3030, 3870, 3746,
         503, 2496,  805, 2480])
Epoch: 1936, Training Loss: 0.48, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 1937 - Batch 1 ########################
IDs in batch 1: tensor([3004, 3379,  842, 4163,  517, 2144, 3834, 4006, 1171, 2450, 1319, 3541,
        2520, 2166, 3199, 3542])
Epoch: 1937, Training Loss: 0.34, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 1938 - Batch 1 ########################
IDs in batch 1: tensor([  92, 2632,  181, 2095, 3031, 1098, 1233,  354, 3655, 1869, 1965, 3996,
        2196, 4107, 1485, 3663])
Epoch: 1938, Training Loss: 0.56, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 1939 - Batch 1 ########################
IDs in batch 1: tensor([2169, 1025, 3524, 1334,  161, 1152, 2298, 2518, 2444, 2805, 2483, 1828,
        1318, 2758, 4217,  352])
Epoch: 1939, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1940 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 3219, 1627, 3872, 2715, 3406, 3051,   88, 1219, 2621,  963, 2717,
         152, 2848, 2804,  434])
Epoch: 1940, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 1941 - Batch 1 ########################
IDs in batch 1: tensor([4189,  470, 1007, 2449, 2041, 3592,  789, 4082, 1482, 2959, 3246, 3651,
        1959,  838, 3372, 3027])
Epoch: 1941, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 1942 - Batch 1 ########################
IDs in batch 1: tensor([  51, 1958, 1510, 2149, 1157, 2721, 3479, 1553, 3706, 2317, 3661, 2913,
        1352, 3660, 4242, 4055])
Epoch: 1942, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1943 - Batch 1 ########################
IDs in batch 1: tensor([3707, 3087, 3879,  674,  933,  217, 3705, 2934,  976, 2300, 3674,  466,
         956, 4101, 1984, 4214])
Epoch: 1943, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1944 - Batch 1 ########################
IDs in batch 1: tensor([  72,  122,   27, 4135, 1410, 1249, 1784,  154,  816,  505,  200, 1579,
        1947,  896, 2614, 1117])
Epoch: 1944, Training Loss: 0.84, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1945 - Batch 1 ########################
IDs in batch 1: tensor([2431, 3057,  359,  164, 4012, 1588, 3765, 3492, 2172,   56, 1209, 4194,
         809,  510, 3466,  928])
Epoch: 1945, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1946 - Batch 1 ########################
IDs in batch 1: tensor([ 152,  781, 2383,   61, 2537,  418, 4065,  670, 3981, 4198, 2235, 2616,
        2670,  520, 1680, 3267])
Epoch: 1946, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 1947 - Batch 1 ########################
IDs in batch 1: tensor([3927, 2170, 1810,  943,  508, 2545, 3159,  733, 3826, 3751, 4114,  378,
        3851, 2480, 3628,  915])
Epoch: 1947, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 1948 - Batch 1 ########################
IDs in batch 1: tensor([3312, 2126,  238, 1540, 2942, 1994, 3680,  527, 1319, 2924, 2742, 2213,
         988, 3272, 1047, 1951])
Epoch: 1948, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1949 - Batch 1 ########################
IDs in batch 1: tensor([2567, 2506, 1179,  527, 3277,  384, 3168, 2406, 1381,  869, 3772, 1914,
         119,  605,  959, 3504])
Epoch: 1949, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1950 - Batch 1 ########################
IDs in batch 1: tensor([3530, 3114,  832, 1452, 3437, 2817, 1333, 3600, 2932, 1104,  785, 3142,
        3938,  640, 1636, 3732])
Epoch: 1950, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1951 - Batch 1 ########################
IDs in batch 1: tensor([ 218, 3945, 2897, 3236, 4140,  280, 2835, 2627, 1310,  483, 1799, 2412,
         341, 2145, 2494,  956])
Epoch: 1951, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1952 - Batch 1 ########################
IDs in batch 1: tensor([ 172, 3537, 3484, 3340, 1913, 1337, 1107, 1951, 2770, 1356, 2966, 3020,
        3308,  773,   21, 3655])
Epoch: 1952, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1953 - Batch 1 ########################
IDs in batch 1: tensor([1551, 1796, 1216, 2619, 2172, 2571, 2428, 1499,  206, 3150, 3993, 1993,
        1727, 2649,  105, 2797])
Epoch: 1953, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 1954 - Batch 1 ########################
IDs in batch 1: tensor([2034,  658, 2655, 2203, 3767,  843,  501, 2815, 3938, 1039,  609,  994,
        3235, 3608, 3797, 2172])
Epoch: 1954, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1955 - Batch 1 ########################
IDs in batch 1: tensor([  59,  226, 2420, 4119, 2848,  970, 1085, 1257, 3204, 1773, 1794,  693,
         883,  359,  961, 3077])
Epoch: 1955, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1956 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 2978, 3592, 1442, 2624, 2546, 1883,  975, 2741,  499, 3532, 3829,
        1200, 1559,  725, 3470])
Epoch: 1956, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1957 - Batch 1 ########################
IDs in batch 1: tensor([2415, 1406, 3888,  871,  345, 3976, 4086, 1877, 4255,   50, 3458,  371,
        2019, 3352, 2898, 2070])
Epoch: 1957, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1958 - Batch 1 ########################
IDs in batch 1: tensor([3974,  281, 2053,  766, 1501,  770, 3300, 1795, 3977, 2751, 2868, 3349,
        2598,  132, 1200,  484])
Epoch: 1958, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1959 - Batch 1 ########################
IDs in batch 1: tensor([1620, 3787, 1794, 1026, 1896,  594, 3896, 3644, 2472, 2028,  141,  475,
         908, 1429, 2219, 2206])
Epoch: 1959, Training Loss: 0.27, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1960 - Batch 1 ########################
IDs in batch 1: tensor([ 566, 2847, 3689, 3492, 1101, 3404, 3397,  876, 2250, 1102,   19,   81,
        2859, 4061, 2782, 3047])
Epoch: 1960, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1961 - Batch 1 ########################
IDs in batch 1: tensor([1532, 3235,  133, 3984,  741, 1597, 2014,  448, 2035, 2745, 1546, 3421,
        2938, 1336, 1981,  154])
Epoch: 1961, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1962 - Batch 1 ########################
IDs in batch 1: tensor([3997, 3853, 2284, 3521,  828,  910,  936, 3453, 2060, 1415, 4226,  895,
        3896, 1726,   88, 1702])
Epoch: 1962, Training Loss: 0.29, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1963 - Batch 1 ########################
IDs in batch 1: tensor([1953, 1004,  259, 1287,  726,  955, 2275, 2191, 1517, 1084, 1092, 1004,
         682, 4240, 1732,  680])
Epoch: 1963, Training Loss: 0.63, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1964 - Batch 1 ########################
IDs in batch 1: tensor([2073, 1996, 2579, 2499, 3701,   81, 1324,  766, 1972, 2717, 1467,  533,
         245, 2589, 1892, 2359])
Epoch: 1964, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 1965 - Batch 1 ########################
IDs in batch 1: tensor([2171, 3253, 2700,  983, 1965, 1988, 3505, 2724,  882, 4265, 2258, 3681,
         981, 1722, 2150, 3826])
Epoch: 1965, Training Loss: 0.34, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1966 - Batch 1 ########################
IDs in batch 1: tensor([ 306,  818, 3816, 2793, 4122,  191,  788, 1322,  679, 3357, 2954, 1825,
        3743, 4203,  934, 3120])
Epoch: 1966, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1967 - Batch 1 ########################
IDs in batch 1: tensor([1993, 2870, 2810, 3009, 2883, 2899,  627, 4027, 1605, 1297, 1138, 1434,
        2729, 2869, 3379,   88])
Epoch: 1967, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1968 - Batch 1 ########################
IDs in batch 1: tensor([2643, 3486,  568, 2973, 1402, 1317,  590, 2005, 1123, 2842,  842, 2461,
        1640,  251, 2353, 2999])
Epoch: 1968, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1969 - Batch 1 ########################
IDs in batch 1: tensor([1321, 2324, 2249, 2246, 3015, 4267, 3438, 4172,   73, 1008,  904, 3597,
         419, 2185, 3219, 3042])
Epoch: 1969, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1970 - Batch 1 ########################
IDs in batch 1: tensor([1080,  854, 4121, 1532, 2382, 2919, 3764, 1335, 3496, 2880, 1274,  899,
        2886, 1360, 3509, 1312])
Epoch: 1970, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 1971 - Batch 1 ########################
IDs in batch 1: tensor([2425, 4218, 3688, 3430, 4227, 1650,  527, 1959, 1037,  658,  508, 4038,
        3585,  234, 3593, 2858])
Epoch: 1971, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1972 - Batch 1 ########################
IDs in batch 1: tensor([2478,   35,  213, 1155, 3060, 2711, 1891,  667, 3699, 1235, 1956, 2236,
          63, 2199, 1982, 3142])
Epoch: 1972, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1973 - Batch 1 ########################
IDs in batch 1: tensor([2063, 3832, 4076,  160, 4036, 2767,  131,  718,  682, 2510, 3513,  261,
         359, 4096, 3098, 4048])
Epoch: 1973, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1974 - Batch 1 ########################
IDs in batch 1: tensor([ 134, 3486, 2095, 2428, 3414, 3719,  469, 1932, 2236, 1160, 1319, 1668,
        2986, 2070, 4055, 2039])
Epoch: 1974, Training Loss: 0.24, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1975 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 2177,  874, 3492, 3659, 3409, 2339, 3692, 3038, 1833, 1269,  512,
        2516,  663, 3311, 3746])
Epoch: 1975, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 1976 - Batch 1 ########################
IDs in batch 1: tensor([1822, 4185, 2546, 1286, 2226, 1803, 2670, 2947,  971, 1761,  606, 1826,
        3630, 3707, 1131, 3342])
Epoch: 1976, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1977 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 3585, 3024, 1156, 3079, 2451, 2505,  796, 2116,  160, 3846, 1485,
        1020, 3401, 3029,  985])
Epoch: 1977, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 1978 - Batch 1 ########################
IDs in batch 1: tensor([3010, 2408, 1171,  172, 3196, 1055, 1195,  974,  398, 2366, 2908, 2494,
        3268, 1341, 2157,  887])
Epoch: 1978, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1979 - Batch 1 ########################
IDs in batch 1: tensor([1682,  956, 3526,  325, 3674, 3460,  136,  280, 3309, 3259, 3702, 1072,
         936, 2045, 1324, 2721])
Epoch: 1979, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 1980 - Batch 1 ########################
IDs in batch 1: tensor([1061, 2509, 1258, 4089, 1633, 3318,  100, 2859, 3953, 1102,  251, 3882,
        1260, 3740,   62,   38])
Epoch: 1980, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 1981 - Batch 1 ########################
IDs in batch 1: tensor([3668,  143, 3683, 2110, 1390,  950, 1312, 1179,  944,  515, 2783,  718,
        2487, 1331, 1140, 2712])
Epoch: 1981, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1982 - Batch 1 ########################
IDs in batch 1: tensor([1110, 3634, 3387,  805,  997, 1923, 3894, 2070, 1057, 3509, 1488,  448,
        2998,  212, 1386, 1260])
Epoch: 1982, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1983 - Batch 1 ########################
IDs in batch 1: tensor([ 961,  962, 2869, 3142, 3767, 1367, 2402, 4173,  534, 3377, 1699,  290,
        3036, 4061, 1383, 1373])
Epoch: 1983, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1984 - Batch 1 ########################
IDs in batch 1: tensor([2400, 3672,  954, 2781,  476, 1081, 2245, 2279, 4068, 1418, 2053, 1961,
        1849,  747, 2892, 4015])
Epoch: 1984, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1985 - Batch 1 ########################
IDs in batch 1: tensor([1006, 2446, 1228, 1884,  577, 3110, 3113, 1276, 1663, 1502, 2442,  965,
         869, 3927,  412, 1726])
Epoch: 1985, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1986 - Batch 1 ########################
IDs in batch 1: tensor([3948, 3862,  262,  960, 2867,  449, 1952, 4037, 3323, 3108, 1337,  975,
        2297, 1675, 2178, 3327])
Epoch: 1986, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 1987 - Batch 1 ########################
IDs in batch 1: tensor([1712,  815, 2927, 2453, 3226,   97,  280, 2733, 3940, 1386,  430, 1116,
        4051, 2967, 2466,  356])
Epoch: 1987, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1988 - Batch 1 ########################
IDs in batch 1: tensor([ 229,  345, 2957,  487,  103, 2505, 3136,  342, 3734, 2137, 3764, 3451,
        1089,  259, 1405, 2206])
Epoch: 1988, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1989 - Batch 1 ########################
IDs in batch 1: tensor([2172, 3286,  326, 2921,  361, 2017, 2413, 3891, 1618, 1198,  814, 1751,
         436, 3238, 2190, 3199])
Epoch: 1989, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1990 - Batch 1 ########################
IDs in batch 1: tensor([ 660, 2629, 1746, 1260,  425, 1519, 4032, 2341,  837, 3373, 2306, 3912,
        3572,  295, 1798, 4068])
Epoch: 1990, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1991 - Batch 1 ########################
IDs in batch 1: tensor([1842, 2953, 3035, 2873, 3246,  942, 2103, 4062, 2796, 3847,  844, 1393,
        3904, 2553,  451, 1419])
Epoch: 1991, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1992 - Batch 1 ########################
IDs in batch 1: tensor([2770, 2127, 2615, 2150, 1774, 3336,  289, 4190, 1085, 1921,   11, 1601,
        3969, 3220, 4166, 4215])
Epoch: 1992, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1993 - Batch 1 ########################
IDs in batch 1: tensor([4215, 2343, 1313,  220, 1845,  200, 1988, 2328, 1977, 3390, 2960, 2458,
        1628, 1177, 2552,  909])
Epoch: 1993, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1994 - Batch 1 ########################
IDs in batch 1: tensor([ 356, 3131,  837, 3185,  983,  918,  727, 2951, 1032, 1984, 3421, 1256,
        1712, 3632, 3257,  674])
Epoch: 1994, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 1995 - Batch 1 ########################
IDs in batch 1: tensor([2590, 2732, 1130, 1626, 1670,  541, 3822,  875,  201, 1454, 2882, 1819,
        3772, 2448, 3327, 2150])
Epoch: 1995, Training Loss: 0.33, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 1996 - Batch 1 ########################
IDs in batch 1: tensor([2574, 1681, 3582, 2828, 1913, 2034, 3289, 3648, 3836,   44, 4128,  137,
        2584, 4158,  818, 2338])
Epoch: 1996, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1997 - Batch 1 ########################
IDs in batch 1: tensor([1762, 2743,  308, 2299, 2961,   64,  257, 3762, 1543, 3181, 3513, 2493,
        2352, 2344, 3564, 1425])
Epoch: 1997, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 1998 - Batch 1 ########################
IDs in batch 1: tensor([3873, 3182, 1361, 2442,  741, 4121,  276, 3592,  670, 3466, 1476, 1272,
        1045,  652, 2271, 1214])
Epoch: 1998, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 1999 - Batch 1 ########################
IDs in batch 1: tensor([1225, 2284, 2649, 2497, 4082, 3921, 2353, 2839, 1796, 2405, 2649, 2936,
        2912, 3989, 1344, 3252])
Epoch: 1999, Training Loss: 0.66, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2000 - Batch 1 ########################
IDs in batch 1: tensor([3110, 1497, 2997, 2489, 2492, 3303, 3843,  396,  834, 3220, 2498, 3780,
        1618, 1284, 3286, 1845])
Epoch: 2000, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2001 - Batch 1 ########################
IDs in batch 1: tensor([2908, 1354, 3870, 3344, 1183, 3135, 1269, 1032, 3987, 3484,  921, 3357,
        4267, 4113, 3121, 3376])
Epoch: 2001, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2002 - Batch 1 ########################
IDs in batch 1: tensor([3304, 2010,   99, 2144, 2546,  569, 3473, 3726, 2220, 2016, 2237, 1198,
        1103, 2466, 3498,  659])
Epoch: 2002, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2003 - Batch 1 ########################
IDs in batch 1: tensor([ 894,  639, 2229, 1158, 2369, 3650, 1686,  180, 3379,  320, 1119,  173,
        3998, 1251, 2180, 3723])
Epoch: 2003, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2004 - Batch 1 ########################
IDs in batch 1: tensor([1763, 1126, 3765, 4113, 2386, 3692, 3698, 3652,  993, 2498, 3437,  269,
        3549,   70, 2358, 3428])
Epoch: 2004, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2005 - Batch 1 ########################
IDs in batch 1: tensor([1481, 1008,  372, 4166,  194, 3808, 2676,  342, 1512, 3389, 2450, 1374,
        2652, 2448, 1122, 3390])
Epoch: 2005, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2006 - Batch 1 ########################
IDs in batch 1: tensor([3004, 1599, 2825, 2701, 3922, 2355, 2869,  368, 3027, 1959, 3656, 2041,
        1305, 1159, 2899,  181])
Epoch: 2006, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2007 - Batch 1 ########################
IDs in batch 1: tensor([3948,    4, 2661,  150,  177,  345, 2755, 1878, 2523, 2844,  832,  953,
        1988, 2150, 1610, 3834])
Epoch: 2007, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2008 - Batch 1 ########################
IDs in batch 1: tensor([1269, 2153,  957, 3434, 4199,  897, 1525, 2073, 2279, 2124,  343,  455,
        3681, 4204, 2463, 1456])
Epoch: 2008, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2009 - Batch 1 ########################
IDs in batch 1: tensor([ 666,  320, 3858, 1780, 3710, 3132, 1911, 3779,  212, 3178,  918, 1649,
         279,  207, 3980, 2609])
Epoch: 2009, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2010 - Batch 1 ########################
IDs in batch 1: tensor([1959, 1001,  333, 2196, 3128, 3392, 2455, 3972, 3421,  849, 4010, 2195,
         630,   82,  812, 1909])
Epoch: 2010, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2011 - Batch 1 ########################
IDs in batch 1: tensor([2678,  713, 3452,  258, 1497, 3208, 3020,  688, 3369, 2153,  557, 3702,
         533,  887,   96, 3671])
Epoch: 2011, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2012 - Batch 1 ########################
IDs in batch 1: tensor([3661, 3898, 4134, 3836, 2280, 3282, 4015, 1309, 3940, 2137, 1661, 2149,
         685, 2272,  625,  826])
Epoch: 2012, Training Loss: 0.30, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2013 - Batch 1 ########################
IDs in batch 1: tensor([4194, 1834, 3409, 2831, 1356, 1404, 2674, 4115,  584,  851,  245, 2365,
        1308,  971, 1444, 3982])
Epoch: 2013, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2014 - Batch 1 ########################
IDs in batch 1: tensor([3600, 4126,   74, 3136, 4184, 3532,  514,   20, 4256, 3187, 1341, 2121,
        3379, 1576, 1728,   38])
Epoch: 2014, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2015 - Batch 1 ########################
IDs in batch 1: tensor([2098, 2974, 3006, 3352, 2957, 2841,  394, 3487, 2617, 2488, 1684, 2040,
        1413, 2656,  685, 4082])
Epoch: 2015, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2016 - Batch 1 ########################
IDs in batch 1: tensor([1285, 4267, 3637, 3312, 3367, 2646, 1045, 3436,  603, 4135, 2546, 1069,
        2581, 2301, 4011,  491])
Epoch: 2016, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2017 - Batch 1 ########################
IDs in batch 1: tensor([2737, 3528, 1381,  632, 2185, 2545, 3330, 4246, 1380, 3705, 1163,   63,
         136,  503, 1023, 2510])
Epoch: 2017, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2018 - Batch 1 ########################
IDs in batch 1: tensor([1284, 1897, 2505, 3470,  601, 3375,  864,  908, 2326, 4008, 2125, 2553,
        2261, 3475, 3968, 2401])
Epoch: 2018, Training Loss: 0.37, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2019 - Batch 1 ########################
IDs in batch 1: tensor([ 841,  430, 1828,  529,  854, 1305, 3455,  417, 1660,  878,  615, 4264,
        3265,  378, 1279, 1310])
Epoch: 2019, Training Loss: 0.43, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2020 - Batch 1 ########################
IDs in batch 1: tensor([  57, 3488,  418, 3465, 2739,  957, 1128,  710,  741, 1470, 3936, 3671,
        1193,  944, 3671,  869])
Epoch: 2020, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2021 - Batch 1 ########################
IDs in batch 1: tensor([1777,  989, 3077, 3888, 2670, 4200, 3056, 2895,  432, 1971, 2555, 2431,
        2018,  971, 1632, 1536])
Epoch: 2021, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2022 - Batch 1 ########################
IDs in batch 1: tensor([3747, 3275, 2035, 3356, 3917,  985, 1367, 3968,  749, 1381, 2508, 3354,
        3771, 3847, 2022, 3345])
Epoch: 2022, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2023 - Batch 1 ########################
IDs in batch 1: tensor([3406, 1909,  195, 3643, 3777, 2839, 1925, 2538,  953, 3693, 1413, 1034,
        3032,  635, 3120, 1241])
Epoch: 2023, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2024 - Batch 1 ########################
IDs in batch 1: tensor([1730, 1088,  789, 1458, 3757,  127, 1275, 2195, 3920,  640, 1668, 2249,
          37, 1428, 2131,  145])
Epoch: 2024, Training Loss: 0.34, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2025 - Batch 1 ########################
IDs in batch 1: tensor([ 110,  190, 3624, 4012, 2526, 3367, 4061, 3287, 4204, 1519, 2366, 2393,
        1896,  195, 4014, 4127])
Epoch: 2025, Training Loss: 0.26, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2026 - Batch 1 ########################
IDs in batch 1: tensor([2261, 2836, 4030,  419,  992, 3208,  121, 2282, 2997, 2537, 3364, 1274,
         568,  280, 4163, 3468])
Epoch: 2026, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2027 - Batch 1 ########################
IDs in batch 1: tensor([3051, 1808, 3990, 2457, 2364, 1895, 3009, 1610, 4116, 4246, 3071, 3377,
         140,  825, 2202,  640])
Epoch: 2027, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2028 - Batch 1 ########################
IDs in batch 1: tensor([1763, 1810,  771, 3505, 2520, 1777, 1069, 2378,  225, 2298,  747, 2065,
        4011,  974, 2182,   10])
Epoch: 2028, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2029 - Batch 1 ########################
IDs in batch 1: tensor([ 950, 3468, 3376,  603, 1618, 2166, 2895, 3521,  289, 2723, 4255, 2797,
        1006, 2581,  656, 3786])
Epoch: 2029, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2030 - Batch 1 ########################
IDs in batch 1: tensor([2520,  497, 1417, 2039, 3981, 1232, 4190, 1756, 3118,  568, 2721, 1860,
        3075, 1882,  970,  657])
Epoch: 2030, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2031 - Batch 1 ########################
IDs in batch 1: tensor([ 133, 1317, 1417, 1624, 1668, 3216, 3489, 1639, 4267, 3351,   32, 2241,
        1673, 3618, 3689,  160])
Epoch: 2031, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2032 - Batch 1 ########################
IDs in batch 1: tensor([2002,  512,    4, 3989, 3184, 2189, 2700,  140, 2229, 3846, 2123, 4105,
        2857, 1026,  127, 2823])
Epoch: 2032, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2033 - Batch 1 ########################
IDs in batch 1: tensor([ 257, 1084, 3882, 2034, 3669,  844,  736,  815, 1610, 3091, 1543,   62,
        2879,  308,  108, 1497])
Epoch: 2033, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2034 - Batch 1 ########################
IDs in batch 1: tensor([2121, 3101, 1326, 3118, 1942, 3713,  681,  558, 1648, 2689, 2002, 4050,
        1413, 4149, 1755,   99])
Epoch: 2034, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2035 - Batch 1 ########################
IDs in batch 1: tensor([4016, 2115, 3338, 2331, 3846, 1495, 3500, 2116, 3858, 3182,  487, 2291,
        4127, 2597, 2885, 2213])
Epoch: 2035, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2036 - Batch 1 ########################
IDs in batch 1: tensor([2581,  717, 2250, 1231, 1176, 1279, 4015, 4223, 1256,  308, 1229, 2180,
        1618,  897, 2938, 4149])
Epoch: 2036, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2037 - Batch 1 ########################
IDs in batch 1: tensor([2772, 2551,  387,  360, 3022, 3964,  968, 1232, 4253, 2516, 3577, 3718,
         794, 3142,  130, 4031])
Epoch: 2037, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2038 - Batch 1 ########################
IDs in batch 1: tensor([1777,  518, 3021, 3738, 1120, 1039, 1414, 3326,  541, 1974, 3336, 1497,
        3897, 1731, 1104,  337])
Epoch: 2038, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2039 - Batch 1 ########################
IDs in batch 1: tensor([2483,  394, 3689, 3389, 1321, 2548, 2255, 4158, 2712, 2617, 1502,  503,
        1349,  992,  184, 3157])
Epoch: 2039, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2040 - Batch 1 ########################
IDs in batch 1: tensor([3506,  593, 2343, 2732,  681, 1751, 3185,  603, 2841, 3436, 2796, 3711,
        1167, 2765, 1690, 2377])
Epoch: 2040, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2041 - Batch 1 ########################
IDs in batch 1: tensor([3178,  747, 1497,  712, 2026,  341,  988, 3783,  786, 2331, 3287, 1913,
        2578, 3398, 3391, 2217])
Epoch: 2041, Training Loss: 0.30, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 2042 - Batch 1 ########################
IDs in batch 1: tensor([2204, 3443, 3028, 3674, 1034, 1318, 3518, 2014,  308, 3265, 1763, 1934,
        1495, 1193, 1198, 2606])
Epoch: 2042, Training Loss: 0.10, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 2043 - Batch 1 ########################
IDs in batch 1: tensor([3091, 4037, 3113, 3002,  556, 1007, 1060,  318,  177, 2815, 2148,  820,
        2746,  217, 2860, 1281])
Epoch: 2043, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.72
######################## Epoch 2044 - Batch 1 ########################
IDs in batch 1: tensor([3309, 2405,  894, 4213, 2509, 3024, 1495, 2124,  398, 4173, 2755,   50,
        1982,  811, 2969, 4122])
Epoch: 2044, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2045 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 2780,  384, 3673, 1020, 1177,  685, 1406, 3072, 1167,   64, 3616,
        3051, 1124, 2274, 2511])
Epoch: 2045, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2046 - Batch 1 ########################
IDs in batch 1: tensor([ 667, 1982,  756, 1075, 2436, 1938, 3351, 2797,  140, 3438, 3188, 2276,
        3242, 1232, 2526, 1559])
Epoch: 2046, Training Loss: 0.41, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2047 - Batch 1 ########################
IDs in batch 1: tensor([1399,  205,   99, 2726, 3216, 3598, 3317, 3271, 3208,   99, 1224, 3839,
        2350, 1825, 1066, 1761])
Epoch: 2047, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2048 - Batch 1 ########################
IDs in batch 1: tensor([2476, 2836, 2835,  534, 1050, 3303, 3282, 2439, 3447,  788,  863, 1456,
        1562, 4048, 3650, 3360])
Epoch: 2048, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2049 - Batch 1 ########################
IDs in batch 1: tensor([2234,  976, 1649, 1432,  228, 3119, 1679, 1399, 2370, 3047, 4125,  976,
        2229, 3948, 1418, 1233])
Epoch: 2049, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2050 - Batch 1 ########################
IDs in batch 1: tensor([ 584, 2632, 3952, 2589, 1157, 1241, 2250, 3896,  359, 2710, 1072, 3119,
        1993, 1571, 3421, 3785])
Epoch: 2050, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2051 - Batch 1 ########################
IDs in batch 1: tensor([3364, 3286, 2456, 3327, 2459, 1200,  513, 1821, 1219, 2598, 2536,  113,
        2104,   14, 1439, 1521])
Epoch: 2051, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2052 - Batch 1 ########################
IDs in batch 1: tensor([2459, 2546, 4060, 2074, 2052, 3876, 3952, 3483, 3753, 4073,  465, 4093,
        2379,  530, 1351, 2614])
Epoch: 2052, Training Loss: 0.53, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2053 - Batch 1 ########################
IDs in batch 1: tensor([3144, 1956, 3074, 1197, 1502, 3020,  512, 2872, 4078,  226,  574,  387,
        1088, 1220,  185, 3780])
Epoch: 2053, Training Loss: 0.48, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2054 - Batch 1 ########################
IDs in batch 1: tensor([4161,  545, 3749, 3728, 2127, 1595, 3075, 1393, 4080,  190,  977,  756,
        4120, 3211,  839,  424])
Epoch: 2054, Training Loss: 0.48, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 2055 - Batch 1 ########################
IDs in batch 1: tensor([ 797,   98, 4158,  281, 3421, 1660, 1665, 3650,  978, 1732, 1611, 2275,
        1065, 3458, 2964,   95])
Epoch: 2055, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2056 - Batch 1 ########################
IDs in batch 1: tensor([1390,  942, 4213, 3972, 2237, 3052, 2467,  145, 1952, 3999,  401, 2965,
         735, 1568, 3313, 2724])
Epoch: 2056, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.69
######################## Epoch 2057 - Batch 1 ########################
IDs in batch 1: tensor([2970,  694,  494, 2980, 3277, 2170, 3702, 2031, 3845, 3190,   38, 1393,
        2146, 2485,  841, 1270])
Epoch: 2057, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2058 - Batch 1 ########################
IDs in batch 1: tensor([2592,  547, 2791, 3218, 2767, 3972, 3803, 2173, 1448,  790, 2845,  164,
        1139, 3511, 3528, 1004])
Epoch: 2058, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2059 - Batch 1 ########################
IDs in batch 1: tensor([3821,  194,  769, 2132, 1289, 1879,  833, 4062,  855, 3790, 2370, 1318,
        3527, 2942, 1425, 2974])
Epoch: 2059, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2060 - Batch 1 ########################
IDs in batch 1: tensor([2620, 2494, 2564, 2838,  732,  879, 1971, 4051, 2897, 1022, 3117, 4204,
        2998, 1360,  824, 1440])
Epoch: 2060, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2061 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 3072, 1685, 2733,   70, 1352, 1722, 2743, 1321, 2758,  555, 3057,
        2693, 3447, 1375, 2482])
Epoch: 2061, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2062 - Batch 1 ########################
IDs in batch 1: tensor([1081,  569, 1090, 1271,  590,  426, 3885, 1380, 3994,  111, 3376, 2237,
        3075, 2241, 3257, 1612])
Epoch: 2062, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2063 - Batch 1 ########################
IDs in batch 1: tensor([ 779,  710,  281, 3594,   93, 1471, 3680, 1370, 3336, 3005,  981, 3530,
         969,  526, 2415, 3795])
Epoch: 2063, Training Loss: 0.17, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2064 - Batch 1 ########################
IDs in batch 1: tensor([4039, 3327, 3786,  186, 2146, 1153, 1914, 1197,  866,  827, 1311, 2752,
         914,  219, 1042,    5])
Epoch: 2064, Training Loss: 0.39, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2065 - Batch 1 ########################
IDs in batch 1: tensor([4176, 1724,  855, 3058, 4133, 2680, 1278, 2780, 3193, 1618, 1733, 3837,
        2237, 2320, 3963,  944])
Epoch: 2065, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2066 - Batch 1 ########################
IDs in batch 1: tensor([1784,  723, 1096, 2264, 2185, 1374,  790, 3127, 2009, 3354, 1821, 3975,
        4099,  344, 2036, 2226])
Epoch: 2066, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2067 - Batch 1 ########################
IDs in batch 1: tensor([3600, 3879, 1396, 2936, 2362, 2789, 1320, 4240, 1442, 4005, 1219, 3485,
        4196, 3975,   61, 2760])
Epoch: 2067, Training Loss: 0.52, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2068 - Batch 1 ########################
IDs in batch 1: tensor([1196, 1970, 1351, 2035, 2382, 1333, 1869, 1575,  183, 2942, 3962, 2366,
        1291, 1098, 1201, 2899])
Epoch: 2068, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2069 - Batch 1 ########################
IDs in batch 1: tensor([1765, 2627,  150, 1185, 2431, 1656, 2327, 2924, 2449, 1242, 2023, 1677,
        2487, 2663, 2934, 4214])
Epoch: 2069, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2070 - Batch 1 ########################
IDs in batch 1: tensor([2538, 2134, 2151, 1090, 2290,  649, 1600,  735,  942, 1201, 2653, 3463,
        3953, 1558, 3526,   95])
Epoch: 2070, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2071 - Batch 1 ########################
IDs in batch 1: tensor([3530, 3168, 3947,  704, 1443, 1038, 2858,  718, 2748, 2464, 1970, 2866,
        3029, 1841,  943, 1059])
Epoch: 2071, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2072 - Batch 1 ########################
IDs in batch 1: tensor([3913, 1294, 2968,  337, 2346,  427, 3721, 2725, 3265, 3594, 1960, 4214,
        1026, 1044, 4185,  848])
Epoch: 2072, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2073 - Batch 1 ########################
IDs in batch 1: tensor([1824, 2347,  198, 2642, 1956,  821, 1341,  494,  693, 3254, 1066, 2073,
        3304, 1360, 2465, 2772])
Epoch: 2073, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2074 - Batch 1 ########################
IDs in batch 1: tensor([4229, 3023,  924,  969, 2111, 2942,  200, 3568, 2391, 3221, 3837, 3664,
        2242, 1445, 2497, 1225])
Epoch: 2074, Training Loss: 0.55, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2075 - Batch 1 ########################
IDs in batch 1: tensor([4084, 3084,    7, 3963, 4258, 2564, 1967, 3886, 1139,  950,  226,  289,
          41, 3980,  920,  497])
Epoch: 2075, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2076 - Batch 1 ########################
IDs in batch 1: tensor([1954,  362,   27, 1786, 1911, 1524, 1959, 2282, 1159, 1214,  160, 2575,
        1173, 2254,  485, 3245])
Epoch: 2076, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2077 - Batch 1 ########################
IDs in batch 1: tensor([4017, 3494, 1346, 3245, 3608, 2627, 2131,  733, 1726, 1507, 3028, 1632,
         886, 3997, 2383, 1775])
Epoch: 2077, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 2078 - Batch 1 ########################
IDs in batch 1: tensor([1994,  193, 3418, 2065, 3373, 1636,  456, 2965, 3943, 3803, 3313, 3701,
         218,  950, 2356, 3081])
Epoch: 2078, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 2079 - Batch 1 ########################
IDs in batch 1: tensor([ 354, 3838, 4139, 1011, 4014, 1498, 3543, 3246, 2030, 3599,  632, 3896,
        1524, 2791,  463,   13])
Epoch: 2079, Training Loss: 0.54, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2080 - Batch 1 ########################
IDs in batch 1: tensor([1333, 1590, 1141, 3440, 1415, 2431, 1699, 1316, 3734, 3533, 2980, 4078,
        3714, 2455,  881, 3120])
Epoch: 2080, Training Loss: 0.43, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 2081 - Batch 1 ########################
IDs in batch 1: tensor([2304, 2324, 3490, 2348,  448, 4139, 3746, 2205, 1977, 3638, 1204, 4235,
          27, 2629, 2087,  805])
Epoch: 2081, Training Loss: 0.36, Validation Loss: 0.78, accuracy = 0.68
######################## Epoch 2082 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 2231, 2415, 3037,  743, 4061, 4242, 1308, 2836,  729,   97,  583,
         870, 1420, 1108, 2810])
Epoch: 2082, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.67
######################## Epoch 2083 - Batch 1 ########################
IDs in batch 1: tensor([1356, 1266,  976, 1155, 2789,  962, 2767, 2763, 3421, 2420, 1883, 1660,
        1195,  147, 1892, 3504])
Epoch: 2083, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.66
######################## Epoch 2084 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 2322,  212, 1700, 2781,  139,  411,  379, 4242, 1779, 3504, 3950,
        2758, 3874, 3398, 1275])
Epoch: 2084, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.66
######################## Epoch 2085 - Batch 1 ########################
IDs in batch 1: tensor([ 407, 2352, 3472,  850,  596, 3150, 1918, 3272,   27, 2453,  968, 2485,
        1746, 2137, 2795,  177])
Epoch: 2085, Training Loss: 0.30, Validation Loss: 0.85, accuracy = 0.65
######################## Epoch 2086 - Batch 1 ########################
IDs in batch 1: tensor([1322,  961, 2866, 2621, 1443, 1434, 2444, 2600,  518, 4126, 1661,  610,
        4163, 4255, 3747, 3552])
Epoch: 2086, Training Loss: 0.36, Validation Loss: 0.83, accuracy = 0.66
######################## Epoch 2087 - Batch 1 ########################
IDs in batch 1: tensor([3513,  960, 2795,  762, 1558, 4205,  482, 1681,  606, 1133, 2851, 3094,
        3650, 4057, 3521,  955])
Epoch: 2087, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.66
######################## Epoch 2088 - Batch 1 ########################
IDs in batch 1: tensor([2600, 1271, 1745, 1530, 2343,  469, 2710, 1583, 2487, 3553,  578, 1625,
         152, 3105, 1732, 3275])
Epoch: 2088, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.67
######################## Epoch 2089 - Batch 1 ########################
IDs in batch 1: tensor([2114,  657, 1302, 3091, 4075, 3509, 2060, 3206, 2614, 2739,  808, 1942,
        1932, 2815, 2541,  251])
Epoch: 2089, Training Loss: 0.44, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2090 - Batch 1 ########################
IDs in batch 1: tensor([2081, 2812,   84, 1636, 2432,  635, 2652,  730, 4048,  424, 1921, 3128,
        3552, 2003,  848, 4255])
Epoch: 2090, Training Loss: 0.28, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2091 - Batch 1 ########################
IDs in batch 1: tensor([2323, 4264, 1981, 2134, 4022,  796, 2196,  781, 3334, 3949, 2051, 1176,
        4126, 1951, 4070, 2467])
Epoch: 2091, Training Loss: 0.93, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2092 - Batch 1 ########################
IDs in batch 1: tensor([3339,  217, 4180, 1418, 3321, 3257, 4006, 1273, 2231,   92, 1512,  982,
        1766,  136,  398, 4017])
Epoch: 2092, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2093 - Batch 1 ########################
IDs in batch 1: tensor([2522, 3863, 4181, 3718, 3696,  194, 1585, 2575, 3866, 3300, 3471, 1891,
        2437, 1566,  326, 1146])
Epoch: 2093, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2094 - Batch 1 ########################
IDs in batch 1: tensor([2868, 2051, 2964,  813,   61,  356, 3308, 2010, 3112, 3219, 3443, 3747,
         407, 3114, 3533, 2005])
Epoch: 2094, Training Loss: 0.42, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2095 - Batch 1 ########################
IDs in batch 1: tensor([1802,  134, 2008,   43, 3621, 4135, 1756, 2748, 1933, 2276, 3156, 2667,
        3226, 2400, 2721, 1947])
Epoch: 2095, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2096 - Batch 1 ########################
IDs in batch 1: tensor([2426, 4268, 3543,  753,   46, 4031, 2223, 1945, 4267, 3734, 1312, 3919,
         398, 1518,  949, 1682])
Epoch: 2096, Training Loss: 0.32, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2097 - Batch 1 ########################
IDs in batch 1: tensor([1225, 3227, 3452,  379, 2465,  884, 2617, 2505,  869, 3715,  256, 2126,
        1213, 3771, 1204, 4170])
Epoch: 2097, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2098 - Batch 1 ########################
IDs in batch 1: tensor([2869, 1971, 2120, 1426,  864,  839, 2183,  672,  512,  281, 2882, 1623,
         790,  417, 1914, 2360])
Epoch: 2098, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2099 - Batch 1 ########################
IDs in batch 1: tensor([ 963, 2117, 3044,  595, 3152,  557, 1747,   64,  593, 1328, 1548,  967,
        2347, 3443, 4174, 1991])
Epoch: 2099, Training Loss: 0.44, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2100 - Batch 1 ########################
IDs in batch 1: tensor([2963, 4166, 1174,  871, 1511,  950, 1658, 4165,  348, 2996, 2420,  637,
        4032, 3406, 2141, 2086])
Epoch: 2100, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2101 - Batch 1 ########################
IDs in batch 1: tensor([1882,  736,  738,  733, 1139, 2597, 1770, 2874, 3643,  255,  594, 1177,
        2754, 4077, 1247,  727])
Epoch: 2101, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2102 - Batch 1 ########################
IDs in batch 1: tensor([3035, 2661, 3211,  926, 1266, 2559, 3876, 3883, 3102,  258,   46, 3608,
        1147,  363, 2050,  851])
Epoch: 2102, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2103 - Batch 1 ########################
IDs in batch 1: tensor([  37, 1480,   31, 3705, 2582, 1281, 1294,  126, 3700,  467, 1333, 1693,
        3299,  785, 2405, 3162])
Epoch: 2103, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2104 - Batch 1 ########################
IDs in batch 1: tensor([2945, 2064,  613, 2504,  666,  145, 2480,  281, 3208, 1028, 1139, 1779,
        3833, 1132, 2276,   88])
Epoch: 2104, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2105 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 1334,  991, 2886, 2980,  887,  109, 1027, 1024, 1297, 3998,  520,
        3543,  555, 1700, 1620])
Epoch: 2105, Training Loss: 0.58, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2106 - Batch 1 ########################
IDs in batch 1: tensor([3271, 1234, 1255, 4011, 3147, 3252,  681, 1263,  953, 2069, 2868,  814,
        2961, 1354, 2151, 2338])
Epoch: 2106, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2107 - Batch 1 ########################
IDs in batch 1: tensor([3112, 1884, 2313,  205, 4190, 3176,  239, 2473,  626, 2291,  660, 4046,
        3094, 1155, 1285, 3757])
Epoch: 2107, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2108 - Batch 1 ########################
IDs in batch 1: tensor([3406,  818, 2506,  676, 4213, 1239,  183, 2046, 3970, 1563,  183,  401,
        1344,  206, 1158, 3588])
Epoch: 2108, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2109 - Batch 1 ########################
IDs in batch 1: tensor([3598, 2246, 1399, 3157, 2323, 2926, 2002, 4067, 1056, 1347, 3936,  342,
        3938, 3869, 3099, 4050])
Epoch: 2109, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2110 - Batch 1 ########################
IDs in batch 1: tensor([1257, 3928, 1823, 1248,  636, 1126, 2225, 2339, 2385,  422, 1642, 3896,
        2258, 2181, 1042,  819])
Epoch: 2110, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2111 - Batch 1 ########################
IDs in batch 1: tensor([3156, 1724,  756,  127, 3202, 3541,   78, 3780, 1931,  578, 1053, 1473,
         255, 3308, 2742, 1140])
Epoch: 2111, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2112 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 4263, 3150,   92, 3435, 1050, 2738, 3891,   97, 2232, 2153,  750,
        3786, 1904,  326,  770])
Epoch: 2112, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2113 - Batch 1 ########################
IDs in batch 1: tensor([2743, 3004, 3921,  312, 1072, 2390, 3727, 3715, 3425,  155, 2724, 3343,
        1626, 3795, 3792, 2085])
Epoch: 2113, Training Loss: 0.23, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2114 - Batch 1 ########################
IDs in batch 1: tensor([2343, 3704, 2564, 2016, 3900, 3444, 3208, 2646, 1836, 3659,  112, 1799,
        2915, 1773, 2827, 2752])
Epoch: 2114, Training Loss: 0.61, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2115 - Batch 1 ########################
IDs in batch 1: tensor([2254,  437, 1250, 4245, 3950, 3077, 3992, 1239,  524, 2455, 2912, 3238,
        3136, 3275, 3113,  593])
Epoch: 2115, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2116 - Batch 1 ########################
IDs in batch 1: tensor([3511, 4017, 3869, 3144, 2452,   71, 1737,  956, 2019,  145, 3120, 1051,
        3151, 3837, 1956,  391])
Epoch: 2116, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2117 - Batch 1 ########################
IDs in batch 1: tensor([2463, 1118, 3961, 2329, 3337, 2535, 1341, 3549,  444, 3681, 1231, 1092,
         470, 3714, 4255,  411])
Epoch: 2117, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2118 - Batch 1 ########################
IDs in batch 1: tensor([1039, 1061, 3148, 1284,   56, 1453, 2069, 2092, 1219, 2255,  848, 1881,
        3444, 1171, 2173, 2908])
Epoch: 2118, Training Loss: 0.31, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2119 - Batch 1 ########################
IDs in batch 1: tensor([  31, 1573,  942,  342,  354,  894, 3016,   27, 3275,  346,   24, 1968,
         220, 2746,  182, 1372])
Epoch: 2119, Training Loss: 0.42, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2120 - Batch 1 ########################
IDs in batch 1: tensor([4031, 2825, 3938, 4062,  523, 3895, 2232, 2103, 3083, 3755, 3883, 4072,
        2627,  657, 2578, 1592])
Epoch: 2120, Training Loss: 0.39, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2121 - Batch 1 ########################
IDs in batch 1: tensor([2306,  822,  437, 1772, 2805,  284,  256, 1707, 3060, 2019, 3553, 3516,
        3632,   60, 4013,  139])
Epoch: 2121, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2122 - Batch 1 ########################
IDs in batch 1: tensor([1569,  954,  408, 2937, 3654, 3963, 1931, 3541, 4070,  321,  185, 4185,
        1438, 2680, 3139, 1510])
Epoch: 2122, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2123 - Batch 1 ########################
IDs in batch 1: tensor([2897,   11, 3651, 3111, 2400, 1680,  875, 2008,  219, 2172,  316,  846,
        1835, 1310, 2161, 2300])
Epoch: 2123, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2124 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 1222, 1103, 2822, 3974, 1470, 4107, 3253,  437,  171,  844,   50,
        3271, 2412, 1896, 2957])
Epoch: 2124, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2125 - Batch 1 ########################
IDs in batch 1: tensor([ 277, 1060, 1626, 2620, 1200, 1445, 1084,  721, 3945, 3071,  949, 2039,
        3321, 4025,  625, 3367])
Epoch: 2125, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2126 - Batch 1 ########################
IDs in batch 1: tensor([3042, 2949, 2615, 1882, 3897, 3886, 1803, 1954, 2890, 1341,  101, 2277,
        2824, 3470, 3829, 1569])
Epoch: 2126, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2127 - Batch 1 ########################
IDs in batch 1: tensor([2230, 2309, 3015, 3451,  680, 1001, 4069,  753,  658, 2703, 3709, 3465,
        3998, 2954, 1712, 4080])
Epoch: 2127, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2128 - Batch 1 ########################
IDs in batch 1: tensor([2219, 2990, 1746,  750,  333, 1643, 4032, 1143, 4131, 3911, 3975, 1834,
        1273,  603,  617, 2296])
Epoch: 2128, Training Loss: 0.32, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2129 - Batch 1 ########################
IDs in batch 1: tensor([3487,  575,  422, 1111,   93, 3055, 2241, 1895, 3615, 3079, 3428, 2241,
        3712, 3259, 3275, 2431])
Epoch: 2129, Training Loss: 0.48, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2130 - Batch 1 ########################
IDs in batch 1: tensor([ 766, 1518,   60, 3744,   19, 1199, 2367, 3829, 2857,  489, 3345,  481,
        2572, 2155,  397,  934])
Epoch: 2130, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2131 - Batch 1 ########################
IDs in batch 1: tensor([4181,  112, 3569,  843, 3675, 2610,   34, 2683, 1677, 3927, 1097, 1080,
        3438, 3872, 1393,  365])
Epoch: 2131, Training Loss: 0.43, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2132 - Batch 1 ########################
IDs in batch 1: tensor([2627,   93, 2568,  595,  656, 2879, 1811, 1932, 1257, 3047, 2455, 2506,
        3536,  199, 3010, 3181])
Epoch: 2132, Training Loss: 0.45, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2133 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 3655, 1247, 2276, 4061, 1686,  813, 3226, 1599, 3650, 3552, 3545,
         740, 1860, 2295, 1536])
Epoch: 2133, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2134 - Batch 1 ########################
IDs in batch 1: tensor([1842, 2026,  255, 1632, 2600, 4009, 2775, 2249, 4003, 3002, 2867, 3072,
        2344,  226, 4015, 1147])
Epoch: 2134, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2135 - Batch 1 ########################
IDs in batch 1: tensor([1450,  936, 1734, 4095, 2487, 1133, 2279, 2297,  108, 3161, 3505, 4263,
        3202, 1756, 2134, 4254])
Epoch: 2135, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2136 - Batch 1 ########################
IDs in batch 1: tensor([  50, 4215, 1963, 2413, 1065,  558, 1445,  136, 2902, 2934, 3532,  292,
        3674, 3655, 3221,  962])
Epoch: 2136, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2137 - Batch 1 ########################
IDs in batch 1: tensor([3993,  547,  653, 4049, 2133, 3017, 1521, 2687, 2629,  265, 1281, 2111,
        1499, 1291, 1588, 1830])
Epoch: 2137, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2138 - Batch 1 ########################
IDs in batch 1: tensor([3663,  596, 1408, 4254, 2156, 2256,   11, 3220, 3496, 4117, 2901, 3058,
         689,  391, 2478, 1624])
Epoch: 2138, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2139 - Batch 1 ########################
IDs in batch 1: tensor([ 451,  357,  239, 1754,  469, 3529, 4134, 4096, 2809, 3379, 2015, 4049,
          77,  340,  974,  652])
Epoch: 2139, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2140 - Batch 1 ########################
IDs in batch 1: tensor([2578,  303, 3147, 2907,  921, 2251, 2492, 2505, 1212, 2828, 2063, 1499,
        4268,  774, 1904, 1860])
Epoch: 2140, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2141 - Batch 1 ########################
IDs in batch 1: tensor([1634, 3194, 2494, 1012, 1530, 2064, 3374, 2134,  554, 1478,  766, 1842,
        2246,  203,  426,  943])
Epoch: 2141, Training Loss: 0.49, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2142 - Batch 1 ########################
IDs in batch 1: tensor([2202, 3111,  796,  632, 3219, 1592, 3746, 1994,  673, 2996, 4015, 1959,
        1146, 4268, 1144, 2472])
Epoch: 2142, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2143 - Batch 1 ########################
IDs in batch 1: tensor([2375,  418, 3180,  514, 2035,  259, 3643,   73, 1770, 3486, 3696, 3009,
         735,  351, 3427,  472])
Epoch: 2143, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2144 - Batch 1 ########################
IDs in batch 1: tensor([1088,  218,  966, 2514, 3644,   96, 3712, 2442,  750,   44,  260, 2855,
         869, 2157, 3329,  467])
Epoch: 2144, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2145 - Batch 1 ########################
IDs in batch 1: tensor([1031,  693,  740, 3551, 1630, 1123, 3480,   39,   10,   62, 2802,  217,
        4268, 3345,  978, 2765])
Epoch: 2145, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2146 - Batch 1 ########################
IDs in batch 1: tensor([3866,  807, 1365, 1061, 2726, 3330, 3954, 2771, 1291,  524, 2664, 2646,
        3834, 2730, 3710, 1519])
Epoch: 2146, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2147 - Batch 1 ########################
IDs in batch 1: tensor([4226, 1657, 2571, 1107, 3021, 1730, 2462, 2687, 1894, 3732, 2932,  276,
        1767, 2102, 3379,  342])
Epoch: 2147, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2148 - Batch 1 ########################
IDs in batch 1: tensor([2377,  947, 2599, 1156, 4003, 2856,  871, 1904, 3475, 3787, 4141, 4200,
        3822, 4117, 3598, 3342])
Epoch: 2148, Training Loss: 0.71, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2149 - Batch 1 ########################
IDs in batch 1: tensor([ 357,  835, 1526,  217,  482, 3161, 1737,  121, 1913, 3255, 2763, 2771,
        4010, 2902, 2796,  660])
Epoch: 2149, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2150 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 1896, 3523, 3035,  232, 1567, 3206, 3345, 3610,  662, 3291,   15,
        3124, 2582, 2835,  417])
Epoch: 2150, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2151 - Batch 1 ########################
IDs in batch 1: tensor([2914, 3378, 1611, 2603, 3022, 1098, 1740, 2180, 1562, 3947, 2498,  757,
        3852, 2004, 2161, 3705])
Epoch: 2151, Training Loss: 0.34, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2152 - Batch 1 ########################
IDs in batch 1: tensor([ 841,  835,   93, 1310, 4075, 3982, 2470, 2088, 1899,  218, 3945, 1056,
        1294,  947, 2155, 2680])
Epoch: 2152, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2153 - Batch 1 ########################
IDs in batch 1: tensor([3448, 2729, 2800, 2030, 4158,  199, 3762, 2897, 2045, 1984, 2159, 1284,
          81, 4008, 2477, 1337])
Epoch: 2153, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2154 - Batch 1 ########################
IDs in batch 1: tensor([ 849, 1704, 3637, 1770, 1543, 3853, 1765, 1287, 1363,  355,  909, 2755,
         436, 1331,   82,  449])
Epoch: 2154, Training Loss: 0.62, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2155 - Batch 1 ########################
IDs in batch 1: tensor([1861,  134,  635, 2462,  789, 1252,   24, 1518, 3850, 4006, 1811, 1454,
        3228, 3031, 4121, 2035])
Epoch: 2155, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2156 - Batch 1 ########################
IDs in batch 1: tensor([ 445,  148, 3459, 3702, 3652, 3812, 4136, 2539, 2915, 2577,  262, 2739,
        3771,  247, 2671, 1089])
Epoch: 2156, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2157 - Batch 1 ########################
IDs in batch 1: tensor([4144, 3983, 2228, 2860,  718, 3139,   71, 1488, 3278, 1640, 3933,  384,
         375, 2644, 1266, 3222])
Epoch: 2157, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2158 - Batch 1 ########################
IDs in batch 1: tensor([3257,  409, 2342, 1049, 1275, 2028,  573,  635, 2872, 3904, 1559,  120,
        1590, 2807, 1602, 3516])
Epoch: 2158, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2159 - Batch 1 ########################
IDs in batch 1: tensor([ 400, 3949, 2524, 1546, 1952, 1196,  578, 2799, 1206, 1418, 4117, 1102,
        3862, 2458, 3947, 2401])
Epoch: 2159, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2160 - Batch 1 ########################
IDs in batch 1: tensor([3321, 2327, 1072, 2863,  128, 2666, 1001, 1663, 3675, 2536, 1372, 1823,
        3214, 2462,  159, 1661])
Epoch: 2160, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2161 - Batch 1 ########################
IDs in batch 1: tensor([2954, 3394,  921,  994, 1885, 3468, 1984, 3417,  199, 2407, 1504, 1762,
        2150, 3557, 1136, 2235])
Epoch: 2161, Training Loss: 0.26, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2162 - Batch 1 ########################
IDs in batch 1: tensor([2447, 1498,  269, 1266, 2202,  626, 2135, 2729,  726, 3718, 4095,  556,
        3518, 2840, 3119, 3444])
Epoch: 2162, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2163 - Batch 1 ########################
IDs in batch 1: tensor([1892, 1321,  181, 1252, 2555,  134, 3610, 1910, 3822, 1367, 3190,  108,
        2529, 2436,  276, 2253])
Epoch: 2163, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2164 - Batch 1 ########################
IDs in batch 1: tensor([4026, 3810, 1390, 1197,  659, 3786,  976,   95, 1225,  539,  517, 2882,
        1945, 1602, 1675, 4058])
Epoch: 2164, Training Loss: 0.77, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2165 - Batch 1 ########################
IDs in batch 1: tensor([1016,  477, 2432,   59, 1883, 1812, 3058, 1295, 3354, 3430, 2276, 2256,
         199, 3226, 1882, 3676])
Epoch: 2165, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2166 - Batch 1 ########################
IDs in batch 1: tensor([3467, 3257,  987, 1810, 3738, 4060, 1365, 2256, 3895, 3581, 3782, 1045,
         245,  862,  797,   74])
Epoch: 2166, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 2167 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 2462, 3669,  652, 2376, 2376, 3377, 3113, 1763, 2241, 3891, 1107,
        2810, 2171, 3989,  199])
Epoch: 2167, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.70
######################## Epoch 2168 - Batch 1 ########################
IDs in batch 1: tensor([2804,  214, 3339, 1061, 3381, 2401, 3183,  290,  529, 3369,  855, 1712,
        3053,  749,  689, 3865])
Epoch: 2168, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.71
######################## Epoch 2169 - Batch 1 ########################
IDs in batch 1: tensor([2550, 2328,  617,  923, 2479, 2902, 3078, 2551, 3988, 1383, 3417,  547,
        3030, 1278, 1287, 4128])
Epoch: 2169, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2170 - Batch 1 ########################
IDs in batch 1: tensor([4088,  774, 3674,  788, 2245, 1988, 2379, 1272,  936, 3157, 2537, 3448,
         693, 1567, 1562, 3532])
Epoch: 2170, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.70
######################## Epoch 2171 - Batch 1 ########################
IDs in batch 1: tensor([ 944, 3500, 3020, 1395, 3088, 2921, 1103, 3912, 3223,   20, 3643,  809,
        2559,  767, 3036, 2443])
Epoch: 2171, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2172 - Batch 1 ########################
IDs in batch 1: tensor([4008, 1726, 2853, 2687,  173,  376, 2806, 2558,  672, 3972, 3238, 1545,
         584, 1934,  324, 2927])
Epoch: 2172, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2173 - Batch 1 ########################
IDs in batch 1: tensor([3991, 1026, 1770, 3920, 1053,  645, 3659,  481, 2437, 3971,  321,    5,
        2045,  229,  583,  970])
Epoch: 2173, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2174 - Batch 1 ########################
IDs in batch 1: tensor([1381, 4238,  639, 2476, 1497, 4128, 2426, 3444, 1710, 4038, 2604, 3318,
        3409,  954, 3785,  188])
Epoch: 2174, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2175 - Batch 1 ########################
IDs in batch 1: tensor([4226, 1825, 1179,  724, 1517, 2565, 2742,  422, 2959,  501, 3156, 2052,
        3888,  886,  279, 1178])
Epoch: 2175, Training Loss: 0.31, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2176 - Batch 1 ########################
IDs in batch 1: tensor([1625, 1878, 2806,  691, 1467,  797,  203, 1122, 1442, 1225, 1853,  436,
        1993, 2724, 3763, 1832])
Epoch: 2176, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2177 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 3577,   99,  281, 3374,  923,  815, 3200,  483,  855, 3536, 2764,
        1959, 2668, 4010, 1310])
Epoch: 2177, Training Loss: 0.54, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2178 - Batch 1 ########################
IDs in batch 1: tensor([1374, 2555, 3401, 3023, 1096, 2494, 4107,  841,  961, 3244, 4049, 2851,
         652,  839, 3541, 4087])
Epoch: 2178, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2179 - Batch 1 ########################
IDs in batch 1: tensor([ 399, 2508, 1799, 3603, 1024, 1319, 3527, 1020, 3533, 2237, 3870, 3987,
         924, 1173, 4056, 4006])
Epoch: 2179, Training Loss: 0.57, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2180 - Batch 1 ########################
IDs in batch 1: tensor([ 408, 2711, 1024,  516, 1062, 1421, 2572, 1137,   71, 1305, 2809, 1425,
        1391, 1540, 3338, 1391])
Epoch: 2180, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2181 - Batch 1 ########################
IDs in batch 1: tensor([2511, 1690, 3300,  448,  778, 4118,  556, 2264, 3148,  258, 2982, 1073,
         459, 3180, 3418, 3234])
Epoch: 2181, Training Loss: 0.28, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2182 - Batch 1 ########################
IDs in batch 1: tensor([1938,  733, 1632, 3426, 3385, 2731, 1495, 1699, 3640, 1625, 1153, 2342,
        3091, 4199, 4075, 1670])
Epoch: 2182, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2183 - Batch 1 ########################
IDs in batch 1: tensor([2313, 3248, 3218, 3992, 3704, 1281, 1167, 3756,  992,  415, 3973, 3600,
        1551, 4253, 1096, 2428])
Epoch: 2183, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2184 - Batch 1 ########################
IDs in batch 1: tensor([1571, 3082, 1305, 2179, 3996,  251, 2476, 3373, 2278,  213, 4148, 1289,
        3190, 2643, 1673, 2135])
Epoch: 2184, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2185 - Batch 1 ########################
IDs in batch 1: tensor([3982, 2520, 1732, 2206, 2721,  628, 3908, 1333, 2742,  361,   25, 2483,
        2343, 1180, 1485, 1294])
Epoch: 2185, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2186 - Batch 1 ########################
IDs in batch 1: tensor([3813, 4199, 2868, 3951,  587,  921, 1258, 1221, 1311, 3334,  714,   43,
        1823, 1072, 3286, 2506])
Epoch: 2186, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2187 - Batch 1 ########################
IDs in batch 1: tensor([ 996, 1675, 1017, 2455,  694, 1257, 4200, 3476,  835,  452, 2764, 1357,
        2993, 1060, 3976,  555])
Epoch: 2187, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2188 - Batch 1 ########################
IDs in batch 1: tensor([3051,  305, 3746,  809, 2682,  203, 1445, 2111, 3719, 2574, 1530, 2902,
        1026,  568,   28, 2498])
Epoch: 2188, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2189 - Batch 1 ########################
IDs in batch 1: tensor([2687, 2278, 2113, 4057,  992, 2271, 2090,  554,  387, 1681,  125, 1498,
        1681, 3166, 2210, 1914])
Epoch: 2189, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2190 - Batch 1 ########################
IDs in batch 1: tensor([ 626,  363,  993,  730, 3692,  883, 2934, 1469, 1860, 1986, 3501,  730,
         290, 2098, 1478, 3002])
Epoch: 2190, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2191 - Batch 1 ########################
IDs in batch 1: tensor([2110,  959, 3718, 4125, 2067, 2049, 1096, 2770, 1236, 4115, 2074, 2383,
        1530, 2842, 2586,  718])
Epoch: 2191, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2192 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 3692, 4197, 2741,  891, 2247,  167, 3185, 3257, 4176, 2003,  450,
        1389, 1075, 3954,  623])
Epoch: 2192, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2193 - Batch 1 ########################
IDs in batch 1: tensor([1994, 3388, 1762, 2108, 2009, 3900, 2469, 1212,  517,  251, 3452, 1956,
        1881, 2661, 2388, 3988])
Epoch: 2193, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2194 - Batch 1 ########################
IDs in batch 1: tensor([4128, 2627, 1980, 3408, 2604, 2461, 1369,  361, 2264, 1753, 2341,  803,
        3961, 3846,  283, 1221])
Epoch: 2194, Training Loss: 0.40, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2195 - Batch 1 ########################
IDs in batch 1: tensor([1279, 1680, 1107, 1834, 1235, 4128, 2022, 4116, 2505, 2961, 2727,  362,
        2247,  302, 2176, 1128])
Epoch: 2195, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2196 - Batch 1 ########################
IDs in batch 1: tensor([2914, 3963,   60, 4033, 1585,  959, 1904, 1130, 2575, 2795, 1910, 2362,
        2993, 2855,  132, 2480])
Epoch: 2196, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2197 - Batch 1 ########################
IDs in batch 1: tensor([ 247,  466, 3190, 2112, 1639, 2689,  820, 1094, 4060, 2568, 1497, 1970,
        4128, 3933, 2670,  829])
Epoch: 2197, Training Loss: 0.16, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2198 - Batch 1 ########################
IDs in batch 1: tensor([2342,  226, 1289, 1324, 4235, 3547,  375, 2322, 1502, 3453, 3472,  757,
        1030,  750,  167,  184])
Epoch: 2198, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2199 - Batch 1 ########################
IDs in batch 1: tensor([2586, 2989,  913, 1175, 3286, 1961,  808, 3886, 1361, 1456,   41, 2443,
         918, 3333, 2450,  888])
Epoch: 2199, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.73
######################## Epoch 2200 - Batch 1 ########################
IDs in batch 1: tensor([ 481, 2025,  699, 4173, 2999,  137, 1953, 3935, 3535,   39, 1397, 4143,
         937,  103, 1628, 3162])
Epoch: 2200, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.72
######################## Epoch 2201 - Batch 1 ########################
IDs in batch 1: tensor([1540, 3714, 3203,  167,  594, 3988, 2059, 1168, 3902, 1620, 3599,  733,
        2479,  835, 3529, 1485])
Epoch: 2201, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2202 - Batch 1 ########################
IDs in batch 1: tensor([1955, 3148,  658, 1765, 3276,  180, 1543, 1900,  377, 1927,  325, 2890,
        1585, 3790,  110, 2883])
Epoch: 2202, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2203 - Batch 1 ########################
IDs in batch 1: tensor([2306, 3607, 3181,  717, 2284, 2155, 2378,  236,  439, 2925,  258, 3469,
         466,  753, 3092, 3991])
Epoch: 2203, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2204 - Batch 1 ########################
IDs in batch 1: tensor([1087, 3072, 3963, 3636, 2109, 3407, 2484,  482, 3183, 2823, 4198,  874,
         436,  870, 3435,  499])
Epoch: 2204, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2205 - Batch 1 ########################
IDs in batch 1: tensor([3506, 1066, 3932, 4131, 2452, 2193,  122, 1799, 1872, 1456, 4086, 2509,
         729,  774, 2458, 1260])
Epoch: 2205, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.72
######################## Epoch 2206 - Batch 1 ########################
IDs in batch 1: tensor([1418,   46, 4093,  167, 2854, 3082,  306, 2564, 2723, 1897, 2509,  797,
        2965, 2516, 2237, 2541])
Epoch: 2206, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2207 - Batch 1 ########################
IDs in batch 1: tensor([3745, 1405,  587, 2991,  129,  213,  936, 2120, 2086,  970, 4125, 2667,
        3677,  467, 3993, 3995])
Epoch: 2207, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2208 - Batch 1 ########################
IDs in batch 1: tensor([1764, 2452, 3985, 1851, 2365, 3377, 2137, 1030, 2110, 2109, 2676, 1053,
        1579, 3970, 1404, 3060])
Epoch: 2208, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2209 - Batch 1 ########################
IDs in batch 1: tensor([ 983, 1414, 1463, 1546, 2606,  593,  245, 1278, 2112,  275, 1810,  198,
        2245, 1909, 3154, 3786])
Epoch: 2209, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2210 - Batch 1 ########################
IDs in batch 1: tensor([ 463, 3505,  266, 3895, 1487, 4200, 3475, 3769, 2712, 2193, 3196, 1892,
        3159, 3447, 2196,  902])
Epoch: 2210, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2211 - Batch 1 ########################
IDs in batch 1: tensor([ 563, 2126, 2758, 4128, 2912, 2207, 2847, 3795,  767, 3875,  323, 3900,
        3323,  539,  112, 2244])
Epoch: 2211, Training Loss: 0.31, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2212 - Batch 1 ########################
IDs in batch 1: tensor([ 122, 2299, 2419, 1229,  476,  617, 3240,  907, 3707, 4093, 1286, 2866,
        2817, 1214, 2365, 3088])
Epoch: 2212, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2213 - Batch 1 ########################
IDs in batch 1: tensor([3238, 3927,  221, 3446, 2942, 3951, 1552, 2725, 2220, 3823, 4095, 1140,
        3753,   15, 3056, 1212])
Epoch: 2213, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2214 - Batch 1 ########################
IDs in batch 1: tensor([ 135, 1222, 1880, 2867, 2287, 3132, 3143, 1566,  326, 3949, 2343, 3948,
        3364, 4014, 3500, 3439])
Epoch: 2214, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2215 - Batch 1 ########################
IDs in batch 1: tensor([1284, 2098,  324,   81, 3235, 2482, 3279, 3902, 3987, 1501, 3400, 2313,
        1294, 3289, 1511, 1343])
Epoch: 2215, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2216 - Batch 1 ########################
IDs in batch 1: tensor([4204, 3492, 2359, 1419, 3392, 1282, 2132,  575, 1098,  489,  514,  582,
         572,  981,  751,  850])
Epoch: 2216, Training Loss: 0.41, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2217 - Batch 1 ########################
IDs in batch 1: tensor([1678,  680, 2144, 3744, 1061, 1495,  773, 4101,  422, 3535, 1224, 1007,
        3123, 2606, 1734, 2575])
Epoch: 2217, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2218 - Batch 1 ########################
IDs in batch 1: tensor([ 854,  988, 1471, 2506, 1723, 3146,  388,  277, 3878, 3275, 2966, 4224,
        3458,  409, 3544, 2895])
Epoch: 2218, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2219 - Batch 1 ########################
IDs in batch 1: tensor([3362, 1498, 1511,  484, 2279, 2832, 3553, 2284, 2148, 2111, 2508, 1716,
        3437,  896, 1044, 2292])
Epoch: 2219, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2220 - Batch 1 ########################
IDs in batch 1: tensor([ 333, 1782, 3672, 3071,  869, 1178, 2825, 3446, 2661, 4156, 1226, 2212,
        3143, 2236, 2192, 3810])
Epoch: 2220, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2221 - Batch 1 ########################
IDs in batch 1: tensor([2902, 2125,  680, 2825, 1849, 3618, 4013, 1841, 2132, 1591, 2873, 1685,
        3441, 2094, 1054,  108])
Epoch: 2221, Training Loss: 0.36, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2222 - Batch 1 ########################
IDs in batch 1: tensor([3200, 1133, 2738,  880,  949, 3197, 1085, 3994, 1482,  794,   11, 2661,
        1367, 3119, 3831, 3493])
Epoch: 2222, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2223 - Batch 1 ########################
IDs in batch 1: tensor([1835, 1357,  924, 1294,  207, 3352,   30,  314, 3441, 1208, 2088,  750,
         969,  274,  753, 2038])
Epoch: 2223, Training Loss: 0.34, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2224 - Batch 1 ########################
IDs in batch 1: tensor([2116,  741, 3465, 3886,  960, 2711, 3812, 3871, 3897, 2250, 4095, 2519,
        1256, 1500, 2170, 2014])
Epoch: 2224, Training Loss: 0.37, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2225 - Batch 1 ########################
IDs in batch 1: tensor([ 365, 2432,   26, 4036, 2464, 1385, 3467, 1604,  815, 4011, 3268,  129,
        2553,  575, 3190, 2775])
Epoch: 2225, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2226 - Batch 1 ########################
IDs in batch 1: tensor([2522,  193, 2189, 3608,  152, 2550, 1122,  492, 2980, 2063, 2876, 2859,
        1910,  778, 1222, 2451])
Epoch: 2226, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2227 - Batch 1 ########################
IDs in batch 1: tensor([1878, 2284, 3608, 1656, 2177, 1053, 3831, 1119, 1235, 4138,  733, 1599,
         591, 1975, 3092, 2542])
Epoch: 2227, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2228 - Batch 1 ########################
IDs in batch 1: tensor([1182, 2797, 1602, 1174, 1747, 1390, 3252, 2780,  128, 4235, 2464, 3537,
        1017, 3818,  627,  602])
Epoch: 2228, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2229 - Batch 1 ########################
IDs in batch 1: tensor([2795, 1050, 2272, 3852, 2403, 3777,  758, 3658, 3398, 1186, 1490, 2668,
        2847, 1712, 3141, 3632])
Epoch: 2229, Training Loss: 0.42, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2230 - Batch 1 ########################
IDs in batch 1: tensor([2784,  350, 1767, 3865, 2385, 4228, 2016, 3543, 2250, 1793, 2682, 2364,
         724, 2086, 3933, 3187])
Epoch: 2230, Training Loss: 0.35, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2231 - Batch 1 ########################
IDs in batch 1: tensor([ 256, 3421, 2028,  475, 2322, 2510, 3564, 1817,  535, 1070, 1167, 2824,
        3005, 2179, 2179, 3516])
Epoch: 2231, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2232 - Batch 1 ########################
IDs in batch 1: tensor([2604, 3994, 3529, 1459, 1385, 2041, 3621, 3928,  960, 3408, 3782,  986,
        2610, 3597,  180, 4086])
Epoch: 2232, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2233 - Batch 1 ########################
IDs in batch 1: tensor([3328, 3831,  556, 1037, 2895, 3873,  852, 1414, 4110, 1443, 4093,  701,
         843, 2505, 2291, 3312])
Epoch: 2233, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2234 - Batch 1 ########################
IDs in batch 1: tensor([1306,  582,  539, 2976, 1501, 4166, 3024, 2680,  685, 2461,  842, 2788,
         949, 3599, 2901, 1451])
Epoch: 2234, Training Loss: 0.30, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2235 - Batch 1 ########################
IDs in batch 1: tensor([2400, 2805, 1347, 3490, 3683, 3074, 4097, 1044, 3920, 1680, 2362, 3236,
        1626, 2290, 2437,  536])
Epoch: 2235, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2236 - Batch 1 ########################
IDs in batch 1: tensor([2407, 3157, 1571,  907, 2328,  762, 1994, 1365, 1102, 3108, 2597, 2014,
         874,  569, 2514,  190])
Epoch: 2236, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2237 - Batch 1 ########################
IDs in batch 1: tensor([ 872, 3082,  425,  497, 3845,  478, 1250, 3964, 3871, 2234, 2905, 1954,
        3772, 2844, 1113, 2176])
Epoch: 2237, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2238 - Batch 1 ########################
IDs in batch 1: tensor([1144, 1344, 1083,  572,  684, 1221, 3675, 1497, 2849, 1602, 3921, 3021,
        2027, 2621, 2838, 3211])
Epoch: 2238, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2239 - Batch 1 ########################
IDs in batch 1: tensor([4108,  503,  965, 4000, 2837, 4072,  368, 2470, 2614, 4184, 3467, 2965,
        2725, 4172, 2479, 1573])
Epoch: 2239, Training Loss: 0.37, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2240 - Batch 1 ########################
IDs in batch 1: tensor([1530, 2484, 2229,  848, 3183, 2902, 3265, 4121, 2255, 2224,  408, 2457,
        3973, 2537, 1344, 2577])
Epoch: 2240, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2241 - Batch 1 ########################
IDs in batch 1: tensor([1793, 3282, 2328,  334, 2448,  173, 3842, 2737, 2748, 4268, 2250,  430,
        4190,  926, 1005, 3529])
Epoch: 2241, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 2242 - Batch 1 ########################
IDs in batch 1: tensor([1780,  463, 4176,  794, 1617, 3976,  871,  721, 3715, 2011, 1124,  324,
         541, 3207, 3802, 1229])
Epoch: 2242, Training Loss: 0.33, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2243 - Batch 1 ########################
IDs in batch 1: tensor([1355, 2934, 2075, 3526, 4172, 1830, 1077, 2413, 1038,  627,  138, 2998,
        4258, 1879, 2182, 1784])
Epoch: 2243, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 2244 - Batch 1 ########################
IDs in batch 1: tensor([1330, 2563,   18, 1110, 1575,  639, 2425, 2334,  489,  469, 3847, 4095,
        1163, 2171, 2732, 4002])
Epoch: 2244, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2245 - Batch 1 ########################
IDs in batch 1: tensor([1252, 3160, 1365, 2847, 2444,  438, 2887, 2030, 4009,  513, 2499, 3870,
         660, 2113, 1054, 1632])
Epoch: 2245, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.69
######################## Epoch 2246 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 1324, 3055, 3121, 1951, 3400, 3826,  652, 1121, 2290,  478, 2544,
        2452, 2385, 3603,  190])
Epoch: 2246, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.69
######################## Epoch 2247 - Batch 1 ########################
IDs in batch 1: tensor([2529, 1956, 3919, 2791, 1212, 1710, 1087, 2425, 1432, 2394,  928, 2546,
        4197, 3542, 2815, 1512])
Epoch: 2247, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 2248 - Batch 1 ########################
IDs in batch 1: tensor([ 965,  490, 2249, 3443, 3342, 3985, 1798, 1833, 1914, 3368, 2078, 3373,
          25, 3917,  639,  388])
Epoch: 2248, Training Loss: 0.37, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 2249 - Batch 1 ########################
IDs in batch 1: tensor([2749,  588, 4055,   84, 3503,  870, 2387, 4058, 2379, 3336, 2942, 4168,
        1853, 1552, 2731, 2731])
Epoch: 2249, Training Loss: 0.29, Validation Loss: 0.77, accuracy = 0.68
######################## Epoch 2250 - Batch 1 ########################
IDs in batch 1: tensor([2771,  839, 1900, 2712,  109, 1273, 3907,  295, 4072, 1001, 2328,  602,
         418, 1363, 3376, 2122])
Epoch: 2250, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2251 - Batch 1 ########################
IDs in batch 1: tensor([1753, 1104,  101,  557, 2296, 2192, 1291, 3036, 2592,   98,  465,  749,
        2641, 1895, 3015, 3968])
Epoch: 2251, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2252 - Batch 1 ########################
IDs in batch 1: tensor([3601,  775, 3447,    5, 1921,  879, 1640, 3079, 1402, 3852,  279, 1375,
         483,  334, 2600, 2963])
Epoch: 2252, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2253 - Batch 1 ########################
IDs in batch 1: tensor([1487, 3999, 2708, 2223,  232, 1685,  448, 1779, 1712, 3181, 2098, 2357,
        3526,  200, 3298, 2789])
Epoch: 2253, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 2254 - Batch 1 ########################
IDs in batch 1: tensor([1525, 2347, 1269, 4242,   34, 4037, 1193, 3772, 3118, 2067, 4027,  701,
        2652, 1285, 3804, 1920])
Epoch: 2254, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2255 - Batch 1 ########################
IDs in batch 1: tensor([ 741, 3671, 1059, 3304, 2388,  397, 1525, 1196,  478, 3509, 3891,  173,
        1904, 4179, 3243, 3734])
Epoch: 2255, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2256 - Batch 1 ########################
IDs in batch 1: tensor([1229, 1731,   64, 3878, 3452,  321, 1855, 2599, 4198, 3945, 3386, 1878,
        4230,  977,  835, 1647])
Epoch: 2256, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2257 - Batch 1 ########################
IDs in batch 1: tensor([3767, 1932, 2352, 1506, 1731,  471, 2711, 1784, 1113,  333, 1023, 3460,
        2231, 2121, 3218, 2173])
Epoch: 2257, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2258 - Batch 1 ########################
IDs in batch 1: tensor([2938,  833, 3406, 1020, 2353, 1357, 4037, 1061, 2313, 1405,  173,  944,
        2060, 4236,  281,  507])
Epoch: 2258, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2259 - Batch 1 ########################
IDs in batch 1: tensor([2185, 2798,  797, 2805, 1237, 1677, 2313, 2595,  418, 3448, 1075, 1370,
        2497, 3563, 3117, 2426])
Epoch: 2259, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2260 - Batch 1 ########################
IDs in batch 1: tensor([2051, 1302, 2451, 4235, 1005, 2013, 3973,  471, 2229, 2828, 1213,  357,
        2180, 1567, 2019, 2141])
Epoch: 2260, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2261 - Batch 1 ########################
IDs in batch 1: tensor([1866,  183, 1555, 1493,  426, 3271, 1619,  185, 2415, 2493, 1030, 3208,
         874, 3963, 2725, 2099])
Epoch: 2261, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2262 - Batch 1 ########################
IDs in batch 1: tensor([3326, 3823, 4268, 3493, 1413, 2275, 2095,  275, 3865, 3036,  547,  510,
        1120, 2587, 3268, 2316])
Epoch: 2262, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2263 - Batch 1 ########################
IDs in batch 1: tensor([3275,  789, 1551, 1840, 3573, 3039, 3873, 2241, 3974, 3473, 3865, 3693,
         127, 1035, 3932,  701])
Epoch: 2263, Training Loss: 0.52, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2264 - Batch 1 ########################
IDs in batch 1: tensor([2091, 3831, 3956, 2745, 3360, 1646, 2081, 1124,  969, 1426, 3192, 1174,
        3166, 4119, 1937,  988])
Epoch: 2264, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2265 - Batch 1 ########################
IDs in batch 1: tensor([1728, 2431, 2913, 1524, 4110, 2653, 1451, 2649,  770, 4120, 3139,  755,
        1306,  943, 1421,  352])
Epoch: 2265, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2266 - Batch 1 ########################
IDs in batch 1: tensor([3311,  790, 2991, 1463,  959, 3859,  523, 1442, 1101, 4267, 1821,  338,
        4030, 3203, 2223, 2287])
Epoch: 2266, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2267 - Batch 1 ########################
IDs in batch 1: tensor([ 324,  804, 2876, 2234, 4110,  828, 2373,  108, 3136, 2009, 1391, 3480,
         538, 1008, 2176, 3843])
Epoch: 2267, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2268 - Batch 1 ########################
IDs in batch 1: tensor([1576, 4229, 3255,  532, 2742, 3220, 3406,  591, 1753, 1578, 3338,  604,
         813, 2632, 1934, 2097])
Epoch: 2268, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2269 - Batch 1 ########################
IDs in batch 1: tensor([3952, 3203, 3938, 1264, 3262, 3434, 2202,  185, 3874,  112,  953,  417,
        3660, 1712, 3581,  330])
Epoch: 2269, Training Loss: 0.40, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2270 - Batch 1 ########################
IDs in batch 1: tensor([ 470, 4075, 3661, 4223, 1611, 3190, 1341, 2788, 1498, 1970, 1054, 3452,
        3264, 3128, 2030, 1124])
Epoch: 2270, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2271 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2423, 1015, 1028,   95,  180,  342, 2188, 1124, 2856, 2272, 1209,
         487, 1878, 3446, 3141])
Epoch: 2271, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2272 - Batch 1 ########################
IDs in batch 1: tensor([3659, 3885, 3083, 1990, 2309, 2890, 1116,  849, 4152, 3912, 2315, 2388,
        3185,  985, 1116, 2341])
Epoch: 2272, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2273 - Batch 1 ########################
IDs in batch 1: tensor([1423, 1467,  937,  330,   15, 2723, 2399, 2668, 4197, 3905,  263,   21,
        3503, 3207, 2465, 4099])
Epoch: 2273, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2274 - Batch 1 ########################
IDs in batch 1: tensor([3590, 1762, 2354, 2874, 1857, 4080, 3392, 3105,   50, 3593, 2244,  804,
         358, 3489, 4008, 1543])
Epoch: 2274, Training Loss: 0.57, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2275 - Batch 1 ########################
IDs in batch 1: tensor([2484, 2292, 2301, 1319, 1117, 2504, 1154, 3496, 3706,  586, 2562, 1267,
        4058,  615, 2616,  954])
Epoch: 2275, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2276 - Batch 1 ########################
IDs in batch 1: tensor([ 660, 1647, 1942,  539, 3100, 2833, 2473, 2631, 1396, 3503, 1206, 1452,
        2355,  417, 2806, 1970])
Epoch: 2276, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.69
######################## Epoch 2277 - Batch 1 ########################
IDs in batch 1: tensor([3461,  820,  593, 2996, 2064,  721, 2087, 3180, 2226,  492, 2697,   31,
        1020, 1488, 1290, 2415])
Epoch: 2277, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2278 - Batch 1 ########################
IDs in batch 1: tensor([3980, 4254, 2642, 3386, 2115, 3434, 4226, 4175, 2912,   25,  129, 4265,
        2393, 3503,   34, 4228])
Epoch: 2278, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2279 - Batch 1 ########################
IDs in batch 1: tensor([2091, 2696, 3028, 1857, 2193,  522,  389, 2978, 2980, 2052, 1819, 1934,
         501, 4220,  432, 3448])
Epoch: 2279, Training Loss: 0.41, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2280 - Batch 1 ########################
IDs in batch 1: tensor([2149,  676, 2876, 1552, 4113, 3860, 3181, 2783, 3355, 1467, 3372, 3118,
        2587,   72, 3101,  732])
Epoch: 2280, Training Loss: 0.24, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2281 - Batch 1 ########################
IDs in batch 1: tensor([1287, 4224, 2572, 2260,  145, 3863, 2347, 3838, 3217, 4100, 1679, 3351,
        3615, 1578, 4044,    7])
Epoch: 2281, Training Loss: 0.32, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2282 - Batch 1 ########################
IDs in batch 1: tensor([ 909,  930, 3604, 2088, 1133, 1500,  694, 3222, 3660, 1177,  534, 1024,
        3696, 1706, 3696, 3907])
Epoch: 2282, Training Loss: 0.39, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2283 - Batch 1 ########################
IDs in batch 1: tensor([3792, 1711, 2487, 1289, 2732, 2172, 3253,  527, 1677,  954, 2078, 1220,
        2170, 1454, 3787, 2821])
Epoch: 2283, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2284 - Batch 1 ########################
IDs in batch 1: tensor([4069,   41, 3951, 1485, 2907, 3282,  625, 2565, 3713, 1225,  970, 1507,
        1885, 3900, 1034,  937])
Epoch: 2284, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2285 - Batch 1 ########################
IDs in batch 1: tensor([3474, 2110, 3204, 2412, 2098, 2272, 1341, 1974, 2986, 1208, 1569,  920,
         610, 1678, 2700, 1986])
Epoch: 2285, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2286 - Batch 1 ########################
IDs in batch 1: tensor([1294, 3870, 4015, 2418, 3850, 3558, 3513, 3469, 2540, 2517, 1258, 1272,
        2631, 2970, 2154, 3060])
Epoch: 2286, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2287 - Batch 1 ########################
IDs in batch 1: tensor([1050, 3055, 1247, 1097, 1633, 1990, 2312, 4228, 1083, 1200,  593,  530,
        3497, 2217, 4044, 1324])
Epoch: 2287, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2288 - Batch 1 ########################
IDs in batch 1: tensor([2347,  914, 3092,  161, 1490, 1819,  236, 1020, 2763, 4199, 3985, 2095,
        1755, 2357, 1794, 1638])
Epoch: 2288, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2289 - Batch 1 ########################
IDs in batch 1: tensor([2281, 3545, 2393, 3999,  850, 2142,  292, 3278, 2262, 2725, 2334, 4238,
        2097, 2051, 3952, 3306])
Epoch: 2289, Training Loss: 0.45, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2290 - Batch 1 ########################
IDs in batch 1: tensor([4008, 1364, 3656,  378,  897, 3547,  395,  732, 2838,  518, 2382,  623,
        4133, 1567, 3872, 3429])
Epoch: 2290, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2291 - Batch 1 ########################
IDs in batch 1: tensor([3435, 2450, 1747,  455, 2285, 3698,  736,   70, 3728, 2281, 1110, 3221,
        3914, 3392, 3553, 1437])
Epoch: 2291, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2292 - Batch 1 ########################
IDs in batch 1: tensor([2444, 2218,   20, 3220, 2095, 3701, 1961, 1594, 2487, 3897, 2324,  456,
        2497, 3441, 3521, 2099])
Epoch: 2292, Training Loss: 0.33, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2293 - Batch 1 ########################
IDs in batch 1: tensor([1380, 3654, 3390, 2367,  497, 3927, 3027, 1569, 2191, 1244, 1402, 1682,
        3300, 2403,  714, 1414])
Epoch: 2293, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2294 - Batch 1 ########################
IDs in batch 1: tensor([2840, 4010, 3553, 1720, 3726, 3386, 2386, 1219,  642, 4258,  260,  572,
         182, 4086, 4094, 3594])
Epoch: 2294, Training Loss: 0.46, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2295 - Batch 1 ########################
IDs in batch 1: tensor([ 484,  944,  871, 2568, 1390,  225, 2376, 3219,  683, 3487, 3208, 1597,
         879,  952, 1090, 1702])
Epoch: 2295, Training Loss: 0.39, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2296 - Batch 1 ########################
IDs in batch 1: tensor([  10,  476, 1196, 1980,   61, 3087, 3270, 1204, 1727, 2401, 2643, 1044,
        3258,   38,  741, 2669])
Epoch: 2296, Training Loss: 0.38, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2297 - Batch 1 ########################
IDs in batch 1: tensor([ 290,  842, 3342, 2271,  991, 3798, 1139,  636, 2441,   70, 3927, 3029,
        1160, 2567, 2244, 1471])
Epoch: 2297, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2298 - Batch 1 ########################
IDs in batch 1: tensor([2091, 1650, 1490, 3199, 3081, 3587,  239, 1649, 2751, 3523, 2947, 2956,
         596, 2947,  380,  523])
Epoch: 2298, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2299 - Batch 1 ########################
IDs in batch 1: tensor([1318, 2354, 3483, 2564,  763,  338, 1178,  476, 2153, 1869, 1822, 4121,
        2540, 2437,  472,  334])
Epoch: 2299, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2300 - Batch 1 ########################
IDs in batch 1: tensor([1062,  829, 1761, 2121, 2433, 2292, 4114, 3948, 2905,  338, 1295, 1736,
        4096,  957,  519, 1061])
Epoch: 2300, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2301 - Batch 1 ########################
IDs in batch 1: tensor([3540, 1495, 1796,   30, 1640, 4226, 3524, 3745, 3964, 2191, 1030, 2241,
        1925,  201, 2815,  946])
Epoch: 2301, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2302 - Batch 1 ########################
IDs in batch 1: tensor([4080,  637, 3648, 1789, 2548, 3321, 1356, 3511, 1613,  358, 3527, 1728,
        1337, 3040, 2431, 3707])
Epoch: 2302, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2303 - Batch 1 ########################
IDs in batch 1: tensor([2342, 3563, 3259, 3436, 4173, 3256, 3541, 2316, 2838, 3541, 2459, 2400,
        3373,  752, 3798, 3429])
Epoch: 2303, Training Loss: 0.58, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2304 - Batch 1 ########################
IDs in batch 1: tensor([2334, 1552,  672, 1332, 3152, 3108, 2026, 2724, 3936, 3327, 2760, 2360,
        2776, 3038,  968,  645])
Epoch: 2304, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2305 - Batch 1 ########################
IDs in batch 1: tensor([1155, 3065, 1982, 2565, 1163, 1777, 2154, 4223, 2729, 1116, 2324, 1330,
        1445,  201, 1434, 3729])
Epoch: 2305, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2306 - Batch 1 ########################
IDs in batch 1: tensor([  82, 3425, 3712, 1276, 2940, 1643, 3181,  283, 3014,  986, 1869, 3407,
        2393, 3573, 1075, 1337])
Epoch: 2306, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2307 - Batch 1 ########################
IDs in batch 1: tensor([ 341, 2220, 1454, 2137,  312, 3739, 3913, 2256, 2590, 3689, 3435, 3790,
         623,  143, 3069, 2476])
Epoch: 2307, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2308 - Batch 1 ########################
IDs in batch 1: tensor([  64, 2829, 3977, 2457,  858, 2540, 2592, 2791, 3094, 3354, 3460, 2755,
        1480, 1482, 4222, 3592])
Epoch: 2308, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2309 - Batch 1 ########################
IDs in batch 1: tensor([3310, 2617,  886,  351,  206, 3257, 3996, 2086, 4253, 2008,  456,   73,
        2219, 1668, 3672, 2571])
Epoch: 2309, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2310 - Batch 1 ########################
IDs in batch 1: tensor([ 154, 1296,  838, 3408,  360, 1773, 3366, 1121, 1379, 1979, 3719, 1153,
        2156, 3806, 3751, 1723])
Epoch: 2310, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2311 - Batch 1 ########################
IDs in batch 1: tensor([3245, 1559, 2497, 2366, 1521, 2546, 4076, 3161, 3885, 4159,  269, 1726,
         134, 4161, 2324, 4036])
Epoch: 2311, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2312 - Batch 1 ########################
IDs in batch 1: tensor([1671,  923,  807, 4044, 3446, 2712, 4172, 1344, 3534, 2442, 3182, 3242,
        2480, 1506, 2237,  588])
Epoch: 2312, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2313 - Batch 1 ########################
IDs in batch 1: tensor([3184, 3430, 3870, 1318, 1935, 1421, 3540, 3987, 1957, 1786, 2154,  295,
        1160, 3428, 2986, 3581])
Epoch: 2313, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2314 - Batch 1 ########################
IDs in batch 1: tensor([2010, 3513, 3255,  653,  582,  427, 3680,   99,  130, 2111,  792, 2583,
        1012, 2235, 2539, 3291])
Epoch: 2314, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2315 - Batch 1 ########################
IDs in batch 1: tensor([ 137, 2467, 1153, 3473, 2366,  205, 3199, 4229, 2938,   10,  873, 3448,
        2749, 1060, 1439, 2219])
Epoch: 2315, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2316 - Batch 1 ########################
IDs in batch 1: tensor([4187, 3460, 2784, 2182, 1183, 2023, 1464, 1236, 2045, 3668,  721, 3389,
        1274, 3652, 1849, 2226])
Epoch: 2316, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2317 - Batch 1 ########################
IDs in batch 1: tensor([1900, 3832, 3239, 3228, 1179,  680, 3475, 1934, 1387, 1984, 2114, 1237,
        3991, 3344, 3401, 3216])
Epoch: 2317, Training Loss: 0.26, Validation Loss: 0.72, accuracy = 0.71
######################## Epoch 2318 - Batch 1 ########################
IDs in batch 1: tensor([4027, 3763,  295, 2701, 1500, 3895, 1371, 2122, 3821, 2081, 1043, 2185,
        4187, 1579,  880,  994])
Epoch: 2318, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2319 - Batch 1 ########################
IDs in batch 1: tensor([3516, 2551, 3731, 1958, 2646, 3781, 3672, 2166,  841, 1226, 3756,  387,
        3710, 2360, 3589,  544])
Epoch: 2319, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2320 - Batch 1 ########################
IDs in batch 1: tensor([1170, 2983,  371, 3408, 3009, 1690, 3598,  133, 1037, 3672,  487, 3036,
        2230, 3246,  255, 2024])
Epoch: 2320, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2321 - Batch 1 ########################
IDs in batch 1: tensor([ 919, 1979, 2034, 2377, 3501,  247, 1859, 1043, 3282, 2125, 3216, 3126,
        1597, 2478, 2106,   46])
Epoch: 2321, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2322 - Batch 1 ########################
IDs in batch 1: tensor([2708, 1624, 1474, 2571, 1490, 2155, 1354, 2743, 1141, 1222,  846,  359,
        2587,  820, 2991, 1267])
Epoch: 2322, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2323 - Batch 1 ########################
IDs in batch 1: tensor([ 658, 1310, 3996, 1610,  662, 1212, 2478, 2815,  910,  371, 1130, 1620,
        2379, 2344,  918, 1817])
Epoch: 2323, Training Loss: 0.26, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2324 - Batch 1 ########################
IDs in batch 1: tensor([ 202, 4114,  644, 2442, 3220, 1379, 2953, 1130, 2248,  517, 3702,  996,
        1272,  412, 3363, 3358])
Epoch: 2324, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2325 - Batch 1 ########################
IDs in batch 1: tensor([3072, 3538, 1927, 1055, 2146, 1445, 1596, 1933, 3283, 2447, 2226, 2729,
         736, 2812, 4096,  770])
Epoch: 2325, Training Loss: 0.28, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2326 - Batch 1 ########################
IDs in batch 1: tensor([3997,  533, 2961, 2856, 2110, 1832,  751, 3675, 3236, 2419, 4018, 3789,
        1251,  996,  646, 1673])
Epoch: 2326, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2327 - Batch 1 ########################
IDs in batch 1: tensor([3870, 3382, 1325, 1116, 2271,  482, 1830, 3659, 3742, 1567, 4217, 3440,
         915, 1061, 3006, 2027])
Epoch: 2327, Training Loss: 0.35, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2328 - Batch 1 ########################
IDs in batch 1: tensor([2393, 2976,  507, 4108, 2763, 3879, 2145, 1990, 4175, 2495, 1971,  622,
        1141, 3919, 2947, 3672])
Epoch: 2328, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2329 - Batch 1 ########################
IDs in batch 1: tensor([ 725,   88, 2016, 4218, 2688,  317, 2539,  930, 3888,  658, 2277,  766,
        2523,  459,  873, 4240])
Epoch: 2329, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2330 - Batch 1 ########################
IDs in batch 1: tensor([1642, 2229,  485, 1357, 3956, 2196, 1896, 1988, 3778, 4067, 4220,  980,
        3504,  325, 2781,  681])
Epoch: 2330, Training Loss: 0.40, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2331 - Batch 1 ########################
IDs in batch 1: tensor([4240,  628, 3511, 1485, 2724, 2876,  133, 1054, 1583, 3570, 1305, 2517,
        3740, 4144,  469, 2742])
Epoch: 2331, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2332 - Batch 1 ########################
IDs in batch 1: tensor([ 541, 3647,  361, 4008, 2950, 1010, 3980, 3676, 4179, 4016, 3009,   78,
        1062,  518,  344, 1472])
Epoch: 2332, Training Loss: 0.74, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2333 - Batch 1 ########################
IDs in batch 1: tensor([ 413,  501, 1311,  152, 1639,  411, 1681, 3733, 2949, 4184,  546,  377,
        3590, 2788, 1214,  569])
Epoch: 2333, Training Loss: 0.54, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2334 - Batch 1 ########################
IDs in batch 1: tensor([1731, 1671, 3404, 2724, 3525,  314, 2064, 1140, 3845, 1970,  636, 2028,
         258, 1968, 3746, 1073])
Epoch: 2334, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2335 - Batch 1 ########################
IDs in batch 1: tensor([ 688, 2295, 3151, 1305, 3804, 1899, 2207,  151, 2390, 2897, 3480, 1107,
        3506, 3058, 2072,  207])
Epoch: 2335, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2336 - Batch 1 ########################
IDs in batch 1: tensor([2516, 3453, 2252, 1959, 2891, 2099, 1647, 2116, 1770, 1968, 3299,  196,
          37, 3505, 3940,  295])
Epoch: 2336, Training Loss: 0.25, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2337 - Batch 1 ########################
IDs in batch 1: tensor([3428, 3228, 1027,  501,  968, 4095, 1345,  930, 3166,  588, 1633, 3936,
        2346, 3617,  265, 3990])
Epoch: 2337, Training Loss: 0.50, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2338 - Batch 1 ########################
IDs in batch 1: tensor([3440, 2406, 2561, 2353, 2145, 1274, 3726, 3334, 1984, 1677, 2115, 2828,
         501,  591,   71,   31])
Epoch: 2338, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2339 - Batch 1 ########################
IDs in batch 1: tensor([ 214, 1706,  359, 3291, 4258, 3921, 3650, 1756, 3444,  593, 3469, 1137,
        3961, 2169, 3777, 2204])
Epoch: 2339, Training Loss: 0.44, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2340 - Batch 1 ########################
IDs in batch 1: tensor([4139, 3563, 3667, 1026,  478,  613,  588, 1128, 1294, 3540, 2352,  781,
        3647, 2510, 1335, 3958])
Epoch: 2340, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2341 - Batch 1 ########################
IDs in batch 1: tensor([2678, 2063, 1396, 1518,  243,  819, 1281, 4166,  851, 2041, 4046, 1671,
          31, 1405,  785, 2996])
Epoch: 2341, Training Loss: 0.37, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2342 - Batch 1 ########################
IDs in batch 1: tensor([2871, 2957, 2286,  872, 3032, 3432, 1196, 1595, 1434,  659,  312, 3267,
         136, 2085,  820,  920])
Epoch: 2342, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2343 - Batch 1 ########################
IDs in batch 1: tensor([ 811, 1845,  531, 1060,  778, 1116, 2905,  112,  401, 1206, 3599,  555,
        2146,  180, 2236, 3743])
Epoch: 2343, Training Loss: 0.30, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2344 - Batch 1 ########################
IDs in batch 1: tensor([ 527,   14,  388, 3160,  141, 1508,  606, 3875,   63, 4265, 2410, 2961,
        2976, 1702, 3701, 1932])
Epoch: 2344, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2345 - Batch 1 ########################
IDs in batch 1: tensor([3968, 2853, 4000,  465, 2161,  837, 3875, 2161, 2745, 2823, 4037, 3206,
        2849,  930, 2342, 1096])
Epoch: 2345, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2346 - Batch 1 ########################
IDs in batch 1: tensor([ 476, 1395, 2724,  723, 2447, 3829, 4213, 1236, 2060, 1836, 2891, 1469,
        2609, 1006, 1098,  380])
Epoch: 2346, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2347 - Batch 1 ########################
IDs in batch 1: tensor([3358,  108, 1942, 1193, 1578,  724,  914, 2810, 2969, 4224, 4170, 4148,
        4157, 1032, 1897,  987])
Epoch: 2347, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2348 - Batch 1 ########################
IDs in batch 1: tensor([ 738,  884,  139, 2995,  125, 3634, 1050, 1044, 2127, 1525, 3617, 3235,
         814, 3763, 2977, 1272])
Epoch: 2348, Training Loss: 0.37, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2349 - Batch 1 ########################
IDs in batch 1: tensor([3124, 2378, 1405, 1041, 2804,  341,  653, 4152, 2252, 3920,  835,   74,
        1080, 1266, 3245, 2249])
Epoch: 2349, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2350 - Batch 1 ########################
IDs in batch 1: tensor([ 434, 2717, 1823,  870,  967, 3664,  537, 3262, 2005, 1679,  617, 2423,
        2883, 1224, 4156, 1863])
Epoch: 2350, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2351 - Batch 1 ########################
IDs in batch 1: tensor([1753,  419,  417, 3853, 2485, 1282,   38, 2098, 1123, 4161, 1524, 2492,
        1297, 4006,  710, 1878])
Epoch: 2351, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2352 - Batch 1 ########################
IDs in batch 1: tensor([ 522, 3479, 3518, 3545, 2183, 1090, 2261, 4242, 2577, 2066, 1436, 4110,
        2466,  181, 3389, 4214])
Epoch: 2352, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2353 - Batch 1 ########################
IDs in batch 1: tensor([2088, 3289, 3837, 2196, 2550, 1871,  919, 1811, 3299, 1612, 2542,  403,
        3838, 3492, 3652, 3897])
Epoch: 2353, Training Loss: 0.33, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2354 - Batch 1 ########################
IDs in batch 1: tensor([2771, 2725, 3677, 3660, 3426, 1057, 3714, 4268,  196, 3390, 1063, 2642,
         960, 1456, 1772,  237])
Epoch: 2354, Training Loss: 0.33, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2355 - Batch 1 ########################
IDs in batch 1: tensor([2377, 1517, 3252, 3712, 3610, 2161, 1131,  159, 2810,  913,  673, 3052,
        2492, 2789, 3148, 3006])
Epoch: 2355, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2356 - Batch 1 ########################
IDs in batch 1: tensor([4027, 2354, 2148, 1371, 4148, 2241, 3072,  758, 3989, 1311, 3707,  781,
        3311, 1316, 2544, 1284])
Epoch: 2356, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2357 - Batch 1 ########################
IDs in batch 1: tensor([ 466, 1076, 2005, 1470, 3710, 3375, 1469, 3388, 3837, 3926, 2287, 2331,
        2420,  481, 1862, 3534])
Epoch: 2357, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2358 - Batch 1 ########################
IDs in batch 1: tensor([2710, 3443,  524,  659, 1331, 1167, 3913,  756, 1886, 1136,  128, 3179,
        3795, 1956, 1794, 1251])
Epoch: 2358, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2359 - Batch 1 ########################
IDs in batch 1: tensor([ 535,   96, 3417, 2758, 1434,  855, 3481, 3827, 3351, 2659,  602, 4068,
        2754, 2964,   78, 1264])
Epoch: 2359, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2360 - Batch 1 ########################
IDs in batch 1: tensor([2011, 3997, 2740, 4027, 3446, 4099, 2455, 1051, 2433, 3438, 2691, 2715,
        3614, 1334, 1556, 2254])
Epoch: 2360, Training Loss: 0.26, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2361 - Batch 1 ########################
IDs in batch 1: tensor([2780, 2940,  555, 3539, 3673,  550, 1840, 1158, 3356, 1219, 3439, 3597,
        1482, 2399,  964, 1436])
Epoch: 2361, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2362 - Batch 1 ########################
IDs in batch 1: tensor([3206, 3981, 3700, 4240,  864, 1177, 2423,  803, 4227, 3947,  993,   92,
        3159,  893, 1720, 1177])
Epoch: 2362, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2363 - Batch 1 ########################
IDs in batch 1: tensor([2599, 3105, 1508,  295, 3115, 3015, 3711,  899, 3816,  552, 1370, 2619,
        1445, 2436, 2070, 3726])
Epoch: 2363, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2364 - Batch 1 ########################
IDs in batch 1: tensor([1134,  704, 2439,  945, 2540, 2598, 1066,  557, 4176,  830, 2765,  594,
         838,  839, 1723, 4015])
Epoch: 2364, Training Loss: 0.28, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2365 - Batch 1 ########################
IDs in batch 1: tensor([1956, 4152, 4013, 3448, 2986,  534, 1122, 2672,  975, 1600, 2117, 3843,
        1343, 1973, 4086,   43])
Epoch: 2365, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 2366 - Batch 1 ########################
IDs in batch 1: tensor([ 409,  320, 4217, 1170, 2451, 2587, 3022, 3872,  228,  848, 1678,  741,
        2953, 4032,  945,  884])
Epoch: 2366, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2367 - Batch 1 ########################
IDs in batch 1: tensor([ 112,  970,  312, 3968, 4062, 3878, 3306, 1480,  670, 2440, 4159, 1255,
        1485, 4258, 1487, 2124])
Epoch: 2367, Training Loss: 0.23, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2368 - Batch 1 ########################
IDs in batch 1: tensor([1247, 1579, 3258,  844,  128, 1103, 2921, 3591,   24, 2969, 2542, 3379,
         465, 1798,   74, 2051])
Epoch: 2368, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2369 - Batch 1 ########################
IDs in batch 1: tensor([2065, 3652, 3507, 2565,  900, 2718, 1277, 3942,  150,  325, 1796, 1143,
        1038, 3367, 3529, 2882])
Epoch: 2369, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2370 - Batch 1 ########################
IDs in batch 1: tensor([2095,  219, 1642, 3453,  994,  520, 1988, 2323, 3424,  430, 1957,  284,
        3882, 1677, 2297, 2145])
Epoch: 2370, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2371 - Batch 1 ########################
IDs in batch 1: tensor([1782,  139, 3638, 1072, 2447,  732, 4087,  591, 3051, 3701, 1452, 2332,
        2059, 2500,   25, 3304])
Epoch: 2371, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.69
######################## Epoch 2372 - Batch 1 ########################
IDs in batch 1: tensor([3514, 2238, 1219, 1322,  947, 2299, 3311, 3244, 4049,  488, 3349, 2170,
        2026, 2087, 3870, 1363])
Epoch: 2372, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2373 - Batch 1 ########################
IDs in batch 1: tensor([2736, 1373, 4055, 3557,  541, 3003, 3254, 2712, 2559, 3654,  735, 3222,
        1894,  505, 4227,  517])
Epoch: 2373, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2374 - Batch 1 ########################
IDs in batch 1: tensor([3609,  870,  159, 2646, 1779, 2052, 4180, 3591,  228, 2538,  470, 4197,
         606,  630, 1868, 3102])
Epoch: 2374, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2375 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 3355, 2780, 2887,  378,    4, 4165,  693,  724,  835,  326, 2099,
        2581, 2890, 1902, 2884])
Epoch: 2375, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2376 - Batch 1 ########################
IDs in batch 1: tensor([ 956,  321, 3318, 2210, 3181, 3808, 3723, 2440, 1083, 2731, 3548, 1624,
        3624, 1026, 1171, 2589])
Epoch: 2376, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2377 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 3852,  663,  325, 3511,  667, 4040,  465,   39,  950,  165,  437,
        3358, 1157,  827, 3547])
Epoch: 2377, Training Loss: 0.52, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2378 - Batch 1 ########################
IDs in batch 1: tensor([ 546, 2086,   14, 1773, 3300, 3455, 2919, 1794,  523, 2489, 2143, 3999,
        2358, 2827, 3109, 3378])
Epoch: 2378, Training Loss: 0.36, Validation Loss: 0.77, accuracy = 0.69
######################## Epoch 2379 - Batch 1 ########################
IDs in batch 1: tensor([ 892, 3563, 1563, 1760, 3504, 3733,  478, 1948, 2391,  875, 1373, 3673,
        4136, 1732,  620,  441])
Epoch: 2379, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2380 - Batch 1 ########################
IDs in batch 1: tensor([3812, 3025,   14, 2521,  749,  805,  413,  550, 3005,  507, 1850, 1796,
        2748,  924, 2478,  733])
Epoch: 2380, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2381 - Batch 1 ########################
IDs in batch 1: tensor([3590,  767, 2586, 2724, 1644, 1965,  606, 1179, 1646, 1356,  640,  969,
        3494, 1661, 2855, 3734])
Epoch: 2381, Training Loss: 0.30, Validation Loss: 0.76, accuracy = 0.69
######################## Epoch 2382 - Batch 1 ########################
IDs in batch 1: tensor([2067, 1540, 3270, 2849, 1233, 1317, 2241, 2879, 2192, 1147, 1851, 3313,
        1364,   13, 1310, 2410])
Epoch: 2382, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2383 - Batch 1 ########################
IDs in batch 1: tensor([1023, 3036, 2493, 1679, 1417, 1351, 3583, 2217, 1578,  833, 1588, 3815,
        4015, 1159, 2734, 2599])
Epoch: 2383, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2384 - Batch 1 ########################
IDs in batch 1: tensor([1575, 1891, 1256, 3642, 1158,  902, 1833,  245, 1195, 3746, 3589, 3193,
        2312,  792, 2998, 2869])
Epoch: 2384, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2385 - Batch 1 ########################
IDs in batch 1: tensor([ 964, 3956,  989, 1432,  985, 1364, 3047,  264, 3656, 2378, 2912,  292,
        1955, 2894, 1988, 1546])
Epoch: 2385, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2386 - Batch 1 ########################
IDs in batch 1: tensor([4198, 3128, 2286,  775, 2440, 2185, 3792, 3754,  190, 1711, 2825, 2087,
        3772, 1861, 3426,  487])
Epoch: 2386, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2387 - Batch 1 ########################
IDs in batch 1: tensor([ 827,  516,  220, 1518, 3871, 4140,  584, 2027, 2848, 3804, 2191,  814,
        1308,  154, 2771, 1146])
Epoch: 2387, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2388 - Batch 1 ########################
IDs in batch 1: tensor([3981,  393, 1794, 1429, 3486,  380, 3003,  477, 2177,  426,  596,  712,
        2595, 2868,  546, 1156])
Epoch: 2388, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2389 - Batch 1 ########################
IDs in batch 1: tensor([2326, 1022, 4070, 3065,  252, 2066, 1955, 3951, 2859, 2366,  300, 2018,
         441, 1072, 3314, 2113])
Epoch: 2389, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2390 - Batch 1 ########################
IDs in batch 1: tensor([2771, 3100, 2383,  920, 2448, 2505, 4004, 1857, 2080, 3077, 3455, 2206,
         137,  469, 2746,  454])
Epoch: 2390, Training Loss: 0.36, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2391 - Batch 1 ########################
IDs in batch 1: tensor([ 556, 3553, 1252, 3417, 3197, 1133, 1883, 4027, 3933,   72,  941,  534,
        1918, 1173,  725,   47])
Epoch: 2391, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2392 - Batch 1 ########################
IDs in batch 1: tensor([2897, 3408, 3236, 4187, 2040, 1020, 1177, 1294, 1600, 1082, 2689, 2167,
         738,  953, 2036, 3712])
Epoch: 2392, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2393 - Batch 1 ########################
IDs in batch 1: tensor([ 243,  766, 1076,  601, 2155, 3039,  815, 1633, 2804, 2337, 3597,  913,
        3954, 3831, 1892, 3270])
Epoch: 2393, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2394 - Batch 1 ########################
IDs in batch 1: tensor([3506, 2151,  813, 2555,  809, 1879, 3501,  496, 3688,  183, 4215, 3718,
        3436, 3057, 1589, 1751])
Epoch: 2394, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2395 - Batch 1 ########################
IDs in batch 1: tensor([3275, 3458, 1495, 1409,   99, 3616,  409, 4238, 2385, 1927, 3993, 1810,
        3543, 2212, 2367,  356])
Epoch: 2395, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2396 - Batch 1 ########################
IDs in batch 1: tensor([1938,  474, 2377, 2085, 4144, 1937,  628,  627,  122, 3238, 3705, 1504,
        4258, 3795, 2465, 1488])
Epoch: 2396, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2397 - Batch 1 ########################
IDs in batch 1: tensor([3023,  207, 1315, 2983, 1283,  741,  441,  995, 2993, 2027,  394, 2275,
        1643,  881, 1076, 4220])
Epoch: 2397, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2398 - Batch 1 ########################
IDs in batch 1: tensor([3812,  308, 2087, 1517, 3577, 3139, 1624, 4015, 1563, 1335, 2341, 3113,
        2721, 1132, 1397, 1680])
Epoch: 2398, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2399 - Batch 1 ########################
IDs in batch 1: tensor([3032,  886, 1098,  869, 3438, 2541, 3407,  438, 3351, 2925, 2980, 4116,
        2706, 4172, 2703, 1990])
Epoch: 2399, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2400 - Batch 1 ########################
IDs in batch 1: tensor([ 538, 2604, 3627, 2280,  718,  511,  127, 3630, 2749,  200, 3298,  937,
         814, 3446, 3617,  617])
Epoch: 2400, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2401 - Batch 1 ########################
IDs in batch 1: tensor([2114,  318, 4226, 4197, 3487, 3721, 2638, 3055, 2500, 4256, 3676, 2104,
        4212, 1012, 2727, 3695])
Epoch: 2401, Training Loss: 0.60, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2402 - Batch 1 ########################
IDs in batch 1: tensor([2063,  333, 1410, 3386, 3635,   70,  955, 3723, 2442, 4240, 2403, 4077,
        3027, 2172, 1887, 1328])
Epoch: 2402, Training Loss: 0.39, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2403 - Batch 1 ########################
IDs in batch 1: tensor([3018, 2463,  150, 4249, 3345, 1902, 3078, 3772,  902, 1439, 1482, 2462,
        2641,  232, 2009,  334])
Epoch: 2403, Training Loss: 0.26, Validation Loss: 0.73, accuracy = 0.70
######################## Epoch 2404 - Batch 1 ########################
IDs in batch 1: tensor([2526, 1935, 1373, 4026, 2359,  823,  841,  463, 1811, 1860, 1406, 3637,
        1248, 2951, 3747, 2412])
Epoch: 2404, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2405 - Batch 1 ########################
IDs in batch 1: tensor([1244, 3040, 2476, 2571, 2403, 2343, 1076,  555, 3585, 2638, 2899,  537,
        1428,  605,  395, 1803])
Epoch: 2405, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.71
######################## Epoch 2406 - Batch 1 ########################
IDs in batch 1: tensor([2045,  438,  843, 2286, 1171, 3762, 3711, 2869, 1972,  934, 3997,  723,
         738, 2017, 1789, 1500])
Epoch: 2406, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2407 - Batch 1 ########################
IDs in batch 1: tensor([1183, 3569,  902,  777, 2013, 2913, 3534, 2253,  391, 3654, 2224, 2049,
        2295, 2383, 2931,  736])
Epoch: 2407, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2408 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2726, 1650, 3399, 1198, 3226, 2391, 1832, 1144, 1737,  750,   11,
         408, 2109, 4075, 1103])
Epoch: 2408, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2409 - Batch 1 ########################
IDs in batch 1: tensor([1335, 3771, 2734, 3397, 1025, 3536, 1913, 4212, 1032,  732, 1134, 1700,
        1841, 2036,  545, 2739])
Epoch: 2409, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2410 - Batch 1 ########################
IDs in batch 1: tensor([ 975, 2444, 3632,  424, 4026, 3792,  749,  255, 4105, 1413, 2717, 3873,
        3428,  841,  499, 3098])
Epoch: 2410, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2411 - Batch 1 ########################
IDs in batch 1: tensor([1660, 2942, 2724, 2150, 2230, 2742, 2431,  753, 1579, 1170, 4080, 2304,
        1110, 1125, 3031, 3777])
Epoch: 2411, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2412 - Batch 1 ########################
IDs in batch 1: tensor([ 207, 3862, 3891, 1747, 3146, 1050, 3344, 2247, 1347, 1944,  261,  819,
        1022, 1524, 3182, 2031])
Epoch: 2412, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2413 - Batch 1 ########################
IDs in batch 1: tensor([2959, 3354, 2275, 3279, 3471, 2907,  388, 2653,  983,  557, 2146,  574,
         821,  864,  908,  437])
Epoch: 2413, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2414 - Batch 1 ########################
IDs in batch 1: tensor([ 555, 4121, 2204,  532, 2230, 1452, 1391, 3126,  816, 2954, 3437, 2234,
         717, 1723, 1432, 2655])
Epoch: 2414, Training Loss: 0.26, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2415 - Batch 1 ########################
IDs in batch 1: tensor([1676, 1034, 2723, 4117, 1773, 2965, 2869, 3493, 1886, 3458, 1121, 2959,
        3159, 1811, 1471, 3102])
Epoch: 2415, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2416 - Batch 1 ########################
IDs in batch 1: tensor([2011, 2616, 3974,  396,   13, 2777, 1023, 4159, 2736, 3746, 2643,  739,
        2953, 3506,  237, 3309])
Epoch: 2416, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2417 - Batch 1 ########################
IDs in batch 1: tensor([1334,  430, 1038, 2812, 1221, 3977, 2589, 3610,  538, 1256, 1088, 3243,
        3842, 3652, 4013, 3972])
Epoch: 2417, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2418 - Batch 1 ########################
IDs in batch 1: tensor([1159, 2545, 1878, 1057, 1144, 3529, 2145,  134, 3852, 1375,  962, 1472,
        4013, 1700, 2787, 2529])
Epoch: 2418, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2419 - Batch 1 ########################
IDs in batch 1: tensor([2031, 2297, 1474,  569,  910, 2644, 2044, 4022,  797, 2041, 3146,  919,
        1396,  712, 2315, 3111])
Epoch: 2419, Training Loss: 0.27, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2420 - Batch 1 ########################
IDs in batch 1: tensor([3618, 1834,  159, 3958, 3056, 3523, 1414, 3669, 2324, 1308,  360,  833,
        2907, 1488,  186,  337])
Epoch: 2420, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2421 - Batch 1 ########################
IDs in batch 1: tensor([3091, 1067, 2388, 1340, 3997, 1766, 2892, 1221, 3747,  265,  738,  997,
        1072, 1051,  849, 3783])
Epoch: 2421, Training Loss: 0.37, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2422 - Batch 1 ########################
IDs in batch 1: tensor([2733, 1015, 4026, 1042, 2232, 1643,  674, 1649, 3543,  125, 1309, 3108,
        1386, 2664, 1982, 4048])
Epoch: 2422, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2423 - Batch 1 ########################
IDs in batch 1: tensor([2797,  182, 2185,   62, 2238, 1370, 1885, 2632, 3031,  554,  345,  667,
        2636, 2209, 3536, 3859])
Epoch: 2423, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2424 - Batch 1 ########################
IDs in batch 1: tensor([1077, 1724, 1125, 4139, 3384, 2942, 2285, 4056,  613,  752, 2444, 2965,
        3079, 2755, 3925, 2141])
Epoch: 2424, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2425 - Batch 1 ########################
IDs in batch 1: tensor([2334, 1410,  148,  609, 3377, 2489, 2437, 3871, 1336, 1871,  128,  188,
         384, 3437,  989,  373])
Epoch: 2425, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2426 - Batch 1 ########################
IDs in batch 1: tensor([1855,  900,   88, 3839, 3997, 3787,  143, 1551,  586, 3250, 2111,  612,
        3091, 3358, 3636, 1263])
Epoch: 2426, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2427 - Batch 1 ########################
IDs in batch 1: tensor([3187, 2717, 1426, 2344,  771, 2365, 3572, 2386, 1309, 1231,  354,  747,
        2282, 3342,  251, 1326])
Epoch: 2427, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2428 - Batch 1 ########################
IDs in batch 1: tensor([3847, 4122, 3440,  665, 2402, 3526, 2229,  815, 2074, 1644, 3573, 3913,
        2342, 2603,  937,   10])
Epoch: 2428, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2429 - Batch 1 ########################
IDs in batch 1: tensor([ 822, 2970, 2599, 1489, 2761,  516, 2314, 4018, 2004,  733,  605, 1578,
        1043, 2099,  572, 1173])
Epoch: 2429, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2430 - Batch 1 ########################
IDs in batch 1: tensor([4149, 2224,  395, 2938,  526, 1213, 3299, 2732,  606, 3985, 2088, 3870,
        1216, 1131, 2124,  136])
Epoch: 2430, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2431 - Batch 1 ########################
IDs in batch 1: tensor([3677, 3344, 3028, 3397, 2754, 3656, 1052, 1950,  970, 3473,  397,  300,
        2522, 1026, 1162, 2710])
Epoch: 2431, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2432 - Batch 1 ########################
IDs in batch 1: tensor([ 942, 1395, 3738, 3092,  811,  499, 2645, 1020, 4180, 2604,  575, 1213,
        3826, 4013, 2603, 3538])
Epoch: 2432, Training Loss: 0.32, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2433 - Batch 1 ########################
IDs in batch 1: tensor([2027, 1642, 2821, 2236, 1568, 1860, 2663,  757, 2973, 3984,  572, 2292,
        4116, 1121, 2936, 2697])
Epoch: 2433, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2434 - Batch 1 ########################
IDs in batch 1: tensor([2807, 2412, 3078,  324, 2500, 2524, 3071, 3146, 2724, 1510, 3689,  822,
         283,   15, 1108, 3643])
Epoch: 2434, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2435 - Batch 1 ########################
IDs in batch 1: tensor([2279, 3547,  322,   63, 3166, 2936, 2715, 1028, 2439, 3700, 3842, 1278,
        2228, 4267,  436,  809])
Epoch: 2435, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2436 - Batch 1 ########################
IDs in batch 1: tensor([3004, 2406, 1501, 4082, 2357, 1519,  127, 2899, 2693, 2540, 2115, 3928,
        2098, 2118, 2258, 1374])
Epoch: 2436, Training Loss: 0.26, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2437 - Batch 1 ########################
IDs in batch 1: tensor([1025, 1076, 1374, 4217,   15, 2360, 2667, 2839, 2244,  566, 3496, 1955,
        1959, 3511,  161, 1272])
Epoch: 2437, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2438 - Batch 1 ########################
IDs in batch 1: tensor([2107, 3091, 3144, 1923, 2157,  965, 2299, 1044,  900, 2706, 2514, 1026,
         441, 2578, 1579,  363])
Epoch: 2438, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2439 - Batch 1 ########################
IDs in batch 1: tensor([1851, 2157, 3289, 2190,  191, 3635, 2964, 3588, 3518, 1249, 3771,  893,
        3044, 1198, 2342,  855])
Epoch: 2439, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2440 - Batch 1 ########################
IDs in batch 1: tensor([2884, 1902, 2793, 3836, 2323,  908, 3676,   38, 1787, 1540,  635,  553,
         623,  515, 2248, 4115])
Epoch: 2440, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2441 - Batch 1 ########################
IDs in batch 1: tensor([2748, 1508, 1102, 4222, 2281,  591, 3211, 2104, 1385, 1138,  120, 1059,
        3277, 2459, 3636, 1480])
Epoch: 2441, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2442 - Batch 1 ########################
IDs in batch 1: tensor([ 792, 2004,   26,  150, 3597,  283, 2751, 3548, 2258, 1189, 1170,  250,
        1270, 2777, 1212, 1833])
Epoch: 2442, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2443 - Batch 1 ########################
IDs in batch 1: tensor([ 165, 3547,  644, 1821,  262, 1159,  726, 1576,  535, 4057, 2640, 2827,
        1562, 3435, 4205,  662])
Epoch: 2443, Training Loss: 0.32, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2444 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 4082,  439, 1872, 4086, 3074, 3647, 1039,  892, 1583,  983, 3785,
        1901, 3954, 3713, 2117])
Epoch: 2444, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2445 - Batch 1 ########################
IDs in batch 1: tensor([3569,  202, 3494, 1861, 2614,  365,  151, 1351, 2355,   74, 4061,  367,
        3159,  184, 2217, 2506])
Epoch: 2445, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2446 - Batch 1 ########################
IDs in batch 1: tensor([ 536,  356, 1084, 2874,  919, 3983, 2049, 2518, 4103, 4044,  234, 3126,
        3933,  795, 3101, 1075])
Epoch: 2446, Training Loss: 0.22, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2447 - Batch 1 ########################
IDs in batch 1: tensor([2156, 1237, 3471, 4057, 2242,  666, 3738, 2180, 2517, 1455, 4072, 3187,
        3891, 4097, 1511,  317])
Epoch: 2447, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2448 - Batch 1 ########################
IDs in batch 1: tensor([2845, 1590, 1618, 4060,  442, 2978, 3497,  281, 3808, 2448,  345, 3757,
        2191,  709, 2884, 3638])
Epoch: 2448, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2449 - Batch 1 ########################
IDs in batch 1: tensor([1672,  740, 1121, 1845, 2711, 2584,  557, 4223, 1990,  904, 3372, 3459,
        1372,  510, 1085, 1005])
Epoch: 2449, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2450 - Batch 1 ########################
IDs in batch 1: tensor([2475, 3847, 2196, 3121,  516, 1711, 3162, 1121, 4108, 2398,  517, 3655,
        3652, 3763, 3538, 2725])
Epoch: 2450, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2451 - Batch 1 ########################
IDs in batch 1: tensor([3073,  188, 2323,   57, 2114,  651, 4039,  380, 1428, 3802, 2419,  263,
         263,  620, 2166, 2773])
Epoch: 2451, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2452 - Batch 1 ########################
IDs in batch 1: tensor([1562,  211, 2666,  269, 4035, 1006,  306, 3535, 1611, 1124,  923, 2851,
        3830, 3275, 3459, 2667])
Epoch: 2452, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2453 - Batch 1 ########################
IDs in batch 1: tensor([1004,   39, 3303, 2638, 3290, 3727, 2046, 3121, 3469,  522, 2848, 1937,
        3871, 2157, 1927,  257])
Epoch: 2453, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2454 - Batch 1 ########################
IDs in batch 1: tensor([2228,  149, 2457, 2770, 3998,  729, 2131, 1949, 3423, 3168,  823, 3265,
        3055,  112,  365, 3065])
Epoch: 2454, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2455 - Batch 1 ########################
IDs in batch 1: tensor([3603, 1168, 3530, 1871, 3621, 2074, 3904, 3204, 3055,  195, 3423, 1793,
         371, 2394, 2051,  508])
Epoch: 2455, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2456 - Batch 1 ########################
IDs in batch 1: tensor([2242,   85,  523, 3514,   47, 4036, 3922, 1185, 2367, 1736, 3343,  872,
        3616, 4039,  245, 2730])
Epoch: 2456, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2457 - Batch 1 ########################
IDs in batch 1: tensor([ 127, 1147,  237, 1779, 3503, 2151, 3755,  384,   61, 4246, 1619,  680,
        1579, 3194, 4003, 3031])
Epoch: 2457, Training Loss: 0.18, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2458 - Batch 1 ########################
IDs in batch 1: tensor([1408, 1895,  693, 3270,  812, 1443, 2157, 2584, 3177,  292, 2349,   31,
         813, 1810, 1306, 2482])
Epoch: 2458, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2459 - Batch 1 ########################
IDs in batch 1: tensor([4038, 3369, 2378, 3881, 1605,  187, 3468, 3069,   97,   97,  260, 1699,
         104, 3304, 3525,  151])
Epoch: 2459, Training Loss: 0.37, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2460 - Batch 1 ########################
IDs in batch 1: tensor([3953,  819, 4061, 1241, 3710,  419,  435, 3942, 1583, 2968,  575, 4026,
         790, 4190, 1008, 3102])
Epoch: 2460, Training Loss: 0.47, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2461 - Batch 1 ########################
IDs in batch 1: tensor([4006,  623, 1959,  489,  993, 1932,  544, 3168, 3638, 2511, 1390,  989,
        1222, 1979, 2433, 4213])
Epoch: 2461, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2462 - Batch 1 ########################
IDs in batch 1: tensor([2483, 3839,  989, 1395, 3471, 3528, 2751, 1027, 1438, 1779, 4086, 2807,
         976, 3793, 2153, 3647])
Epoch: 2462, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2463 - Batch 1 ########################
IDs in batch 1: tensor([2151, 2908, 3876,  642, 2841, 4122, 1244, 2120,  346, 2080, 3184,   47,
        1354,  529, 2453, 1334])
Epoch: 2463, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2464 - Batch 1 ########################
IDs in batch 1: tensor([4024, 4189, 3751,    5,  371, 2856, 1877,  858,  266, 3428,  401, 3037,
         177, 1651, 1671,  438])
Epoch: 2464, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2465 - Batch 1 ########################
IDs in batch 1: tensor([ 455, 1698, 3952, 3244, 2459,  485, 2974, 3818, 4009,   71,  869, 1335,
         544, 3878, 3390, 1877])
Epoch: 2465, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2466 - Batch 1 ########################
IDs in batch 1: tensor([2599, 3742, 2587, 2586, 1938, 1702,  308, 2883,  743, 3489, 1118, 2687,
        3607,  522, 1226,  590])
Epoch: 2466, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2467 - Batch 1 ########################
IDs in batch 1: tensor([3151, 1802, 1001,   99,  510, 2176, 2041, 2207,  244,  183, 1627, 2538,
        1047, 2154, 3940,  282])
Epoch: 2467, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2468 - Batch 1 ########################
IDs in batch 1: tensor([2362,  136,  425, 1250, 3781,  101, 3534, 4168, 2636, 3094,  595, 3374,
         681, 2730,  907, 3661])
Epoch: 2468, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2469 - Batch 1 ########################
IDs in batch 1: tensor([4039, 1672, 1491, 1949, 3478, 3349, 3384, 3190,  834, 1399, 3553, 1754,
        2827, 1530, 1766,  508])
Epoch: 2469, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2470 - Batch 1 ########################
IDs in batch 1: tensor([4005, 3872,  890, 3479,  966, 1444, 4107, 2640,  399, 2338, 3530,  733,
        1291,  642,  316, 4097])
Epoch: 2470, Training Loss: 0.47, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2471 - Batch 1 ########################
IDs in batch 1: tensor([4012, 4212, 2013,  276, 3087,  670, 3714, 1700, 2489,  955, 3564, 2206,
        4223, 2202, 2859, 4200])
Epoch: 2471, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2472 - Batch 1 ########################
IDs in batch 1: tensor([3327, 3760,  515, 1347, 1821,  481, 3020, 1781, 1162, 4040, 3478, 1731,
        2453, 2842, 4086, 3896])
Epoch: 2472, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2473 - Batch 1 ########################
IDs in batch 1: tensor([2300, 3715, 3204, 3336, 3742, 2106, 3058, 1882, 3956, 1910, 4152, 1685,
        2353,   15, 1452, 1399])
Epoch: 2473, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2474 - Batch 1 ########################
IDs in batch 1: tensor([1532, 1685,   64, 3524, 4184, 2065, 3618, 2924, 1103, 2223,  451, 1277,
        1818, 1552, 2416, 2104])
Epoch: 2474, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2475 - Batch 1 ########################
IDs in batch 1: tensor([2591, 1596,  451, 2458, 2847, 3421, 3749, 4217,  955, 1414,  150, 1212,
          72, 1374, 1699, 2475])
Epoch: 2475, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2476 - Batch 1 ########################
IDs in batch 1: tensor([4073, 3002,   84,  112,  444, 2828, 2183, 3762,  662, 2581, 1041,  625,
        1665, 3264, 3381, 1453])
Epoch: 2476, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2477 - Batch 1 ########################
IDs in batch 1: tensor([4165, 3016, 3311, 2763,  709, 4077,  985,  775,   73, 3006, 2752, 3282,
        4058, 1756, 1825, 2046])
Epoch: 2477, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2478 - Batch 1 ########################
IDs in batch 1: tensor([ 325,  872, 2116,  243,  942,  888, 3627,  965,  213, 1508, 3858, 3130,
         993, 3388,  137, 1177])
Epoch: 2478, Training Loss: 0.45, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2479 - Batch 1 ########################
IDs in batch 1: tensor([ 829, 2448, 1185, 2844, 3317, 1212, 3913, 3081, 3637, 4000, 2624, 2095,
        3022,  531, 2305,  622])
Epoch: 2479, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2480 - Batch 1 ########################
IDs in batch 1: tensor([1935,  572, 2331, 3250, 3702,   20, 3344, 1189, 2118, 3160,  563, 1442,
        3933, 2180, 2568, 2574])
Epoch: 2480, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2481 - Batch 1 ########################
IDs in batch 1: tensor([3146, 1334,  170, 3404, 3714, 1605, 3533, 4114,  283, 3939,  814,  363,
        1927, 2236, 4154, 1023])
Epoch: 2481, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2482 - Batch 1 ########################
IDs in batch 1: tensor([ 260, 2741, 2010, 1379, 1354, 2727, 2545, 3489, 2646,  982, 1500,  961,
        1953, 3525,  834, 3988])
Epoch: 2482, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2483 - Batch 1 ########################
IDs in batch 1: tensor([1967,  805, 3644, 2469, 1374, 2963,  751, 1132, 1618,  221, 3351,  341,
        3352, 3018, 2173,  656])
Epoch: 2483, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2484 - Batch 1 ########################
IDs in batch 1: tensor([3767, 1374, 2943,  335, 2363,  606, 1052, 3110, 2980, 3139, 2497, 1918,
        3022, 1444, 4050, 1668])
Epoch: 2484, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2485 - Batch 1 ########################
IDs in batch 1: tensor([ 630, 3558, 3782,  766, 3977, 4118,   32, 2125, 3072,  516, 2746, 1855,
        2812,  196,  194, 2094])
Epoch: 2485, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2486 - Batch 1 ########################
IDs in batch 1: tensor([1596,  771,  838, 2961, 1984, 3329, 3102, 1740, 3428, 1448,  990,  823,
        1512, 1641,  656, 2119])
Epoch: 2486, Training Loss: 0.39, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2487 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2859, 2710,  628, 3572, 4049, 3072,  130, 3002,  981, 2777, 1897,
        1236, 3000, 1693, 2643])
Epoch: 2487, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2488 - Batch 1 ########################
IDs in batch 1: tensor([1034,  302,  357, 1773, 2869,  602, 3027, 2980, 2891, 1710, 2228, 2387,
        2253, 2204, 4172,  609])
Epoch: 2488, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2489 - Batch 1 ########################
IDs in batch 1: tensor([3458,  830,  627, 3655, 2437, 1949, 3640, 1073, 2004, 4249,  808, 3376,
        4048, 1774, 1734, 1934])
Epoch: 2489, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2490 - Batch 1 ########################
IDs in batch 1: tensor([ 236,  787, 3888, 4024, 3860, 3618, 3279, 4128, 1481,  864, 1351, 3241,
        3998,  130, 4126,  513])
Epoch: 2490, Training Loss: 0.59, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2491 - Batch 1 ########################
IDs in batch 1: tensor([1130,  594, 3098, 2218, 4038,  234,  512, 1406, 3423, 1175, 2019,  206,
         645,  496,  376, 2188])
Epoch: 2491, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2492 - Batch 1 ########################
IDs in batch 1: tensor([2558, 1670, 2039, 2978, 3364, 2492,   60,  469,  245, 3987, 2124, 2620,
        1226, 3417,  498, 1025])
Epoch: 2492, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2493 - Batch 1 ########################
IDs in batch 1: tensor([1051, 4068,  609, 3643,  644, 1677, 3617, 1678,  968,  875, 2459, 3278,
        2938, 1896, 1660, 1836])
Epoch: 2493, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2494 - Batch 1 ########################
IDs in batch 1: tensor([1556, 4230, 2207,  320, 2822, 1443, 1063, 3549, 3146, 2306, 2067, 2996,
        3911, 2135, 2577,  687])
Epoch: 2494, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2495 - Batch 1 ########################
IDs in batch 1: tensor([  77, 1276, 4086, 3390, 3693, 2257, 2455,  584,  577, 4049, 1260, 2791,
        2498,  196,  368, 2882])
Epoch: 2495, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2496 - Batch 1 ########################
IDs in batch 1: tensor([1932, 3987, 2761, 2456,  835, 1781, 2871, 1950, 1700, 3996, 3032,  546,
         904, 3982, 1015, 1104])
Epoch: 2496, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2497 - Batch 1 ########################
IDs in batch 1: tensor([1103, 2249, 3202,   57, 2045, 3323, 2986, 4267,  343,  547,  266, 3016,
        1634, 4240, 3652, 2844])
Epoch: 2497, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2498 - Batch 1 ########################
IDs in batch 1: tensor([1680,  828, 3473,  937, 3372,   28,  666, 1732, 1755, 3526, 2157, 2721,
         763, 3589, 3364, 1305])
Epoch: 2498, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2499 - Batch 1 ########################
IDs in batch 1: tensor([2824,  804,  378, 1808, 2087, 1214,  645, 2945, 3049,  278, 1233,   49,
        4077, 2758, 1168, 3009])
Epoch: 2499, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2500 - Batch 1 ########################
IDs in batch 1: tensor([2276, 1588, 4138,  832, 3669, 3754,  878, 2217, 1437, 1425, 2257, 2736,
        3146, 1991, 2383, 1495])
Epoch: 2500, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2501 - Batch 1 ########################
IDs in batch 1: tensor([ 318, 1495, 2354, 1954,   11, 3447, 1710,  966, 2723, 3757, 2659, 2575,
         739, 4082, 2866, 2327])
Epoch: 2501, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2502 - Batch 1 ########################
IDs in batch 1: tensor([2476, 1226,  843, 4135, 1824,   20, 3726, 3372,   74, 2954, 3501,  803,
        3395, 2070, 2435, 2524])
Epoch: 2502, Training Loss: 0.38, Validation Loss: 0.82, accuracy = 0.68
######################## Epoch 2503 - Batch 1 ########################
IDs in batch 1: tensor([4084, 1982, 3624,  945, 2003, 4097, 1402, 3278, 2493, 1093,  369, 4103,
        2039, 2113, 1098, 3489])
Epoch: 2503, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2504 - Batch 1 ########################
IDs in batch 1: tensor([4126,  914, 1777, 1155,   85,  909,  332, 3387,  171, 1644, 2703, 3570,
        2542, 3452,  727, 3912])
Epoch: 2504, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2505 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3701, 3970, 3782, 3141, 2462, 2974, 2583, 3379, 2117,  749, 1321,
         988, 4220, 2931,  180])
Epoch: 2505, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2506 - Batch 1 ########################
IDs in batch 1: tensor([2344,  375, 3425,  151,  682,  980, 3573,  574, 3503, 4110,  320, 1954,
        3545, 3777,  632,  488])
Epoch: 2506, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2507 - Batch 1 ########################
IDs in batch 1: tensor([2866, 1153, 3344,  496,  476, 1526, 2706,  522, 3782,  436, 4007, 3656,
        2378, 4215, 3767, 3185])
Epoch: 2507, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2508 - Batch 1 ########################
IDs in batch 1: tensor([2857, 3661, 2399, 1732,   21, 4220, 3058,  276, 1830, 2770, 4027, 2466,
         138, 3919, 3010,  880])
Epoch: 2508, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2509 - Batch 1 ########################
IDs in batch 1: tensor([4189, 3002,  365, 2358,  238, 3527, 3314, 1160,  137, 1954, 2399, 2470,
        3338, 2511, 1352, 2157])
Epoch: 2509, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2510 - Batch 1 ########################
IDs in batch 1: tensor([3523, 3764,  819, 1502,  471,  957, 3082, 2828, 1746,  825, 4011, 1953,
        2247, 1379, 1649, 2869])
Epoch: 2510, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2511 - Batch 1 ########################
IDs in batch 1: tensor([1333, 3573, 2577, 3994, 2629, 3387, 4197, 3731, 2013, 3738, 2520, 3390,
        3473,  980, 1777, 2171])
Epoch: 2511, Training Loss: 0.28, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2512 - Batch 1 ########################
IDs in batch 1: tensor([3795, 3977, 3353,  412, 1415,  846, 4105, 2025,  894, 2467,  365, 3057,
         305, 3859, 3286, 1081])
Epoch: 2512, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2513 - Batch 1 ########################
IDs in batch 1: tensor([3542, 2050, 1006, 2431, 2649,  484, 1474, 2343, 2760,  590, 1973, 2446,
         312, 3355, 3635,   31])
Epoch: 2513, Training Loss: 0.35, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2514 - Batch 1 ########################
IDs in batch 1: tensor([2166, 2738, 2091,  456, 2514, 1885, 1880, 3705, 2284, 3275, 1285, 1623,
        3455, 4107, 2523, 3101])
Epoch: 2514, Training Loss: 0.54, Validation Loss: 0.77, accuracy = 0.70
######################## Epoch 2515 - Batch 1 ########################
IDs in batch 1: tensor([3407, 1855, 3321, 2656,  308, 3409, 1452,  821, 3815, 2386, 1028, 3942,
        4159, 2740, 2736,  519])
Epoch: 2515, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2516 - Batch 1 ########################
IDs in batch 1: tensor([ 529, 1385, 3388, 3529, 2592, 3065, 3373,  919,  352, 1665, 3114,  186,
        3765, 1428, 1206, 2969])
Epoch: 2516, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2517 - Batch 1 ########################
IDs in batch 1: tensor([2712, 1723,  808, 3299, 2219, 1673, 1764, 3754,  822, 2322,  937, 1700,
        1322,  536,  470, 1092])
Epoch: 2517, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2518 - Batch 1 ########################
IDs in batch 1: tensor([3764, 3683,  680, 2760,  846, 3526, 2141, 3183, 3545, 2199, 1650,  682,
        1108,  992,  408, 2723])
Epoch: 2518, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2519 - Batch 1 ########################
IDs in batch 1: tensor([1745, 4144, 1273,  508, 1718,  687, 2450, 1452, 1361, 2199, 1213,  635,
         384,  323,  523, 3363])
Epoch: 2519, Training Loss: 0.41, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2520 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 2736,  171,  112,  673, 3479, 3417, 2178, 3668, 3468, 1234, 1740,
         325,  137, 3028, 2170])
Epoch: 2520, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2521 - Batch 1 ########################
IDs in batch 1: tensor([2255, 3078,  541, 4087, 4136, 3184,  886, 4085,  224, 3208, 2872,  203,
         462, 1117,  335, 2116])
Epoch: 2521, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2522 - Batch 1 ########################
IDs in batch 1: tensor([1872, 2030, 1574,  481, 1360,  833, 3518, 2219, 4007, 2737,  724, 3667,
         417, 2883, 1730, 2366])
Epoch: 2522, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2523 - Batch 1 ########################
IDs in batch 1: tensor([ 990, 2133, 1037, 1780, 2167, 2649, 4185, 1925,  595, 2408,  138, 2696,
        3475, 3185, 3369,  843])
Epoch: 2523, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2524 - Batch 1 ########################
IDs in batch 1: tensor([3521,  541,  193, 2314, 3544, 1959, 1292, 4141, 4076, 2408, 1496, 4235,
        3329, 1628,  937, 1991])
Epoch: 2524, Training Loss: 0.26, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2525 - Batch 1 ########################
IDs in batch 1: tensor([ 341,  738,  674, 1395, 1970, 1402, 3443, 3040, 4189, 3227, 1012, 2723,
         774, 1764, 1884, 1938])
Epoch: 2525, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2526 - Batch 1 ########################
IDs in batch 1: tensor([1374,  965, 2487,  714, 1960, 2244, 2520, 1965, 2275, 1065, 2209,  828,
        3370, 2539,  660, 2957])
Epoch: 2526, Training Loss: 0.37, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2527 - Batch 1 ########################
IDs in batch 1: tensor([1022, 2334, 2927, 2764, 1597, 1032, 4105, 2842, 1423,  603, 1925, 2960,
        2408,  773,  689, 3841])
Epoch: 2527, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2528 - Batch 1 ########################
IDs in batch 1: tensor([  26, 1901, 3827, 1434, 3110, 1779, 2017, 3264, 3618, 3777, 3658, 3898,
        2256,  335, 3084, 3278])
Epoch: 2528, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2529 - Batch 1 ########################
IDs in batch 1: tensor([3017,  897,  459,  333, 2102, 2121, 2727,  181, 3077, 2103, 3036, 3006,
        1318, 1043,  842,  665])
Epoch: 2529, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2530 - Batch 1 ########################
IDs in batch 1: tensor([1014, 1308, 3536, 4085, 3838, 4194,  325, 2436, 3044, 2851, 2953, 4156,
        2660, 3976,  843, 3283])
Epoch: 2530, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2531 - Batch 1 ########################
IDs in batch 1: tensor([2782, 3009,  773,  152, 2758,  954,  474, 1625, 1404, 4213, 4038, 2114,
        2031, 2393, 3065, 2181])
Epoch: 2531, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2532 - Batch 1 ########################
IDs in batch 1: tensor([2680,  335, 2249, 2309, 1730, 3484, 3953,  432,  805, 2700, 2238, 2845,
        1762, 1716, 2828, 3729])
Epoch: 2532, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2533 - Batch 1 ########################
IDs in batch 1: tensor([4266, 4099, 2046, 3984, 2114, 3647, 3143, 2185, 2031, 3536, 3630, 1611,
          15, 1050, 1015, 3926])
Epoch: 2533, Training Loss: 0.28, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2534 - Batch 1 ########################
IDs in batch 1: tensor([1948, 3472, 3895, 1085, 4119,  441, 1872, 1070, 1834, 3267, 4013, 2046,
        2689, 2969, 1467, 3190])
Epoch: 2534, Training Loss: 0.36, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2535 - Batch 1 ########################
IDs in batch 1: tensor([2913, 2558, 4117, 2965, 1592,  348,  822, 3003, 3384,  375, 3226, 3886,
         747, 3446, 1454, 2510])
Epoch: 2535, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2536 - Batch 1 ########################
IDs in batch 1: tensor([1122, 1927,  563, 2014,  341, 4018, 3275, 2393, 3251, 1244, 4061, 4031,
        3883, 1755,  399, 3052])
Epoch: 2536, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2537 - Batch 1 ########################
IDs in batch 1: tensor([1777, 3827, 3984, 1273, 3121, 3543,  732, 1418, 3112, 3865, 1234, 3476,
         739,  121, 1921, 2378])
Epoch: 2537, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2538 - Batch 1 ########################
IDs in batch 1: tensor([1698, 3598, 1008,  676, 2727, 3452, 1640,   47, 3094,  594,  569, 1708,
        4005,  523, 1171, 2789])
Epoch: 2538, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2539 - Batch 1 ########################
IDs in batch 1: tensor([3504, 2339,   72, 3308, 1635, 1420,  891,  412, 1824, 2727, 2232,  837,
        2984, 3121, 2544, 2086])
Epoch: 2539, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2540 - Batch 1 ########################
IDs in batch 1: tensor([ 854, 1225, 3484, 3795, 3321, 1491, 3743, 1128, 1391, 1037, 2761,  497,
        2764,  788, 3707, 1810])
Epoch: 2540, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2541 - Batch 1 ########################
IDs in batch 1: tensor([3180, 3715, 2523, 1180, 2428,  704, 1413, 3469, 3541, 2741, 3495, 3607,
        2169, 3071, 2890, 1318])
Epoch: 2541, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2542 - Batch 1 ########################
IDs in batch 1: tensor([2854, 2574, 2219, 2514, 1734,  470, 2887, 2290, 3027,  583,  636, 1450,
         809, 3747, 1869,  895])
Epoch: 2542, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2543 - Batch 1 ########################
IDs in batch 1: tensor([1944, 2019, 4168, 2873, 1160, 3071, 1802, 2031, 3219, 1796, 2546, 2327,
        4146, 4143, 1124, 2539])
Epoch: 2543, Training Loss: 0.48, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2544 - Batch 1 ########################
IDs in batch 1: tensor([1028, 2555, 3567, 3521, 2767, 3693, 3021,  924, 2433,  657, 3964, 1810,
        2610, 3472,  577,  413])
Epoch: 2544, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2545 - Batch 1 ########################
IDs in batch 1: tensor([1859,  390,  977, 2648, 3749, 2968, 3706,  532, 2710, 1179, 2754, 1236,
        3192, 3628, 3404, 2133])
Epoch: 2545, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2546 - Batch 1 ########################
IDs in batch 1: tensor([ 878, 2344, 2066, 3401, 2261,  945,  723, 2872, 3382, 3047, 2991, 1438,
        3746, 3804, 3467, 1395])
Epoch: 2546, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2547 - Batch 1 ########################
IDs in batch 1: tensor([3101, 1583, 3279,  811, 2117, 3886, 1309, 2044,  102, 1322, 2067,  184,
        3511, 1958, 3902, 1821])
Epoch: 2547, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2548 - Batch 1 ########################
IDs in batch 1: tensor([2081, 2035, 3141, 3785,  490, 2795, 2415, 1075,  338, 3765, 1250, 3810,
        2884, 1646,  553, 3242])
Epoch: 2548, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2549 - Batch 1 ########################
IDs in batch 1: tensor([1640, 2706,  390, 1177,  539, 2740, 1994, 1007, 3499, 2797, 1566, 1415,
         890, 2605, 1147, 3235])
Epoch: 2549, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2550 - Batch 1 ########################
IDs in batch 1: tensor([1700, 1861, 2847, 2517,  976,  412, 4227, 3995,  919, 1467, 2795, 1004,
        3236,  308,  450, 2724])
Epoch: 2550, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2551 - Batch 1 ########################
IDs in batch 1: tensor([1532, 2459, 1647,  159, 2315, 3616, 2024,  289, 3936, 1139,  830, 2504,
        1481, 1680, 1399,  180])
Epoch: 2551, Training Loss: 0.26, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2552 - Batch 1 ########################
IDs in batch 1: tensor([3971, 1118, 1975, 2359, 3712,  411, 2599, 3947, 3930,  497,  413,  295,
        3384,  466,  354, 3932])
Epoch: 2552, Training Loss: 0.33, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2553 - Batch 1 ########################
IDs in batch 1: tensor([ 920, 1952, 1320, 3591, 1660, 1710,  300, 3876,   37, 1387, 1740, 2028,
        3781, 1804, 3551, 2937])
Epoch: 2553, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2554 - Batch 1 ########################
IDs in batch 1: tensor([1336, 1896, 1092, 3839, 1226, 1927, 1894, 2254, 3992, 1371, 4051, 2271,
        2997, 3528, 1644, 1467])
Epoch: 2554, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2555 - Batch 1 ########################
IDs in batch 1: tensor([2854, 1506, 1830, 1802, 2618, 1051, 1171, 3634, 1024, 2034, 3995, 1391,
        1216, 3467, 1085, 4267])
Epoch: 2555, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2556 - Batch 1 ########################
IDs in batch 1: tensor([ 376, 2035, 3949,  526, 1282, 1285, 3087, 2926, 2514, 2591, 1136,  132,
        1909,  763, 3961, 2670])
Epoch: 2556, Training Loss: 0.52, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2557 - Batch 1 ########################
IDs in batch 1: tensor([3060, 4232, 4195, 1730, 2498, 2646,  477, 1421, 3018, 2921, 1032, 2072,
         981, 1852, 4139, 3436])
Epoch: 2557, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2558 - Batch 1 ########################
IDs in batch 1: tensor([3815,  730, 2519, 2629,  607,   61, 1180,  557, 1957, 1795,   82,  658,
         577,  474, 1045, 2800])
Epoch: 2558, Training Loss: 0.41, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2559 - Batch 1 ########################
IDs in batch 1: tensor([2419, 2680, 3204, 2449, 3220, 3016, 4038, 2226,  943, 3485, 2180,  930,
        1766, 3003,  796, 1871])
Epoch: 2559, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.72
######################## Epoch 2560 - Batch 1 ########################
IDs in batch 1: tensor([1374, 2857,  402, 1186, 3974, 1956, 2599, 1517, 2863, 1728,  384,  557,
         812, 2444,  637, 2575])
Epoch: 2560, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2561 - Batch 1 ########################
IDs in batch 1: tensor([2917,    5, 2149,  684, 1675, 1953,  987, 3030, 3793, 2204, 1663, 1949,
        2621,  591, 4053,  537])
Epoch: 2561, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2562 - Batch 1 ########################
IDs in batch 1: tensor([ 205, 3399, 1504,  672, 2141, 1067,  138, 3141,  709, 2144, 4174,  699,
         358, 2350, 3190, 1352])
Epoch: 2562, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2563 - Batch 1 ########################
IDs in batch 1: tensor([3144, 2074, 1686, 2782, 1022, 1981, 3314, 3989, 3904, 2449,   18, 2668,
         813,  830,  978, 1720])
Epoch: 2563, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.72
######################## Epoch 2564 - Batch 1 ########################
IDs in batch 1: tensor([2223, 2206, 1862,  281, 4033, 1349, 2376, 2584, 3834, 1545, 4267, 4115,
         365,  974,  691, 1965])
Epoch: 2564, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2565 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 4232, 2894, 3236, 2914,  320, 2039,  211, 2423, 2993, 2817, 1904,
        1315, 1328,  510, 3904])
Epoch: 2565, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2566 - Batch 1 ########################
IDs in batch 1: tensor([ 122, 2242, 1119, 1005,  857,  524, 2213, 1763,  660, 1051,  213, 1103,
         459, 2840, 2802, 1849])
Epoch: 2566, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2567 - Batch 1 ########################
IDs in batch 1: tensor([3242, 3009, 3188, 2998, 3398, 1317, 1037, 2565,  642, 2064, 1010,  149,
         490, 3521, 2510, 1156])
Epoch: 2567, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2568 - Batch 1 ########################
IDs in batch 1: tensor([2568,  626, 2701,  880, 1270,  193,  300,  281,  345,  140,  489, 2542,
        3091,  337,  944, 4002])
Epoch: 2568, Training Loss: 0.42, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2569 - Batch 1 ########################
IDs in batch 1: tensor([1322, 3638, 4061, 2278, 1072, 1996,  552, 2642, 4218, 3675,  516,  180,
        3962, 3683, 3334, 3120])
Epoch: 2569, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2570 - Batch 1 ########################
IDs in batch 1: tensor([2085,  191, 2177,  944,  663, 2462,  247, 2354, 3123, 1417, 1933, 2953,
         379, 2641,  858, 2940])
Epoch: 2570, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2571 - Batch 1 ########################
IDs in batch 1: tensor([ 547,  151, 3988, 3875,  943, 3533, 1778, 1722,  792, 2464, 2517, 3753,
        2119,  128, 1041, 4100])
Epoch: 2571, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2572 - Batch 1 ########################
IDs in batch 1: tensor([3681, 1419, 2317, 3117, 3956, 2477, 2131,  199,  819, 1075, 1222, 2209,
        4088,  926, 3869,  946])
Epoch: 2572, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2573 - Batch 1 ########################
IDs in batch 1: tensor([2435, 4213, 2417, 3869, 2183,   86,  880, 4095,  345, 2373, 2148,  832,
        1764, 2423, 1993,  969])
Epoch: 2573, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.70
######################## Epoch 2574 - Batch 1 ########################
IDs in batch 1: tensor([ 881,  397, 2842, 2824, 2523,  224, 1825, 3883,  379, 3318,  673,  155,
        3558,  888, 2276, 2484])
Epoch: 2574, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.70
######################## Epoch 2575 - Batch 1 ########################
IDs in batch 1: tensor([2825, 2371,   38, 1519,  448,  974, 4108, 2787, 2924, 1445,   11, 2913,
         306, 2917,  113, 2559])
Epoch: 2575, Training Loss: 0.40, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2576 - Batch 1 ########################
IDs in batch 1: tensor([2521, 2914,   61,  904, 1122, 4101,  531,  953, 2494,  384, 2056, 1570,
        4256, 3206, 3537, 2154])
Epoch: 2576, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2577 - Batch 1 ########################
IDs in batch 1: tensor([ 322, 2149, 1525, 2868, 3187, 1016,  892, 1163, 3152, 1567,  346,  781,
        3110, 2415,  425, 2391])
Epoch: 2577, Training Loss: 0.27, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2578 - Batch 1 ########################
IDs in batch 1: tensor([2723,   64, 2589, 2067,  658, 2734, 4257,  785, 2370, 4154,  424,   57,
        3504,  303, 1472, 3334])
Epoch: 2578, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2579 - Batch 1 ########################
IDs in batch 1: tensor([  30, 3654, 2035, 1286, 3478, 3581, 2091, 3870, 1171, 4227,  348,  517,
        3871, 4035, 3789, 3355])
Epoch: 2579, Training Loss: 0.46, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2580 - Batch 1 ########################
IDs in batch 1: tensor([1237,  415, 4212, 2118, 1974,  306,  667, 1870, 1340, 3356, 1546,  401,
        1965, 1073, 3390,  327])
Epoch: 2580, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2581 - Batch 1 ########################
IDs in batch 1: tensor([1044, 4002, 1457, 1895,   41,  818, 2536, 3030,  532, 2018,  814, 4093,
        2715, 3192, 1010,  135])
Epoch: 2581, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2582 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 1766, 2890, 2316,  101,  243, 3742, 3342,  590,  470, 3444, 3020,
        3401, 2932, 2017, 3466])
Epoch: 2582, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2583 - Batch 1 ########################
IDs in batch 1: tensor([1469, 3366, 3675, 2212, 3313, 1502, 2314, 2836, 3636, 2644,  773, 1751,
        2582, 2866,  167, 2978])
Epoch: 2583, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2584 - Batch 1 ########################
IDs in batch 1: tensor([1993, 1421, 3451, 2957,  848, 2664, 2117, 3360, 1672, 3349, 3471, 3037,
        2650, 2462, 1945, 1937])
Epoch: 2584, Training Loss: 0.76, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2585 - Batch 1 ########################
IDs in batch 1: tensor([1921, 1271, 3408, 3521, 2387,  257, 3239, 1097, 2356, 4230, 4115, 3323,
        2793, 2363, 1239, 2879])
Epoch: 2585, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2586 - Batch 1 ########################
IDs in batch 1: tensor([1009,  498, 2298,  908, 2645, 1318, 1216,  476,  170, 1404, 1244, 2102,
        3532, 3942, 3676, 4220])
Epoch: 2586, Training Loss: 0.24, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2587 - Batch 1 ########################
IDs in batch 1: tensor([1117,  751, 1975,  914, 4148, 2247, 4099, 3470, 1363, 1157, 1678, 1916,
        2796, 2355, 2286,  161])
Epoch: 2587, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2588 - Batch 1 ########################
IDs in batch 1: tensor([1067,  426, 2498,  338, 2870,  388, 2954, 2388,   57, 3738, 2179,  496,
        1704, 3037, 2366, 2199])
Epoch: 2588, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2589 - Batch 1 ########################
IDs in batch 1: tensor([3996,  915,  399, 1374,  554, 2354, 2372, 2619,   74, 2643, 2461, 1600,
        3092, 3119, 1250, 2659])
Epoch: 2589, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2590 - Batch 1 ########################
IDs in batch 1: tensor([ 717, 1591, 2791, 1128,  848,  324,  535,  314, 2938,    5,  337, 3597,
         851,  730, 2154, 1959])
Epoch: 2590, Training Loss: 0.31, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2591 - Batch 1 ########################
IDs in batch 1: tensor([3250, 3264, 2599, 3885,  463, 2726, 1057, 1289, 4173, 2764, 1355, 2500,
         211,   44, 2678, 3610])
Epoch: 2591, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2592 - Batch 1 ########################
IDs in batch 1: tensor([2348, 4051, 3290, 3115, 1562,  260, 2627,  741,   22, 2859,  909, 1501,
        2440,  732, 1099,  236])
Epoch: 2592, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2593 - Batch 1 ########################
IDs in batch 1: tensor([3367, 2125, 2805, 2305,  391, 1318, 3709,  757,   28, 2420, 2858,  527,
        2346,  467,  398, 2370])
Epoch: 2593, Training Loss: 0.18, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2594 - Batch 1 ########################
IDs in batch 1: tensor([2574, 2999, 2965,  122,  251, 3769, 1373, 1455, 2742,  982, 1452, 1512,
        2003,  135,  274, 1971])
Epoch: 2594, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2595 - Batch 1 ########################
IDs in batch 1: tensor([3614, 4242, 1408, 2038, 1438, 2145,  384, 2600, 2286, 1333, 1097, 1463,
        1415, 1420, 2366, 1911])
Epoch: 2595, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2596 - Batch 1 ########################
IDs in batch 1: tensor([2444, 1852, 2386, 2600, 1116, 2973, 1248, 3603, 2857, 3672, 3220, 2565,
        3795, 2085, 3112, 1075])
Epoch: 2596, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2597 - Batch 1 ########################
IDs in batch 1: tensor([1972, 2579,  930, 1493, 3714, 1506, 1279, 3021, 4265, 3781,  376, 3505,
        3600, 2013, 3680,  835])
Epoch: 2597, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2598 - Batch 1 ########################
IDs in batch 1: tensor([ 965, 1904,  432, 1429,  371,   10, 1076,  225, 1472, 1218, 3458, 2458,
        1088, 4022, 2577, 2701])
Epoch: 2598, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2599 - Batch 1 ########################
IDs in batch 1: tensor([ 854,  325, 1752, 2203, 3850, 1869, 1053, 1473, 2902, 1799,  803, 3251,
        3020, 2086, 1007,  342])
Epoch: 2599, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2600 - Batch 1 ########################
IDs in batch 1: tensor([2695, 3792,  649, 1351, 1753, 3378, 2191, 2081, 3721, 1182, 4027, 2860,
        1638, 1726, 2680, 3047])
Epoch: 2600, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2601 - Batch 1 ########################
IDs in batch 1: tensor([3754,  981, 1076, 2500, 4229,  170, 3744, 1198, 1891, 3114,   97, 1153,
        3760, 2074, 1124, 2800])
Epoch: 2601, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2602 - Batch 1 ########################
IDs in batch 1: tensor([3769, 3866,  813, 2960, 1457, 2394, 1066, 3762, 1679, 3364, 1209, 2649,
        3738, 2149,  735,  359])
Epoch: 2602, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2603 - Batch 1 ########################
IDs in batch 1: tensor([2667, 3960, 1755, 4024, 4158, 3920, 2376, 3289,  982, 3813, 1646, 3162,
         960, 3312, 2661, 2005])
Epoch: 2603, Training Loss: 0.37, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2604 - Batch 1 ########################
IDs in batch 1: tensor([  15, 1718, 3753, 2465, 4175, 2873, 2777, 3621, 2815, 4060, 1481, 4224,
        4033, 2355, 2538, 2344])
Epoch: 2604, Training Loss: 0.37, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2605 - Batch 1 ########################
IDs in batch 1: tensor([2064, 2342, 3065, 1628, 2066,  897, 2331,  402,  554, 3264, 4128, 3208,
        1098, 3866, 3698, 3607])
Epoch: 2605, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2606 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 2323, 3928, 3216, 1640, 2223, 2324,  361, 2708, 2838, 3484, 2123,
        3258, 3038, 1614,  573])
Epoch: 2606, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2607 - Batch 1 ########################
IDs in batch 1: tensor([1536,   72, 3652, 1171, 4212, 1337, 1434, 2595, 2428, 2535,  637, 2603,
        1024, 3055, 2575,  578])
Epoch: 2607, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2608 - Batch 1 ########################
IDs in batch 1: tensor([2519,   99, 2568, 2783, 1445,  444, 3251,   20, 1589, 1777, 3489, 1180,
        2894, 2405,  201,  207])
Epoch: 2608, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2609 - Batch 1 ########################
IDs in batch 1: tensor([1938, 3218, 2810, 4107, 1861,  894, 1763, 1118,   20, 2182,  832,  962,
        2202, 2924, 1437, 2457])
Epoch: 2609, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2610 - Batch 1 ########################
IDs in batch 1: tensor([1345,  878,  955, 2148,  991, 2193,  456, 3721, 3635, 1724,  594,  100,
        3009, 1740, 1736, 4158])
Epoch: 2610, Training Loss: 0.36, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2611 - Batch 1 ########################
IDs in batch 1: tensor([2087,  807,  171,  915,  149, 2804, 2431, 1122, 3790, 1042, 3494,  601,
         660, 3208, 4026, 1878])
Epoch: 2611, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2612 - Batch 1 ########################
IDs in batch 1: tensor([ 292, 2328,  218, 2375, 3458, 1984,  341, 3499,  963, 1857, 1493, 2571,
        2444, 1859, 2664, 2905])
Epoch: 2612, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2613 - Batch 1 ########################
IDs in batch 1: tensor([1171, 2656,  946,  955, 3547, 1482, 2589,  923, 4228, 2056, 1589,  132,
        1324, 2210,  149, 2984])
Epoch: 2613, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2614 - Batch 1 ########################
IDs in batch 1: tensor([2806, 3718, 4115, 1704,  594, 4232, 3246, 1493, 3399,   18, 1673, 3919,
        3286, 1351, 1335,  976])
Epoch: 2614, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2615 - Batch 1 ########################
IDs in batch 1: tensor([1143, 2854, 3214, 1569,  200, 2151, 2683, 2063,  226, 1736,  967, 2463,
        2872, 1519, 1502,  661])
Epoch: 2615, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2616 - Batch 1 ########################
IDs in batch 1: tensor([1218, 3018, 3610, 3673, 3511, 1131,  295,  550,  864, 3913, 1779, 2104,
        1084,  620, 2604, 1496])
Epoch: 2616, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2617 - Batch 1 ########################
IDs in batch 1: tensor([1682, 3630, 2509,  635, 1143, 2969,  411, 3177,   11,  805, 1748, 3271,
        1781,  555, 3743, 2965])
Epoch: 2617, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2618 - Batch 1 ########################
IDs in batch 1: tensor([1271,  753,  687, 4218, 2652, 1180, 1320, 3072, 4114,  609, 1371,  896,
        3440, 1093, 2692, 2212])
Epoch: 2618, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2619 - Batch 1 ########################
IDs in batch 1: tensor([2839, 3024, 2552, 2488, 3102, 1024,   25,  269, 2842, 2500, 1986, 2942,
         636,  351, 3677, 1699])
Epoch: 2619, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2620 - Batch 1 ########################
IDs in batch 1: tensor([1711, 3417,  926, 1618, 1351,  274, 1159, 3638, 2277,  482, 2494, 1489,
         533,  851,  820, 1620])
Epoch: 2620, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2621 - Batch 1 ########################
IDs in batch 1: tensor([1679, 1808, 2902, 1643, 3382, 2072,  482, 1201, 4061, 1373, 3527, 3004,
        3197,  863,  426, 3598])
Epoch: 2621, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2622 - Batch 1 ########################
IDs in batch 1: tensor([3498, 2226, 2014, 2159,  191,   26, 2315, 1971,  753, 1391, 3726, 2545,
        3399, 2826,  743, 3220])
Epoch: 2622, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2623 - Batch 1 ########################
IDs in batch 1: tensor([3637, 3847, 4251, 2086,  558, 1510, 1039, 2247, 1092,  691,  757, 3042,
        2372, 1485, 3132,  713])
Epoch: 2623, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2624 - Batch 1 ########################
IDs in batch 1: tensor([3239, 2287, 3947, 2344, 2810, 1143,  645, 2932, 1324, 1273, 1225,  388,
        1049, 2802, 3600, 1977])
Epoch: 2624, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2625 - Batch 1 ########################
IDs in batch 1: tensor([3922,  300, 3997, 2390, 3427, 3604, 1326,  857, 3642, 2408, 2134, 1985,
        1793, 1273, 1242, 3306])
Epoch: 2625, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2626 - Batch 1 ########################
IDs in batch 1: tensor([2961, 2897, 2171, 1285, 1647, 1761, 3049, 2327,  665, 2059,  609, 1168,
          25, 1960, 3377, 3980])
Epoch: 2626, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2627 - Batch 1 ########################
IDs in batch 1: tensor([ 456, 3948, 4217, 4173, 1784, 2581, 2667,  674, 1010, 1772, 2986,  974,
         444, 4122, 3756, 2044])
Epoch: 2627, Training Loss: 0.31, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2628 - Batch 1 ########################
IDs in batch 1: tensor([2982, 2828, 2690, 2853, 3781, 3283, 3793, 3344, 1022, 3616, 1754, 1450,
        1276, 2544, 3827, 3159])
Epoch: 2628, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2629 - Batch 1 ########################
IDs in batch 1: tensor([ 470, 3487, 3823,  527, 1080,  762,   86, 2796,  680, 1821,  588, 4148,
        1087, 3505, 3481, 2295])
Epoch: 2629, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2630 - Batch 1 ########################
IDs in batch 1: tensor([ 440, 3500, 3842, 3176,  640, 2898, 1143, 1332,  946, 2352, 2403, 3529,
        2871, 2379, 3749, 1851])
Epoch: 2630, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2631 - Batch 1 ########################
IDs in batch 1: tensor([2015, 1639,  902,  342,  941, 1623, 2320, 2133,  792, 1802, 1579, 2511,
        2558,  194, 2431, 3832])
Epoch: 2631, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2632 - Batch 1 ########################
IDs in batch 1: tensor([ 781, 1290,  725, 3637, 4033, 3859, 1182, 2278,  330, 3870, 2113, 3886,
         463, 2442,  372, 1508])
Epoch: 2632, Training Loss: 0.29, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2633 - Batch 1 ########################
IDs in batch 1: tensor([3862, 4154, 2504,  790, 3913, 2886, 3704, 3503, 3326,  389, 4117, 2364,
        4117, 3743, 2155, 2739])
Epoch: 2633, Training Loss: 0.52, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2634 - Batch 1 ########################
IDs in batch 1: tensor([ 740, 1225,  902, 2252, 2983, 1133, 3823, 4255, 2620,  774, 2905, 1421,
        1789,  626, 2153, 3672])
Epoch: 2634, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2635 - Batch 1 ########################
IDs in batch 1: tensor([1340, 1571, 2913,   42, 1489, 1684, 4051, 3065, 3577,  849, 1640, 2309,
        3394, 1849, 2969, 3897])
Epoch: 2635, Training Loss: 0.31, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2636 - Batch 1 ########################
IDs in batch 1: tensor([3879,  373, 3960, 2825,  261,   86,  354, 3028, 4203, 2355,  747, 1438,
        1990, 4051, 1617, 2440])
Epoch: 2636, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2637 - Batch 1 ########################
IDs in batch 1: tensor([ 276, 1219, 3958,  251, 3202,  508,  981,  769, 3681, 3479, 4255, 1393,
        3176, 2246, 3465, 3661])
Epoch: 2637, Training Loss: 0.43, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2638 - Batch 1 ########################
IDs in batch 1: tensor([2649, 3098, 3936, 2836, 2132,  101, 1049, 4143, 4267, 3339, 2913, 1417,
        3357, 2485, 2180,  520])
Epoch: 2638, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2639 - Batch 1 ########################
IDs in batch 1: tensor([3437, 1330, 3277, 3421, 3902, 3689,  258,  160,  617, 3693, 2687, 3114,
        2559, 1251, 1282,  198])
Epoch: 2639, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2640 - Batch 1 ########################
IDs in batch 1: tensor([4121, 1767, 2558, 4056, 2195,  415, 3306, 1031, 2329, 1994, 1472, 2234,
        3418, 2885, 2627,  871])
Epoch: 2640, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2641 - Batch 1 ########################
IDs in batch 1: tensor([1056, 1320,  378, 2086, 3159, 3394, 1648, 2157, 2953, 1025, 4046,  407,
          85,  926, 3518, 3031])
Epoch: 2641, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2642 - Batch 1 ########################
IDs in batch 1: tensor([2087, 2537,  714, 3030,  762, 1921, 1599, 2137, 3199, 3200,  558, 2956,
        3333, 1224,  469, 1072])
Epoch: 2642, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2643 - Batch 1 ########################
IDs in batch 1: tensor([3651, 2247, 1672, 1438, 4086, 1610,  203,  173, 1061,  959,  439, 1589,
        1718,  255,  640, 2103])
Epoch: 2643, Training Loss: 0.53, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2644 - Batch 1 ########################
IDs in batch 1: tensor([3400, 3702, 4125, 2466, 4144, 1963, 3123,  111, 3018, 1224, 2754, 1028,
        1795, 2264,  292, 3888])
Epoch: 2644, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2645 - Batch 1 ########################
IDs in batch 1: tensor([ 679, 2065, 2418,  154, 1855,  968, 4126, 3650, 2849, 3440, 2498, 1302,
         582, 3762,  408, 3594])
Epoch: 2645, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2646 - Batch 1 ########################
IDs in batch 1: tensor([2113, 1250, 2388, 3025, 2230, 2261, 1326, 2751, 1490, 2666,  145, 1361,
        4134, 3352,  224,    5])
Epoch: 2646, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2647 - Batch 1 ########################
IDs in batch 1: tensor([3994,  995, 2855, 3020, 3397, 2740, 1594,  593, 1118, 3812, 3695, 1415,
        2453, 2835, 3222, 1761])
Epoch: 2647, Training Loss: 0.35, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2648 - Batch 1 ########################
IDs in batch 1: tensor([ 283, 2855,  516, 3815, 2581,   81, 2248,  666, 3214, 2045, 1343,  475,
        1933,  665, 2700, 2469])
Epoch: 2648, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2649 - Batch 1 ########################
IDs in batch 1: tensor([ 199, 3803, 2085, 2461, 3111, 1626, 1510, 1237, 1436, 3990,  735, 3760,
        3521, 3541, 4046, 1618])
Epoch: 2649, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2650 - Batch 1 ########################
IDs in batch 1: tensor([ 546, 2234, 1450, 1869,  482, 3065,  358, 2041, 1718, 1588, 3397, 1583,
        1116, 2943, 1003, 3545])
Epoch: 2650, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2651 - Batch 1 ########################
IDs in batch 1: tensor([4096,  237,   85, 2550,  152,  318, 2035, 1220,   95, 1026, 3217,  128,
        3511, 1423, 1524, 2088])
Epoch: 2651, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2652 - Batch 1 ########################
IDs in batch 1: tensor([1573, 3379, 2579, 1209, 1651, 2495, 1385, 2671,   32, 2492, 1605, 1789,
         476, 3963, 3712, 1458])
Epoch: 2652, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2653 - Batch 1 ########################
IDs in batch 1: tensor([1833,  507, 3242, 2440, 2419, 1823, 3406, 3406, 2614, 1028, 2008,  789,
        1519,  315, 3829, 2255])
Epoch: 2653, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2654 - Batch 1 ########################
IDs in batch 1: tensor([2934, 3131, 3271, 4223,  606, 2296, 2603, 3648, 1746, 2771, 2794, 3234,
        3387, 3254, 3907,  712])
Epoch: 2654, Training Loss: 0.29, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2655 - Batch 1 ########################
IDs in batch 1: tensor([3812, 3557, 3671, 4022, 2301, 3222, 1092,  757, 3216,   20, 4184, 2936,
        1061,  574, 3329,  714])
Epoch: 2655, Training Loss: 0.34, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2656 - Batch 1 ########################
IDs in batch 1: tensor([2730,  343, 3640, 1916, 2605, 1796, 2367,  441, 4070, 3073, 1193, 2729,
        3640, 1260, 3467, 3446])
Epoch: 2656, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2657 - Batch 1 ########################
IDs in batch 1: tensor([ 947, 1174,  126, 3594, 2435, 1251, 1061,   81, 3643, 1518, 2377,  258,
        2575,   32, 1627,  519])
Epoch: 2657, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2658 - Batch 1 ########################
IDs in batch 1: tensor([3311, 2111, 1282, 3740, 2618,  398,  627, 2796, 3907, 3451, 2763, 1819,
        2423,  971,  709, 2621])
Epoch: 2658, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2659 - Batch 1 ########################
IDs in batch 1: tensor([1228, 3810, 1641,  753, 3936,  363,   98,  290, 3971, 1038, 3131, 3698,
         316, 1702, 4187,  182])
Epoch: 2659, Training Loss: 0.59, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2660 - Batch 1 ########################
IDs in batch 1: tensor([ 427, 2444, 3493, 2172, 4254,  101, 4249, 2034,  315, 2417, 3250, 3375,
        1102, 2710, 2737, 1708])
Epoch: 2660, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2661 - Batch 1 ########################
IDs in batch 1: tensor([4173, 2123, 1440, 3418, 3214, 1512, 3261, 4097,  465, 3002, 2894,  843,
        2605,  838, 2314,  713])
Epoch: 2661, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2662 - Batch 1 ########################
IDs in batch 1: tensor([1849, 2326, 4136,  104, 1991, 1594,  712, 3427, 2191, 2787, 4003, 3636,
        2514, 1913,  892, 2767])
Epoch: 2662, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2663 - Batch 1 ########################
IDs in batch 1: tensor([1853, 2524, 1085, 3734, 1871, 2741, 4179, 1051, 1636, 2306, 2578, 1493,
        1573, 3183, 1832, 2746])
Epoch: 2663, Training Loss: 0.40, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2664 - Batch 1 ########################
IDs in batch 1: tensor([ 753,  434, 1043, 1642,  365,  569, 2645,  758, 1340, 1680, 2804,  450,
          37, 3719, 1648, 2688])
Epoch: 2664, Training Loss: 0.22, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2665 - Batch 1 ########################
IDs in batch 1: tensor([ 646,   70, 1504, 3998,  300, 1004, 1156, 3700, 2718, 2110, 2292, 1419,
         269, 3501, 3490, 1097])
Epoch: 2665, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2666 - Batch 1 ########################
IDs in batch 1: tensor([2092,  815, 3102,  300, 4257,   26, 1003, 1313, 3798, 3661,  228, 1623,
        1999, 3772, 2448, 1746])
Epoch: 2666, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2667 - Batch 1 ########################
IDs in batch 1: tensor([2063, 1335, 1487,  837, 1626,   47, 3073,  674, 2868, 1677, 2145, 2141,
        1508, 1811,  373, 2695])
Epoch: 2667, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2668 - Batch 1 ########################
IDs in batch 1: tensor([ 763, 3015, 3446,  882,  302, 1809, 3787, 2405, 2419, 3446, 3873, 1247,
        3513, 2203, 2436, 1124])
Epoch: 2668, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2669 - Batch 1 ########################
IDs in batch 1: tensor([1730,  376,  228,  733,  689,  557,  437,  425, 1181, 3183,  919, 1716,
        3112, 3698, 2561, 3025])
Epoch: 2669, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2670 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 3785, 2710, 3166, 3370, 2091, 2537, 3389,  177, 4013, 2137,  388,
        3513, 1316, 3214, 2102])
Epoch: 2670, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2671 - Batch 1 ########################
IDs in batch 1: tensor([2579, 3826,  531, 3721, 3115, 2274, 1733, 1552, 1161, 3291,  522, 2284,
        2937, 1324, 3525,  890])
Epoch: 2671, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2672 - Batch 1 ########################
IDs in batch 1: tensor([3202, 3375, 1663, 1102, 4070, 3329, 1682,  276, 3083, 4190, 2563, 3813,
        3117,  252, 2015, 1938])
Epoch: 2672, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2673 - Batch 1 ########################
IDs in batch 1: tensor([2073, 1948, 1470, 4095, 2839, 2102,  135, 1038,  206, 2913,  606, 2853,
        3200, 3256,  756, 1920])
Epoch: 2673, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2674 - Batch 1 ########################
IDs in batch 1: tensor([2777,  463, 1575, 2794, 3897, 2049,  472, 4138, 1611, 1655,  417, 3246,
        3593, 2587, 2558, 4253])
Epoch: 2674, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2675 - Batch 1 ########################
IDs in batch 1: tensor([3439, 3493, 1053, 2901, 1846,  497, 3258, 3166, 4035, 3853, 1308,  792,
        2845, 1152, 3992,  866])
Epoch: 2675, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2676 - Batch 1 ########################
IDs in batch 1: tensor([3382, 2963, 1124, 2983,  481,  321, 2917, 1840,  252, 1179, 3601,  281,
        2148, 4061,  897, 1004])
Epoch: 2676, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2677 - Batch 1 ########################
IDs in batch 1: tensor([1128, 3379,  869, 2872, 2777, 1663, 1718,  552, 2597, 2432, 2315, 2798,
         442, 3394, 1699, 3152])
Epoch: 2677, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2678 - Batch 1 ########################
IDs in batch 1: tensor([1220, 3309, 2355, 2234, 3710,   37,  322,  547, 2151, 3381, 2166, 3278,
         357, 2606, 1982, 2497])
Epoch: 2678, Training Loss: 0.47, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2679 - Batch 1 ########################
IDs in batch 1: tensor([1973, 3870, 3092,  590,   93, 2314, 2871, 1787, 2734, 1410, 2670, 1626,
        1395, 3655,  591,  295])
Epoch: 2679, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2680 - Batch 1 ########################
IDs in batch 1: tensor([1140, 1921, 1005, 2664, 1156, 3818, 3279,  723,  332,  937, 1354, 1355,
        1868, 2298,  838, 3874])
Epoch: 2680, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2681 - Batch 1 ########################
IDs in batch 1: tensor([1976, 2817, 1879, 1047, 1626, 2085, 1755, 1592, 1485,  403, 1351, 3146,
         358, 3078, 2110, 2496])
Epoch: 2681, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2682 - Batch 1 ########################
IDs in batch 1: tensor([1556, 2869, 2526,  902,  662, 2866, 3199,  340, 4198, 3964,  830, 2026,
        2173,  234, 3753, 1467])
Epoch: 2682, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2683 - Batch 1 ########################
IDs in batch 1: tensor([3920, 2053, 1216, 4180, 1372,  367, 3400, 1162, 4038, 1399, 2026,  531,
        2390, 2019, 2232, 1556])
Epoch: 2683, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.70
######################## Epoch 2684 - Batch 1 ########################
IDs in batch 1: tensor([2656, 2587, 3399, 3400,   49, 2620, 1498, 2799, 1630, 2137, 1711,  236,
         100,  434,  750, 2159])
Epoch: 2684, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2685 - Batch 1 ########################
IDs in batch 1: tensor([3902, 2618, 2365, 1625,  786, 3780, 4170, 3658,  171, 2565,  721, 1469,
        1861, 3495, 3872,   72])
Epoch: 2685, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2686 - Batch 1 ########################
IDs in batch 1: tensor([3395,  710, 2155, 2821, 3911,  593, 4017, 2521, 2632,  786, 4030, 4230,
        2271,  422, 1034, 2781])
Epoch: 2686, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2687 - Batch 1 ########################
IDs in batch 1: tensor([3647,  218, 3553, 3159, 1782, 3483,  740, 1605, 1944, 2973, 1730, 3908,
          25,  733, 1088,  344])
Epoch: 2687, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2688 - Batch 1 ########################
IDs in batch 1: tensor([3414, 4214, 3699, 4215, 3188, 1575, 3700, 2676,  726,  770, 2500, 2691,
        1325, 1855, 1510,  483])
Epoch: 2688, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2689 - Batch 1 ########################
IDs in batch 1: tensor([2059, 2711, 4121, 3113, 1121, 1596,  292, 3902, 2196, 1290, 2806, 3841,
        1944, 2721,  102, 1235])
Epoch: 2689, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2690 - Batch 1 ########################
IDs in batch 1: tensor([3286, 2133, 2828, 1493,  455,   97, 1385,  129, 2106,  236,   46, 2783,
        4018,  738,  437, 3831])
Epoch: 2690, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2691 - Batch 1 ########################
IDs in batch 1: tensor([1409, 3433, 3698, 3617, 1285,  535, 2835,  920, 2049, 3658, 2805, 2810,
         947, 4138, 3492, 1808])
Epoch: 2691, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.71
######################## Epoch 2692 - Batch 1 ########################
IDs in batch 1: tensor([3472, 2536,  628, 2902,  503, 2241,  637, 3807,  483, 4264, 1219, 1727,
        3733, 3423, 2026, 1862])
Epoch: 2692, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2693 - Batch 1 ########################
IDs in batch 1: tensor([2429,  730,  899, 2581, 1855, 2107, 3069, 2717, 3091,  398, 1237, 3473,
        3609,  844,  183, 1961])
Epoch: 2693, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2694 - Batch 1 ########################
IDs in batch 1: tensor([3743, 3948, 3262, 4131, 1853, 2480,  717, 1625, 1605, 3379,  317, 1923,
        1122, 1121, 3044, 1134])
Epoch: 2694, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2695 - Batch 1 ########################
IDs in batch 1: tensor([1349,  930,  897, 1331, 2170, 3119, 1291, 3655, 1796, 1700, 1367, 1570,
        3009, 1419, 3343, 4124])
Epoch: 2695, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2696 - Batch 1 ########################
IDs in batch 1: tensor([ 688,  997,  138, 2644, 4036, 2670,   73, 2317, 4009,  145, 1723,  105,
        3161, 3592, 4197, 3398])
Epoch: 2696, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2697 - Batch 1 ########################
IDs in batch 1: tensor([ 251, 2943, 2199,  656, 1493, 4000,  140, 1546, 1844, 3345,  928, 1123,
        2860, 4212, 3466, 3656])
Epoch: 2697, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2698 - Batch 1 ########################
IDs in batch 1: tensor([1347, 2213, 3115, 1548, 2620, 3339, 1678, 3478, 2545, 3713,  869, 3499,
        1341, 2354, 1575, 2202])
Epoch: 2698, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2699 - Batch 1 ########################
IDs in batch 1: tensor([ 244, 4072, 3683, 1393,  749,  926, 2034, 2817, 3659, 4184, 3459, 1186,
         354, 2023, 4036,  478])
Epoch: 2699, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2700 - Batch 1 ########################
IDs in batch 1: tensor([ 763,  260, 2540, 1417,  104,  890,  167, 1326, 3927, 3718,  327,  264,
        1418, 1012, 4213,    7])
Epoch: 2700, Training Loss: 0.64, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2701 - Batch 1 ########################
IDs in batch 1: tensor([2772,  160, 3669, 3287, 2388, 1504, 2391, 2617, 3400, 2706, 3808, 3585,
         545, 3514,  992, 2873])
Epoch: 2701, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2702 - Batch 1 ########################
IDs in batch 1: tensor([3833, 1037, 3852, 2924, 3136, 3188, 3845, 1808,  721, 2056, 3780,  627,
        3018, 1295, 1512, 1123])
Epoch: 2702, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2703 - Batch 1 ########################
IDs in batch 1: tensor([ 936,  995, 1979, 2587, 1521, 1389, 1880, 2817,  261,  955, 4051, 3514,
        1949, 1682,  751, 1144])
Epoch: 2703, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2704 - Batch 1 ########################
IDs in batch 1: tensor([ 483, 3873, 3392, 1103,  445, 3000,  324, 3314, 1133, 3837, 2795, 1649,
        3472, 1354, 3772, 3823])
Epoch: 2704, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2705 - Batch 1 ########################
IDs in batch 1: tensor([1642,  947,  568, 1656, 3468, 4119, 4266, 1340, 3588, 2177,  510, 1646,
        3568, 2423, 4152, 3329])
Epoch: 2705, Training Loss: 0.71, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2706 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 1981, 3721, 2655,  897,  554, 3939,  257, 2887, 2871,  102,  573,
        1372, 2428, 3734, 1934])
Epoch: 2706, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2707 - Batch 1 ########################
IDs in batch 1: tensor([3841, 2924, 3154,  873,  556, 4144, 1274,  518, 3180, 3351,  424, 2378,
        3953, 3015, 1421, 2511])
Epoch: 2707, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2708 - Batch 1 ########################
IDs in batch 1: tensor([3057,  658, 1252, 3461, 1925,  552, 1020, 1213, 3528, 3311, 1665,  363,
        1698,  792, 3700, 3713])
Epoch: 2708, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2709 - Batch 1 ########################
IDs in batch 1: tensor([ 878,  751,  119, 1104, 2008,  846,  942, 3554, 4186, 2980,  109, 1470,
        4060, 3528,  167, 2725])
Epoch: 2709, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2710 - Batch 1 ########################
IDs in batch 1: tensor([3364,  879,  807, 3706, 3762, 2099, 3500,  959, 2017,  812, 2672, 2285,
         946, 2086, 2278, 3706])
Epoch: 2710, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2711 - Batch 1 ########################
IDs in batch 1: tensor([3428, 2761, 2483,  119, 2477, 1126, 2858, 3328, 3245, 1225,  795, 1113,
        3523,    7, 3652, 1595])
Epoch: 2711, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2712 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 3609, 3123,   46, 1077, 3782,  276, 2853, 2104, 3371, 1344, 1206,
         380, 1113,   41, 1376])
Epoch: 2712, Training Loss: 0.34, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2713 - Batch 1 ########################
IDs in batch 1: tensor([2209, 1099,  826, 3511, 2050, 2467, 2051, 2053,  733, 1397, 2332, 2189,
        4072, 2362,  596, 3166])
Epoch: 2713, Training Loss: 0.29, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2714 - Batch 1 ########################
IDs in batch 1: tensor([1189, 2514, 3902, 4015,  463, 1008, 2505, 2408, 3812, 4222,  809,  289,
        1881,  531,  841, 1418])
Epoch: 2714, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2715 - Batch 1 ########################
IDs in batch 1: tensor([ 150, 3594,   30, 3656,  469, 1763, 3702,  630, 1484, 1499, 3333, 2431,
        1158, 1044, 1881, 4012])
Epoch: 2715, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2716 - Batch 1 ########################
IDs in batch 1: tensor([1179, 1020, 1957, 2940,  639, 1841, 2829,  873, 4011, 2581, 2905, 2780,
        2516, 3974, 1633, 3738])
Epoch: 2716, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2717 - Batch 1 ########################
IDs in batch 1: tensor([ 660, 3936, 3283,  141, 2758, 1373, 3214, 2250,  140, 3254, 1393,   74,
        4267, 1862,  726, 2710])
Epoch: 2717, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2718 - Batch 1 ########################
IDs in batch 1: tensor([1932,  805,  161,  229, 2821, 1201, 4227, 2195,  855, 1277,  351, 1851,
        2620, 1278, 1921, 3233])
Epoch: 2718, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2719 - Batch 1 ########################
IDs in batch 1: tensor([1119,  426,  255,  842,  738, 3516, 3444,   72,  324, 1315, 2015, 2238,
        2934,  586, 3435, 1933])
Epoch: 2719, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2720 - Batch 1 ########################
IDs in batch 1: tensor([1559,  709, 3162, 1113, 2309, 2776, 1935, 2600, 3410, 3151,  895, 1957,
        3635, 2886,  822, 2117])
Epoch: 2720, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2721 - Batch 1 ########################
IDs in batch 1: tensor([3150,  796, 1677, 2135, 1886,  122, 1648, 2598, 2241, 2648, 1568, 3531,
        1022, 3217, 1628, 1920])
Epoch: 2721, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2722 - Batch 1 ########################
IDs in batch 1: tensor([1009, 3460, 1952, 3119, 1501, 3969, 4036, 1684,  436, 2092, 1235, 3790,
        2693, 1404, 2360, 2365])
Epoch: 2722, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2723 - Batch 1 ########################
IDs in batch 1: tensor([ 284, 2018, 4246, 3252,  295, 1952, 3456,  109, 4049, 3323, 3723,   14,
         524, 2235, 2203, 1038])
Epoch: 2723, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 2724 - Batch 1 ########################
IDs in batch 1: tensor([2011, 3713, 1241, 2749, 4230, 2731, 3410, 2721, 2103, 2967, 4032, 2937,
         483, 4181, 3837, 3178])
Epoch: 2724, Training Loss: 0.50, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2725 - Batch 1 ########################
IDs in batch 1: tensor([3940, 2387, 3640, 3806, 1204, 4223, 3448, 1552, 2711,  247, 3473,   21,
        3710,  607, 3533, 2641])
Epoch: 2725, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.71
######################## Epoch 2726 - Batch 1 ########################
IDs in batch 1: tensor([2420, 4121,  194, 1110, 3627, 4018, 3398,  813, 3961, 2733, 1879, 1938,
        3240, 1481, 3476, 3746])
Epoch: 2726, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2727 - Batch 1 ########################
IDs in batch 1: tensor([2485, 4087, 3038, 1406, 2331, 1751, 1901,  672, 3717, 3203, 1420, 3922,
        2137, 3087, 1406, 2526])
Epoch: 2727, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2728 - Batch 1 ########################
IDs in batch 1: tensor([1588, 1421,  541,  217, 1671,  121, 2327,  818, 3540,  635, 3872, 3673,
        3594, 3542,  470, 1209])
Epoch: 2728, Training Loss: 0.29, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2729 - Batch 1 ########################
IDs in batch 1: tensor([1384,  963, 2937, 2925, 3452, 4266, 1438, 2517, 1509, 2821, 3409, 4245,
        3228,  788, 3785, 3984])
Epoch: 2729, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2730 - Batch 1 ########################
IDs in batch 1: tensor([3714, 2416, 2860, 1579, 1241, 4179, 1914, 2840,  424, 3127, 3235,   81,
        3310,  701, 3710, 2925])
Epoch: 2730, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2731 - Batch 1 ########################
IDs in batch 1: tensor([2271, 3368,  884, 1918,  607, 3874, 2927,  786, 2541, 1260, 3895, 1832,
        3529, 3390, 1611, 1590])
Epoch: 2731, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2732 - Batch 1 ########################
IDs in batch 1: tensor([2359, 2564,  980,  844, 1932, 3395, 1119, 2610,   70, 3585, 3891, 1406,
        2224, 2023, 3466, 2926])
Epoch: 2732, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2733 - Batch 1 ########################
IDs in batch 1: tensor([1052, 2478, 2232, 3168,  777, 1004, 2696, 2220,  588,  282, 2069,  397,
         673, 1740, 1625, 1525])
Epoch: 2733, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2734 - Batch 1 ########################
IDs in batch 1: tensor([1098,   21, 1585,  835, 2729, 1500, 3253, 2265, 1949,  872, 1440, 3233,
         507, 1316, 4007, 2610])
Epoch: 2734, Training Loss: 0.26, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 2735 - Batch 1 ########################
IDs in batch 1: tensor([2892,   19, 2348, 3907, 1147, 1467, 2516, 2542, 3119, 4084,  110, 2073,
        3628,  300,  701, 3669])
Epoch: 2735, Training Loss: 0.15, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 2736 - Batch 1 ########################
IDs in batch 1: tensor([3740, 2059, 3521, 2467, 2413, 1473,  439, 3311,  465, 4136, 2423, 1305,
         138, 1681, 2450,   97])
Epoch: 2736, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2737 - Batch 1 ########################
IDs in batch 1: tensor([1313, 1379, 4000, 3594, 2777, 2461, 3374, 1933, 3894,  164, 1775, 4268,
        2751, 3139,  316, 1857])
Epoch: 2737, Training Loss: 0.62, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2738 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 1812, 1551, 3436, 2104, 2726,  661,  645, 4258, 3830, 1231, 1707,
         193, 3156, 3150, 2855])
Epoch: 2738, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2739 - Batch 1 ########################
IDs in batch 1: tensor([ 884, 3636, 4144, 2500, 3056, 2463, 2459, 2663, 3836, 3652, 3945,  214,
        2188,  688, 3936, 1088])
Epoch: 2739, Training Loss: 0.34, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2740 - Batch 1 ########################
IDs in batch 1: tensor([2193, 1399, 1504, 1310, 1858,  524, 1954,  523,  878, 3199, 1596,  814,
        1698, 4228, 3756, 2437])
Epoch: 2740, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2741 - Batch 1 ########################
IDs in batch 1: tensor([2960, 3131,  412, 2069, 1610, 2290, 1679,  393, 2056, 3902,  881,  106,
        2242,  265, 4060,  200])
Epoch: 2741, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 2742 - Batch 1 ########################
IDs in batch 1: tensor([3131, 1932, 4065, 3630, 2672,  401, 3406,  465,   99, 3113, 2678,  155,
        1410,  494, 2172,  183])
Epoch: 2742, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2743 - Batch 1 ########################
IDs in batch 1: tensor([  13,  680, 4062, 1647, 3980, 1971,  852, 3878, 4037, 4088, 3025, 2199,
        1012, 2868,  198,  346])
Epoch: 2743, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2744 - Batch 1 ########################
IDs in batch 1: tensor([3804,  400, 1131, 1938, 1706, 3369,  594,   97, 3664, 2970, 1453,  360,
         321,  379,  947,  923])
Epoch: 2744, Training Loss: 0.49, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2745 - Batch 1 ########################
IDs in batch 1: tensor([1429,  511, 4024,  323, 2696, 1451, 4222, 3709, 3894, 3407, 3536, 1119,
         106, 3648, 1310,  384])
Epoch: 2745, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2746 - Batch 1 ########################
IDs in batch 1: tensor([ 812, 2005, 1255, 2296, 1166, 2692, 1863, 4016, 2223,  281, 1218, 3516,
        2691, 1502, 2385,  128])
Epoch: 2746, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2747 - Batch 1 ########################
IDs in batch 1: tensor([3087, 3573, 4076,  574, 3674, 2202, 3832, 3650,  956, 2236, 4080, 2582,
         713, 1487, 2312, 2826])
Epoch: 2747, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2748 - Batch 1 ########################
IDs in batch 1: tensor([ 563, 2255,  478, 1761, 3747,  639, 1218, 1156, 1497, 1731, 1657, 1571,
        3303, 1052,   74, 2529])
Epoch: 2748, Training Loss: 0.38, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2749 - Batch 1 ########################
IDs in batch 1: tensor([2718, 2337, 2663, 3114, 1395, 1576,  171, 2256,  899, 1423, 2835, 3778,
        3459, 3577, 3159, 4089])
Epoch: 2749, Training Loss: 0.23, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2750 - Batch 1 ########################
IDs in batch 1: tensor([1020, 1823, 3760, 1803, 4139,   64, 2598, 1059,  238, 1444,  337, 3478,
         644, 3658, 1996, 2258])
Epoch: 2750, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2751 - Batch 1 ########################
IDs in batch 1: tensor([1648, 1737, 2328, 4138,  384,  612, 2995, 1443,   72, 3388, 3869, 3802,
          57,  787, 2189,  250])
Epoch: 2751, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2752 - Batch 1 ########################
IDs in batch 1: tensor([1340, 2867, 1098, 1536, 2107, 2541, 2993, 3769, 2009,  492, 1605, 4184,
         961, 2429,  205, 3875])
Epoch: 2752, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2753 - Batch 1 ########################
IDs in batch 1: tensor([4014, 1755,  694, 4159, 1877, 1948, 3551, 2604,   39, 1752,  846, 3094,
        1730, 1163, 4138, 2726])
Epoch: 2753, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2754 - Batch 1 ########################
IDs in batch 1: tensor([ 523,   59, 1380, 1176, 1007, 4138, 3572, 1084, 3983, 1341, 3226,  401,
        2309, 1679, 2479, 2377])
Epoch: 2754, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2755 - Batch 1 ########################
IDs in batch 1: tensor([1025, 1984, 4194, 1971, 3245, 1409, 3590, 3069, 1840,  816, 1457, 3115,
        2506, 2671, 3084, 3778])
Epoch: 2755, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2756 - Batch 1 ########################
IDs in batch 1: tensor([ 148,   47, 2382,  566, 2663, 1954, 3656, 2472, 1195, 2172,  430, 1087,
        1131, 2895, 2060, 1258])
Epoch: 2756, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2757 - Batch 1 ########################
IDs in batch 1: tensor([3235, 3547, 2542,  895, 4212, 3498,  475, 1171,  941, 2324, 2407, 2884,
        1345, 2772, 4141, 2354])
Epoch: 2757, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2758 - Batch 1 ########################
IDs in batch 1: tensor([2828, 1763,  295, 3635,  659, 4235,  575, 2636, 4008, 3903,  701, 2112,
        1932, 3120, 2431, 3671])
Epoch: 2758, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2759 - Batch 1 ########################
IDs in batch 1: tensor([1346, 3188, 1357, 2282, 2009, 3025, 2721, 3949, 2090, 2687, 2420,  518,
        2264,  496, 2213, 1575])
Epoch: 2759, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2760 - Batch 1 ########################
IDs in batch 1: tensor([ 471, 2428, 2795,  485, 1474, 2304, 2496,  952,  651,  379, 3988, 3276,
        1684, 1166, 1671, 4011])
Epoch: 2760, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2761 - Batch 1 ########################
IDs in batch 1: tensor([2978, 3053, 3529, 1965, 2449,  832, 3939,  109, 4246,   44, 2788, 4101,
        2004, 3886, 1062, 3636])
Epoch: 2761, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2762 - Batch 1 ########################
IDs in batch 1: tensor([3264,  435, 3417, 4228, 1311, 4154, 3567, 2499, 1860, 2050, 3871,  578,
        2225, 1258, 2415, 1264])
Epoch: 2762, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2763 - Batch 1 ########################
IDs in batch 1: tensor([2327, 4157, 3160, 2203,  757, 4075, 3897, 3375, 2022, 2114, 1271,  735,
        2796,  590, 2810, 4035])
Epoch: 2763, Training Loss: 0.31, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2764 - Batch 1 ########################
IDs in batch 1: tensor([  20,  399,  441, 3628, 2884,   95, 1052,  359, 3795, 4185, 1333, 3514,
         102, 4103,  822, 2500])
Epoch: 2764, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2765 - Batch 1 ########################
IDs in batch 1: tensor([3813,  652, 3489, 1107, 1364, 3538, 2483, 1383,   11, 2284, 1365, 2620,
        4089, 3226, 3858, 2313])
Epoch: 2765, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2766 - Batch 1 ########################
IDs in batch 1: tensor([4062, 2771, 2712, 4154, 3455, 3652, 2999, 2069,  693, 1325,  717, 2463,
        3664, 1092, 2605, 2963])
Epoch: 2766, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 2767 - Batch 1 ########################
IDs in batch 1: tensor([1206, 1052, 4203,  535, 2931, 3706,  269, 3907, 1665, 3610, 1909, 3842,
        4154, 3797, 1938,  261])
Epoch: 2767, Training Loss: 0.36, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2768 - Batch 1 ########################
IDs in batch 1: tensor([2231, 3194, 4232, 3651, 4082, 2668,  290, 1933, 1324,  857, 3279, 1650,
        3826, 3156, 2849,  808])
Epoch: 2768, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2769 - Batch 1 ########################
IDs in batch 1: tensor([3006, 1429,  359, 4025, 3989,  725, 2872, 2252, 1321, 3399, 3695,  913,
         873, 2378, 2646, 2400])
Epoch: 2769, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.68
######################## Epoch 2770 - Batch 1 ########################
IDs in batch 1: tensor([1614,  305, 3781, 3390, 1895,  961, 2280, 2296, 2851, 3936, 1061, 1826,
        3652, 2426, 3472,  990])
Epoch: 2770, Training Loss: 0.11, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2771 - Batch 1 ########################
IDs in batch 1: tensor([1784, 1250, 2661, 2940, 2431, 1395, 1328, 3733, 1644, 1469,  882,  505,
        1272, 2836, 3081,   63])
Epoch: 2771, Training Loss: 0.32, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2772 - Batch 1 ########################
IDs in batch 1: tensor([4198, 2231, 3648, 2842,  874, 2976, 1072, 2418, 2423, 3150,  195, 2886,
        3475, 2879, 4255, 3040])
Epoch: 2772, Training Loss: 0.34, Validation Loss: 0.84, accuracy = 0.67
######################## Epoch 2773 - Batch 1 ########################
IDs in batch 1: tensor([1295, 1231, 2829, 2179,  352, 1611,  721, 1952, 3538, 2440, 2207,   93,
         815, 1517, 4078, 2086])
Epoch: 2773, Training Loss: 0.61, Validation Loss: 0.84, accuracy = 0.68
######################## Epoch 2774 - Batch 1 ########################
IDs in batch 1: tensor([1716, 3532,  981, 1500, 3837,  805, 3444, 4267, 2199, 2970, 3785,  141,
        2356, 2466, 3975, 2379])
Epoch: 2774, Training Loss: 0.14, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 2775 - Batch 1 ########################
IDs in batch 1: tensor([3382, 1379,  846, 3238, 1901,  752, 1455, 1730, 1633, 3514, 3353, 1140,
         435, 2482, 3443, 3218])
Epoch: 2775, Training Loss: 0.20, Validation Loss: 0.87, accuracy = 0.67
######################## Epoch 2776 - Batch 1 ########################
IDs in batch 1: tensor([3713,  866, 3764, 4253, 3255, 2913, 2693,  891, 2134,  750, 3006, 1781,
        2678, 2278,  147,   84])
Epoch: 2776, Training Loss: 0.06, Validation Loss: 0.88, accuracy = 0.67
######################## Epoch 2777 - Batch 1 ########################
IDs in batch 1: tensor([ 546, 1281, 2188, 3467,  496, 4097, 2542, 1630, 1877, 4022,   10, 4013,
        4139, 2459, 1555,  184])
Epoch: 2777, Training Loss: 0.11, Validation Loss: 0.88, accuracy = 0.67
######################## Epoch 2778 - Batch 1 ########################
IDs in batch 1: tensor([ 670, 1590, 2798, 3949,  335, 3905, 2305, 2324, 1241,  213, 4146, 4218,
        2220,  448, 3401, 2394])
Epoch: 2778, Training Loss: 0.14, Validation Loss: 0.87, accuracy = 0.67
######################## Epoch 2779 - Batch 1 ########################
IDs in batch 1: tensor([3980, 1258,  519, 2931, 1536, 2886, 3609, 2984, 3536, 1566,  325, 2457,
        3109, 2600,  775, 2408])
Epoch: 2779, Training Loss: 0.23, Validation Loss: 0.87, accuracy = 0.67
######################## Epoch 2780 - Batch 1 ########################
IDs in batch 1: tensor([2035, 2257, 1414, 2331, 2095, 2767,  565, 3952,   19, 3683, 1640, 1390,
         987, 1931, 3159, 2551])
Epoch: 2780, Training Loss: 0.22, Validation Loss: 0.86, accuracy = 0.68
######################## Epoch 2781 - Batch 1 ########################
IDs in batch 1: tensor([2812, 2453, 3573, 1588, 2316,  857, 2462, 2232, 2313, 3073, 3731, 4025,
        1959,  394, 1248,  263])
Epoch: 2781, Training Loss: 0.18, Validation Loss: 0.87, accuracy = 0.68
######################## Epoch 2782 - Batch 1 ########################
IDs in batch 1: tensor([ 965, 3932, 1101,  646, 1976, 4108, 1636, 4025,   35, 2712, 4152, 1147,
        2276, 2520, 1830, 3806])
Epoch: 2782, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.68
######################## Epoch 2783 - Batch 1 ########################
IDs in batch 1: tensor([1075, 3427, 1623,  736, 2876, 2905, 1506,  205, 2473, 2718, 3732, 2418,
        2391,  535, 2977,  983])
Epoch: 2783, Training Loss: 0.14, Validation Loss: 0.87, accuracy = 0.68
######################## Epoch 2784 - Batch 1 ########################
IDs in batch 1: tensor([2936, 1163, 3032,  774,  478, 1333, 1330,   61, 4266,  220, 1234,  620,
        2038, 3968, 3131, 3417])
Epoch: 2784, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.68
######################## Epoch 2785 - Batch 1 ########################
IDs in batch 1: tensor([3344, 3821, 3409, 2299, 1961,   59, 2601,   64, 4173,  636, 3590, 2921,
        1206,  245,  623, 3642])
Epoch: 2785, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.68
######################## Epoch 2786 - Batch 1 ########################
IDs in batch 1: tensor([1491, 2968, 3308,   72,  508, 2595, 1881,  463, 2555,  829, 2782, 3815,
        3964, 2609,   71, 1234])
Epoch: 2786, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2787 - Batch 1 ########################
IDs in batch 1: tensor([1676, 2754, 2419, 1402, 3700,  536, 2035, 2537, 2819, 3544, 4096, 3369,
        3156, 1951, 2480, 2104])
Epoch: 2787, Training Loss: 0.25, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 2788 - Batch 1 ########################
IDs in batch 1: tensor([ 302, 3338, 4222, 2235, 2440,  282, 3755, 2618, 2356, 2191, 2183, 2755,
        2017, 2656, 2478, 2764])
Epoch: 2788, Training Loss: 0.68, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2789 - Batch 1 ########################
IDs in batch 1: tensor([1661,  986, 3507, 4154, 1712, 3181, 1195,  322, 4234, 1518, 3272, 1956,
        3248,  514, 3345, 2375])
Epoch: 2789, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2790 - Batch 1 ########################
IDs in batch 1: tensor([4228, 3845, 2879, 2505, 1886,   98,  970,  756, 2231,  418, 2146, 1237,
         305, 2609, 3742, 1999])
Epoch: 2790, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 2791 - Batch 1 ########################
IDs in batch 1: tensor([ 837, 3418,  113, 1239, 1641,  382, 3000, 3834, 1457, 4009,   86, 3786,
        2676, 3118,  985, 1045])
Epoch: 2791, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2792 - Batch 1 ########################
IDs in batch 1: tensor([3468, 1317, 4096, 2094, 3426, 3446, 3254,  928, 2725, 2170, 1250, 1081,
        2873,   62, 4017, 3014])
Epoch: 2792, Training Loss: 0.20, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2793 - Batch 1 ########################
IDs in batch 1: tensor([3493,  890,  679, 2046, 4062, 1589, 4031, 3632, 3637, 2328, 1519,  155,
         390,  195, 1880, 2552])
Epoch: 2793, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2794 - Batch 1 ########################
IDs in batch 1: tensor([ 626, 2081,  463,  844,   13, 1255, 1803, 1740,  596, 1271, 3275, 3123,
         818, 1885, 2653, 3950])
Epoch: 2794, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2795 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3940, 2927, 1282, 2924, 2366, 4128, 3313, 1088, 2365, 3495, 3787,
        3065, 2313, 1206, 3618])
Epoch: 2795, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2796 - Batch 1 ########################
IDs in batch 1: tensor([4008, 2837, 3529, 2463,  220, 3036, 1517, 1909, 3286, 1794, 2448,  779,
        1278, 2251, 3432, 3984])
Epoch: 2796, Training Loss: 0.51, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2797 - Batch 1 ########################
IDs in batch 1: tensor([1918, 1024, 1984,  173, 2558, 2112, 1379, 1174, 2256, 1175, 1556, 3024,
         439,  988, 1080, 2230])
Epoch: 2797, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 2798 - Batch 1 ########################
IDs in batch 1: tensor([1273, 2049,  183, 3207, 1171, 2973, 3500,  881, 3871, 2800, 4062,  756,
        1073, 1104, 1220,  332])
Epoch: 2798, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 2799 - Batch 1 ########################
IDs in batch 1: tensor([2017,  132, 1766, 3658,  352, 4004, 2343, 2538, 1271, 4024,  262, 2126,
        1834,  691, 3600, 3373])
Epoch: 2799, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2800 - Batch 1 ########################
IDs in batch 1: tensor([ 712, 1419, 1951, 1016, 4264, 2505, 4121, 1346, 2159, 3668, 3494,  732,
         451,  987, 1152, 3036])
Epoch: 2800, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2801 - Batch 1 ########################
IDs in batch 1: tensor([ 987,  425,  454, 2149, 2983,  469,  363, 2030,  919, 2812, 2996, 3248,
        1094, 4185,   74, 2179])
Epoch: 2801, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2802 - Batch 1 ########################
IDs in batch 1: tensor([3226, 1491, 1639, 2218, 2721, 1458, 1108, 3286,  755, 4121,  880, 3218,
         713,  691, 1686,  815])
Epoch: 2802, Training Loss: 0.39, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2803 - Batch 1 ########################
IDs in batch 1: tensor([3952, 3717,  639, 4025, 3252, 2309, 1745, 3243, 1072,  946, 3951, 3813,
        3755, 1289, 3327, 2347])
Epoch: 2803, Training Loss: 0.36, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2804 - Batch 1 ########################
IDs in batch 1: tensor([2382, 1956, 3132, 2775, 3259, 3883,   50, 2771,  462, 1171, 1273,  442,
        1620, 3783, 3345, 3465])
Epoch: 2804, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2805 - Batch 1 ########################
IDs in batch 1: tensor([ 606,  545,  819, 2229, 2536, 2247, 2620, 2425, 3495, 2932, 2277,  683,
          92, 4204, 1778, 1328])
Epoch: 2805, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2806 - Batch 1 ########################
IDs in batch 1: tensor([2919, 2682, 1334, 2591, 3661, 1909, 3707, 1384, 1278, 3180, 1222, 3827,
        1644, 3141, 2752, 4014])
Epoch: 2806, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2807 - Batch 1 ########################
IDs in batch 1: tensor([ 260, 3177, 1921, 1574, 3009, 2617, 1457, 2857, 1548,  352, 2835, 3588,
        1131, 2514, 1140,  277])
Epoch: 2807, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2808 - Batch 1 ########################
IDs in batch 1: tensor([  57,  426, 2475, 4225, 2853, 1480,  199, 2159,  926, 3637,   70, 2238,
        1232, 3831,  401,  545])
Epoch: 2808, Training Loss: 0.40, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2809 - Batch 1 ########################
IDs in batch 1: tensor([4144,  870, 3714, 3084, 3764,  555, 2791, 1896,  875, 4225, 2568,  382,
        3732,  256,  814, 1222])
Epoch: 2809, Training Loss: 0.42, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2810 - Batch 1 ########################
IDs in batch 1: tensor([1832, 2905,  997, 2435,  595, 1385, 1677, 3075, 3831,  314, 3537, 1868,
         454, 1436, 3568, 3790])
Epoch: 2810, Training Loss: 0.26, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2811 - Batch 1 ########################
IDs in batch 1: tensor([2441, 1551, 3964, 3483, 3581, 2372,  986, 3956, 1248, 1324, 1656, 3156,
        3927, 2710, 3123, 1035])
Epoch: 2811, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2812 - Batch 1 ########################
IDs in batch 1: tensor([2436,  533, 1108, 2367, 2425,  691,   15, 2323, 1604, 4009, 4149, 1232,
        3343, 3399, 2155, 3717])
Epoch: 2812, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2813 - Batch 1 ########################
IDs in batch 1: tensor([3362,  305, 1648, 1871, 1248, 2292, 4065, 2114, 1070,  691, 2366,  569,
         595,  382,  143, 3644])
Epoch: 2813, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2814 - Batch 1 ########################
IDs in batch 1: tensor([ 588, 3218,  775, 2773,  873, 1706, 2170, 3938, 1087, 3839, 1573, 1122,
        3401, 3438,  120,  342])
Epoch: 2814, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2815 - Batch 1 ########################
IDs in batch 1: tensor([3544, 1176,  199, 4024, 3217,  422, 3394,  688, 1645, 2339, 3940, 1354,
        3881, 1732,  508, 2260])
Epoch: 2815, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2816 - Batch 1 ########################
IDs in batch 1: tensor([3239, 2203, 1281, 2719, 1444, 1073,  971, 1276, 1406, 3410, 3742, 2242,
         622,   41,  113, 2957])
Epoch: 2816, Training Loss: 0.24, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2817 - Batch 1 ########################
IDs in batch 1: tensor([ 869,  262, 3452, 2260, 2970, 1225, 1900, 1994, 1044, 1789, 1284, 2398,
        1052, 1384, 4220, 1317])
Epoch: 2817, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2818 - Batch 1 ########################
IDs in batch 1: tensor([4190,  924, 3251, 1337,  954, 3015, 1459, 3312, 3745, 3113,  125,  325,
        1835, 1179,  170, 3917])
Epoch: 2818, Training Loss: 0.44, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2819 - Batch 1 ########################
IDs in batch 1: tensor([3409,  228, 4014,    5, 2406, 3336, 2617, 1784, 1804, 2805, 1679, 1249,
        2022, 1809, 3891, 2206])
Epoch: 2819, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2820 - Batch 1 ########################
IDs in batch 1: tensor([2597, 1239, 3709, 2149,  524, 1355,  770,  896,  976, 2689, 2765, 3732,
        1163, 2868, 3647, 4214])
Epoch: 2820, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2821 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 3211, 3244, 1415, 1884, 1272,  881,  678,  292, 2960, 2564, 4199,
        1570, 3589, 2783, 3873])
Epoch: 2821, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 2822 - Batch 1 ########################
IDs in batch 1: tensor([1335,  758, 3845, 2103, 3636, 3673, 3388, 2151,  411, 1409, 2468, 2990,
        2592,  949, 2477,  167])
Epoch: 2822, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2823 - Batch 1 ########################
IDs in batch 1: tensor([ 515, 1190, 3953,  818, 1857, 3964, 3767, 2008, 4226, 3952, 2357, 3323,
        3727,  596, 3017, 4055])
Epoch: 2823, Training Loss: 0.48, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2824 - Batch 1 ########################
IDs in batch 1: tensor([ 454,  724, 2691, 1038, 4161, 1116, 3751, 1632,  879,  165, 4158, 3128,
        2226,  658, 3976, 3630])
Epoch: 2824, Training Loss: 0.52, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2825 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 2403, 3588, 2403, 2274, 4136,  569, 2322, 4264, 4069, 1270,  523,
        2823, 2069, 3388, 2069])
Epoch: 2825, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2826 - Batch 1 ########################
IDs in batch 1: tensor([1038,  225, 2448, 1426, 1658, 3185, 1376, 1158, 3544, 3996, 1075, 1789,
         472, 3832,  234, 3866])
Epoch: 2826, Training Loss: 0.44, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2827 - Batch 1 ########################
IDs in batch 1: tensor([ 607, 2358, 3658, 2143, 3757, 3983, 3344, 1196, 2376, 2789, 1976, 3372,
        2758, 4159,  188, 2470])
Epoch: 2827, Training Loss: 0.49, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2828 - Batch 1 ########################
IDs in batch 1: tensor([3303, 4085,  926, 1668, 3681, 2473, 2721,   72,  382, 3430, 2621,  306,
        2989, 3663, 1996, 1116])
Epoch: 2828, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2829 - Batch 1 ########################
IDs in batch 1: tensor([ 134, 2908,  623,  152,  247,  640, 4012, 3156, 1599, 3738, 1017, 1274,
        3699,  388, 1237, 4007])
Epoch: 2829, Training Loss: 0.26, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2830 - Batch 1 ########################
IDs in batch 1: tensor([1731,  321,   50,  583,  774, 2406, 2736, 1670, 3972, 2179,  110,  957,
        1273, 3963, 1962,  419])
Epoch: 2830, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2831 - Batch 1 ########################
IDs in batch 1: tensor([1166,  518, 1702, 3031, 2015,  657, 3344, 2899, 3554, 3617, 1070, 2149,
         596,  393, 2921, 2867])
Epoch: 2831, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2832 - Batch 1 ########################
IDs in batch 1: tensor([  38, 2299, 1639, 1324, 2176, 3660,  258,   15, 1351, 1372,  476, 1482,
        2719, 1677, 1421, 3789])
Epoch: 2832, Training Loss: 0.24, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2833 - Batch 1 ########################
IDs in batch 1: tensor([3378, 2764, 1260, 3974, 1981, 1159,  441, 3873,  372, 3235, 1275, 2104,
        3953,   92, 1093,  255])
Epoch: 2833, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2834 - Batch 1 ########################
IDs in batch 1: tensor([2472, 1918, 1895, 2024,  594, 2668, 4172, 2244, 2226, 3304, 2408, 3030,
        3615, 2791, 2290, 2963])
Epoch: 2834, Training Loss: 0.85, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2835 - Batch 1 ########################
IDs in batch 1: tensor([1558,  904, 1341,  631,  346, 3356, 3092, 3018,  380, 1269, 3291, 1737,
        3020, 2466, 4215,  797])
Epoch: 2835, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2836 - Batch 1 ########################
IDs in batch 1: tensor([1271,  674, 3226,  812, 4143,  732, 2725, 2538, 3590, 2959, 3542,  888,
        3333, 2452, 2936, 2949])
Epoch: 2836, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2837 - Batch 1 ########################
IDs in batch 1: tensor([ 874, 2627, 2914,  902, 3998,  584, 1315, 4138,  449, 1510, 1055, 3721,
        2765, 3751, 3977, 1457])
Epoch: 2837, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 2838 - Batch 1 ########################
IDs in batch 1: tensor([2738,   56, 2312, 4158,  848,  636, 2587, 3987, 2074, 1604, 3976,  959,
         170, 3197, 4012,  835])
Epoch: 2838, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2839 - Batch 1 ########################
IDs in batch 1: tensor([3507,   71, 4009,  250,  140, 2676, 2142, 3993, 3582, 1882, 1870, 2584,
        1881, 1511, 2649, 1233])
Epoch: 2839, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 2840 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 2086, 3876, 4143, 4152,  132, 3460, 3897, 1981, 2689,  893,  276,
        2914,  338, 3415, 3603])
Epoch: 2840, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 2841 - Batch 1 ########################
IDs in batch 1: tensor([1690, 4199, 4139,  949, 2052, 2693, 3997, 1286, 2742, 3200, 1591, 2296,
        3838, 3458,   46, 3017])
Epoch: 2841, Training Loss: 0.21, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2842 - Batch 1 ########################
IDs in batch 1: tensor([4255,  399, 1852, 2399, 3782, 1454,  804,  282, 2401,  520, 2882,  330,
        2002, 2406, 2371, 2346])
Epoch: 2842, Training Loss: 0.20, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 2843 - Batch 1 ########################
IDs in batch 1: tensor([3680,  605, 3056,  796, 4227, 1086, 3399, 1877,  781, 2937,  582, 1405,
        1138, 3688, 4228, 2346])
Epoch: 2843, Training Loss: 0.24, Validation Loss: 0.86, accuracy = 0.68
######################## Epoch 2844 - Batch 1 ########################
IDs in batch 1: tensor([3392, 1870,  950,  584,  818, 3632, 3262, 1636, 2729,  825, 2542,  956,
        1365,  563, 3278, 1821])
Epoch: 2844, Training Loss: 0.15, Validation Loss: 0.87, accuracy = 0.67
######################## Epoch 2845 - Batch 1 ########################
IDs in batch 1: tensor([2347,  275,  649,  778, 3466, 1286,  895, 3714, 1679, 2465,  825,  803,
        2282, 4084, 3385, 2234])
Epoch: 2845, Training Loss: 0.11, Validation Loss: 0.88, accuracy = 0.68
######################## Epoch 2846 - Batch 1 ########################
IDs in batch 1: tensor([4025, 1526, 2024, 2274,  883, 1747, 1700, 3245, 3617, 1379, 3747,  736,
        1213, 1952,  855,  815])
Epoch: 2846, Training Loss: 0.09, Validation Loss: 0.90, accuracy = 0.67
######################## Epoch 2847 - Batch 1 ########################
IDs in batch 1: tensor([1313, 2788,  959,   70, 2990, 1176, 4026,  128, 1955, 3141, 1181, 3406,
        2004,  122, 3587, 2890])
Epoch: 2847, Training Loss: 0.21, Validation Loss: 0.90, accuracy = 0.67
######################## Epoch 2848 - Batch 1 ########################
IDs in batch 1: tensor([ 321, 1902,  384,  225, 1354,  670, 1308, 2498, 3647, 2653, 2429,  964,
         277, 2703, 3997, 1841])
Epoch: 2848, Training Loss: 0.05, Validation Loss: 0.92, accuracy = 0.66
######################## Epoch 2849 - Batch 1 ########################
IDs in batch 1: tensor([2604, 3451, 3777,  396, 1711,  316,  110, 1047, 1226, 4068, 1632, 1981,
        2295, 3632,  323, 3900])
Epoch: 2849, Training Loss: 0.33, Validation Loss: 0.92, accuracy = 0.65
######################## Epoch 2850 - Batch 1 ########################
IDs in batch 1: tensor([4060, 4226, 1921,  949,  193, 3378, 4062, 1566, 3569, 4062, 2115, 1228,
         752, 2417, 1498, 2984])
Epoch: 2850, Training Loss: 0.06, Validation Loss: 0.91, accuracy = 0.66
######################## Epoch 2851 - Batch 1 ########################
IDs in batch 1: tensor([1057, 1044, 1340, 1861, 3615, 2253,   92, 2180, 2413,  667, 3964, 2926,
        2819, 2072, 1260, 1853])
Epoch: 2851, Training Loss: 0.10, Validation Loss: 0.89, accuracy = 0.66
######################## Epoch 2852 - Batch 1 ########################
IDs in batch 1: tensor([1428,  975, 4016, 1485, 1751, 2826, 2604, 1974,   34, 2103, 2226, 1331,
        3349, 1235, 2193,  295])
Epoch: 2852, Training Loss: 0.10, Validation Loss: 0.89, accuracy = 0.66
######################## Epoch 2853 - Batch 1 ########################
IDs in batch 1: tensor([3002, 1384, 3472,  612, 3793,  223, 3430, 1333, 4011, 2124, 2285, 2094,
         615, 4057, 1108, 2598])
Epoch: 2853, Training Loss: 0.11, Validation Loss: 0.89, accuracy = 0.67
######################## Epoch 2854 - Batch 1 ########################
IDs in batch 1: tensor([3119, 2667, 3241,  314, 2300, 3813, 2234,  474,   38, 3597, 2387,  684,
        3486,  818, 2104, 2562])
Epoch: 2854, Training Loss: 0.08, Validation Loss: 0.88, accuracy = 0.67
######################## Epoch 2855 - Batch 1 ########################
IDs in batch 1: tensor([3187, 3572, 3317,  981, 2014, 2627, 3927, 2621,   61, 4013, 2073, 1125,
        2290,  879, 3014, 3869])
Epoch: 2855, Training Loss: 0.15, Validation Loss: 0.87, accuracy = 0.68
######################## Epoch 2856 - Batch 1 ########################
IDs in batch 1: tensor([1133, 3950, 2332, 1684, 1487, 2217, 1251,  517, 1395, 3754, 1044, 1102,
        1828,  590, 1775,   47])
Epoch: 2856, Training Loss: 0.32, Validation Loss: 0.86, accuracy = 0.69
######################## Epoch 2857 - Batch 1 ########################
IDs in batch 1: tensor([ 196, 3672, 2049, 3127, 1231,  622,   28, 2582, 3991,  113, 1397, 4008,
        3942,  852, 2947, 3031])
Epoch: 2857, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2858 - Batch 1 ########################
IDs in batch 1: tensor([1509,  361, 1635, 2081, 1023, 2484, 4082, 2088, 3650, 2517, 1251, 2126,
        1440, 4025, 4174, 2934])
Epoch: 2858, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2859 - Batch 1 ########################
IDs in batch 1: tensor([2217,   24, 2754, 1537,  455, 1075, 3582,  890, 2188, 2050,  824, 1594,
        3112, 1308, 3253, 1566])
Epoch: 2859, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2860 - Batch 1 ########################
IDs in batch 1: tensor([2840, 4263, 2317, 1388, 1333, 3947, 1961, 2746, 1835, 4149,  975, 4024,
         452, 2708,  714,  489])
Epoch: 2860, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2861 - Batch 1 ########################
IDs in batch 1: tensor([1993,  842, 1945, 1802,  566, 3786, 3658,  262,    5, 2114, 3228, 4089,
        2583, 2740, 2809,  996])
Epoch: 2861, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2862 - Batch 1 ########################
IDs in batch 1: tensor([2098, 2539, 1645, 3181, 1204,  684, 3570,  788,  340,  843, 3710, 1247,
        3349, 1344, 3436, 3757])
Epoch: 2862, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2863 - Batch 1 ########################
IDs in batch 1: tensor([3644, 2248, 3742,   70, 3693, 3581,  989, 3152,  713, 2553,  689, 2393,
        2652, 1141, 1467, 2080])
Epoch: 2863, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2864 - Batch 1 ########################
IDs in batch 1: tensor([ 539, 1087, 2085,  661, 1174, 4261, 2075,  961, 2927,  417,  362, 3356,
         888, 2354, 1484, 3728])
Epoch: 2864, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2865 - Batch 1 ########################
IDs in batch 1: tensor([2258, 3780, 4245, 2511,  411, 1421, 3087, 1563, 3888, 2892, 4133, 1887,
        1726, 2689, 4093, 3658])
Epoch: 2865, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2866 - Batch 1 ########################
IDs in batch 1: tensor([3100, 2559, 3604, 1627,   63,  869, 2555, 2346, 3423, 2244, 3798, 1660,
         111,  980, 1120, 2799])
Epoch: 2866, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2867 - Batch 1 ########################
IDs in batch 1: tensor([ 221, 1004, 3020, 1866,  206, 3745, 3947, 1961, 3903, 2610,  408,  739,
         488, 3446, 4226, 4025])
Epoch: 2867, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2868 - Batch 1 ########################
IDs in batch 1: tensor([ 584,  663, 3208, 2378, 1493, 2153, 3927, 4065, 2146,  594, 2561, 3922,
        1726, 3497, 3907,  888])
Epoch: 2868, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2869 - Batch 1 ########################
IDs in batch 1: tensor([4031, 1710, 1212,  871,  830, 3433, 1589, 3632, 1938, 1980, 3781, 1764,
        3582,   30, 2681, 2225])
Epoch: 2869, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2870 - Batch 1 ########################
IDs in batch 1: tensor([1092, 3310, 1728, 1204,  563, 2276, 2495, 1746, 3778, 3497, 2251, 3455,
        3478, 3483, 1927, 1073])
Epoch: 2870, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2871 - Batch 1 ########################
IDs in batch 1: tensor([ 994, 3709, 2907, 2080, 4068,  102, 1897, 2553,  276, 1397, 1640, 2539,
        1723, 2432, 2078, 2581])
Epoch: 2871, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2872 - Batch 1 ########################
IDs in batch 1: tensor([2934,  662, 2697,  818, 1069, 1640, 2334,  569, 3113, 2414, 1954,  432,
        4024, 3847, 3087, 3557])
Epoch: 2872, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2873 - Batch 1 ########################
IDs in batch 1: tensor([1146, 1044, 1954, 3438, 1336,  243,  512, 2060, 1894, 1985,  557, 2190,
         190,  283, 1474, 2726])
Epoch: 2873, Training Loss: 0.19, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2874 - Batch 1 ########################
IDs in batch 1: tensor([1206, 1014,  408,  263, 1845, 3635, 1042, 3455, 1257, 2871, 1163, 2277,
         908, 2721,  318, 4115])
Epoch: 2874, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2875 - Batch 1 ########################
IDs in batch 1: tensor([1167,  915, 1485, 2312, 3378, 3343,  721, 3789, 1948, 3859, 4205, 3381,
         839, 3109, 3334, 1511])
Epoch: 2875, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2876 - Batch 1 ########################
IDs in batch 1: tensor([3947, 3917,  556, 4268, 3882, 2161, 1555, 1162,  167,  743, 2876, 2192,
        1426, 3608, 3407, 4186])
Epoch: 2876, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2877 - Batch 1 ########################
IDs in batch 1: tensor([1551, 4069,  435,  346, 2492, 3244,  815,  499, 1007, 1118, 1171, 2228,
        1812, 1858,  781,   52])
Epoch: 2877, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2878 - Batch 1 ########################
IDs in batch 1: tensor([3742, 2895, 1201, 1845, 3216, 3268,  653, 3902, 1445, 1927, 2114, 1252,
         945, 3353, 2416, 1731])
Epoch: 2878, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2879 - Batch 1 ########################
IDs in batch 1: tensor([1247,   72,  338, 3351, 3401, 1511, 2386, 1081, 3898, 1506, 1877,  393,
         769, 2908, 1312, 4072])
Epoch: 2879, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2880 - Batch 1 ########################
IDs in batch 1: tensor([ 508, 3355, 2347, 2324,  827, 2099,  662, 4108, 1877, 2856, 4181, 3487,
         679, 2514, 2461,  389])
Epoch: 2880, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2881 - Batch 1 ########################
IDs in batch 1: tensor([ 110, 2237, 2601, 2331,  649, 2567, 2536, 3841,  779, 2441,  602, 4212,
        3252, 1672,  788, 3459])
Epoch: 2881, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2882 - Batch 1 ########################
IDs in batch 1: tensor([1869, 2127, 2296, 1519, 2188, 3355,  635,  276, 2476, 2458, 3738, 1198,
        1404, 3240, 2132, 3143])
Epoch: 2882, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2883 - Batch 1 ########################
IDs in batch 1: tensor([4186, 2895, 3058, 3252, 2176, 2743, 2974, 2887,   27, 2915, 2449,  108,
        1521,  262, 3950, 2085])
Epoch: 2883, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2884 - Batch 1 ########################
IDs in batch 1: tensor([4242, 1117, 1196, 2924, 1925,  755, 1764,  505, 2966, 2688, 2810, 2085,
        2860, 4068, 1604,  391])
Epoch: 2884, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2885 - Batch 1 ########################
IDs in batch 1: tensor([3427, 2614,   93, 1868, 1589, 3258, 2640,  167, 4087, 2963, 1965, 1419,
        3208, 2359, 1617, 2456])
Epoch: 2885, Training Loss: 0.37, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2886 - Batch 1 ########################
IDs in batch 1: tensor([4268, 2188, 2477, 1370,  926,  205, 1373, 1047, 3500, 1579, 1651, 2894,
        2866, 2192,  591, 3236])
Epoch: 2886, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2887 - Batch 1 ########################
IDs in batch 1: tensor([1341, 1704, 1005, 4048, 2721, 2196, 2669, 2983, 2968, 4195, 2383, 1883,
        2726, 1575,  983, 4094])
Epoch: 2887, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2888 - Batch 1 ########################
IDs in batch 1: tensor([ 625,  591, 1423, 1022, 3528, 1273, 4268, 2320,  869, 3600, 3494, 3100,
        2009,  149, 2995, 1868])
Epoch: 2888, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2889 - Batch 1 ########################
IDs in batch 1: tensor([3689,  338, 2086, 2907,  855, 2008, 2156,  436, 2898, 2245, 1232,  395,
        3642, 3829, 2510, 2156])
Epoch: 2889, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2890 - Batch 1 ########################
IDs in batch 1: tensor([2598, 2572, 2376, 3627, 2837, 1274, 1126,  769, 3410, 2205, 1543, 1720,
        2514, 1678, 3351,  832])
Epoch: 2890, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2891 - Batch 1 ########################
IDs in batch 1: tensor([2317,  803,  348, 2982, 3465,   34, 2050, 3891, 4161, 1456, 3948, 1976,
        1993, 1154, 1858, 1043])
Epoch: 2891, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2892 - Batch 1 ########################
IDs in batch 1: tensor([2142,  145, 3939, 3016,  656, 4180, 3010, 1938, 3834,  501, 4179, 3072,
        3656, 1545, 3199, 1938])
Epoch: 2892, Training Loss: 0.25, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2893 - Batch 1 ########################
IDs in batch 1: tensor([  31,  321, 3381, 3674,  723, 1698, 4238, 2692, 2568, 2154, 3009, 1418,
        2272, 2446,  788, 3244])
Epoch: 2893, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 2894 - Batch 1 ########################
IDs in batch 1: tensor([1276, 2824,  361, 1167, 2188, 3837, 1004, 1720, 1089, 2406,  914, 3883,
        1996, 1802, 3270, 1661])
Epoch: 2894, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2895 - Batch 1 ########################
IDs in batch 1: tensor([3211, 2346, 2121, 4048, 1312, 3109, 1887, 1863,  887, 1152, 1321, 2183,
        3976,  136, 2505, 3839])
Epoch: 2895, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2896 - Batch 1 ########################
IDs in batch 1: tensor([ 487, 3667, 1252, 3749, 1963, 3265, 1892,  427, 1704, 2265, 3958, 2142,
        3557, 2752, 3123,  900])
Epoch: 2896, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2897 - Batch 1 ########################
IDs in batch 1: tensor([3036, 4016, 2926, 3370, 3925, 2226, 1113, 2366, 2763, 2102,  966, 1439,
        1599, 3115, 2821, 3039])
Epoch: 2897, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2898 - Batch 1 ########################
IDs in batch 1: tensor([ 277, 3238,  440, 3882, 1897,  587,  978, 3818,  536,  266, 3014,  357,
        1953, 1543,  398,  808])
Epoch: 2898, Training Loss: 0.42, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2899 - Batch 1 ########################
IDs in batch 1: tensor([1872, 1761, 2407,  646, 1918,  714, 4204,  790, 2729, 1287,  779, 2799,
        1352,   32, 2868,  387])
Epoch: 2899, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2900 - Batch 1 ########################
IDs in batch 1: tensor([3871, 2452, 4184, 2509, 3600, 4120,  436, 2475, 1627, 1632, 1935,  237,
         245, 2764,  440, 1884])
Epoch: 2900, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2901 - Batch 1 ########################
IDs in batch 1: tensor([3177, 2432,  790, 2691, 2124, 3072,  320, 3533, 3818, 1041, 2188, 3344,
        2094, 1294, 3467, 2697])
Epoch: 2901, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2902 - Batch 1 ########################
IDs in batch 1: tensor([2038, 2983,  143, 1346, 1346,  850, 3992, 1761, 4223, 1108, 1558, 2108,
        4030, 3255, 2810, 2755])
Epoch: 2902, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2903 - Batch 1 ########################
IDs in batch 1: tensor([3143, 3300, 3277, 2028, 1125, 3719, 1132, 1082,  924, 2587, 4253, 1153,
         724, 3833, 3306, 3327])
Epoch: 2903, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2904 - Batch 1 ########################
IDs in batch 1: tensor([2352, 3018, 3408,  128,  878, 1846,  232,  194, 3498, 3826, 1370, 2907,
         161, 1916, 3272, 2417])
Epoch: 2904, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2905 - Batch 1 ########################
IDs in batch 1: tensor([1080,   32, 3283, 2555, 1755, 2798, 3654, 1017,  969, 2470, 1443,  132,
         491, 1633, 2341, 3083])
Epoch: 2905, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2906 - Batch 1 ########################
IDs in batch 1: tensor([2648,  140, 1185, 2731, 1470,  236, 3943, 3852,  522,  610, 2195, 1812,
        2193, 2986,  753, 1967])
Epoch: 2906, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2907 - Batch 1 ########################
IDs in batch 1: tensor([2297, 1775, 1972, 3069, 1255, 3780, 3481,  388, 1883,  550,  191,  497,
         670, 1317, 1970,  224])
Epoch: 2907, Training Loss: 0.21, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2908 - Batch 1 ########################
IDs in batch 1: tensor([2739, 3753,  105, 3843, 3802, 3472,  125, 2439, 4050, 3377,  160, 2879,
        1330, 3434, 2428, 2469])
Epoch: 2908, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2909 - Batch 1 ########################
IDs in batch 1: tensor([1506,   51, 1373, 2443, 1087, 3563, 3939, 4135, 1454, 2232, 1305, 4051,
        2537, 2279,  667, 1155])
Epoch: 2909, Training Loss: 0.39, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 2910 - Batch 1 ########################
IDs in batch 1: tensor([ 606, 4190,  712, 3664, 3881, 2284, 1574, 2717, 3021, 2177, 1069, 2281,
         875,  478, 4246, 4195])
Epoch: 2910, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2911 - Batch 1 ########################
IDs in batch 1: tensor([4000,  437,  991, 1070, 2324, 2664, 3120, 3073, 3908, 2253, 3310, 1470,
         591,  333, 2826, 1252])
Epoch: 2911, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2912 - Batch 1 ########################
IDs in batch 1: tensor([  61, 4075,   72, 3738, 3765, 2479, 2709, 1517, 3753,  738,  276, 2908,
         770, 3644, 3886,  829])
Epoch: 2912, Training Loss: 0.33, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2913 - Batch 1 ########################
IDs in batch 1: tensor([1045, 2193, 3214,  726, 1200, 1234, 2008, 3176, 1767,  750, 3732, 3252,
        2773,   27, 2258, 3470])
Epoch: 2913, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 2914 - Batch 1 ########################
IDs in batch 1: tensor([4114, 1473, 1404, 1231, 1009, 2172, 2219,  819, 2836, 4222, 3507, 2998,
        4256, 1627, 2506, 2706])
Epoch: 2914, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2915 - Batch 1 ########################
IDs in batch 1: tensor([3698, 2306, 3528, 2010, 3180, 2697, 1320,  980, 2731, 4101, 3379, 2751,
        1799,  870,  834, 1537])
Epoch: 2915, Training Loss: 0.18, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 2916 - Batch 1 ########################
IDs in batch 1: tensor([4175, 1548, 2856, 2518, 1331,  775,  615, 2159,  515, 2148, 2338, 2383,
        2536, 3227, 3699,  145])
Epoch: 2916, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 2917 - Batch 1 ########################
IDs in batch 1: tensor([1201, 4082, 1914,  663, 2782, 2431, 3040, 2492, 2505, 3016, 4089,   38,
         456, 1302, 4166, 2274])
Epoch: 2917, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2918 - Batch 1 ########################
IDs in batch 1: tensor([3927, 3989, 3298,   10, 1660, 4197, 3830, 1718, 2561, 2609, 2402,  167,
        1285, 3570,  418, 1712])
Epoch: 2918, Training Loss: 0.20, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2919 - Batch 1 ########################
IDs in batch 1: tensor([1125,  427, 3300, 1562, 2687, 2244, 1953, 3947, 1870, 1038,  923, 1498,
        2494, 2015,   57, 2561])
Epoch: 2919, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 2920 - Batch 1 ########################
IDs in batch 1: tensor([2064, 2606, 1901, 3379, 1507, 1340, 3587,  812, 1861,  926, 2202, 2754,
        1644, 2605, 1231, 2582])
Epoch: 2920, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 2921 - Batch 1 ########################
IDs in batch 1: tensor([3152,  373, 2127, 2123, 3483, 1851, 2931, 3058, 1357, 1193, 3259, 1996,
         375, 1938,  471,  778])
Epoch: 2921, Training Loss: 0.43, Validation Loss: 0.86, accuracy = 0.69
######################## Epoch 2922 - Batch 1 ########################
IDs in batch 1: tensor([3465, 1834, 4152, 1086,  825,  983, 2727, 3437, 3377, 1116, 2781,  469,
        3764, 3904, 3194, 2234])
Epoch: 2922, Training Loss: 0.15, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 2923 - Batch 1 ########################
IDs in batch 1: tensor([3822, 1770,  594, 3336, 4003,  109, 3582,  405, 3793, 1793,  201, 1075,
         103,  516, 2476, 2993])
Epoch: 2923, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.68
######################## Epoch 2924 - Batch 1 ########################
IDs in batch 1: tensor([2110, 1955, 3044,  432,  852, 2431,  170, 3394, 3465,  740, 3236, 1796,
        1472, 2478, 4014, 2109])
Epoch: 2924, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 2925 - Batch 1 ########################
IDs in batch 1: tensor([3102,  352,  573, 3882,  161,  805, 1263, 3985,  390, 3290, 3338,  452,
         368, 1543, 3021, 2003])
Epoch: 2925, Training Loss: 0.28, Validation Loss: 0.84, accuracy = 0.68
######################## Epoch 2926 - Batch 1 ########################
IDs in batch 1: tensor([3053,  449, 3582, 4253,  786,  839, 1370, 2452, 3244, 1583,  704,  317,
        1726, 1073, 4245, 3182])
Epoch: 2926, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2927 - Batch 1 ########################
IDs in batch 1: tensor([1464, 1504, 2323, 3317, 3557,  824, 1356, 1123,  767, 3252,   42, 3823,
        2579, 1124, 1973, 3851])
Epoch: 2927, Training Loss: 0.30, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2928 - Batch 1 ########################
IDs in batch 1: tensor([2517, 1417, 3696, 3202, 4035, 2246,  609, 1287, 2858, 3058, 2369, 1034,
          85, 1942, 1632, 3539])
Epoch: 2928, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2929 - Batch 1 ########################
IDs in batch 1: tensor([1846, 1248, 3257,  610, 1284, 4080, 3714, 1953, 1722, 2458,  274, 1229,
        1006,  149, 3052, 1927])
Epoch: 2929, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 2930 - Batch 1 ########################
IDs in batch 1: tensor([3204, 1234,  893, 1649, 3084, 3010, 1765, 2632, 3424,   61, 2523, 3540,
        2014, 4154,  223, 2772])
Epoch: 2930, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2931 - Batch 1 ########################
IDs in batch 1: tensor([1720,  526, 2246, 2418, 1351, 1263,  367, 1035, 3397, 1484, 1878, 2313,
        2879, 3240,  266, 2295])
Epoch: 2931, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2932 - Batch 1 ########################
IDs in batch 1: tensor([3980, 3222, 2641, 3126, 3356, 1986, 1410, 1678,  389, 1871, 1225, 2317,
        3557, 1381, 2656, 1899])
Epoch: 2932, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.68
######################## Epoch 2933 - Batch 1 ########################
IDs in batch 1: tensor([2467,  896, 2464, 4088, 1642, 2247, 1500, 2144,  683, 2706, 3283,  190,
        3700, 1311, 1266,  262])
Epoch: 2933, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.68
######################## Epoch 2934 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 3401,   86,  437, 3936, 2601,  514, 2523, 3251, 2113,  355,  314,
        2393,  826, 3688, 2793])
Epoch: 2934, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 2935 - Batch 1 ########################
IDs in batch 1: tensor([ 185,  805, 4027, 1911, 2605,  830, 2060,   57, 2842,  550, 3862, 2919,
        3109,  659,  269,  283])
Epoch: 2935, Training Loss: 0.28, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2936 - Batch 1 ########################
IDs in batch 1: tensor([1124,  368, 2121, 4230,  805,  117, 1270, 2362, 2541, 2190,  262, 3115,
        1221, 3551, 3222,  219])
Epoch: 2936, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2937 - Batch 1 ########################
IDs in batch 1: tensor([1657,  969, 4197, 4025,   64, 3360, 1081, 3289, 1104, 2271, 1132, 3074,
        3872, 1580, 3888, 3246])
Epoch: 2937, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 2938 - Batch 1 ########################
IDs in batch 1: tensor([4015, 3542, 1066, 3311, 3254, 4084, 3262,  678, 1650, 1140, 3426,   39,
        3042, 1276, 3119, 4165])
Epoch: 2938, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2939 - Batch 1 ########################
IDs in batch 1: tensor([ 943, 3074, 3564, 3244,  350,  918, 1226,  481,  640, 1536,  379, 3987,
        3072, 3234,  590, 2204])
Epoch: 2939, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2940 - Batch 1 ########################
IDs in batch 1: tensor([2295, 1395, 3753, 2250, 2840,  837, 3115,   21,  583, 4148, 2696, 2908,
        3651,  805,  792, 1511])
Epoch: 2940, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2941 - Batch 1 ########################
IDs in batch 1: tensor([4027, 3643, 3218,  251, 1121, 3290, 4212,  432,   24, 2680,  632,  228,
        2487,  930, 1442, 3109])
Epoch: 2941, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 2942 - Batch 1 ########################
IDs in batch 1: tensor([1765, 3255, 2876, 2746, 1370, 3233, 2271, 1923,  193, 2349, 1543, 2894,
        3083, 1585, 1418, 3715])
Epoch: 2942, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 2943 - Batch 1 ########################
IDs in batch 1: tensor([4088, 3865,  526,  583, 3055, 2028, 1266,  482, 3777, 4218,  340,  809,
        1032,  735, 2986, 2394])
Epoch: 2943, Training Loss: 0.35, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2944 - Batch 1 ########################
IDs in batch 1: tensor([1044,  763, 1819, 2998,  787, 3544, 2797, 1008, 2360, 2610, 3672,  886,
        1087, 2443,  893,  444])
Epoch: 2944, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2945 - Batch 1 ########################
IDs in batch 1: tensor([3478, 3439, 2417, 3241, 1166, 1426, 1328, 4032, 3148,  324, 2897, 3241,
        3037,  277, 3088, 3747])
Epoch: 2945, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2946 - Batch 1 ########################
IDs in batch 1: tensor([ 117,  794, 2983, 3581, 3618,  625, 1426, 3866,  660,  659, 3822, 1718,
        1034, 3349, 1673,  408])
Epoch: 2946, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2947 - Batch 1 ########################
IDs in batch 1: tensor([3530,  923, 3375, 1787,   26, 3334,  884, 4038, 3039, 1415, 2690, 3109,
        3226, 2377, 1321, 2463])
Epoch: 2947, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2948 - Batch 1 ########################
IDs in batch 1: tensor([2849, 1555,  380, 1668,  372,  316, 3577, 2013, 3141, 1154, 4016, 3617,
        1177, 1886, 2191, 3953])
Epoch: 2948, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2949 - Batch 1 ########################
IDs in batch 1: tensor([  28, 2927,  463, 2644, 4099, 2857,  350, 4184, 2681, 2111, 4000, 3143,
        1183,  851, 3746, 2746])
Epoch: 2949, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2950 - Batch 1 ########################
IDs in batch 1: tensor([3614, 1651, 4057, 3813, 3971, 2836, 2833, 1833, 2030, 2740, 1343, 3564,
        1270, 1162, 3157,  326])
Epoch: 2950, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2951 - Batch 1 ########################
IDs in batch 1: tensor([2230, 1415, 1680, 2320, 2148, 1974, 3798,  851, 2446, 2305, 2538, 1386,
        2415, 3161,  982, 3120])
Epoch: 2951, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2952 - Batch 1 ########################
IDs in batch 1: tensor([1761, 2149,  574, 1824, 1333, 1311, 2791, 2715,  613, 1923, 3333,  518,
        3177, 2723, 2715, 3663])
Epoch: 2952, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2953 - Batch 1 ########################
IDs in batch 1: tensor([4159, 1387, 1408, 4238, 2493,  218, 1963, 2024,  104, 1862, 2494, 2729,
        2553, 3940,  135,  673])
Epoch: 2953, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2954 - Batch 1 ########################
IDs in batch 1: tensor([3903, 3368, 3593, 1762,  234, 3751, 3669,  337, 3311, 3242, 3024, 3036,
        3996,  377, 1204, 3083])
Epoch: 2954, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2955 - Batch 1 ########################
IDs in batch 1: tensor([1938,   92, 2444, 1748, 4027, 3833,  100, 1850,  476, 3022,  604, 2072,
        2459, 3870, 2999, 1817])
Epoch: 2955, Training Loss: 0.10, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 2956 - Batch 1 ########################
IDs in batch 1: tensor([  26, 1363, 3803, 2839,  554,   37,  513,  693, 1808,  491, 4032,  956,
         161,  526, 3533, 1927])
Epoch: 2956, Training Loss: 0.39, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2957 - Batch 1 ########################
IDs in batch 1: tensor([1264,  578, 4031, 2277, 2469,  207, 2574, 1828,  662, 1330,  693, 1285,
         774, 1882, 1573, 2701])
Epoch: 2957, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2958 - Batch 1 ########################
IDs in batch 1: tensor([ 990, 2451, 1891, 2809, 2649, 3960, 3429, 1363,  260, 2932, 2620,  994,
         862, 3056,   21, 1154])
Epoch: 2958, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2959 - Batch 1 ########################
IDs in batch 1: tensor([ 808, 1530, 2890,  523, 2890, 3336, 3406, 2040, 1904,  622, 3815, 2282,
        1098, 1154, 1956, 2740])
Epoch: 2959, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2960 - Batch 1 ########################
IDs in batch 1: tensor([4048, 3523, 2393,  449, 1868, 1910, 3939, 1618, 2748, 2133, 2794, 1076,
        1879, 2894, 1176, 2416])
Epoch: 2960, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2961 - Batch 1 ########################
IDs in batch 1: tensor([3733,  340, 2824, 3387,  666, 3551, 2277, 2125, 3143, 3920,  910, 2205,
        2737,  928, 1285, 3688])
Epoch: 2961, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2962 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 3200,  104, 2867, 1302, 2087, 3367, 2583, 2249, 3318, 2734, 3636,
        4251,  322, 2369, 1860])
Epoch: 2962, Training Loss: 0.25, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2963 - Batch 1 ########################
IDs in batch 1: tensor([1708,  394, 2088, 3270, 2514,  942, 2725,  445, 1497, 3275,  278,  582,
        3671, 1075, 2323, 2251])
Epoch: 2963, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2964 - Batch 1 ########################
IDs in batch 1: tensor([4214,  965, 2509, 3121, 3417, 2052, 3763,   30, 3056, 3618, 3660, 1251,
        2495,  588, 4025, 3541])
Epoch: 2964, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2965 - Batch 1 ########################
IDs in batch 1: tensor([2966, 2914, 1060, 1396, 2516, 2749, 4103, 4196, 4060, 2284, 1387,  357,
         244,  730, 4077,  613])
Epoch: 2965, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2966 - Batch 1 ########################
IDs in batch 1: tensor([ 442, 1649,  356, 1286,  796, 1077,  257, 4220, 3875,  483, 1423,  534,
        3353, 1658, 1545, 3385])
Epoch: 2966, Training Loss: 0.42, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2967 - Batch 1 ########################
IDs in batch 1: tensor([2924, 2066,  823, 2334,  954, 1590, 2035, 1014, 4215, 1613, 3494, 2120,
        4128,  834, 4180, 3845])
Epoch: 2967, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2968 - Batch 1 ########################
IDs in batch 1: tensor([3451, 1991, 1509, 3466, 1708,  819,  710, 2393,  970, 3323, 3157,  774,
         128, 4087,  143,  546])
Epoch: 2968, Training Loss: 0.28, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2969 - Batch 1 ########################
IDs in batch 1: tensor([ 988, 1500, 4166, 3270, 3364, 2511, 3157, 3373, 1600, 1574, 2687, 2742,
        3858, 2441, 2659, 1282])
Epoch: 2969, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2970 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 2314, 1583,  109, 1935,  167, 4067, 3452, 2632, 2990,  982, 2429,
         340, 1322, 4251,  893])
Epoch: 2970, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2971 - Batch 1 ########################
IDs in batch 1: tensor([ 527,  439, 1626, 3869, 2812, 4203, 4185,  926, 4089, 4039, 1602,  489,
        2212, 2537, 3506, 2013])
Epoch: 2971, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2972 - Batch 1 ########################
IDs in batch 1: tensor([2655, 2167, 2120, 1289, 2483, 3885, 2433, 3254, 1286, 4215, 2945,  229,
         890,  375, 3108, 3459])
Epoch: 2972, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2973 - Batch 1 ########################
IDs in batch 1: tensor([ 100, 4170, 3754, 1204,  264, 1512, 2349, 3706, 3614, 2817,  258, 1627,
        2073, 1728, 4121, 1351])
Epoch: 2973, Training Loss: 0.32, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2974 - Batch 1 ########################
IDs in batch 1: tensor([1163,  518, 2627, 1222, 3756, 3035, 3141, 4230, 3199, 3181, 3318,  607,
        3218, 3214,  475, 3290])
Epoch: 2974, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2975 - Batch 1 ########################
IDs in batch 1: tensor([  78, 3537, 1746, 1810, 2258, 3964,  459, 3005,  237,  137, 3111, 3763,
        2065,  913, 2854, 1128])
Epoch: 2975, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 2976 - Batch 1 ########################
IDs in batch 1: tensor([1860, 4060, 3083, 1081, 1496, 1850, 2689, 2236, 3303, 3151, 2413, 3598,
        3385, 2172,  263, 2765])
Epoch: 2976, Training Loss: 0.14, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 2977 - Batch 1 ########################
IDs in batch 1: tensor([2621,  262, 4176,  358,  393, 3364, 1234,  747, 3739,  924,  481, 1010,
        1548, 4025, 3429, 2329])
Epoch: 2977, Training Loss: 0.20, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2978 - Batch 1 ########################
IDs in batch 1: tensor([ 459, 4173,  335,  774, 2038, 2228, 3563,  139, 3886, 2957, 3387, 1179,
          84, 1657, 3782, 3860])
Epoch: 2978, Training Loss: 0.24, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 2979 - Batch 1 ########################
IDs in batch 1: tensor([3448, 3499, 2826, 1804,  980, 1060,   68, 3554, 2309, 3950, 2578, 1896,
        3254, 2107, 2693, 1748])
Epoch: 2979, Training Loss: 0.31, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 2980 - Batch 1 ########################
IDs in batch 1: tensor([ 317, 2917, 3309, 1555, 2416, 1471, 1795, 1365, 3105,  989,  750, 4017,
        4055, 3505, 1137, 2822])
Epoch: 2980, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2981 - Batch 1 ########################
IDs in batch 1: tensor([ 295, 1351, 3362, 3156, 3715,  295, 4227, 3152, 3637, 4140, 1823, 2107,
         494, 2393, 4119, 2991])
Epoch: 2981, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2982 - Batch 1 ########################
IDs in batch 1: tensor([3705, 2621, 1310, 3219, 1457, 3920, 2539, 3389, 2356, 2885,  966, 2691,
        3643, 2401,  792,  415])
Epoch: 2982, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2983 - Batch 1 ########################
IDs in batch 1: tensor([1588, 3869,   93,  345, 2390, 3065,  693, 2510,  223, 1420, 3146, 1355,
         391, 1947, 3659, 2400])
Epoch: 2983, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2984 - Batch 1 ########################
IDs in batch 1: tensor([2126,  881, 2780,  976, 3494, 3053, 1154, 2196, 3429, 1887, 2718, 1051,
        3599, 2034, 3977, 3376])
Epoch: 2984, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 2985 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 3010, 1855, 3075, 2706, 3150, 4124, 3447,  966, 1340,  834, 1247,
        2828, 1237, 2230,  452])
Epoch: 2985, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 2986 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 3047, 2795, 2393, 4027, 1239, 2591, 1842, 1612, 1180, 2986,   97,
         976, 1373,  954, 3425])
Epoch: 2986, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 2987 - Batch 1 ########################
IDs in batch 1: tensor([ 359,  658,  733,  914,  752,  811, 4082,  427, 1592,  196, 2391, 1935,
        1087, 3650, 3858,   38])
Epoch: 2987, Training Loss: 0.51, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2988 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 1752, 3427, 2328, 3675, 3858,  556, 3921, 1388,  532,   31,  874,
         649,  171, 3572, 2828])
Epoch: 2988, Training Loss: 0.26, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2989 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 3568, 3099,  274, 1942,  260, 3035,   46,  566, 4242, 3513, 2056,
        3993, 1702,  770, 3311])
Epoch: 2989, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2990 - Batch 1 ########################
IDs in batch 1: tensor([2398, 2806, 3069,  154, 1710, 1233, 2115, 1043, 2274, 2193, 3154, 1747,
        2120,   88, 3529, 3532])
Epoch: 2990, Training Loss: 0.28, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2991 - Batch 1 ########################
IDs in batch 1: tensor([3524, 1745, 4195, 3673,   10, 1968, 4198,  150, 3065, 3539, 1764,  320,
        4195, 4038, 1248,  491])
Epoch: 2991, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2992 - Batch 1 ########################
IDs in batch 1: tensor([1950, 2031, 4080, 1178, 1884, 1066, 3535, 4229, 2974, 4078,  850, 1887,
        1764, 2967, 3521, 1391])
Epoch: 2992, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2993 - Batch 1 ########################
IDs in batch 1: tensor([ 676, 1434, 3368,  997, 1260, 3917, 3465, 4238, 2306, 3961, 3537, 2567,
        2591, 2894, 2346, 3557])
Epoch: 2993, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2994 - Batch 1 ########################
IDs in batch 1: tensor([1795, 2510, 4197,  615, 1270, 3418, 1225, 3677, 2049,  942,  527, 1849,
        2014, 1263, 4056,  467])
Epoch: 2994, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2995 - Batch 1 ########################
IDs in batch 1: tensor([2954, 2649,  739,  678,  763, 2226, 3177, 1426, 2688, 3795, 2899,  252,
         181, 2166,  360, 1291])
Epoch: 2995, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2996 - Batch 1 ########################
IDs in batch 1: tensor([ 220, 1343, 2809, 2092, 3384, 2053, 3781, 3141,  781, 3524, 1506, 1712,
        2996,  936, 3902,  531])
Epoch: 2996, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2997 - Batch 1 ########################
IDs in batch 1: tensor([1646, 2159,  351, 1173, 2456, 3701,  256, 2819,  345, 2798, 2664,  181,
        4199, 1360, 3688, 2984])
Epoch: 2997, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2998 - Batch 1 ########################
IDs in batch 1: tensor([2489, 2161, 2870,  816,  106, 1498, 3425, 2860, 2094, 1521, 1028,   74,
        2793, 3440, 3712, 3183])
Epoch: 2998, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2999 - Batch 1 ########################
IDs in batch 1: tensor([3862, 2537,  596,  373,  194,  568, 2254, 3749, 2754, 3711,  609,  557,
        3286, 2772, 3268, 2157])
Epoch: 2999, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3000 - Batch 1 ########################
IDs in batch 1: tensor([2202,  165, 1491, 1167, 4227, 2199, 2926, 1491, 2863,   68, 2372, 3879,
        1102,  752,  721, 3896])
Epoch: 3000, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3001 - Batch 1 ########################
IDs in batch 1: tensor([1157, 4232, 1578, 1693, 3227, 3733, 3588, 2209,  969, 1085, 2638, 3474,
        3933, 3853, 2812,  757])
Epoch: 3001, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 3002 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 2081, 1945, 1328, 3554, 4138, 3971, 1633, 1372, 3047,   18,  405,
        3904, 1795,  131,  666])
Epoch: 3002, Training Loss: 0.23, Validation Loss: 0.74, accuracy = 0.72
######################## Epoch 3003 - Batch 1 ########################
IDs in batch 1: tensor([1614, 3610, 1656, 2524, 3178, 4101, 1578, 1660, 2976,  362, 2372, 1141,
         191, 1069, 4103, 2689])
Epoch: 3003, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3004 - Batch 1 ########################
IDs in batch 1: tensor([ 874, 3827, 4033,  874, 2671, 1316, 1088, 2516, 3027, 3112, 2924,  842,
        3022, 1932, 2869, 1241])
Epoch: 3004, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3005 - Batch 1 ########################
IDs in batch 1: tensor([1546, 1076, 3872, 1480,  687, 2959,  265, 3974,  876, 2717,   71,  121,
        2947,  360,  129, 2828])
Epoch: 3005, Training Loss: 0.39, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3006 - Batch 1 ########################
IDs in batch 1: tensor([3995, 2385, 4082, 2292, 3255, 3345, 3557, 1443, 1852, 1851,  626, 2161,
        4077,  379, 2366, 2334])
Epoch: 3006, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3007 - Batch 1 ########################
IDs in batch 1: tensor([3187, 3789, 2868,  635, 3449, 2234,  488, 1041, 3162, 1646, 1772,  672,
        2403,   70, 3760,  829])
Epoch: 3007, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3008 - Batch 1 ########################
IDs in batch 1: tensor([3787,  661, 1518, 3587, 2777,  317,  141, 3806, 1374, 3358, 1508,  332,
         815, 3391, 3699, 3328])
Epoch: 3008, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3009 - Batch 1 ########################
IDs in batch 1: tensor([3789, 2559, 4224, 1726, 1959,  342,  996, 1972, 1923, 1965,  691, 1624,
        1302,  332, 1256, 2998])
Epoch: 3009, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3010 - Batch 1 ########################
IDs in batch 1: tensor([2942, 1005,  470,  435,  483, 1092, 2724, 2838, 4263, 1958, 3283,  368,
        4099, 1264, 4180,  989])
Epoch: 3010, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3011 - Batch 1 ########################
IDs in batch 1: tensor([ 681, 1322,  198, 3829, 1161, 1385, 3434, 1421, 3461, 1766,  538, 2218,
        1130, 1305, 3593,  663])
Epoch: 3011, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3012 - Batch 1 ########################
IDs in batch 1: tensor([1592, 1073, 1374, 3832, 4184,  220, 1438, 4024,  290,  516, 2065, 1199,
        3572, 3747, 1355, 1573])
Epoch: 3012, Training Loss: 0.52, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3013 - Batch 1 ########################
IDs in batch 1: tensor([2209,  181, 3516, 2868, 3922, 2053, 2926, 3152, 1570, 2119, 3081, 2488,
         348, 4217, 2644, 3166])
Epoch: 3013, Training Loss: 0.32, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3014 - Batch 1 ########################
IDs in batch 1: tensor([  77,  941, 1795, 2709, 3400, 1673, 4012, 2452, 1948, 1252, 1892, 1224,
         981,  555, 1597,  704])
Epoch: 3014, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3015 - Batch 1 ########################
IDs in batch 1: tensor([3803,  878, 4087, 1315,  211, 3194, 2234, 3385, 1005, 1473, 3368, 2825,
        1006,  141, 1463, 1094])
Epoch: 3015, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3016 - Batch 1 ########################
IDs in batch 1: tensor([4263, 2645,  773, 3038, 2627, 3570, 3221,  183, 1198, 1065, 4093, 3539,
         725,  680, 2990, 2551])
Epoch: 3016, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3017 - Batch 1 ########################
IDs in batch 1: tensor([ 472, 2028, 2700, 3876,  778,  989, 3651, 3813, 3810, 2949, 2949, 1007,
        3970, 4159, 2894,  941])
Epoch: 3017, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3018 - Batch 1 ########################
IDs in batch 1: tensor([2161, 3410, 2723, 1189, 1428, 1226,  505, 3813,  909, 2745, 1734, 2742,
        3587, 3492, 4249, 2667])
Epoch: 3018, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3019 - Batch 1 ########################
IDs in batch 1: tensor([2488, 2371, 3268, 3022, 3501, 4117,  941, 2296,  726,  606,  823,  450,
        2701, 1600, 3594, 1185])
Epoch: 3019, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3020 - Batch 1 ########################
IDs in batch 1: tensor([1276, 2431, 3498, 2468, 3340, 2091, 2053, 2775, 3168, 4075, 1959, 1043,
         651,  792,  517, 1798])
Epoch: 3020, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3021 - Batch 1 ########################
IDs in batch 1: tensor([3683, 2884, 2402, 2450,  388, 4055, 1023, 2661, 2137, 3506, 2182,  442,
        3044, 3309, 3504, 2223])
Epoch: 3021, Training Loss: 0.43, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3022 - Batch 1 ########################
IDs in batch 1: tensor([1195, 1502,  954, 2912, 3123, 1976, 3240,  778,  604,  451, 1022, 2008,
         930, 3124, 3016,  149])
Epoch: 3022, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.71
######################## Epoch 3023 - Batch 1 ########################
IDs in batch 1: tensor([3938, 2040, 1001,  466, 1278, 2796, 2449, 1891, 1536, 1766, 1437,  936,
         587, 2316,  363, 1299])
Epoch: 3023, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3024 - Batch 1 ########################
IDs in batch 1: tensor([1360,  678, 1310, 1620, 3036,  185, 2815, 4097, 2344, 4062, 3919, 1508,
        1504,   52,  587, 2660])
Epoch: 3024, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3025 - Batch 1 ########################
IDs in batch 1: tensor([1973, 1594, 1672, 2026, 2537, 1537,  515, 2715,  154, 3850, 1488,  316,
        2644,   21,  578, 2741])
Epoch: 3025, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 3026 - Batch 1 ########################
IDs in batch 1: tensor([ 403, 1255, 1803, 3719, 2060,   61, 1176, 2618, 3760, 4101, 2313, 2758,
        2412, 2540, 1722,  396])
Epoch: 3026, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 3027 - Batch 1 ########################
IDs in batch 1: tensor([3756, 1728, 4033, 1724, 1761,  314,  132, 3952, 2125, 2601, 1073, 3379,
        3283, 3151, 2787, 1343])
Epoch: 3027, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 3028 - Batch 1 ########################
IDs in batch 1: tensor([1948, 1895, 3786, 1834, 2796, 2802, 2122,   44, 3712, 1546, 1543, 1975,
        1589, 3278,   32, 2298])
Epoch: 3028, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.69
######################## Epoch 3029 - Batch 1 ########################
IDs in batch 1: tensor([3276, 2526,   28, 1860, 2963, 2279,  147, 2745, 3314,  555, 1599, 1645,
        2025, 3271, 3053,  632])
Epoch: 3029, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.69
######################## Epoch 3030 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 3746, 3888, 1518, 2936,  145, 2461, 1727, 3005, 2244, 1648, 2355,
        1836, 2738, 3702,  314])
Epoch: 3030, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 3031 - Batch 1 ########################
IDs in batch 1: tensor([1866, 1171, 2947, 1638, 1052,  346,  996, 3052, 3029, 3136,  613,  287,
        2780, 2455, 2202, 2377])
Epoch: 3031, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.70
######################## Epoch 3032 - Batch 1 ########################
IDs in batch 1: tensor([ 977, 3771, 3581, 2223, 3663, 3656,  684,  818,  398, 2231, 1702, 3208,
        3829,  894, 2567, 2369])
Epoch: 3032, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3033 - Batch 1 ########################
IDs in batch 1: tensor([1015, 1275, 2506, 3827, 2400, 3270, 2526,  213, 1286,  305, 3743, 1822,
        3259, 3047, 3159, 3975])
Epoch: 3033, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3034 - Batch 1 ########################
IDs in batch 1: tensor([2230,  875,  617, 2106, 2890,  512, 4214, 3635, 2849, 2342, 3536, 1132,
        2644, 2315, 1291, 3859])
Epoch: 3034, Training Loss: 0.31, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 3035 - Batch 1 ########################
IDs in batch 1: tensor([1633, 2653, 2102, 1193, 3830, 1823, 2111, 3697, 1471, 4185,  894, 1648,
        3545, 3005,  214, 1043])
Epoch: 3035, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3036 - Batch 1 ########################
IDs in batch 1: tensor([2539, 1273, 1484, 1195, 2199, 3492, 2441, 2322, 1132, 1445, 4161, 1900,
         465, 2382, 4013, 4024])
Epoch: 3036, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3037 - Batch 1 ########################
IDs in batch 1: tensor([2230,  993, 1404, 2710, 4086, 1009,  882,   24,  918, 3087, 1341, 2483,
        3583, 3786, 1066, 3139])
Epoch: 3037, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3038 - Batch 1 ########################
IDs in batch 1: tensor([2441, 2226, 3065, 2776,  327, 2256, 2423,   14, 4119, 1111,  837, 1863,
         797, 1842, 1916, 2882])
Epoch: 3038, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3039 - Batch 1 ########################
IDs in batch 1: tensor([2414, 2346, 1044,  155,  656, 3366,  200, 2470,  758, 1604, 4261,  667,
        3762, 1251,  229, 3344])
Epoch: 3039, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3040 - Batch 1 ########################
IDs in batch 1: tensor([1409, 2535, 2107, 2509,  683, 3308, 2718, 2413,  258, 4068,  882, 3321,
        1708,  199,  100,  217])
Epoch: 3040, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3041 - Batch 1 ########################
IDs in batch 1: tensor([3962, 2591, 2419, 2248, 1030,  923, 3278, 2754, 2224, 1136,  510,  678,
          73, 3373, 3927, 2847])
Epoch: 3041, Training Loss: 0.46, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3042 - Batch 1 ########################
IDs in batch 1: tensor([ 295, 3530,   74, 1067, 2856, 3496,  544, 2436, 3874,  409,  367, 2156,
         292, 2028, 3368, 1053])
Epoch: 3042, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 3043 - Batch 1 ########################
IDs in batch 1: tensor([3506, 1540, 1388, 2765, 3635, 3667, 4040, 2828,  488, 3866, 3290,  644,
        3039,  887, 2749,  815])
Epoch: 3043, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3044 - Batch 1 ########################
IDs in batch 1: tensor([3842,  537, 2520, 1278, 1868, 2070, 3243, 4039, 1463, 1798, 2589, 2287,
        2291,  213, 1306, 1993])
Epoch: 3044, Training Loss: 0.15, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3045 - Batch 1 ########################
IDs in batch 1: tensor([1092, 1376, 3936, 1956,  910, 1766, 2365,  687,   97, 2837, 1955,  527,
         427, 3838, 3394, 3535])
Epoch: 3045, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3046 - Batch 1 ########################
IDs in batch 1: tensor([2956,  961,  365, 4103, 2052, 3600, 3032, 2996, 1133, 3240,  384, 3489,
        3390, 3733, 3351, 2097])
Epoch: 3046, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3047 - Batch 1 ########################
IDs in batch 1: tensor([2176, 1933, 2111,  610,  193, 3873,  417, 4128,  886, 3558,  756, 1234,
         770, 2908,  512,   59])
Epoch: 3047, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3048 - Batch 1 ########################
IDs in batch 1: tensor([2597, 3699, 1698, 3489,  371, 2984,   85, 3262, 2956, 1568,  345,  537,
        2172, 2925, 2553, 1209])
Epoch: 3048, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3049 - Batch 1 ########################
IDs in batch 1: tensor([ 710,  891, 1328, 3168, 2013,  788, 2406,  212, 1256, 2023, 3082, 3384,
        2092, 1370, 2951, 3637])
Epoch: 3049, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3050 - Batch 1 ########################
IDs in batch 1: tensor([1080, 2682,  573, 2347, 3208, 3751, 2498, 2942, 1860, 3599, 3733, 2095,
        2726,  763, 2296, 3715])
Epoch: 3050, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3051 - Batch 1 ########################
IDs in batch 1: tensor([1892, 1140, 4196,  771, 3554,  550,  926, 1580, 1471,  823, 3807, 3926,
         352, 2775, 2378, 3370])
Epoch: 3051, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3052 - Batch 1 ########################
IDs in batch 1: tensor([1955, 4238, 2817, 1809, 2385, 1858, 2493, 4229, 1793, 4199, 2437, 1678,
        2921, 1597, 4238, 1948])
Epoch: 3052, Training Loss: 0.40, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3053 - Batch 1 ########################
IDs in batch 1: tensor([3721,  771, 3511, 2572,  388,  908, 1879, 2959,  150, 2789, 2338, 1641,
        2425, 2715, 3126,  851])
Epoch: 3053, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3054 - Batch 1 ########################
IDs in batch 1: tensor([ 535, 1794, 2587, 3564, 4078,   49, 3465, 2847, 2715, 3017, 2736,  632,
        3030, 3233, 1005, 2670])
Epoch: 3054, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3055 - Batch 1 ########################
IDs in batch 1: tensor([ 709, 2018, 4185,  625, 1592, 1579,  857,  852, 4240,  518,  161,  141,
        2559, 1354, 2849, 2119])
Epoch: 3055, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3056 - Batch 1 ########################
IDs in batch 1: tensor([3382, 1051, 1063, 2599,  873, 2603, 1986, 3610,  252,  315, 1459, 1855,
        1859, 2431, 1740, 1861])
Epoch: 3056, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3057 - Batch 1 ########################
IDs in batch 1: tensor([3058, 1340,   11, 1563, 1111,   25,  558, 3459, 4230,  612, 1167, 1410,
        1166, 1647,  527, 3375])
Epoch: 3057, Training Loss: 0.35, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3058 - Batch 1 ########################
IDs in batch 1: tensor([1004,  730, 2603, 1186, 3940, 2968, 3813,  394, 1596, 3886, 1390, 3592,
        1177, 3997, 1325, 1902])
Epoch: 3058, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3059 - Batch 1 ########################
IDs in batch 1: tensor([3394, 3344, 1543, 1958,  636, 1354,  481,  415, 2568, 1590,  182, 3997,
         238, 3940, 1552, 1842])
Epoch: 3059, Training Loss: 0.41, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3060 - Batch 1 ########################
IDs in batch 1: tensor([3217, 2440, 1563, 3961, 3409, 2879, 2901, 1484, 2947, 1299, 4068, 1043,
        1972, 2616,  627, 2149])
Epoch: 3060, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3061 - Batch 1 ########################
IDs in batch 1: tensor([4215, 4085, 3610, 3267,  656, 3789, 2966,  186, 1627, 3031, 2418,  854,
        2009, 3264, 2824, 2954])
Epoch: 3061, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3062 - Batch 1 ########################
IDs in batch 1: tensor([  64, 1780,  137, 2086, 2668,  825, 3544, 1858,  363, 1789, 1003, 1234,
        1980, 3995, 3506, 2046])
Epoch: 3062, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3063 - Batch 1 ########################
IDs in batch 1: tensor([2572, 2358, 2973, 3926, 2027, 2991, 4251,  996, 1065,  532, 1042, 1772,
        1879,   34, 1491,  503])
Epoch: 3063, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3064 - Batch 1 ########################
IDs in batch 1: tensor([2901, 3003, 1271, 3749, 2049, 3980, 3177, 2145,  344,   24, 2859,  258,
         377, 2993, 2755, 2483])
Epoch: 3064, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3065 - Batch 1 ########################
IDs in batch 1: tensor([ 352, 3516, 2854, 3732, 1179, 2278, 2281, 1986, 3999, 2983, 2344,   42,
        3187, 1952, 1942,  245])
Epoch: 3065, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3066 - Batch 1 ########################
IDs in batch 1: tensor([2141, 1252, 2478, 1850, 3394, 2748, 2027, 1459, 3518, 1014, 2095, 3037,
         395, 3029, 1099, 1126])
Epoch: 3066, Training Loss: 0.23, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 3067 - Batch 1 ########################
IDs in batch 1: tensor([2624, 1044, 3526, 4256, 1371, 3476, 3060, 2412,  838, 2378, 2780, 1387,
         125, 3972, 3507, 2040])
Epoch: 3067, Training Loss: 0.15, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3068 - Batch 1 ########################
IDs in batch 1: tensor([4251,  779, 3355, 1644, 3738, 3338,  557,  259, 3544,  505, 1921, 3527,
        2892,  934,   51,  756])
Epoch: 3068, Training Loss: 0.09, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3069 - Batch 1 ########################
IDs in batch 1: tensor([1500, 1984, 2376, 2868,  128, 2575, 2185, 1297, 2213, 1076, 2431, 1208,
        1828, 3438, 2645, 3806])
Epoch: 3069, Training Loss: 0.40, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3070 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2111, 1677, 2205, 2856, 3435, 2287,  811, 1035,  869, 2925, 1764,
        1136, 4135, 1545, 3432])
Epoch: 3070, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.68
######################## Epoch 3071 - Batch 1 ########################
IDs in batch 1: tensor([ 672, 3553, 2731, 1017, 1675, 2689, 3872, 1454, 2144,  422,  846, 3354,
        3859, 2487,  516,  510])
Epoch: 3071, Training Loss: 0.20, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3072 - Batch 1 ########################
IDs in batch 1: tensor([2413,   44, 2724, 4258, 2247, 3782, 3391, 1471, 1077, 3022, 1490, 2874,
         993, 3998, 2203,  674])
Epoch: 3072, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3073 - Batch 1 ########################
IDs in batch 1: tensor([2172, 3862, 3279,  295, 3988, 2927, 2683, 4174,  377, 2978,   82, 3474,
        2179, 4009, 1137, 1437])
Epoch: 3073, Training Loss: 0.22, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3074 - Batch 1 ########################
IDs in batch 1: tensor([ 823, 3802, 3960, 3826, 3214, 3244, 2110,  756, 2040,  714, 3193,  488,
        1069,  615, 2851, 2726])
Epoch: 3074, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3075 - Batch 1 ########################
IDs in batch 1: tensor([1746, 1959, 1723, 1951, 2932, 1159, 3885,  753, 3608,  829, 2229,  788,
        3447, 3503, 2497,   61])
Epoch: 3075, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3076 - Batch 1 ########################
IDs in batch 1: tensor([1124, 3792, 2356, 2980,  536, 1020, 3370, 3371,  199, 3255, 3282, 2251,
        3537,   63, 2868,  187])
Epoch: 3076, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3077 - Batch 1 ########################
IDs in batch 1: tensor([ 427, 4173, 1260, 1812, 1367, 2003, 2064, 1258, 1436,  214, 3597, 2145,
         555,  394,  449, 3677])
Epoch: 3077, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 3078 - Batch 1 ########################
IDs in batch 1: tensor([3733,  666,  628,  613, 3675, 1258,  900, 4205, 1277,  106, 3588, 1684,
        1055, 3783,  653, 3870])
Epoch: 3078, Training Loss: 0.83, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3079 - Batch 1 ########################
IDs in batch 1: tensor([2317,    5, 2146, 3083, 3570, 2738, 4179,  239,  992, 2772, 3927, 2937,
        2315, 2682, 1881, 1665])
Epoch: 3079, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3080 - Batch 1 ########################
IDs in batch 1: tensor([2204,  959, 3769, 1008, 1437, 1953,   24, 3940,  816, 1976, 2446, 2443,
        2804, 1872, 1575, 3024])
Epoch: 3080, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3081 - Batch 1 ########################
IDs in batch 1: tensor([ 778, 4089,  131,  172,   51, 3270, 3446, 1364, 2899,  980,  993, 1660,
         557, 2317, 2118, 3185])
Epoch: 3081, Training Loss: 0.28, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 3082 - Batch 1 ########################
IDs in batch 1: tensor([1294, 1377,  959, 1914, 1354,  371, 4011, 2767, 3879, 1201, 2546, 3610,
        1242, 3668, 2688, 4136])
Epoch: 3082, Training Loss: 0.15, Validation Loss: 0.83, accuracy = 0.69
######################## Epoch 3083 - Batch 1 ########################
IDs in batch 1: tensor([4165, 4060,  412,  670, 2934,  188, 2804, 1651, 1443, 1537,  862, 1570,
        3785, 3352,  985, 4068])
Epoch: 3083, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3084 - Batch 1 ########################
IDs in batch 1: tensor([2965, 2313,  850, 1024,  537,  516,  126,  397, 1620, 2472, 4232, 1671,
        3995, 2678, 4163, 1216])
Epoch: 3084, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.69
######################## Epoch 3085 - Batch 1 ########################
IDs in batch 1: tensor([ 680, 1624, 3460, 1733, 3047, 2450,  469, 3948, 3969,  894,  530, 4139,
        3275, 2791, 2009,  667])
Epoch: 3085, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.69
######################## Epoch 3086 - Batch 1 ########################
IDs in batch 1: tensor([3414, 2600,  145, 2940, 1351, 3664,  729, 3753,  430, 1632, 1968, 1953,
         873, 2879,  103, 4195])
Epoch: 3086, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3087 - Batch 1 ########################
IDs in batch 1: tensor([4058, 3253,  908, 1618, 2464, 1066, 3878, 3204, 2075,  964, 1062, 4101,
        2488, 3197, 1154, 2279])
Epoch: 3087, Training Loss: 0.31, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3088 - Batch 1 ########################
IDs in batch 1: tensor([3600, 4014, 1794, 2640, 3930, 2432, 2406, 3787, 1630, 3378,  356, 3822,
        4039,   63,  820,   52])
Epoch: 3088, Training Loss: 0.44, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3089 - Batch 1 ########################
IDs in batch 1: tensor([1896,  917,  915, 1124, 1824, 1980,   38, 1655, 4194, 2641, 2431, 2357,
        2148, 4186, 2496, 3947])
Epoch: 3089, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3090 - Batch 1 ########################
IDs in batch 1: tensor([3990, 3441,  125,  185, 3969, 3787, 2568, 3476,  237, 3119, 3879, 1349,
        2280,  494,  866, 1221])
Epoch: 3090, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3091 - Batch 1 ########################
IDs in batch 1: tensor([2659, 4156,  957, 3128, 2148, 2838, 2349, 2092, 2836, 1133, 4009, 3194,
         312,  363,  395, 4139])
Epoch: 3091, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3092 - Batch 1 ########################
IDs in batch 1: tensor([ 631, 2676,   47, 2019, 1247,  372, 3742, 2555, 2969,  969,  491, 1980,
        3100, 2791, 4225, 4213])
Epoch: 3092, Training Loss: 0.28, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3093 - Batch 1 ########################
IDs in batch 1: tensor([3526, 1107, 2072, 1285,  466,    5, 1892, 2119, 3441, 2159, 4138, 2387,
        2192,  529, 3382, 2597])
Epoch: 3093, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3094 - Batch 1 ########################
IDs in batch 1: tensor([1201, 2605,  824, 1050,  954, 1521, 2986, 1248,  226,   38,  788,  871,
        1658, 3632,  881, 3537])
Epoch: 3094, Training Loss: 0.30, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3095 - Batch 1 ########################
IDs in batch 1: tensor([1592, 1644,  960, 4144, 3369, 3015, 2296, 4139,  954, 4039, 1817, 2659,
        1260, 4236, 3337, 2797])
Epoch: 3095, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3096 - Batch 1 ########################
IDs in batch 1: tensor([3903,  723,  756, 3962, 1284,  312, 1419, 2655,  199, 1168,  455, 2967,
        2775, 2860, 2247, 2465])
Epoch: 3096, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3097 - Batch 1 ########################
IDs in batch 1: tensor([1160, 3991, 2641, 1734,  842, 1682,  974, 2799, 2157, 3368, 1017, 3241,
        2245,  373, 2931, 1117])
Epoch: 3097, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3098 - Batch 1 ########################
IDs in batch 1: tensor([ 487, 3219, 2440,  875, 4033,  667,  615, 4138, 2742, 1770, 2448, 1658,
        1073, 2407,  978, 2249])
Epoch: 3098, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3099 - Batch 1 ########################
IDs in batch 1: tensor([3015, 3834, 2885, 2545, 3235,  183, 1282,  536,  876, 3344, 3321, 3903,
         900, 2246, 2104, 1879])
Epoch: 3099, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3100 - Batch 1 ########################
IDs in batch 1: tensor([3554, 2960, 1219, 3951,  610, 4026, 4017, 3592, 2183, 1436, 3246, 2605,
        1206, 2589, 1708,  206])
Epoch: 3100, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3101 - Batch 1 ########################
IDs in batch 1: tensor([4122, 1267,  105,  816, 3831,  566, 4115, 3732, 2114, 1773, 3021, 1772,
        1174, 3016, 4214, 1901])
Epoch: 3101, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3102 - Batch 1 ########################
IDs in batch 1: tensor([1219, 3256, 2339, 4094,  976, 4215, 2015,  108, 1256, 2871, 2277, 4067,
        3926, 1471, 3541, 3439])
Epoch: 3102, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3103 - Batch 1 ########################
IDs in batch 1: tensor([1727, 4185, 3119,   59,  546,  536, 2046, 1970,  403, 2746, 3161, 1014,
        3547, 2945, 4253,  718])
Epoch: 3103, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3104 - Batch 1 ########################
IDs in batch 1: tensor([1700, 2499,  961, 3117, 1084, 2377, 3016, 1497, 2295, 3767, 3590, 3479,
        3823, 2989, 2717,  902])
Epoch: 3104, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3105 - Batch 1 ########################
IDs in batch 1: tensor([1035, 2059, 1952,  937, 1601, 2819, 2740, 1434, 2338, 3206, 3020,  662,
        1185, 1793, 3846, 3358])
Epoch: 3105, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3106 - Batch 1 ########################
IDs in batch 1: tensor([ 315, 3900, 1098, 1423, 3786,  762, 2429, 2025, 1443, 3908, 2572, 1845,
         883, 2711,  990, 3778])
Epoch: 3106, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3107 - Batch 1 ########################
IDs in batch 1: tensor([ 738, 3995, 4138, 2767, 1408, 2592, 2066, 1438,  277, 1055, 4225, 2591,
          96, 2060, 1278,   47])
Epoch: 3107, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3108 - Batch 1 ########################
IDs in batch 1: tensor([4069, 3479, 1499, 2363, 1636, 1921, 1361,   37, 1197, 3588, 1357, 2523,
         358, 3689, 3663,   81])
Epoch: 3108, Training Loss: 0.16, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3109 - Batch 1 ########################
IDs in batch 1: tensor([1728, 3846, 2748, 4016, 3227, 4179, 1947, 1360,   34, 4185, 3458, 3954,
         681,  387, 2338,  894])
Epoch: 3109, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3110 - Batch 1 ########################
IDs in batch 1: tensor([ 960, 3330,  527, 3888,  403, 2905, 2898,  396, 1558, 1655, 3976, 1480,
        1126, 1144, 1186,  413])
Epoch: 3110, Training Loss: 0.20, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3111 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 3408, 2237, 3303, 2225,  583,  376, 2516, 1249, 4124,  583,  588,
        1056, 3306, 3926, 1099])
Epoch: 3111, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3112 - Batch 1 ########################
IDs in batch 1: tensor([3779, 3471, 3971, 3821, 2146, 2477,  953,  573,  363, 1765,  612, 1639,
        3932, 1911,  451, 1277])
Epoch: 3112, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3113 - Batch 1 ########################
IDs in batch 1: tensor([2349, 2431, 1120, 1799, 1410, 3385, 3734,  434, 4046, 2876, 2912,  514,
        1297,  993, 2022, 1037])
Epoch: 3113, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3114 - Batch 1 ########################
IDs in batch 1: tensor([ 895,  344, 3458,  890, 2897, 2271, 2415, 1632,  723, 1360,  340, 1834,
        2013, 3298, 1332, 1324])
Epoch: 3114, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3115 - Batch 1 ########################
IDs in batch 1: tensor([2887, 3180, 2731, 1965, 1921,  101, 1185, 3663, 3289, 1923,  139, 1218,
        4205,  934, 2299, 1395])
Epoch: 3115, Training Loss: 0.21, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3116 - Batch 1 ########################
IDs in batch 1: tensor([3044,  888, 4140, 2783, 1504,  448, 3972,  422,   51, 1139,  970, 1354,
        1320, 4140,  603, 1410])
Epoch: 3116, Training Loss: 0.52, Validation Loss: 0.82, accuracy = 0.69
######################## Epoch 3117 - Batch 1 ########################
IDs in batch 1: tensor([4222, 3755, 2956, 1518, 2954, 3896, 2437,  795, 3972, 2493, 1799, 1070,
        2342, 2352,  455, 4015])
Epoch: 3117, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3118 - Batch 1 ########################
IDs in batch 1: tensor([ 843, 1390, 1832, 1668,  887, 1070, 1990,  376,  778, 4189, 1038, 2739,
        1349, 3895, 2851, 2959])
Epoch: 3118, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3119 - Batch 1 ########################
IDs in batch 1: tensor([3968, 1453, 2439,   74, 4187, 2721, 4195, 1414, 2306, 3945, 2508, 2802,
        4076, 3713, 3115, 1077])
Epoch: 3119, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3120 - Batch 1 ########################
IDs in batch 1: tensor([1650, 1772, 1260, 3152, 3234, 2546, 3020, 1823, 3123, 1779, 2956,  476,
        2551,  804, 1977, 2382])
Epoch: 3120, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3121 - Batch 1 ########################
IDs in batch 1: tensor([2030, 4173, 1506, 3742, 1591, 2509, 2797, 3427, 2265, 3882, 2230, 2777,
        3069, 1107, 1308, 3425])
Epoch: 3121, Training Loss: 0.08, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3122 - Batch 1 ########################
IDs in batch 1: tensor([1981, 1887, 1116, 3486, 2583, 3388, 3767, 2349, 3779, 4002, 1891,  435,
        1311, 3409, 2078,   19])
Epoch: 3122, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3123 - Batch 1 ########################
IDs in batch 1: tensor([1371,  577,  604, 1594, 1524, 1620, 2324, 3933, 1017,  588, 4220, 2407,
        3202, 1599, 4226, 1562])
Epoch: 3123, Training Loss: 0.18, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3124 - Batch 1 ########################
IDs in batch 1: tensor([ 936, 1324, 2331, 2542, 2312, 1973,  220,  994, 2577, 2518, 3388, 2167,
        3563, 2095,  873,  108])
Epoch: 3124, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3125 - Batch 1 ########################
IDs in batch 1: tensor([2204,   68, 3831, 2403, 3447,  398, 1006,  155, 1932,  394, 1977, 3917,
        3323,  483, 1088,  346])
Epoch: 3125, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3126 - Batch 1 ########################
IDs in batch 1: tensor([1826, 4080, 4017, 3250,  989, 3264, 1031,  652, 1902, 3252, 1752, 4004,
         375, 1836,  834, 2116])
Epoch: 3126, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3127 - Batch 1 ########################
IDs in batch 1: tensor([ 154,  869, 1877, 2264, 3289,  335, 2322, 2959,  704, 2282,  127, 1948,
        3822, 3975, 1438,  584])
Epoch: 3127, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3128 - Batch 1 ########################
IDs in batch 1: tensor([4004,  101, 3938, 2978, 2465,  871, 2452, 1597, 3254,  499, 2798,  824,
        1760, 4093, 3044,  622])
Epoch: 3128, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3129 - Batch 1 ########################
IDs in batch 1: tensor([1099,  154, 1575, 2712, 2406, 2116, 3557, 1305, 3349, 3415,  488, 3853,
        3676, 2045,  724,  804])
Epoch: 3129, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3130 - Batch 1 ########################
IDs in batch 1: tensor([ 234, 2674,  442, 1787, 2011,  155, 3714, 3704, 3529, 1830, 1754,   50,
        2182, 1410, 2449, 4199])
Epoch: 3130, Training Loss: 0.23, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3131 - Batch 1 ########################
IDs in batch 1: tensor([3214, 3739, 2220, 3655, 2950, 2090,  187, 1761, 1861,  828, 1070, 1590,
        2851, 4067, 4236, 2710])
Epoch: 3131, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3132 - Batch 1 ########################
IDs in batch 1: tensor([3951, 2991, 2640, 1902, 2871, 3437, 1723, 1852, 4061,  924, 3984,   25,
        4254, 2323, 3264, 1991])
Epoch: 3132, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3133 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 1255, 3792, 3642, 3094, 4073, 2046, 1389, 2661, 3494,  924, 3194,
        1830, 2382, 4257,  881])
Epoch: 3133, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3134 - Batch 1 ########################
IDs in batch 1: tensor([ 256, 1711, 4198, 1720, 2111, 1640,  448, 1317, 1684, 2603, 1585, 3895,
        2606,  964, 3782, 1186])
Epoch: 3134, Training Loss: 0.18, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3135 - Batch 1 ########################
IDs in batch 1: tensor([1310, 2824, 2524, 1656, 2400, 1789, 3827, 3765, 3200, 1508, 4170, 1945,
        2914, 1982, 3734, 3252])
Epoch: 3135, Training Loss: 0.29, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3136 - Batch 1 ########################
IDs in batch 1: tensor([3434, 3343, 2600, 3729, 3309, 1055, 2742,  740,  736, 3187, 3052, 3763,
        3870, 1049, 2256, 3075])
Epoch: 3136, Training Loss: 0.17, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3137 - Batch 1 ########################
IDs in batch 1: tensor([1419, 3284, 2809, 1818, 2260, 3985,  593, 2218,  672, 3812, 3160, 3816,
        3398, 1960, 1287, 4236])
Epoch: 3137, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3138 - Batch 1 ########################
IDs in batch 1: tensor([ 914, 3549,  252, 1686, 1645, 2369,  637, 3323, 1548, 3656,  257, 3242,
        1900, 4242, 3554, 1985])
Epoch: 3138, Training Loss: 0.23, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3139 - Batch 1 ########################
IDs in batch 1: tensor([3715, 3466, 2176,  202,    7,  496, 2624, 3727,  281,  635, 3194, 1166,
        2740, 3087, 2341, 3637])
Epoch: 3139, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3140 - Batch 1 ########################
IDs in batch 1: tensor([3807, 1782, 2799,  234,   88, 2555,  992, 2866, 2123, 3214, 3532, 1361,
         226, 3836,   34,  839])
Epoch: 3140, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3141 - Batch 1 ########################
IDs in batch 1: tensor([2301, 4218,  539, 3895, 3897, 2368,   42, 1196, 1308, 3387,  666, 2365,
        1006, 3896,  417,  871])
Epoch: 3141, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3142 - Batch 1 ########################
IDs in batch 1: tensor([3110, 2190,  539, 1003, 1141, 2313, 3223, 2604, 2357, 2431, 3985,  119,
        3536, 1119, 4031, 1726])
Epoch: 3142, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3143 - Batch 1 ########################
IDs in batch 1: tensor([2800,  980, 1887, 1871, 2262, 3147, 2887,  345,  496, 1209, 2028,  689,
        3834, 2365, 1682, 3075])
Epoch: 3143, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3144 - Batch 1 ########################
IDs in batch 1: tensor([1811,  749, 2653,  226, 2444,  850,  376, 1887, 2912, 1540,  606, 1916,
         372, 2479,  652,   78])
Epoch: 3144, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3145 - Batch 1 ########################
IDs in batch 1: tensor([2565, 1536, 1594, 2568, 1617, 1746,   15,  558, 3057,  346,  821, 1982,
        1406, 3409,  470, 4226])
Epoch: 3145, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3146 - Batch 1 ########################
IDs in batch 1: tensor([1931, 1566, 2478, 1610, 3592,  814, 3529, 4110,   95, 4246,   18, 4039,
        2426,   56, 3364,  513])
Epoch: 3146, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3147 - Batch 1 ########################
IDs in batch 1: tensor([1809, 3600,   30, 3710, 3151, 3936, 1478, 2664, 2479,  967, 1124, 2562,
        1264, 3601, 1808, 3333])
Epoch: 3147, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3148 - Batch 1 ########################
IDs in batch 1: tensor([1633, 2863, 2689, 2726, 4032, 4224, 2133, 1120,  884, 3870, 3987, 3087,
        2815, 3951, 2172,  820])
Epoch: 3148, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3149 - Batch 1 ########################
IDs in batch 1: tensor([1445, 3147, 2385, 3904, 2969, 2591, 2324,  508, 2169, 2892,  314,  117,
        3883, 3616, 3672, 3503])
Epoch: 3149, Training Loss: 0.15, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3150 - Batch 1 ########################
IDs in batch 1: tensor([1484, 1024, 2646, 3087, 1384, 1619, 3493, 1285, 1179, 3648, 3858, 2331,
        1880, 1512, 2415, 1162])
Epoch: 3150, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3151 - Batch 1 ########################
IDs in batch 1: tensor([1440,  399, 2791, 2159, 1880, 2546, 1089, 3541, 3384, 3006, 2787, 1518,
        2219, 1244, 2429, 1038])
Epoch: 3151, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3152 - Batch 1 ########################
IDs in batch 1: tensor([3834,  794, 4097, 1066, 3727,  335, 1568, 2876, 1331, 2572, 2457, 1163,
        1069, 1651, 1136,  533])
Epoch: 3152, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3153 - Batch 1 ########################
IDs in batch 1: tensor([2959, 3614, 1841,  476, 3514,  914, 2255, 3933, 3810, 2499,  639, 3719,
         683, 3456, 3486, 3638])
Epoch: 3153, Training Loss: 0.34, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3154 - Batch 1 ########################
IDs in batch 1: tensor([3786,  228,  752, 1916, 4087,   21, 2839, 3969, 3077, 1294, 3729, 1163,
        4108,  987,  862, 1638])
Epoch: 3154, Training Loss: 0.39, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3155 - Batch 1 ########################
IDs in batch 1: tensor([1979, 4030,  539,  966,  487,  823, 3850, 3228, 1951, 1957, 3409, 2767,
        3436,  989, 4156,  534])
Epoch: 3155, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3156 - Batch 1 ########################
IDs in batch 1: tensor([1455, 2190, 3028, 2745, 3525,  944,  875, 3810, 2053, 3536, 3408, 1626,
         363, 2996, 2806,  736])
Epoch: 3156, Training Loss: 0.22, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3157 - Batch 1 ########################
IDs in batch 1: tensor([1050, 1753, 2373, 1579, 3688,  498,  283, 2925, 3193, 2731, 2462, 3098,
        1618, 3697,  511, 2815])
Epoch: 3157, Training Loss: 0.15, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3158 - Batch 1 ########################
IDs in batch 1: tensor([2854,   27, 1038, 2523, 3414, 1734, 1044, 4205,  574,  849,  333, 4036,
        2499, 1320,  983, 2591])
Epoch: 3158, Training Loss: 0.17, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3159 - Batch 1 ########################
IDs in batch 1: tensor([ 583, 1934,  665, 3594,  704, 2784, 2995, 2290, 1042, 3047, 2284, 3744,
         593, 2764,  155, 2868])
Epoch: 3159, Training Loss: 0.16, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3160 - Batch 1 ########################
IDs in batch 1: tensor([1519,  953, 4040,  302, 2815, 2835, 2212, 1419, 4101,  613, 3018, 2553,
        2353, 2599, 2508, 4127])
Epoch: 3160, Training Loss: 0.08, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3161 - Batch 1 ########################
IDs in batch 1: tensor([3563,   15, 1711, 2315, 1060, 3863, 3408, 1660, 3438, 1553, 4072, 1380,
        1311, 2646, 1916, 1963])
Epoch: 3161, Training Loss: 0.14, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3162 - Batch 1 ########################
IDs in batch 1: tensor([2693, 3246, 3769,  514,  985, 3243, 2248, 1507, 4235,  546, 4031, 2371,
        2132, 2065, 1914,   11])
Epoch: 3162, Training Loss: 0.08, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3163 - Batch 1 ########################
IDs in batch 1: tensor([  44, 1056, 3456, 2487, 3526, 2453,  137,  718, 1455, 3804, 2842,  807,
        3102, 3386,  427, 3254])
Epoch: 3163, Training Loss: 0.13, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3164 - Batch 1 ########################
IDs in batch 1: tensor([ 424,  322, 3141, 3777, 1439, 3251, 3360, 4240, 3865,  337, 3742, 1872,
        2459,  959, 4101,  725])
Epoch: 3164, Training Loss: 0.12, Validation Loss: 0.88, accuracy = 0.69
######################## Epoch 3165 - Batch 1 ########################
IDs in batch 1: tensor([1878, 1128,  522, 2555,  365,  292,  937, 1862, 2494, 1448, 4013, 2225,
         108, 1675, 2579, 2432])
Epoch: 3165, Training Loss: 0.05, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3166 - Batch 1 ########################
IDs in batch 1: tensor([3672, 1914, 1024, 4157, 2207, 4024, 1355, 3374, 3980,  659, 1107,  874,
        1214, 3634, 2858, 1737])
Epoch: 3166, Training Loss: 0.46, Validation Loss: 0.87, accuracy = 0.69
######################## Epoch 3167 - Batch 1 ########################
IDs in batch 1: tensor([1746, 2041, 1356,  775, 1393,  348, 3523, 4172, 4218, 2832, 2166, 4159,
        1294, 1363,  674,  389])
Epoch: 3167, Training Loss: 0.13, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3168 - Batch 1 ########################
IDs in batch 1: tensor([3852, 1952, 3311, 4084, 2169, 2360, 1574, 1360, 2828, 3283, 3597,    5,
          78, 4254, 1678, 1802])
Epoch: 3168, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3169 - Batch 1 ########################
IDs in batch 1: tensor([2616, 1499,  583, 2495, 1920, 1972,  893,  917, 3830, 1442, 2244,  225,
         613, 1376, 2413, 3753])
Epoch: 3169, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3170 - Batch 1 ########################
IDs in batch 1: tensor([2976, 2668, 3822, 3184, 1960, 3539, 3896, 3283, 2232, 4018,  454, 1844,
        1638, 3108, 3904, 1286])
Epoch: 3170, Training Loss: 0.11, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3171 - Batch 1 ########################
IDs in batch 1: tensor([ 327, 1212, 1146, 2712, 2338, 1499, 3904, 2005, 4185, 1642,  471, 2088,
        1517, 1595, 1496, 4010])
Epoch: 3171, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.70
######################## Epoch 3172 - Batch 1 ########################
IDs in batch 1: tensor([1312,  924, 2538, 2943, 1116,   92,  892, 3795, 1270,  578,  822, 2482,
        4266, 1566, 3821, 3184])
Epoch: 3172, Training Loss: 0.29, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3173 - Batch 1 ########################
IDs in batch 1: tensor([2550, 1614, 4266,   44, 3635, 1236, 2150, 4080, 1043, 2605, 1004, 1409,
         644, 3349, 2719,  617])
Epoch: 3173, Training Loss: 0.25, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3174 - Batch 1 ########################
IDs in batch 1: tensor([3900,  357, 3476, 3547, 2644, 4258, 4036, 3597,  807, 3486, 3180, 1088,
        1521, 2459, 1602, 1402])
Epoch: 3174, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3175 - Batch 1 ########################
IDs in batch 1: tensor([1884, 2700, 1881,  965, 3587,  649,  872, 3823, 1588,  658, 1612, 2855,
         796, 3425, 1682,  341])
Epoch: 3175, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3176 - Batch 1 ########################
IDs in batch 1: tensor([3846, 1488, 3369, 2420, 2150, 1397, 4225, 2996, 1028,  384, 3432, 3200,
        3471, 3192, 3202,   72])
Epoch: 3176, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3177 - Batch 1 ########################
IDs in batch 1: tensor([4159, 3812, 3388, 1050, 3038, 3601, 3143, 2349,  954, 3553, 4152, 2690,
        1176, 1670, 1289, 1990])
Epoch: 3177, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3178 - Batch 1 ########################
IDs in batch 1: tensor([2326, 1965, 1421, 3767,  128, 2085, 3272, 2051, 3973, 3357, 1417, 3856,
        2855, 4214, 3433, 3925])
Epoch: 3178, Training Loss: 0.39, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3179 - Batch 1 ########################
IDs in batch 1: tensor([2356, 1391,  687,  989, 3015, 3542, 1748, 3276, 3969,  243,  544, 3615,
        3409, 1361, 1141, 1117])
Epoch: 3179, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3180 - Batch 1 ########################
IDs in batch 1: tensor([4266, 1212, 3885, 2574, 3386, 1138, 4120, 3040, 3882, 1354, 2041, 2960,
        1491, 2463, 1510, 2133])
Epoch: 3180, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3181 - Batch 1 ########################
IDs in batch 1: tensor([2328, 1139, 2871, 3160, 3401, 2010, 3475, 2341, 3352, 1673, 3763, 1197,
         394, 2441,  185, 1272])
Epoch: 3181, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3182 - Batch 1 ########################
IDs in batch 1: tensor([3913, 1699,  815, 3339, 2178, 2260, 1087, 2412, 1054, 4055, 2995, 2251,
        2996, 4217, 2051,  202])
Epoch: 3182, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3183 - Batch 1 ########################
IDs in batch 1: tensor([2819,  636,  255, 1986, 2847, 1990, 2247, 3728, 3902, 2127, 3025,  263,
        2672, 3669,  606, 2015])
Epoch: 3183, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3184 - Batch 1 ########################
IDs in batch 1: tensor([3415, 2217, 2413,  119, 2710,  820, 2252, 2995,  605, 3328, 3363, 1574,
         814,   98, 1251,  941])
Epoch: 3184, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3185 - Batch 1 ########################
IDs in batch 1: tensor([1686, 1574, 1753, 1836, 1336, 2802, 2839, 3954, 2181,  245,  539,  756,
         947, 2230, 1027,  372])
Epoch: 3185, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3186 - Batch 1 ########################
IDs in batch 1: tensor([2154,  491, 2045, 1740, 1065, 3333, 2359, 1157, 2420,   44, 2913, 1198,
        2480, 1671, 2845, 2376])
Epoch: 3186, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3187 - Batch 1 ########################
IDs in batch 1: tensor([2011, 3368,  729, 1548,  384, 2425, 3449,  874,  520, 1143, 1980,  330,
         188, 1904,  351, 1656])
Epoch: 3187, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3188 - Batch 1 ########################
IDs in batch 1: tensor([3272, 3928,  278, 3936,  323, 2559, 1418, 3077, 2880, 1901,   70,  287,
        1128, 2924, 1763, 4011])
Epoch: 3188, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3189 - Batch 1 ########################
IDs in batch 1: tensor([3372, 3695,  714, 2551, 4173, 4073, 3499, 3216, 1562, 1894, 3789, 1868,
        1628, 3094, 1976, 2416])
Epoch: 3189, Training Loss: 0.27, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3190 - Batch 1 ########################
IDs in batch 1: tensor([3669, 1003,  661,  343,  872, 1131, 1266, 2894, 1138,  766, 1927, 1117,
         373, 1375,  834, 1826])
Epoch: 3190, Training Loss: 0.70, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3191 - Batch 1 ########################
IDs in batch 1: tensor([2432, 2436, 1498, 3524, 3044, 2328, 3656, 2111, 1335, 2982,  934,   73,
         202,  379, 4228, 2587])
Epoch: 3191, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3192 - Batch 1 ########################
IDs in batch 1: tensor([ 645, 2565,  828,  957, 2120, 2643, 2632,  323,  595, 1473, 3109, 2367,
        3207, 2529, 1825,  532])
Epoch: 3192, Training Loss: 0.21, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3193 - Batch 1 ########################
IDs in batch 1: tensor([  61, 1660,  472, 3671, 1025, 3541, 3637, 3130, 1679, 4198, 1367, 3650,
        3197, 1532, 1994, 3922])
Epoch: 3193, Training Loss: 0.31, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3194 - Batch 1 ########################
IDs in batch 1: tensor([3792, 3891, 2848, 2009, 4073, 3485, 2729,  556, 1310, 1163, 3634, 1681,
         563, 3161,  872,  136])
Epoch: 3194, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3195 - Batch 1 ########################
IDs in batch 1: tensor([3842, 2229,  389, 1552, 1458,  718, 4070, 3553, 2499, 3052, 3718, 2179,
         605, 1488,  631,  829])
Epoch: 3195, Training Loss: 0.25, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3196 - Batch 1 ########################
IDs in batch 1: tensor([4126,  102, 3372, 3451, 1795, 2217, 3328, 1022, 1070, 1384, 2730, 3088,
        2632, 2793, 3252,    5])
Epoch: 3196, Training Loss: 0.18, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3197 - Batch 1 ########################
IDs in batch 1: tensor([ 361, 2733,  244,  338, 3499, 1830, 1200, 3407, 2583, 3888, 2740, 1437,
        2810, 1434, 1024, 2312])
Epoch: 3197, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3198 - Batch 1 ########################
IDs in batch 1: tensor([2844, 2590, 2072, 1982, 2394,   35, 1583, 4000, 4107, 3015,  904,  212,
        1212, 1122, 3544, 2060])
Epoch: 3198, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3199 - Batch 1 ########################
IDs in batch 1: tensor([  96, 1041, 2117, 1170, 1010,  262,  900, 3470, 3244, 1959,  838, 3640,
         483, 2442,  130, 1620])
Epoch: 3199, Training Loss: 0.40, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3200 - Batch 1 ########################
IDs in batch 1: tensor([ 505,  803, 3391,  487,   97, 2997,   47, 3920, 1971, 3469,  188, 3290,
         498, 3154, 2536,  649])
Epoch: 3200, Training Loss: 0.09, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3201 - Batch 1 ########################
IDs in batch 1: tensor([ 105,  883, 3317,  809,  441, 2451, 1196, 3015, 4061, 1054, 1728, 2632,
        2667,  894, 2780,  165])
Epoch: 3201, Training Loss: 0.13, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3202 - Batch 1 ########################
IDs in batch 1: tensor([1209,  194, 1053, 3701, 2244, 1193, 1153,  943, 2505, 2841, 2198, 1389,
        1214, 3404, 1543,  182])
Epoch: 3202, Training Loss: 0.29, Validation Loss: 0.89, accuracy = 0.70
######################## Epoch 3203 - Batch 1 ########################
IDs in batch 1: tensor([1933, 1646, 1897,  902, 3894,  252, 3700,  419, 2238,  976, 1015, 1563,
        1963, 1371,  659,   56])
Epoch: 3203, Training Loss: 0.15, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3204 - Batch 1 ########################
IDs in batch 1: tensor([  30, 3917,  207, 1007, 2638, 2260, 3150,  343, 2198,  402,  651, 1858,
          42, 3098, 2050, 4100])
Epoch: 3204, Training Loss: 0.27, Validation Loss: 0.90, accuracy = 0.71
######################## Epoch 3205 - Batch 1 ########################
IDs in batch 1: tensor([3894, 3970, 2805, 1777, 1811, 1521,   52, 3493,  337, 2145, 3569, 3453,
         477, 3989, 1635,  852])
Epoch: 3205, Training Loss: 0.19, Validation Loss: 0.90, accuracy = 0.72
######################## Epoch 3206 - Batch 1 ########################
IDs in batch 1: tensor([4039, 2452, 1804, 1118, 4213, 2313, 3888, 4000, 2950, 1209, 2575, 3358,
          31, 2004, 2610,  483])
Epoch: 3206, Training Loss: 0.24, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3207 - Batch 1 ########################
IDs in batch 1: tensor([ 344, 1734, 3494,   51, 3806,  544, 2783, 3386, 1369,   30, 1318, 2642,
         609, 3181, 2119,  714])
Epoch: 3207, Training Loss: 0.07, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3208 - Batch 1 ########################
IDs in batch 1: tensor([3014, 2936, 1959, 1640, 2587, 1456, 1229, 1267, 3589, 1408, 3950, 2120,
        1668, 3683, 4144, 3409])
Epoch: 3208, Training Loss: 0.18, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3209 - Batch 1 ########################
IDs in batch 1: tensor([ 143, 1895, 3746, 3881, 4124, 1521,  805, 2499, 3035, 1183, 3446, 1104,
          42, 1507, 3329, 3792])
Epoch: 3209, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3210 - Batch 1 ########################
IDs in batch 1: tensor([2171, 2840, 2195,  535, 4200, 3528, 1737, 1993, 2092, 4080, 2145, 3456,
          73,  442,  556, 1063])
Epoch: 3210, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3211 - Batch 1 ########################
IDs in batch 1: tensor([3896, 1956,   27, 1448, 4267, 3677, 3797, 1863, 2760,  996, 1870, 1495,
         507, 2248, 3219, 2641])
Epoch: 3211, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3212 - Batch 1 ########################
IDs in batch 1: tensor([1075, 1260, 3842, 3925,  752, 3447, 4061,  769, 3105, 1861, 1993,  610,
         596, 3370, 1923, 1017])
Epoch: 3212, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3213 - Batch 1 ########################
IDs in batch 1: tensor([ 426, 2696,  687, 1309, 3108, 2535, 1668, 2417, 2595,  945, 1634, 2664,
         971,  373, 2403, 3018])
Epoch: 3213, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3214 - Batch 1 ########################
IDs in batch 1: tensor([1125, 1594,  398,  615,  815,  943, 1005, 3314, 3514, 3764, 2390, 3208,
        2764, 2010,  949, 2134])
Epoch: 3214, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3215 - Batch 1 ########################
IDs in batch 1: tensor([3888, 1347, 1512,  644, 1186,   14, 3272, 2120, 1685, 2219, 2224, 1444,
        1161, 2169,   43, 3781])
Epoch: 3215, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3216 - Batch 1 ########################
IDs in batch 1: tensor([3541, 3609, 3339,  557, 1953, 2583, 1821, 4198,  303,  827, 1139, 2459,
        1472,  398, 1911, 2638])
Epoch: 3216, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3217 - Batch 1 ########################
IDs in batch 1: tensor([1668, 3962, 1632,  993,  993,  767, 3583, 2479,  239, 1626,  474, 2462,
          25, 1434,  512, 3851])
Epoch: 3217, Training Loss: 0.44, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3218 - Batch 1 ########################
IDs in batch 1: tensor([3148,  265,  100, 1012, 2011, 1904, 3218, 2120, 3160, 2341,  975, 3044,
         206, 2535, 4214, 2499])
Epoch: 3218, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3219 - Batch 1 ########################
IDs in batch 1: tensor([1286, 2597, 2081, 2182, 3389, 2142,  281,   93, 2070, 2237, 3865, 3842,
         441,  663, 3182,  171])
Epoch: 3219, Training Loss: 0.34, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3220 - Batch 1 ########################
IDs in batch 1: tensor([3624, 2495, 3053, 3908, 1526, 2899, 2465,  185, 2844, 1085, 3704, 2741,
         198, 3334, 3850, 4044])
Epoch: 3220, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3221 - Batch 1 ########################
IDs in batch 1: tensor([2198,  512, 3326, 1833, 2470, 3120, 3418, 3577, 3472, 3329, 1604, 3818,
        2937, 1310,  777, 2931])
Epoch: 3221, Training Loss: 0.62, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3222 - Batch 1 ########################
IDs in batch 1: tensor([4257, 3815, 2480,  874, 3248, 2648, 4257, 3188, 1196,  897,  601, 2134,
        1167, 3532, 2739, 3102])
Epoch: 3222, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3223 - Batch 1 ########################
IDs in batch 1: tensor([2349,  558, 1373, 1822, 1681,  532,  952, 2449, 4176, 1305, 3523,  966,
         723, 2393,  776,  604])
Epoch: 3223, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3224 - Batch 1 ########################
IDs in batch 1: tensor([2764, 2472, 2246, 1899, 2413,  934, 2290,   14, 2331, 2610, 2232, 1851,
        2993,  260, 3044, 2993])
Epoch: 3224, Training Loss: 0.57, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3225 - Batch 1 ########################
IDs in batch 1: tensor([1340,   73, 2284, 4267, 2682, 1344,  640, 3159, 1563, 3826, 2492, 2316,
        3344, 1061, 3329, 2102])
Epoch: 3225, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3226 - Batch 1 ########################
IDs in batch 1: tensor([3660, 4175, 3343, 4122,   52, 2957, 2857, 2008, 1502,  666, 4227, 2309,
        3654, 1567, 1200, 3156])
Epoch: 3226, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3227 - Batch 1 ########################
IDs in batch 1: tensor([2498, 3652,  474, 1179, 2599, 2587,  269, 2375, 4212, 1443, 4053, 4127,
        3101,  536, 3838, 1610])
Epoch: 3227, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3228 - Batch 1 ########################
IDs in batch 1: tensor([2465,  622, 2218, 1443, 3989,  361, 2546,  873, 2678, 1590, 2731, 3600,
         275, 1118,  354, 2629])
Epoch: 3228, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3229 - Batch 1 ########################
IDs in batch 1: tensor([2777, 1782, 2765,  315,  332,  595, 2548,   27,  442, 3113, 1871, 1413,
        1639,  852,  844, 1277])
Epoch: 3229, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3230 - Batch 1 ########################
IDs in batch 1: tensor([2510, 1778, 3813, 2760, 3262, 1221,  101, 2146, 3564, 3498, 3583, 3259,
          81, 2301, 2199, 2073])
Epoch: 3230, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3231 - Batch 1 ########################
IDs in batch 1: tensor([1767, 3851,  111, 1003, 1024, 1786,  251, 1605, 4175, 2376,  691, 2536,
        2806, 3200, 3644, 4220])
Epoch: 3231, Training Loss: 0.24, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3232 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 1976,  131, 2775, 3131,  771, 1022,  220, 2582, 1482, 2026, 2257,
         151, 1974, 3897, 1510])
Epoch: 3232, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.69
######################## Epoch 3233 - Batch 1 ########################
IDs in batch 1: tensor([3846, 2338,  790,  427,  518,  632, 2915, 3228, 3712, 3100, 1937, 2053,
        3705, 2199, 2070, 2510])
Epoch: 3233, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3234 - Batch 1 ########################
IDs in batch 1: tensor([1239, 2824, 2415, 3183, 3372,  149,  891, 2559, 2521, 2484, 2234,  869,
        3597, 3139, 1239, 2571])
Epoch: 3234, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3235 - Batch 1 ########################
IDs in batch 1: tensor([2752, 3947, 2470, 1285, 3798, 3326, 2356, 2618, 3115,  595,   74, 2034,
        1168, 2045, 4012, 2578])
Epoch: 3235, Training Loss: 0.13, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3236 - Batch 1 ########################
IDs in batch 1: tensor([1610,  138, 1518, 1231, 2219, 2794, 2206, 3507, 2743, 1113, 2277,   41,
        3701, 1053, 2121,  503])
Epoch: 3236, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3237 - Batch 1 ########################
IDs in batch 1: tensor([3081, 3604, 4165, 2644,  846, 2819,  360, 3518, 2277, 1156,  894, 1269,
        1270, 3368,  908, 4013])
Epoch: 3237, Training Loss: 0.11, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3238 - Batch 1 ########################
IDs in batch 1: tensor([3486, 3689, 3642, 4067, 1344,  186, 3196,  232, 2832, 2697,  412, 4101,
        2439, 2504, 2312, 1072])
Epoch: 3238, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3239 - Batch 1 ########################
IDs in batch 1: tensor([  10,  252, 2479,   49, 1038, 4065,  412, 1707, 3373, 3862, 3683, 3118,
        3733, 2731, 1506, 4165])
Epoch: 3239, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3240 - Batch 1 ########################
IDs in batch 1: tensor([3428, 3985, 3025, 4188, 2041,    4,  527, 2854,  710, 3314, 2659,  327,
        3895, 3255,   28, 2581])
Epoch: 3240, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3241 - Batch 1 ########################
IDs in batch 1: tensor([ 945, 4122, 2844, 4032, 1925, 2295, 1396, 2545, 1221, 1065, 3765, 2119,
         584, 3778, 2035, 1045])
Epoch: 3241, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3242 - Batch 1 ########################
IDs in batch 1: tensor([2145, 1423,   47, 4030,  822, 3004, 2416,   92,  513, 2934, 3317, 3564,
        2807, 3974, 1959, 1147])
Epoch: 3242, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3243 - Batch 1 ########################
IDs in batch 1: tensor([ 882, 2837, 1355, 3590, 4065, 2795, 1916, 1458, 3003, 2420, 2117, 3970,
        2383, 4213, 3970, 2732])
Epoch: 3243, Training Loss: 0.35, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3244 - Batch 1 ########################
IDs in batch 1: tensor([1521, 2620, 3695, 2265, 3360, 2435, 1918, 2736, 3660, 4032,  155, 2260,
        2035, 1753, 1708, 3005])
Epoch: 3244, Training Loss: 0.17, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3245 - Batch 1 ########################
IDs in batch 1: tensor([1568, 3406, 3961, 3287, 4072, 1022, 1099, 3792,   82, 4135, 3222, 1279,
        3971, 2461, 2563, 1445])
Epoch: 3245, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3246 - Batch 1 ########################
IDs in batch 1: tensor([3148, 3667, 1589,  974, 1984, 2378,  667, 1686, 2408, 3216, 1278, 1050,
         884,  417, 2316, 2934])
Epoch: 3246, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3247 - Batch 1 ########################
IDs in batch 1: tensor([ 678, 1651, 1274,   70, 1406, 3756,  997, 3287,  902, 2031, 2038,  132,
         357, 3100, 1931, 3278])
Epoch: 3247, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3248 - Batch 1 ########################
IDs in batch 1: tensor([1377, 1755, 2385, 2767, 3543,  517, 1509, 2320, 2031, 2046, 2449, 1442,
         183, 2603, 1289, 4040])
Epoch: 3248, Training Loss: 0.37, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3249 - Batch 1 ########################
IDs in batch 1: tensor([ 432, 1279,  438, 1108,   64, 1226, 3700, 2516, 4246,  832, 2253, 3790,
        1439, 3055,   14, 1077])
Epoch: 3249, Training Loss: 0.39, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3250 - Batch 1 ########################
IDs in batch 1: tensor([1942, 1219, 1173, 2949,  180, 2872, 1817, 2022, 3659, 1772, 1832, 1080,
         263, 1869, 2926, 1942])
Epoch: 3250, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3251 - Batch 1 ########################
IDs in batch 1: tensor([1080, 2447,  172, 3652, 3812, 3950, 2169, 3643, 1154,  926, 2511, 3024,
        2413, 1333, 3675,  357])
Epoch: 3251, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3252 - Batch 1 ########################
IDs in batch 1: tensor([1478, 2178, 4026, 3908, 1070, 4039, 1001, 1933, 3718, 3162, 3244, 3942,
        2295, 1155,  733, 3492])
Epoch: 3252, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3253 - Batch 1 ########################
IDs in batch 1: tensor([3763, 3300,  110, 1365, 3071,  121,  259, 1700, 1442, 4118, 2817, 4220,
        2377, 1443,  736, 2183])
Epoch: 3253, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3254 - Batch 1 ########################
IDs in batch 1: tensor([3207, 2618, 2725,  471, 1625, 3206,  323, 1583, 3490, 1507,  970, 3990,
        1589, 2708, 3124,   51])
Epoch: 3254, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3255 - Batch 1 ########################
IDs in batch 1: tensor([3130,  954, 1286,  684, 2640, 1318, 4057, 2517, 1600, 3806, 3599, 3723,
        1085, 2529, 3468, 3674])
Epoch: 3255, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3256 - Batch 1 ########################
IDs in batch 1: tensor([2010, 1588,  680,  676, 2030, 1317, 3506, 4115, 3318, 3551, 2616,  194,
        3594,  934, 4013, 2410])
Epoch: 3256, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3257 - Batch 1 ########################
IDs in batch 1: tensor([3042, 4195, 2892, 4175, 3310, 1569, 2504,  994, 3206, 3218, 2066,  152,
        3587, 2075,  408, 3581])
Epoch: 3257, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3258 - Batch 1 ########################
IDs in batch 1: tensor([ 354, 2094, 2299, 3083, 1161, 1834,  529, 3084, 2680, 3833,  450,  357,
        1452,  665,  824, 4223])
Epoch: 3258, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3259 - Batch 1 ########################
IDs in batch 1: tensor([3339, 3098, 4080,  828, 1166, 2978,  312,  613, 2649,  812, 2932, 3549,
        2045,  557, 2192,  778])
Epoch: 3259, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3260 - Batch 1 ########################
IDs in batch 1: tensor([ 637, 3415, 1415,  302,  186, 2067, 4007,  515, 1646,  892, 1567, 1812,
        2478, 2428,  407, 2439])
Epoch: 3260, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3261 - Batch 1 ########################
IDs in batch 1: tensor([2393, 1826, 2149,   73, 3258,  466, 2312, 2428,  483,  978, 1047, 4055,
        2275, 4173, 2413,  101])
Epoch: 3261, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3262 - Batch 1 ########################
IDs in batch 1: tensor([3636, 2796, 4246, 2401, 3977,  303, 3473, 2467, 2451, 1126, 2915,  897,
        2150,  100, 3521, 2056])
Epoch: 3262, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3263 - Batch 1 ########################
IDs in batch 1: tensor([2765, 1167, 1097, 2653,  904, 3651, 2770,  944,  930, 3928, 4139, 1453,
        1023, 1804, 1026, 2693])
Epoch: 3263, Training Loss: 0.22, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3264 - Batch 1 ########################
IDs in batch 1: tensor([2886, 2261, 3401, 1305, 3318, 2859, 2426, 2653,  344, 2506, 3830, 3333,
          64,  430, 3356,  930])
Epoch: 3264, Training Loss: 0.24, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3265 - Batch 1 ########################
IDs in batch 1: tensor([1365, 3543, 4127, 3241, 1802, 2220, 1537, 2719,  572, 3159, 2185,  751,
        3573,  518, 1678, 2516])
Epoch: 3265, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3266 - Batch 1 ########################
IDs in batch 1: tensor([2429, 3409, 1845,  694, 2116, 2715,  568,  488, 2957,  970, 1174, 1959,
        3999,  442, 2176,  909])
Epoch: 3266, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3267 - Batch 1 ########################
IDs in batch 1: tensor([3913,  154,  150, 1585, 2145, 2578, 3745, 3259, 3360,   86, 3268, 3677,
         122, 1363, 1962,  672])
Epoch: 3267, Training Loss: 0.20, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3268 - Batch 1 ########################
IDs in batch 1: tensor([ 957, 1226, 3180, 1031, 1555, 2125, 1176,  191,  517, 2996, 2523, 1568,
        1128,  355, 4229, 3087])
Epoch: 3268, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3269 - Batch 1 ########################
IDs in batch 1: tensor([3415, 1167, 1195, 2693, 1663, 1619, 2477, 3830,  315, 3535, 3783, 3808,
         785,   30, 1993, 1988])
Epoch: 3269, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3270 - Batch 1 ########################
IDs in batch 1: tensor([3683,   52, 1285, 3830, 4157, 1970,  988, 3264,  408, 2751,  279, 1121,
        1432, 1200, 2806, 2468])
Epoch: 3270, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3271 - Batch 1 ########################
IDs in batch 1: tensor([ 763, 2765, 2386, 2026,  430, 3747, 3289, 1370, 2031, 1970,  670,  126,
        2331, 1857, 4058, 1027])
Epoch: 3271, Training Loss: 0.26, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3272 - Batch 1 ########################
IDs in batch 1: tensor([1038, 1024, 1189, 2169, 1065, 1685, 2776, 2844, 2132, 2442,  217, 2734,
        4125, 4038, 2982,  917])
Epoch: 3272, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3273 - Batch 1 ########################
IDs in batch 1: tensor([1600, 1321,  322, 3782, 1377, 1087, 3557,  201, 4000, 2559,  522, 2154,
        3128, 1032, 3947, 2013])
Epoch: 3273, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3274 - Batch 1 ########################
IDs in batch 1: tensor([2111, 3077, 4268, 4245, 2828, 1972, 2689, 4060,  869, 1883,  345, 1352,
        3803, 3363,  968, 4261])
Epoch: 3274, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3275 - Batch 1 ########################
IDs in batch 1: tensor([2182, 3988, 3740,  866, 2080, 2004, 1916,  375,  854,  857,  391,  505,
        1139, 2587, 1381, 4000])
Epoch: 3275, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3276 - Batch 1 ########################
IDs in batch 1: tensor([2106, 2692, 3190, 1562, 1834, 1644,  327, 1794, 2258, 1383, 1309, 1032,
         214, 3727, 1209,  879])
Epoch: 3276, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3277 - Batch 1 ########################
IDs in batch 1: tensor([1574,  198, 2494, 1055, 3958, 3389,  587,  164,  826,  578, 3337, 3378,
        4197, 1035, 3500, 2883])
Epoch: 3277, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3278 - Batch 1 ########################
IDs in batch 1: tensor([1913, 2965, 2976, 2913,  334, 3970, 1080, 3870, 2053, 1471, 1720,  244,
         326, 2104,  670, 1986])
Epoch: 3278, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3279 - Batch 1 ########################
IDs in batch 1: tensor([4036, 2225, 3673,  988, 3471, 1971,   20, 1270, 2431, 1944,  988, 3834,
        1745, 2841, 2275, 3953])
Epoch: 3279, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3280 - Batch 1 ########################
IDs in batch 1: tensor([1512, 3964,  816, 1545, 1952,  145, 3503, 2708, 4025, 2797, 1605, 3600,
         584,   72, 2436, 1636])
Epoch: 3280, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3281 - Batch 1 ########################
IDs in batch 1: tensor([4261, 1699, 2965, 1386, 3397, 2584,  161,  324, 4217, 1080,  232, 2870,
        4204, 1727, 3677, 1031])
Epoch: 3281, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3282 - Batch 1 ########################
IDs in batch 1: tensor([1558, 2734, 2758,  127, 1911, 1077, 1025, 2882, 2246, 1921, 3267, 1417,
        1740, 2668, 1684, 3886])
Epoch: 3282, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3283 - Batch 1 ########################
IDs in batch 1: tensor([3465, 3478, 2949, 4024,  947, 1763, 2932, 2966,  517, 1282, 4204, 4187,
        3415,  503, 3283, 2388])
Epoch: 3283, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3284 - Batch 1 ########################
IDs in batch 1: tensor([4049,   95, 2712, 2309, 2386, 1487,  212, 2926, 3964,  606,  586, 2763,
        1956, 2963, 2092, 2271])
Epoch: 3284, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3285 - Batch 1 ########################
IDs in batch 1: tensor([ 196, 1177, 3839, 2925,  846,  852,  626,  289, 3208, 3154, 3514, 1880,
        1453, 2125, 4095, 1133])
Epoch: 3285, Training Loss: 0.18, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3286 - Batch 1 ########################
IDs in batch 1: tensor([2917, 3712, 1871,  586, 2860, 3749, 3364, 1551,  635,  749,  237, 2155,
         515, 2770, 3284, 4181])
Epoch: 3286, Training Loss: 0.35, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3287 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 2242,  534, 1283, 3378, 2245, 3676, 3374, 3240, 3036, 4196, 3258,
        2246,  631, 1419, 2224])
Epoch: 3287, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3288 - Batch 1 ########################
IDs in batch 1: tensor([ 852,   86, 3501, 1708, 1094, 2189, 2688, 1101, 3785, 4163, 3408, 3282,
         895, 1385,  228, 2692])
Epoch: 3288, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3289 - Batch 1 ########################
IDs in batch 1: tensor([1638,  334, 1372, 4141,  891,  766, 2142, 2731, 2378, 2425, 3127,  953,
        2017, 1070, 2546,  387])
Epoch: 3289, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3290 - Batch 1 ########################
IDs in batch 1: tensor([1639, 2465, 1495, 3516, 1840,  277, 3275, 2167,  396,  113,  779, 1162,
         757, 2360, 1663, 3408])
Epoch: 3290, Training Loss: 0.26, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3291 - Batch 1 ########################
IDs in batch 1: tensor([1454, 1294, 2399, 1159,  546, 1685, 2669, 4026,  936, 1136, 1566, 2770,
        4240,  910,  947,  519])
Epoch: 3291, Training Loss: 0.22, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3292 - Batch 1 ########################
IDs in batch 1: tensor([2827, 2831, 1141, 4000, 2859, 1065,  964, 3733, 2606, 3216, 2761, 3478,
        1826, 4124, 1242, 1034])
Epoch: 3292, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3293 - Batch 1 ########################
IDs in batch 1: tensor([3486, 3142, 2059, 3608, 3740, 3469, 2066, 1308, 3081,  105,  334,  809,
        3600,  842,  875, 1625])
Epoch: 3293, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3294 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 1866, 2536, 2524, 3029, 4030, 3333, 4108,  295,  205, 2290, 3000,
        2996, 3152, 2671, 2080])
Epoch: 3294, Training Loss: 0.24, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3295 - Batch 1 ########################
IDs in batch 1: tensor([ 306, 1663, 3162, 2880, 3024, 1821, 1772, 2011, 1834, 1312, 2045, 1985,
        3367, 3660, 3765, 3922])
Epoch: 3295, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3296 - Batch 1 ########################
IDs in batch 1: tensor([2797,  887, 3973, 2279, 1834,  873, 3557, 3447, 1235, 3438, 1308, 2523,
        3483, 3358, 1765, 1357])
Epoch: 3296, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3297 - Batch 1 ########################
IDs in batch 1: tensor([1934, 1968, 3731, 2064, 1610,  390, 4060, 2610, 3471, 2287, 3521, 1270,
        2376, 3846, 3839, 2484])
Epoch: 3297, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3298 - Batch 1 ########################
IDs in batch 1: tensor([2575, 1077, 1349, 2169, 1116, 3087,  826,  138,  172, 2149, 2217, 2281,
        2919, 1910,  890, 3185])
Epoch: 3298, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3299 - Batch 1 ########################
IDs in batch 1: tensor([ 991, 1386, 1746, 2003,  863,  601, 1069, 1817, 3583, 4232,  106, 1266,
        2615, 3058, 2246,  351])
Epoch: 3299, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3300 - Batch 1 ########################
IDs in batch 1: tensor([1753, 3948, 3558, 2742, 4062, 1850, 2124, 3707, 3146,  987, 1072, 1113,
        1347,  503, 3874, 1374])
Epoch: 3300, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3301 - Batch 1 ########################
IDs in batch 1: tensor([3119, 3181, 2592, 2963, 2212, 1845,  536, 2837, 1047, 4263, 1213, 3972,
         143, 3081, 3496,   13])
Epoch: 3301, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3302 - Batch 1 ########################
IDs in batch 1: tensor([2264,  981, 3656, 1810, 1863, 3052,   88, 4135, 1803, 3369,  790, 2256,
         375,  558, 1913, 3425])
Epoch: 3302, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3303 - Batch 1 ########################
IDs in batch 1: tensor([4087, 1559,  244, 2213, 2475, 3594, 3521, 1250,  918, 4224, 2245, 1009,
         388, 2892,  256, 3781])
Epoch: 3303, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3304 - Batch 1 ########################
IDs in batch 1: tensor([ 778, 3637, 1639, 3430, 3101, 2798,  247,  488,  726, 2203,  182, 1476,
        2146, 1341,   84, 2832])
Epoch: 3304, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3305 - Batch 1 ########################
IDs in batch 1: tensor([3015, 1305, 3573, 3902, 3536, 1054, 2034, 1580, 1612, 2961,  378, 1957,
         344, 3927,  359, 1156])
Epoch: 3305, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3306 - Batch 1 ########################
IDs in batch 1: tensor([2126,  750, 2150,  797, 3624, 3563, 2505,  573, 1763, 2740,   63, 1363,
        4238,  749, 3723,  662])
Epoch: 3306, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3307 - Batch 1 ########################
IDs in batch 1: tensor([ 276, 2036, 2672,  244, 1737,   34, 3873,  455, 2520, 3985, 1171, 1712,
        2373,  546, 3382, 2476])
Epoch: 3307, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3308 - Batch 1 ########################
IDs in batch 1: tensor([1085, 1611, 1228,  617, 1918, 3468, 1636,  368, 2826, 3642,  575, 1950,
        1443, 1093, 1195,  546])
Epoch: 3308, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3309 - Batch 1 ########################
IDs in batch 1: tensor([ 632, 3810, 2277, 1010, 1748, 1484, 3624, 3004, 2793,   73, 4198, 2761,
        2383, 1798,  375, 3397])
Epoch: 3309, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3310 - Batch 1 ########################
IDs in batch 1: tensor([3524, 1055, 4037,  857,  538, 2157, 3991, 3087, 1053,  355, 3291, 2999,
        2746, 3932, 1585, 1014])
Epoch: 3310, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3311 - Batch 1 ########################
IDs in batch 1: tensor([ 666, 3815, 3216, 3021, 2676, 2968, 2740, 1950, 2313, 2102, 2066, 3052,
         982,  238, 1119, 1720])
Epoch: 3311, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3312 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 3900, 3729, 1526,  103, 3188, 4266, 2901, 3372, 4036, 3865, 2111,
        2141, 3139,  789, 1737])
Epoch: 3312, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3313 - Batch 1 ########################
IDs in batch 1: tensor([3208,  314,   96, 3973, 3934, 2146, 3020,  956, 3206, 2982, 2151, 2199,
        3642, 3236, 1828, 3235])
Epoch: 3313, Training Loss: 0.39, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3314 - Batch 1 ########################
IDs in batch 1: tensor([3948, 3199, 1284, 1496,  910, 1225, 1042, 3852, 1357, 1122, 1346, 1159,
        3194, 1123,  165, 1377])
Epoch: 3314, Training Loss: 0.31, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3315 - Batch 1 ########################
IDs in batch 1: tensor([2342, 4107,  617, 3656,  250, 3146, 3399,  987, 1452, 1489,   52, 3990,
         281, 3521, 3142, 1980])
Epoch: 3315, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3316 - Batch 1 ########################
IDs in batch 1: tensor([ 225, 1677,  467, 1499, 1521, 3078, 2578, 3882, 1627, 1579, 2539, 3246,
        2771,   96, 1866, 3290])
Epoch: 3316, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3317 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2443,  427, 1510, 2370, 3463, 1369,  666,  854, 1798, 3778,  610,
        4058, 3953, 3187, 2617])
Epoch: 3317, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3318 - Batch 1 ########################
IDs in batch 1: tensor([ 491, 2094,  821, 1163,  220, 2791,  475,  238, 1967,  730,   44, 1107,
        2765, 1318, 1728,  718])
Epoch: 3318, Training Loss: 0.45, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3319 - Batch 1 ########################
IDs in batch 1: tensor([3765,  709, 1736, 1761, 1208, 1134, 3069,   38, 1453, 1263, 1445, 2996,
        3203, 1371, 4133,  245])
Epoch: 3319, Training Loss: 0.32, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3320 - Batch 1 ########################
IDs in batch 1: tensor([2572, 1200, 3618, 1833, 3475, 2286, 1206, 2159, 3399, 1583, 3190, 1665,
        3453, 1502, 1563, 3807])
Epoch: 3320, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3321 - Batch 1 ########################
IDs in batch 1: tensor([3377, 1592, 2731, 1722, 4033, 2847,  536, 2895, 3942, 4118, 1886, 3926,
        4198, 2641, 2771, 3333])
Epoch: 3321, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3322 - Batch 1 ########################
IDs in batch 1: tensor([ 108,  395, 2408, 4148, 2559, 2009,  866, 1626,  632, 2045,  451, 1857,
        2073, 4227, 3055, 3069])
Epoch: 3322, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3323 - Batch 1 ########################
IDs in batch 1: tensor([1084, 3549, 1039, 1158, 3437,  503,  224, 3356, 1377, 1618, 2978, 4212,
        2176, 1158, 1299, 2358])
Epoch: 3323, Training Loss: 0.17, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3324 - Batch 1 ########################
IDs in batch 1: tensor([1858, 2860, 1488,  314,  203, 3099, 2671, 1355, 1613, 2332, 1747, 3859,
        1900, 3847, 2826, 3117])
Epoch: 3324, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3325 - Batch 1 ########################
IDs in batch 1: tensor([1423, 1994, 3693, 2405, 1080, 3120, 1546, 3196, 3377,  302,  342, 2708,
         255,   84, 2810, 1097])
Epoch: 3325, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.71
######################## Epoch 3326 - Batch 1 ########################
IDs in batch 1: tensor([3417,  651, 3723, 4033, 2156, 1072,  555,  411, 1746, 2249, 3577, 1640,
         214, 4236, 3911, 1478])
Epoch: 3326, Training Loss: 0.23, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3327 - Batch 1 ########################
IDs in batch 1: tensor([ 199, 4152, 1887, 2788, 1708, 3082, 3207,  566,  813,  788, 2546, 1955,
        2242, 1168, 2167, 2755])
Epoch: 3327, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3328 - Batch 1 ########################
IDs in batch 1: tensor([1734, 1373, 3051, 3299, 1809, 3208, 1161,  732, 2264, 3456,  982, 4253,
        1285, 1384,   85, 2326])
Epoch: 3328, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3329 - Batch 1 ########################
IDs in batch 1: tensor([3455,  282,  417, 1337, 1712,  239, 2355, 1642, 4181, 1282, 3377,  173,
        4154, 1452,  969,  573])
Epoch: 3329, Training Loss: 0.33, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3330 - Batch 1 ########################
IDs in batch 1: tensor([3714, 3394, 1834, 2712, 1237, 2755, 1176, 4165, 4025, 3894, 2458, 4258,
        3000, 4235, 4013, 1418])
Epoch: 3330, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3331 - Batch 1 ########################
IDs in batch 1: tensor([2853, 3022, 4146, 3495, 2067, 2754, 3618, 2051, 3900,  200, 3637, 3808,
        1868,  354, 2252, 2833])
Epoch: 3331, Training Loss: 0.49, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3332 - Batch 1 ########################
IDs in batch 1: tensor([3936,  232, 3451, 1623, 1332, 3897,  320, 3233, 3306,  812, 1443, 3940,
        1795, 1136,  361, 3087])
Epoch: 3332, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3333 - Batch 1 ########################
IDs in batch 1: tensor([4214, 2280,  725, 1183, 3254,  418, 1764, 4225, 2360, 3006, 2932, 3930,
        3036,  497, 2870, 1817])
Epoch: 3333, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3334 - Batch 1 ########################
IDs in batch 1: tensor([2039, 3177, 2616, 2441,  601, 1623,  426, 1716, 2238, 1627, 1132, 3435,
        3262,  982,  588, 3120])
Epoch: 3334, Training Loss: 0.21, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3335 - Batch 1 ########################
IDs in batch 1: tensor([2488, 2624, 3642, 1440, 3604,  357,  515, 1675, 3160,  667, 1093, 3837,
        3494, 4022,  522, 3541])
Epoch: 3335, Training Loss: 0.27, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3336 - Batch 1 ########################
IDs in batch 1: tensor([2410, 4078, 1063,  119, 1279, 3449, 2726, 2999, 2372,  934,  289, 1737,
        2408,  407, 4078,  489])
Epoch: 3336, Training Loss: 0.11, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3337 - Batch 1 ########################
IDs in batch 1: tensor([4165, 1042, 2078, 4122, 1589, 2867, 3057, 1363, 2845,  997, 3845, 2346,
        2730, 1457,  375, 3945])
Epoch: 3337, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3338 - Batch 1 ########################
IDs in batch 1: tensor([1754,  155, 2151, 2193, 2470,  673, 1809, 1991,  605, 2536, 3028, 4228,
        4004, 2670, 1473, 2997])
Epoch: 3338, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3339 - Batch 1 ########################
IDs in batch 1: tensor([ 978, 2579, 2027, 2118,  199, 2653, 2121, 3532, 1315,  150,  622, 3354,
        3960, 3252, 1219, 1318])
Epoch: 3339, Training Loss: 0.11, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3340 - Batch 1 ########################
IDs in batch 1: tensor([1711, 1878, 2014, 1054,   95, 4122,  432, 2406, 1718,  873, 2081, 2660,
         721, 3058, 1855, 1200])
Epoch: 3340, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3341 - Batch 1 ########################
IDs in batch 1: tensor([3981, 1124, 2504, 3677, 3981, 1976,  758,  962, 2350, 1266, 2134, 3489,
        3211, 2674, 1536, 3739])
Epoch: 3341, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3342 - Batch 1 ########################
IDs in batch 1: tensor([4215,  814, 1360, 4242, 3241,  321, 4236, 1442,  609, 1110, 3658, 1961,
        1753, 3496, 1772,  823])
Epoch: 3342, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3343 - Batch 1 ########################
IDs in batch 1: tensor([ 455, 3891, 2974, 4078, 2649, 4263, 1651, 2832, 3743, 3157, 3604,   73,
         897, 3518, 2890, 1698])
Epoch: 3343, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 3344 - Batch 1 ########################
IDs in batch 1: tensor([ 566, 3637, 4263, 2526, 1579,  352, 2629, 4022,  334,   10,   35, 3300,
        1972, 3689, 1794,  950])
Epoch: 3344, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3345 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 1525, 2584, 2091, 2621, 3875, 3227, 2005, 2609,  941, 3850, 3498,
        2085, 3945, 1485, 3364])
Epoch: 3345, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3346 - Batch 1 ########################
IDs in batch 1: tensor([1299, 2463, 2025, 3908, 3313,  147, 3399, 4008, 1432,  727,  789, 3147,
         380, 2494,  890, 2154])
Epoch: 3346, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3347 - Batch 1 ########################
IDs in batch 1: tensor([3790, 2332,   49,  577,  359,  980, 1821, 1420,  344,  398, 3102, 3798,
         323, 1316, 3248, 1005])
Epoch: 3347, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3348 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 2028,  854, 1206,   99, 2892, 1580,  223, 2609,  733, 2727,   84,
        3208,  640, 1166, 3088])
Epoch: 3348, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3349 - Batch 1 ########################
IDs in batch 1: tensor([3474, 2520,  920, 1803,  256, 2075,  953,  190, 3533, 3256, 2066, 2873,
         127, 1123, 2099, 3424])
Epoch: 3349, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3350 - Batch 1 ########################
IDs in batch 1: tensor([1491, 2505, 1985, 2254, 2548, 1453,  837,  306, 2872, 1685, 3311,  247,
        2220, 1855, 2204, 1251])
Epoch: 3350, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3351 - Batch 1 ########################
IDs in batch 1: tensor([1658, 3740, 1081, 1130, 1869,  947, 3541, 3968, 1234, 3755,  691, 2925,
        3812, 1062, 2063, 3938])
Epoch: 3351, Training Loss: 0.41, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3352 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 4004, 3989, 3092,  497, 3187, 3334,  963,  379, 1562, 1065, 2812,
        1591, 2871, 1878,  824])
Epoch: 3352, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3353 - Batch 1 ########################
IDs in batch 1: tensor([1901,  274,  120,  448, 3343,  832, 1113,  196, 1960, 2258, 2505, 1053,
         863, 2484, 3221,   24])
Epoch: 3353, Training Loss: 0.23, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3354 - Batch 1 ########################
IDs in batch 1: tensor([ 361,  750, 2712, 4228, 1942, 1891, 3981, 3440,  125, 4232, 3206, 2748,
        2719, 3311, 1628, 4186])
Epoch: 3354, Training Loss: 0.18, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3355 - Batch 1 ########################
IDs in batch 1: tensor([ 496,   73,  527,  721, 3583, 3704, 1140, 2209, 1840, 3588, 2812, 2284,
        2115, 3618, 1880, 2080])
Epoch: 3355, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3356 - Batch 1 ########################
IDs in batch 1: tensor([3427,  863,  882,  947, 1415, 1458,   56, 2480, 4048, 1328, 4036,  496,
        3534,   14,  181,  497])
Epoch: 3356, Training Loss: 0.27, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3357 - Batch 1 ########################
IDs in batch 1: tensor([2337, 1798,  770, 4251, 1055, 1661,  890,  531, 3712,  787,  930, 1251,
        2866, 1037, 1866,  642])
Epoch: 3357, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3358 - Batch 1 ########################
IDs in batch 1: tensor([1181, 1011, 3132, 1972, 3154, 3152, 3115, 1895, 3276, 1386, 2498, 1017,
        1452, 4187, 1011, 4189])
Epoch: 3358, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3359 - Batch 1 ########################
IDs in batch 1: tensor([1070, 3261, 2718,  794, 3919,  646, 2244, 1351, 3484, 3692, 4057, 2535,
        1281, 1319, 3528, 2185])
Epoch: 3359, Training Loss: 0.27, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3360 - Batch 1 ########################
IDs in batch 1: tensor([1633, 4197, 3693, 3372, 1325, 1679, 1793, 3036,    5, 2671, 2407, 2470,
        4144, 1125, 3875, 3850])
Epoch: 3360, Training Loss: 0.24, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3361 - Batch 1 ########################
IDs in batch 1: tensor([3021,  550, 3524, 2701, 1024,  138, 2483, 3082, 2795, 2895, 1619, 1160,
        1397, 3448,  687, 2905])
Epoch: 3361, Training Loss: 0.22, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3362 - Batch 1 ########################
IDs in batch 1: tensor([3917, 2802, 1429, 2504, 2170, 1257,   30, 3798, 2693, 3271,  604,  850,
        2729, 1171, 1022, 1491])
Epoch: 3362, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3363 - Batch 1 ########################
IDs in batch 1: tensor([1975,  401,  462, 3676, 2616, 3656,  238, 2316, 2478, 3891,  229, 1642,
        1054,   74,  251, 3731])
Epoch: 3363, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3364 - Batch 1 ########################
IDs in batch 1: tensor([3975, 3789, 3942, 3113, 2182, 3992,  934,  955, 3190,  915, 1266, 3453,
        3018, 3989, 1070, 4227])
Epoch: 3364, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3365 - Batch 1 ########################
IDs in batch 1: tensor([4046, 3458,  290, 2483, 3241, 1456, 3710, 2984, 1281,   24,  289, 2476,
        2198, 1623, 1108,  990])
Epoch: 3365, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3366 - Batch 1 ########################
IDs in batch 1: tensor([2668, 1354, 1157, 3025, 1476, 1630, 2253, 1671, 3871, 1732,  893, 2161,
        3793,  193, 1646, 3142])
Epoch: 3366, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3367 - Batch 1 ########################
IDs in batch 1: tensor([2402, 1311, 3881, 3837, 1686, 3704, 1604,  245,  382, 1255, 2256,  714,
         399,  944, 3309, 3342])
Epoch: 3367, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3368 - Batch 1 ########################
IDs in batch 1: tensor([3614, 3802, 2859, 1840, 3304, 2264, 3023, 2913,  546, 3425, 1420, 2772,
        3832, 1648, 3052, 3866])
Epoch: 3368, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3369 - Batch 1 ########################
IDs in batch 1: tensor([2740, 1067, 2461, 2440, 4058, 4108, 2407,  262, 1610,   96, 1285,  672,
        1379, 1851,  863, 2468])
Epoch: 3369, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3370 - Batch 1 ########################
IDs in batch 1: tensor([3052, 3286, 1290,  907, 4125, 2980, 2235, 2847, 1386, 3128, 3808, 1152,
        2271, 2444, 1986,  586])
Epoch: 3370, Training Loss: 0.19, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3371 - Batch 1 ########################
IDs in batch 1: tensor([2010, 4254,  753, 3913,  950, 2919, 1841, 1121, 3894,  323, 1234,  292,
        1325, 4084,  994, 3999])
Epoch: 3371, Training Loss: 0.18, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3372 - Batch 1 ########################
IDs in batch 1: tensor([1325, 3531, 2472,  957, 3390, 2498, 3272,  773, 2831, 1824,  712, 2624,
        2726, 2726,  701,  892])
Epoch: 3372, Training Loss: 0.43, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3373 - Batch 1 ########################
IDs in batch 1: tensor([1279, 3079, 3257, 3993, 3907, 1208,  741, 2966, 3615, 1155, 1914, 4264,
         133, 2190, 2370,  945])
Epoch: 3373, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3374 - Batch 1 ########################
IDs in batch 1: tensor([2469, 2745, 3496,  520,   27, 3338, 3404,  544, 3317, 2120,   85, 1793,
        2672, 1802,  259, 1904])
Epoch: 3374, Training Loss: 0.40, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3375 - Batch 1 ########################
IDs in batch 1: tensor([2237, 3769,   26, 2480,  729, 3696, 2292, 3069, 2195, 2780, 3762, 1118,
        2687, 1967, 2771, 2734])
Epoch: 3375, Training Loss: 0.37, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3376 - Batch 1 ########################
IDs in batch 1: tensor([ 137, 3771, 1126, 4009, 3760, 2115, 3521, 4036,  577, 3449,  743,  371,
        3276, 4195,  289,  503])
Epoch: 3376, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3377 - Batch 1 ########################
IDs in batch 1: tensor([2466, 1241, 1439, 2926, 1491, 2347, 2072, 2642, 1663, 3583, 1316, 2406,
        2760,  796, 2028, 3509])
Epoch: 3377, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3378 - Batch 1 ########################
IDs in batch 1: tensor([2416,  368, 1294,  871, 2095, 2751, 1661, 1836, 3960, 3123, 2092, 2125,
         883, 1553, 3610,  436])
Epoch: 3378, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3379 - Batch 1 ########################
IDs in batch 1: tensor([3452, 2306,  969, 1967, 3478, 1818, 2795, 2437, 3049,  824, 1745, 1982,
        2712,  863, 3744,   70])
Epoch: 3379, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3380 - Batch 1 ########################
IDs in batch 1: tensor([1038,  494, 3255, 1640, 1775,  738,  396, 4107, 3390, 2574, 3712, 1958,
        3592, 3323, 1458, 1862])
Epoch: 3380, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3381 - Batch 1 ########################
IDs in batch 1: tensor([1934,  805, 2362, 1092, 4053,  312, 2614, 2793, 2264,  778, 3590,  250,
        4213, 1826, 2314, 4087])
Epoch: 3381, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3382 - Batch 1 ########################
IDs in batch 1: tensor([1502,  704, 3875,  398, 1588, 1175, 1828,  539, 4039, 3702, 2575, 2279,
        2784, 3810,  139, 1414])
Epoch: 3382, Training Loss: 0.13, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3383 - Batch 1 ########################
IDs in batch 1: tensor([2631, 2044, 3091, 1646,  372,  100, 4242, 1089, 4065,  955, 1804, 1900,
        2296, 3984, 3728, 2317])
Epoch: 3383, Training Loss: 0.11, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3384 - Batch 1 ########################
IDs in batch 1: tensor([3834, 4212, 1933, 3543, 1482, 4061, 2272, 1602, 1308, 3142, 3536, 1393,
         419, 1360, 3876, 4166])
Epoch: 3384, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3385 - Batch 1 ########################
IDs in batch 1: tensor([ 963, 1356, 2947, 1120, 2056, 2044, 1914, 3401, 3525,  477, 2406, 1273,
        3903,  826, 3321, 2229])
Epoch: 3385, Training Loss: 0.08, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3386 - Batch 1 ########################
IDs in batch 1: tensor([4031, 2805,  354, 1272, 4175, 4004, 2322, 2986,  415, 3988, 1487, 3852,
        2842,  217, 2831, 2314])
Epoch: 3386, Training Loss: 0.23, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3387 - Batch 1 ########################
IDs in batch 1: tensor([1967, 3204, 4027, 4022,  661, 1546, 3798,  369, 4222, 2078, 1933, 2157,
        2447, 3440, 2522, 2484])
Epoch: 3387, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3388 - Batch 1 ########################
IDs in batch 1: tensor([2789, 2126, 4014, 3400, 3836, 2949, 1456, 3251, 3618,  986, 3083, 2290,
        1010,  666, 1594,  586])
Epoch: 3388, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3389 - Batch 1 ########################
IDs in batch 1: tensor([ 887,  160, 3554,  126, 2456, 3371, 3021, 1308,  709, 3465, 1871, 1974,
        1895, 3568, 2050, 1733])
Epoch: 3389, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3390 - Batch 1 ########################
IDs in batch 1: tensor([2725,  805, 3005, 1185,  332,   82, 3607, 4073, 2423, 1028, 4061, 2413,
         250, 3484, 2695, 4131])
Epoch: 3390, Training Loss: 0.22, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3391 - Batch 1 ########################
IDs in batch 1: tensor([1625, 3197, 2587, 1476, 2577, 3389, 3525, 2250, 2603, 2859, 1760,  517,
        4080, 2010,   15, 1302])
Epoch: 3391, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3392 - Batch 1 ########################
IDs in batch 1: tensor([1526,   41,  184, 2407, 2772,  507,  775, 1809, 3004, 1206,  554, 1619,
        2993, 2413,  494, 3354])
Epoch: 3392, Training Loss: 0.14, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3393 - Batch 1 ########################
IDs in batch 1: tensor([3781, 1569, 2548,  659, 3949,  681, 1846, 4070, 3178, 3018, 2610, 1005,
         894, 1624,  359,  680])
Epoch: 3393, Training Loss: 0.16, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3394 - Batch 1 ########################
IDs in batch 1: tensor([2415, 1496, 1707, 1457, 3689,  884,  312, 3461, 1434, 3073, 3313, 3157,
         103, 2927, 2789, 2847])
Epoch: 3394, Training Loss: 0.20, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3395 - Batch 1 ########################
IDs in batch 1: tensor([1216, 2590, 2156, 3480, 3049, 2833, 2951, 2819, 1003,  887,  505, 3466,
        1452, 3309,  487, 1511])
Epoch: 3395, Training Loss: 0.28, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3396 - Batch 1 ########################
IDs in batch 1: tensor([3628, 1965, 3133, 1336, 1260, 3037, 2815, 3447, 1993, 2668, 2949, 4051,
        4031, 4056, 3888,   85])
Epoch: 3396, Training Loss: 0.20, Validation Loss: 0.86, accuracy = 0.73
######################## Epoch 3397 - Batch 1 ########################
IDs in batch 1: tensor([1913, 3299, 1459, 3233, 2541,  379,  821, 2663,  471,  717,  512, 3753,
         752, 2192, 3526,  963])
Epoch: 3397, Training Loss: 0.08, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3398 - Batch 1 ########################
IDs in batch 1: tensor([1973, 3994, 2499, 2541, 2242, 3020, 2504, 1954,  815, 4100, 3371, 4031,
        2295, 1626, 1473,   37])
Epoch: 3398, Training Loss: 0.21, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3399 - Batch 1 ########################
IDs in batch 1: tensor([3330, 3489, 1895,  136, 1552, 1042, 3607, 1857, 1985,  451, 3651, 2126,
         418, 3473, 1381, 3333])
Epoch: 3399, Training Loss: 0.21, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3400 - Batch 1 ########################
IDs in batch 1: tensor([3436, 3760, 3040, 4128, 3542, 1034, 2274,  786, 4186, 2332,  937, 4057,
        1452, 4089, 2693, 3028])
Epoch: 3400, Training Loss: 0.19, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3401 - Batch 1 ########################
IDs in batch 1: tensor([1761, 2189, 1201, 2968,   15, 2088, 4226, 3114, 3553, 2890, 3640, 2869,
        2763, 3495,  662,   37])
Epoch: 3401, Training Loss: 0.06, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3402 - Batch 1 ########################
IDs in batch 1: tensor([3112,  269, 3968,  514, 2775, 2444,  432, 3879, 3486, 3200,  432, 2521,
        3740,  778, 1252,  890])
Epoch: 3402, Training Loss: 0.07, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3403 - Batch 1 ########################
IDs in batch 1: tensor([2568, 1012, 3029,  858,  680, 2905, 2331, 2545, 2777,  497, 3337, 3447,
         474, 2103, 3952,  685])
Epoch: 3403, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3404 - Batch 1 ########################
IDs in batch 1: tensor([1212, 2420, 3329, 3384,  422, 2719, 3795, 3168, 3746, 1177, 2053, 1599,
        1881,  471,  871, 2354])
Epoch: 3404, Training Loss: 0.05, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3405 - Batch 1 ########################
IDs in batch 1: tensor([1569, 3051, 2063, 1313, 1341, 1032, 1871, 3118,  191, 2609,  732,  553,
        1676, 3585, 1506, 2777])
Epoch: 3405, Training Loss: 0.28, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3406 - Batch 1 ########################
IDs in batch 1: tensor([2717,  112, 1310, 1295, 2019, 1955, 1326, 3139, 3418, 3593, 2938, 3005,
         119, 2260, 2936, 1618])
Epoch: 3406, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3407 - Batch 1 ########################
IDs in batch 1: tensor([4226,  954,  620,  773, 3593, 2506,  947, 2322, 1377, 2712,  897, 3859,
        2127, 3032, 1213, 2088])
Epoch: 3407, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3408 - Batch 1 ########################
IDs in batch 1: tensor([ 884, 1035, 4100, 4253, 3265,  302, 1349,  884, 2755, 2973,  292, 1781,
        3196, 2305,   99, 1737])
Epoch: 3408, Training Loss: 0.14, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3409 - Batch 1 ########################
IDs in batch 1: tensor([3276, 2366,  332, 3228, 2552, 3939, 2495, 3308,  199, 2203, 2828, 1576,
         173, 3870, 4116, 2579])
Epoch: 3409, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3410 - Batch 1 ########################
IDs in batch 1: tensor([2997, 2676, 3514, 1734, 1274, 4174, 1756, 3323, 3865, 3390, 1846, 3185,
         586, 1146, 1440, 3971])
Epoch: 3410, Training Loss: 0.03, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3411 - Batch 1 ########################
IDs in batch 1: tensor([ 350, 4062,  676,   18, 2604, 2320, 1066, 2046, 2412,   51, 1673,  622,
        4227,  679, 2324, 1918])
Epoch: 3411, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3412 - Batch 1 ########################
IDs in batch 1: tensor([1974,  854, 1670, 2251,  923,  672, 1310, 4035,  436, 2261,  456,  976,
        2640, 1163, 3652,  996])
Epoch: 3412, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3413 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 3648, 2002, 3583,  850, 4030, 1212, 3148, 3542, 4249, 3000, 2731,
        2347, 1234, 2969, 2758])
Epoch: 3413, Training Loss: 0.23, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3414 - Batch 1 ########################
IDs in batch 1: tensor([2035,  492, 3494, 1054, 1096,  879,  975, 3948,  440, 1322, 2763,  991,
        2849,  757, 3256, 1957])
Epoch: 3414, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3415 - Batch 1 ########################
IDs in batch 1: tensor([2039, 1540, 3121,   20, 4227, 3610,   72,  718, 3180,  398,  709, 3432,
        2002, 4229, 2439,  843])
Epoch: 3415, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3416 - Batch 1 ########################
IDs in batch 1: tensor([1914, 3036, 2678, 4240, 1389, 3810, 1374,  588,  676, 1070, 1059, 1555,
         413, 3409, 4149, 1076])
Epoch: 3416, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3417 - Batch 1 ########################
IDs in batch 1: tensor([2901, 3721, 1437, 1493, 1965, 2584,  131, 1590,  839, 1686, 3593, 2036,
        3166, 3991,  119, 1395])
Epoch: 3417, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3418 - Batch 1 ########################
IDs in batch 1: tensor([1232, 3971, 4122, 2256, 3538, 3386, 2305, 4118, 2700, 3391, 1640, 3117,
        3433, 4238, 4138,  259])
Epoch: 3418, Training Loss: 0.27, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3419 - Batch 1 ########################
IDs in batch 1: tensor([3987, 2937,  135, 1418, 3075,  554,  388, 2960, 2942, 3206,  136, 3564,
        2013, 3133, 2701, 3531])
Epoch: 3419, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3420 - Batch 1 ########################
IDs in batch 1: tensor([4005, 1881, 2495,  975, 2659, 2097, 2255, 3364, 4115,  729, 1588, 4261,
        2835, 2248, 3894, 2436])
Epoch: 3420, Training Loss: 0.23, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3421 - Batch 1 ########################
IDs in batch 1: tensor([2027, 2559, 2423, 3803, 3352, 3871, 2274,  321, 2151, 3841, 4234, 3747,
        2873,  713,  565, 2379])
Epoch: 3421, Training Loss: 0.35, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3422 - Batch 1 ########################
IDs in batch 1: tensor([ 120, 1575,  732, 3360,  529, 2285,  221, 3030, 1309, 3529,  910, 1886,
        3108, 4195, 3072, 1746])
Epoch: 3422, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3423 - Batch 1 ########################
IDs in batch 1: tensor([2575, 4172, 2799, 1241, 2428, 3444,  680, 2344,  121,  924, 3177, 2872,
        3853, 2800, 3842,  666])
Epoch: 3423, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3424 - Batch 1 ########################
IDs in batch 1: tensor([ 863, 2231, 1996, 3902, 3847,  514, 3453, 1405,   20,  516, 2734,  280,
        3379, 1257, 2059, 1954])
Epoch: 3424, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3425 - Batch 1 ########################
IDs in batch 1: tensor([3642, 2894, 3040, 3387, 1208, 1552, 3681, 4075,  830, 2004,  510,  626,
        3110, 2317, 1897, 2133])
Epoch: 3425, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3426 - Batch 1 ########################
IDs in batch 1: tensor([2482, 2970,  437,  164, 1499,  265, 3671, 4203, 4113,  969, 2465, 2072,
        3020,  870, 3821, 3874])
Epoch: 3426, Training Loss: 0.50, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3427 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 1364, 2780, 3865, 1163, 2885, 2787, 1117, 3378, 3984, 3060,   92,
        3314, 2059, 4229, 2485])
Epoch: 3427, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3428 - Batch 1 ########################
IDs in batch 1: tensor([2250, 3843, 2366,  757, 3943, 2277, 1648, 3439, 2924, 2114,   28, 2738,
         496, 1693, 3932,  863])
Epoch: 3428, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3429 - Batch 1 ########################
IDs in batch 1: tensor([2595, 3832, 3664, 3541, 3152, 3357, 1380, 3485, 3029, 2563, 3052, 3504,
        2476,  472, 2956,  449])
Epoch: 3429, Training Loss: 0.19, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3430 - Batch 1 ########################
IDs in batch 1: tensor([2947,  908, 1700, 2954, 2468, 2312, 2169, 3509, 2807, 4186,  440, 3355,
        1967, 1476, 1491, 4122])
Epoch: 3430, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3431 - Batch 1 ########################
IDs in batch 1: tensor([4227,  475, 2369,  900,  396, 4220,  394, 1488, 4067, 3507, 2567, 2924,
        2924, 1591, 2107, 1628])
Epoch: 3431, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3432 - Batch 1 ########################
IDs in batch 1: tensor([1913, 2826,  920, 2741,  448, 1602, 3151, 3112,  601, 4031,  769, 2544,
        1859,  736, 1420, 3903])
Epoch: 3432, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3433 - Batch 1 ########################
IDs in batch 1: tensor([ 879, 2901,   15, 1731, 2934, 3706,  645, 1226,  813,   28,  805, 1844,
         184,  105,   19, 1822])
Epoch: 3433, Training Loss: 0.25, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3434 - Batch 1 ########################
IDs in batch 1: tensor([3423, 1069, 1580, 2659,  639, 2663, 3408, 3617, 3356,  195, 3744, 1222,
        3381,   63, 1007, 3236])
Epoch: 3434, Training Loss: 0.05, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3435 - Batch 1 ########################
IDs in batch 1: tensor([2104, 2488, 3683, 4180, 2177, 4000, 2179, 1355, 2660,  971, 3841, 3177,
        1120, 1857,   93, 3435])
Epoch: 3435, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3436 - Batch 1 ########################
IDs in batch 1: tensor([3658, 3530, 3498,  945,  727, 2477, 2517, 1604, 1093, 1592, 3995,  334,
         193, 3921, 3476, 4228])
Epoch: 3436, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3437 - Batch 1 ########################
IDs in batch 1: tensor([2373, 1201, 2327,  317, 2691, 1809,  659, 1152, 3527, 2915, 2764,  862,
        4003, 4026, 2142,   99])
Epoch: 3437, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3438 - Batch 1 ########################
IDs in batch 1: tensor([3428, 1752, 1766, 1457, 2856, 2210, 2709,  355, 3275,  918, 3099, 1844,
          95, 2107, 4229, 2614])
Epoch: 3438, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3439 - Batch 1 ########################
IDs in batch 1: tensor([2135, 2024, 2198, 2489, 2386, 2346, 3648, 3374, 1495, 3942, 1284, 4005,
        4094, 2224,  510,  852])
Epoch: 3439, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3440 - Batch 1 ########################
IDs in batch 1: tensor([1310, 1008, 1894, 4180, 2315, 1356, 2390, 2117,  389, 3438, 3822, 2295,
         321,  211, 3221, 4114])
Epoch: 3440, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3441 - Batch 1 ########################
IDs in batch 1: tensor([1140,  660, 2022,  280, 3049,  824, 1199, 4251,  879, 1880, 2256, 2480,
         786,  639, 4120, 1686])
Epoch: 3441, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3442 - Batch 1 ########################
IDs in batch 1: tensor([4254, 3652,  736, 2375, 1225, 1371, 3552, 1963, 3009, 1231, 4013,  165,
        2734, 1101, 2256,  553])
Epoch: 3442, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3443 - Batch 1 ########################
IDs in batch 1: tensor([3526, 3700, 1360, 3732, 4077, 1199, 4124,  465, 1080, 1661,  656, 2555,
        3235,  966, 4174, 2592])
Epoch: 3443, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3444 - Batch 1 ########################
IDs in batch 1: tensor([1070, 2298, 2741, 1402, 1405, 2450, 2343,  119, 2761, 3039, 1017, 2394,
         260, 4076,  699, 2564])
Epoch: 3444, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3445 - Batch 1 ########################
IDs in batch 1: tensor([2968, 1042, 2887, 4033, 3483, 1237,  143, 2153, 3656, 1994, 1226, 2353,
         930, 1698, 3729,  485])
Epoch: 3445, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3446 - Batch 1 ########################
IDs in batch 1: tensor([1357,   52, 1711, 1675, 2272,  610, 1872, 1802, 1862, 1613, 2796, 1399,
        1459,  672, 2521, 3358])
Epoch: 3446, Training Loss: 0.19, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3447 - Batch 1 ########################
IDs in batch 1: tensor([1567, 2313,  595, 3832, 3875,  196, 1328, 4156, 3927, 3343, 3303,  161,
        2114,  452,  234, 2905])
Epoch: 3447, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3448 - Batch 1 ########################
IDs in batch 1: tensor([1027, 2640, 1026, 1302, 3353,  661, 2108, 2868, 3338, 4096, 1753,  327,
         141, 3203,  816, 4165])
Epoch: 3448, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3449 - Batch 1 ########################
IDs in batch 1: tensor([4176, 2348, 2286, 1716, 2697, 1175, 3732, 1976, 1028,  138, 3218,  393,
        2209, 3200,  882, 3053])
Epoch: 3449, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3450 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 1096, 4038, 3099, 2800,  284, 1248, 1335, 3077,   60, 2771, 1284,
        2013, 1054, 1931,  864])
Epoch: 3450, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3451 - Batch 1 ########################
IDs in batch 1: tensor([3112, 1766,  812, 2390, 1107,  963, 3898, 3256,  908, 2810, 1200, 2492,
        2394, 2244, 1444, 1833])
Epoch: 3451, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3452 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 2306, 3767, 3330, 1305,  194, 1274, 2004, 3976, 4161, 3243, 1421,
        1578, 2371,  405, 3524])
Epoch: 3452, Training Loss: 0.08, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3453 - Batch 1 ########################
IDs in batch 1: tensor([ 236, 1092, 2132, 3590, 1614, 3617, 3704,  788, 3964, 1650, 3330, 1646,
        3354, 3200,  494, 1234])
Epoch: 3453, Training Loss: 0.14, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3454 - Batch 1 ########################
IDs in batch 1: tensor([3236, 1569,  470, 2347,  883, 1558, 2606, 2125, 1436,  513, 3430,  820,
        3903,  724, 3738, 2114])
Epoch: 3454, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 3455 - Batch 1 ########################
IDs in batch 1: tensor([2595, 4117, 2782, 1851,  878, 3630,  238, 1963, 3564, 3911, 2350, 1660,
        2301, 4119, 2487, 1457])
Epoch: 3455, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 3456 - Batch 1 ########################
IDs in batch 1: tensor([1218, 2643,  920, 3717,  961, 2748, 2117, 3135, 3837, 3037,  395, 3526,
        3726, 1902, 2891, 1497])
Epoch: 3456, Training Loss: 0.16, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3457 - Batch 1 ########################
IDs in batch 1: tensor([1181, 4200, 2155, 1364, 2663, 3719,  214,  378, 2433, 1752, 1649,  325,
        2323, 3793, 1802, 2523])
Epoch: 3457, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3458 - Batch 1 ########################
IDs in batch 1: tensor([3371, 3998, 1772,  583, 2984, 2260, 3874,  635, 1136, 3152, 3193, 4006,
        1426, 2738, 3121, 2452])
Epoch: 3458, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3459 - Batch 1 ########################
IDs in batch 1: tensor([3465, 3102,  499,  674, 3558, 1413, 1082,   44, 2663, 1700, 3304, 2787,
         326,  507, 4024, 1877])
Epoch: 3459, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3460 - Batch 1 ########################
IDs in batch 1: tensor([1010,  171,  919, 2126, 1256, 2431,  887, 1988,  335, 1343, 3782, 2146,
          44,  910, 1376,  819])
Epoch: 3460, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3461 - Batch 1 ########################
IDs in batch 1: tensor([ 181, 3885,  244,  135, 2495, 2606, 2771, 1380, 1168,  155, 2724, 1984,
        2681,  762, 2751, 2115])
Epoch: 3461, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3462 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 2099, 1311, 4103,  880,  873, 1023, 1296, 2297, 2467,  128, 3317,
         681,  372,  177, 2767])
Epoch: 3462, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3463 - Batch 1 ########################
IDs in batch 1: tensor([1136, 2478, 2018, 3135, 3049, 3847, 1118, 3975,  786, 1910, 3261, 2016,
         779,   74, 1556, 3162])
Epoch: 3463, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3464 - Batch 1 ########################
IDs in batch 1: tensor([4108, 2844, 1070, 2546, 3311, 3430,  137, 2121, 2393, 4061,   98, 2659,
        1103, 3693, 3351,  657])
Epoch: 3464, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3465 - Batch 1 ########################
IDs in batch 1: tensor([ 826, 2145, 2137, 3509, 1162, 1063, 2605,  777, 3669, 2890, 3518, 3782,
        3430,  869, 3984, 1111])
Epoch: 3465, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3466 - Batch 1 ########################
IDs in batch 1: tensor([ 425,  134, 4235, 1423, 1763, 1234, 1945, 1410, 3202, 1909, 1830, 1711,
        3917, 1126, 3016,  956])
Epoch: 3466, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3467 - Batch 1 ########################
IDs in batch 1: tensor([3714,  691, 3252, 3374, 2734, 3542, 3142, 3876,  338, 2087, 4115,  981,
        2038, 1034, 1880, 3845])
Epoch: 3467, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3468 - Batch 1 ########################
IDs in batch 1: tensor([3952, 2465, 4062, 3475, 2440, 1488, 4173,  832, 1335, 3717, 2541, 3353,
        1038, 1861, 2009, 3337])
Epoch: 3468, Training Loss: 0.16, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3469 - Batch 1 ########################
IDs in batch 1: tensor([2011, 1098, 2181, 1200, 4205, 1850, 3810,  994, 2894, 2736, 2687, 2013,
        2688, 2826, 3074, 1562])
Epoch: 3469, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 3470 - Batch 1 ########################
IDs in batch 1: tensor([1031, 1673, 3962, 4232, 1761,  988, 1139,  769,  498, 1093, 2571, 1124,
         601, 2371,  201,  161])
Epoch: 3470, Training Loss: 0.57, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3471 - Batch 1 ########################
IDs in batch 1: tensor([3467, 2706, 2518, 2789, 3253,  681, 3385, 3282, 1297, 2631, 4027,  280,
          63, 1599, 3204,  962])
Epoch: 3471, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3472 - Batch 1 ########################
IDs in batch 1: tensor([3200, 1902, 2429, 2644, 3712, 2472, 1374, 1910, 2297, 4093,  498,  484,
        3544,  573,  645, 3406])
Epoch: 3472, Training Loss: 0.18, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3473 - Batch 1 ########################
IDs in batch 1: tensor([1275, 2540, 3184, 2209, 3567,  340, 1200, 3290, 3717,  687, 1530,  140,
         872,  308, 1239, 3345])
Epoch: 3473, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3474 - Batch 1 ########################
IDs in batch 1: tensor([3757,  613, 1137, 1200,  463,  217, 4218,  110, 1635, 2535, 2784,  807,
         126, 2842,  360, 4152])
Epoch: 3474, Training Loss: 0.16, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3475 - Batch 1 ########################
IDs in batch 1: tensor([2867, 4263,  921, 3427, 2003, 3949, 2408,  879, 1558,  365, 1702,  820,
         321, 1626, 3754, 1618])
Epoch: 3475, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3476 - Batch 1 ########################
IDs in batch 1: tensor([3465, 3778, 2150, 1999, 1124,  730, 1346, 3197,  869,  320,  327,  930,
        3220,  864, 3160, 2327])
Epoch: 3476, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3477 - Batch 1 ########################
IDs in batch 1: tensor([4057, 3689, 4124,   18, 3744, 2232, 4076,  237,  779, 1256, 3150, 3676,
        3239,   62, 3836, 1746])
Epoch: 3477, Training Loss: 0.28, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3478 - Batch 1 ########################
IDs in batch 1: tensor([1103, 1043, 2442, 3334, 1861, 1570, 1050, 1030, 2218, 2793,  503,  191,
        3385,  194, 1918, 3882])
Epoch: 3478, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3479 - Batch 1 ########################
IDs in batch 1: tensor([3018, 1708, 3299, 4224,   51, 4110, 2337, 1080,  426,  875, 3128, 1789,
        1870, 1948, 3245,  883])
Epoch: 3479, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3480 - Batch 1 ########################
IDs in batch 1: tensor([4107, 3718,   62, 1866, 2028, 3108,  954, 4094, 2682, 1402, 4198, 1103,
        1704, 4184, 2367, 3327])
Epoch: 3480, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3481 - Batch 1 ########################
IDs in batch 1: tensor([1641, 2247, 1778, 1408, 3530, 4133,  430,  915,  915,  852, 2907,  518,
         701,   78, 2894, 2551])
Epoch: 3481, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.72
######################## Epoch 3482 - Batch 1 ########################
IDs in batch 1: tensor([3783, 3875,  508, 1952, 2989, 2157, 2245, 3217, 1951, 2011, 1679, 3950,
        2934,  206,  907, 2590])
Epoch: 3482, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3483 - Batch 1 ########################
IDs in batch 1: tensor([2069, 2131, 3994, 1540, 3865, 1756, 2352, 2667,  934,  971, 2741, 4200,
        2563, 2579, 4190, 2579])
Epoch: 3483, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3484 - Batch 1 ########################
IDs in batch 1: tensor([ 665, 2954, 1810, 3042, 1872, 2190,   86, 1052, 3532, 1459, 2448, 2886,
        2014,  184, 3628, 3148])
Epoch: 3484, Training Loss: 0.42, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3485 - Batch 1 ########################
IDs in batch 1: tensor([3943, 4215,  164, 3135, 3984, 2986, 2151, 3938, 1619,  652, 1762, 3279,
        1017,  913, 1319, 1895])
Epoch: 3485, Training Loss: 0.20, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3486 - Batch 1 ########################
IDs in batch 1: tensor([1176, 3321,  997,  400, 1996, 1957, 1921, 1960, 1443,  773, 1315, 2643,
        1387,  361, 3378,   50])
Epoch: 3486, Training Loss: 0.17, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3487 - Batch 1 ########################
IDs in batch 1: tensor([ 527, 1718, 3349, 1702, 2763, 3846, 3091, 3833, 3614, 2842,  666, 3719,
        2339, 3697, 2114, 3808])
Epoch: 3487, Training Loss: 0.24, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3488 - Batch 1 ########################
IDs in batch 1: tensor([3179, 1566,  994,  380, 2604, 1859, 1372, 1767, 4204,  678, 3369, 2039,
         785, 1897, 1968, 3651])
Epoch: 3488, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.71
######################## Epoch 3489 - Batch 1 ########################
IDs in batch 1: tensor([2228, 1073, 3609, 3898, 2965, 3845,  405, 2812, 3156,  733, 1418, 3603,
        2298, 2360, 1904, 2295])
Epoch: 3489, Training Loss: 0.34, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3490 - Batch 1 ########################
IDs in batch 1: tensor([3299, 2796, 1383, 3038, 3917, 3114, 1700, 3821, 3507, 3845, 3357,  574,
        2788, 2770, 2836, 3683])
Epoch: 3490, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 3491 - Batch 1 ########################
IDs in batch 1: tensor([2745, 3932, 1377,  133,  150, 4204, 1006, 3244,  582, 3731,  838,  279,
        1009,  758, 2024, 1213])
Epoch: 3491, Training Loss: 0.18, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3492 - Batch 1 ########################
IDs in batch 1: tensor([3038, 3196, 1923,  756, 3544, 1680, 2857,  794, 3850,  770, 3896, 1111,
         180, 2892, 3715, 1451])
Epoch: 3492, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3493 - Batch 1 ########################
IDs in batch 1: tensor([2963, 2260,  363, 2198, 1911,  849,  498, 3922,  649, 2591, 4256, 2357,
        3802,  456, 2934, 1387])
Epoch: 3493, Training Loss: 0.15, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 3494 - Batch 1 ########################
IDs in batch 1: tensor([ 651,  407,  394, 3721, 2399,  266, 1176, 2117, 3243,  491, 1266, 2845,
         395, 2334, 1057, 1450])
Epoch: 3494, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3495 - Batch 1 ########################
IDs in batch 1: tensor([ 151, 3962, 3904, 3381,  245,   68, 2414, 3792, 2765, 3130, 3053,  977,
         987, 2967, 1726, 3435])
Epoch: 3495, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3496 - Batch 1 ########################
IDs in batch 1: tensor([1665, 3712, 2064, 3863, 3597, 4235, 1136, 3989, 1008, 1098, 3366, 2131,
         532, 1604, 3035,  781])
Epoch: 3496, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3497 - Batch 1 ########################
IDs in batch 1: tensor([4251,  795, 1464, 2148, 3102, 3244, 3438, 2615, 3351, 1234,  609, 3771,
         586, 1364, 2254, 3983])
Epoch: 3497, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3498 - Batch 1 ########################
IDs in batch 1: tensor([2794, 1973,  752, 3705, 1383,  704, 2763,   62, 3183, 1614, 4128, 3970,
        2629, 3446, 3236,  403])
Epoch: 3498, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.70
######################## Epoch 3499 - Batch 1 ########################
IDs in batch 1: tensor([1322,  947,  359,  930, 2300, 1537, 3856, 2891, 4184, 3876, 1934, 1137,
        3533, 2110, 4198,  727])
Epoch: 3499, Training Loss: 0.08, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3500 - Batch 1 ########################
IDs in batch 1: tensor([3532, 3207,  104, 2295,  777, 1502, 2823, 1704,  713, 2170, 4075, 2823,
        4170, 4055,  170, 1030])
Epoch: 3500, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.71
######################## Epoch 3501 - Batch 1 ########################
IDs in batch 1: tensor([3398,  816, 2883,   92, 2856, 1552, 2638, 1317, 1548, 2848, 1728,  405,
        2375, 2483, 1508, 3529])
Epoch: 3501, Training Loss: 0.11, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3502 - Batch 1 ########################
IDs in batch 1: tensor([  95, 3998, 1625, 2959, 3786, 1988, 3539, 3073, 2300, 1283, 2383, 2842,
         400, 1920, 3740, 3312])
Epoch: 3502, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3503 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 3836, 1680,  251, 2376, 1756, 1676,  762, 1278, 2328,  681, 4227,
        3023, 1121, 1952, 3449])
Epoch: 3503, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3504 - Batch 1 ########################
IDs in batch 1: tensor([ 133,  884, 3581, 1976, 2476,  827, 2276, 1974,  787, 1214, 1583,  396,
        3830, 4157, 3474,  910])
Epoch: 3504, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3505 - Batch 1 ########################
IDs in batch 1: tensor([3700, 1383, 3255, 2418,  149,  213, 1573,   25, 1712, 1977, 2583,  665,
        3406, 3027, 2382,  465])
Epoch: 3505, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3506 - Batch 1 ########################
IDs in batch 1: tensor([ 243, 1383,  747, 4108,  738, 1452, 4075,  161,  607, 3871, 1451, 3289,
        1952, 1220, 1214, 3378])
Epoch: 3506, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3507 - Batch 1 ########################
IDs in batch 1: tensor([ 523, 2291, 3590,  854, 1954, 2331,  425,  824, 3853, 3681,  762, 1225,
        1740,  829,  736,  164])
Epoch: 3507, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3508 - Batch 1 ########################
IDs in batch 1: tensor([2419, 1009, 3144,  977, 1023,  663, 4036,  809, 2755, 1224, 1470, 2668,
        1196, 1171, 1727, 1023])
Epoch: 3508, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3509 - Batch 1 ########################
IDs in batch 1: tensor([3238,  510,   82, 1257, 1630, 1708, 1426, 2908, 3987, 4008,  127, 3014,
        1638, 3308, 1886, 1099])
Epoch: 3509, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3510 - Batch 1 ########################
IDs in batch 1: tensor([1614,  218, 4261, 1275,  211, 1563,  797, 2561, 1782, 1331, 2984, 2256,
         900, 1698, 1624, 3255])
Epoch: 3510, Training Loss: 0.31, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3511 - Batch 1 ########################
IDs in batch 1: tensor([2600, 2440,  846, 3827,  378, 1480, 2312,  530,  303, 1540, 2328, 1672,
        2791,  926, 1087, 3642])
Epoch: 3511, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3512 - Batch 1 ########################
IDs in batch 1: tensor([3650, 3610, 1090, 3616, 4099, 2537,  804, 2537, 4134, 1487,  841, 4268,
        3754, 3006, 1287, 2970])
Epoch: 3512, Training Loss: 0.41, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3513 - Batch 1 ########################
IDs in batch 1: tensor([1337, 3242, 1502, 3921, 1754, 3451, 3943, 2659,  151, 4107, 1680,  649,
          70,  259, 1981, 2298])
Epoch: 3513, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3514 - Batch 1 ########################
IDs in batch 1: tensor([4005, 1892, 2272,  391, 3244,  369, 3020,  587, 2745, 2343,  520, 3745,
        2178, 1108, 1825,  214])
Epoch: 3514, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3515 - Batch 1 ########################
IDs in batch 1: tensor([ 642,  854,  440,  709,  138, 4218,  941, 4185,  816, 2248, 1942,  141,
         893, 1852, 3330,  219])
Epoch: 3515, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3516 - Batch 1 ########################
IDs in batch 1: tensor([  96, 4031,  199, 2787, 2192, 2115, 2016,  652, 2091, 1803,  631,  942,
         102,  292, 2857, 3813])
Epoch: 3516, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3517 - Batch 1 ########################
IDs in batch 1: tensor([3943, 1228, 2643, 4230, 3381, 2960, 3270, 3907,  238, 1772, 2712, 2578,
        3216, 2740, 3208,  727])
Epoch: 3517, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3518 - Batch 1 ########################
IDs in batch 1: tensor([3027, 1299, 1896, 4068, 3919,  214, 2016, 1218, 2589, 1555, 3532,  682,
        3984, 2450, 2590, 3762])
Epoch: 3518, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3519 - Batch 1 ########################
IDs in batch 1: tensor([2365,  180, 3570, 3250, 2074, 3049, 3375, 2402, 2347, 1266, 1644, 1733,
        2443, 3130, 3971, 2848])
Epoch: 3519, Training Loss: 0.20, Validation Loss: 0.82, accuracy = 0.70
######################## Epoch 3520 - Batch 1 ########################
IDs in batch 1: tensor([1374,  978, 4073, 1974, 1455,  106,  844, 2295,  256,   96, 2234, 1613,
        1950, 3219, 1233, 1766])
Epoch: 3520, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3521 - Batch 1 ########################
IDs in batch 1: tensor([1023, 3782, 1373,  180, 2829, 3977, 1177, 3499, 2195, 1221, 1085, 1425,
         910, 1708, 1780,  361])
Epoch: 3521, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3522 - Batch 1 ########################
IDs in batch 1: tensor([3003,   95, 3250, 1536, 1051, 3963,   57, 1198, 3847, 3747, 2362, 3448,
         533,  183, 3349, 3680])
Epoch: 3522, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3523 - Batch 1 ########################
IDs in batch 1: tensor([2731, 2212, 3778, 2141,  213, 1252, 2244, 1986,  771, 1811, 4258, 2459,
        3182, 4172,  264, 2555])
Epoch: 3523, Training Loss: 0.25, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3524 - Batch 1 ########################
IDs in batch 1: tensor([2582, 1295, 2177, 1821, 2863, 1200, 1589, 3193,  262, 1604, 3953, 4008,
        1485,   62,  243, 3569])
Epoch: 3524, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3525 - Batch 1 ########################
IDs in batch 1: tensor([2189, 4075, 3541,  596,  529, 1585,  238,  945, 3435,  327, 3176, 1146,
        3804,   71, 1341, 3214])
Epoch: 3525, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3526 - Batch 1 ########################
IDs in batch 1: tensor([2482, 3449,    5,  234, 1138,  489, 3465,  314, 3342, 3443, 2429, 3014,
         876,  342, 3438, 1080])
Epoch: 3526, Training Loss: 0.31, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3527 - Batch 1 ########################
IDs in batch 1: tensor([2564, 1720, 1700, 1773, 4085, 1218,  223, 2771, 3894, 1332, 1402,  813,
        1356, 2555, 2799,  206])
Epoch: 3527, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3528 - Batch 1 ########################
IDs in batch 1: tensor([  59,  816, 4232, 1332, 1235,  411, 2408, 1179,  777, 3974, 1945, 1657,
        2452, 1722, 1352,  462])
Epoch: 3528, Training Loss: 0.21, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3529 - Batch 1 ########################
IDs in batch 1: tensor([3490, 2822, 1620,  794, 2297, 3655,   24,  978, 2840,  492, 1499, 3018,
        3421, 2996, 4124, 2343])
Epoch: 3529, Training Loss: 0.16, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3530 - Batch 1 ########################
IDs in batch 1: tensor([3111, 1901, 1676, 4100, 4139, 3577, 3977, 2849, 1886, 2876, 1229, 1146,
        2464, 2091, 3635, 1075])
Epoch: 3530, Training Loss: 0.33, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3531 - Batch 1 ########################
IDs in batch 1: tensor([2842, 3005,  334, 1357,   11, 3177,  558,  214, 1834, 1901,  850, 2653,
         199, 2667, 3340, 2498])
Epoch: 3531, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3532 - Batch 1 ########################
IDs in batch 1: tensor([3610, 3336, 2172, 2357, 1236, 3950, 4187,   34, 3573, 1408, 3634,  866,
        3355,   88,   70,  199])
Epoch: 3532, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3533 - Batch 1 ########################
IDs in batch 1: tensor([3469, 1809, 3654, 3100, 1840, 1453, 1045, 1834, 2309, 1884, 1322, 1313,
        3310,  610,  448, 2853])
Epoch: 3533, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3534 - Batch 1 ########################
IDs in batch 1: tensor([3433, 3005, 4058, 3676, 1051, 4014, 1793, 2915, 3558,  662,  438, 2433,
        4222, 1657, 1948,  957])
Epoch: 3534, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3535 - Batch 1 ########################
IDs in batch 1: tensor([3029, 1661, 1600, 2767, 2284,  710, 2447,  630, 1270, 2751, 2405, 1228,
        2765,  729, 1180, 2244])
Epoch: 3535, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3536 - Batch 1 ########################
IDs in batch 1: tensor([2715, 3755,  684, 2004, 2572, 2860, 3514, 3100,  344, 1086, 1088,  636,
        4184, 2777,  839, 1746])
Epoch: 3536, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3537 - Batch 1 ########################
IDs in batch 1: tensor([3573, 1390,   22, 2661,  969, 3336, 1213,   34, 2360, 3110,  805, 2802,
        3756, 1558, 4075, 3552])
Epoch: 3537, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3538 - Batch 1 ########################
IDs in batch 1: tensor([1434, 3841, 2087,  384,  908, 2959, 1748, 2190, 1252, 1330, 1819, 2189,
        2751,  388, 3554,  651])
Epoch: 3538, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3539 - Batch 1 ########################
IDs in batch 1: tensor([3265,  653, 3452, 1066, 2301, 2968,  639,  165, 2827, 4097, 1521, 1663,
        3688, 1755, 2826,  438])
Epoch: 3539, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3540 - Batch 1 ########################
IDs in batch 1: tensor([3808, 3845, 2373,  738, 1991, 2523, 2367, 2099, 2898,  956, 2218, 2277,
        4261, 2568,  427,   18])
Epoch: 3540, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3541 - Batch 1 ########################
IDs in batch 1: tensor([1916,  842,  766, 2776,  907, 3818, 1084,  341,  454, 1069, 1313,  586,
        1495,  398, 2478, 3982])
Epoch: 3541, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3542 - Batch 1 ########################
IDs in batch 1: tensor([3073,  266, 3593, 1425, 1934, 2260, 3985, 3939, 1845, 3002, 3528,  425,
        3874, 2599, 2938, 2370])
Epoch: 3542, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3543 - Batch 1 ########################
IDs in batch 1: tensor([1942, 1949, 2028, 3607, 2521,  774, 1199, 3418, 3478, 1226, 3727,  694,
        2329, 3389, 3214, 4255])
Epoch: 3543, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3544 - Batch 1 ########################
IDs in batch 1: tensor([3317, 4172, 3353,   25, 3674,  412, 1699, 3117, 1982, 2886, 3381,  419,
        2030, 3407,  491, 4000])
Epoch: 3544, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3545 - Batch 1 ########################
IDs in batch 1: tensor([ 630,  136, 2022, 3846, 1065,  688,   97,  131, 2250, 2300, 4100, 1291,
         177,  841, 2461, 3940])
Epoch: 3545, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3546 - Batch 1 ########################
IDs in batch 1: tensor([3286, 2425,  849, 3688, 3417, 2456,  369, 1845,   41, 2401, 4168, 2482,
        3308, 2087, 3279, 2464])
Epoch: 3546, Training Loss: 0.35, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3547 - Batch 1 ########################
IDs in batch 1: tensor([1271, 3159, 2500, 3661,  635, 1970, 1704, 1174, 3753,  375,  534, 1291,
          99, 1116, 1174, 3284])
Epoch: 3547, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3548 - Batch 1 ########################
IDs in batch 1: tensor([3384, 1945,  422, 2242, 1335, 3010,  879, 1404,  501, 4017, 2833, 1467,
        1208,  843, 2416, 3878])
Epoch: 3548, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3549 - Batch 1 ########################
IDs in batch 1: tensor([2281, 3628, 3647,  277,  501, 3091, 2604, 1868, 4058, 2895,  138, 3429,
        1081, 3336, 1096,  713])
Epoch: 3549, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3550 - Batch 1 ########################
IDs in batch 1: tensor([ 740, 2087, 3178, 3608, 3859,  672, 2081, 4198, 3372, 3398, 1130, 3017,
         987,  306,  148, 1686])
Epoch: 3550, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3551 - Batch 1 ########################
IDs in batch 1: tensor([ 547, 3563,  280, 4122, 1454,   24, 2011, 1501, 2736, 1947, 1508, 3845,
         262, 3876, 1126, 2776])
Epoch: 3551, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3552 - Batch 1 ########################
IDs in batch 1: tensor([1059, 2314,  710, 1140, 4117, 3483,  758, 2250,  769, 1155, 4144,  688,
        1552, 2991, 3987, 2245])
Epoch: 3552, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3553 - Batch 1 ########################
IDs in batch 1: tensor([3953, 3872,  829, 3753, 2745, 1138, 2604, 1420, 4240, 1110, 2755,  360,
        2669,  680, 2110,  315])
Epoch: 3553, Training Loss: 0.11, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3554 - Batch 1 ########################
IDs in batch 1: tensor([ 797, 3913,  878, 3921, 3271, 1181, 2331, 3027, 2347, 3329, 1107, 4152,
        2212, 1122, 2589, 2385])
Epoch: 3554, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3555 - Batch 1 ########################
IDs in batch 1: tensor([2085, 2966, 1617, 1965, 3467, 3860, 2296, 2562,  684,  862,  474, 3693,
        3518, 3055, 1084, 2327])
Epoch: 3555, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3556 - Batch 1 ########################
IDs in batch 1: tensor([1822, 3872, 3460, 1681, 1913, 1354, 3141,  239, 2036,  724,  850, 3418,
        2398,  150, 1942, 3081])
Epoch: 3556, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3557 - Batch 1 ########################
IDs in batch 1: tensor([1267, 2841, 3781,  971, 1233, 3677, 2251,  229, 1506,  368, 2053, 2339,
         790, 2574, 3710, 1504])
Epoch: 3557, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3558 - Batch 1 ########################
IDs in batch 1: tensor([ 250,  170, 1985, 3615,   47, 4094,  345,   72,  243, 4139, 3672, 4012,
        3765, 1396, 2480, 3005])
Epoch: 3558, Training Loss: 0.37, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3559 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 3369, 1799, 3589,  756,  187, 3113, 3415, 3614, 1585, 3961,  762,
        3352, 3276,  596, 3964])
Epoch: 3559, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3560 - Batch 1 ########################
IDs in batch 1: tensor([3162,  396, 3962, 3958, 2937, 4080, 1097,   61, 2740, 2777, 3343, 2416,
         401, 3782,  151, 3797])
Epoch: 3560, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3561 - Batch 1 ########################
IDs in batch 1: tensor([3956,  637,  747, 1389, 2798,  138,  545, 2249, 3564,  211, 1597, 2247,
        2352, 1326, 2157, 2145])
Epoch: 3561, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3562 - Batch 1 ########################
IDs in batch 1: tensor([1863, 2986, 2887, 2763, 1116, 1958,  191, 1773, 1312, 1248, 1285,   41,
        1066, 1390,  663, 2872])
Epoch: 3562, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3563 - Batch 1 ########################
IDs in batch 1: tensor([ 334,  394, 3987,  305, 2726, 1773, 1595, 1196, 3290, 2674, 3772, 1670,
        1600, 3439,  556, 2696])
Epoch: 3563, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.70
######################## Epoch 3564 - Batch 1 ########################
IDs in batch 1: tensor([  28,   59, 4175, 1458, 3925, 4264, 1159, 2510, 3367,  983, 1733, 1264,
        2905, 1499, 1675, 2800])
Epoch: 3564, Training Loss: 0.34, Validation Loss: 0.80, accuracy = 0.70
######################## Epoch 3565 - Batch 1 ########################
IDs in batch 1: tensor([1306,  829, 2091, 1336, 2989,  987, 2179,  895,  964, 2664, 1065, 3757,
        3428, 2610, 3444, 2388])
Epoch: 3565, Training Loss: 0.31, Validation Loss: 0.80, accuracy = 0.71
######################## Epoch 3566 - Batch 1 ########################
IDs in batch 1: tensor([2957,  519, 2541, 1267, 2961, 1287, 2968,  854,  862,   44, 2365, 1809,
        2095, 2794,  566, 1190])
Epoch: 3566, Training Loss: 0.41, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3567 - Batch 1 ########################
IDs in batch 1: tensor([ 494,  127, 1126, 1044, 1097,  900, 1454, 1496,  881, 4204, 1084, 4157,
         390, 2196, 3795, 1258])
Epoch: 3567, Training Loss: 0.91, Validation Loss: 0.81, accuracy = 0.71
######################## Epoch 3568 - Batch 1 ########################
IDs in batch 1: tensor([3982, 3373,  489, 2874, 4170, 3832, 1464, 4050, 2989, 2455, 4226, 1277,
         924, 1144, 3815, 2739])
Epoch: 3568, Training Loss: 0.46, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3569 - Batch 1 ########################
IDs in batch 1: tensor([ 770,  141, 3337, 3227, 1096, 3109,  926, 4031, 3430, 3797, 3152, 3180,
        2296, 1882, 2558, 1476])
Epoch: 3569, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3570 - Batch 1 ########################
IDs in batch 1: tensor([2552, 1921,  134, 2644, 2919, 4007, 1661,  590, 2701, 3997, 2660, 2804,
        2770,  263, 2170, 1681])
Epoch: 3570, Training Loss: 0.21, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3571 - Batch 1 ########################
IDs in batch 1: tensor([1860, 1897, 2452, 1702, 2477,  658,  225, 2484, 2244, 2482, 3598,  403,
         628, 2290,  257, 3834])
Epoch: 3571, Training Loss: 0.07, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3572 - Batch 1 ########################
IDs in batch 1: tensor([ 102,  101, 4257,  883, 2435, 1196, 3193, 1643, 2805, 3709, 2299, 1476,
         723,  933, 3131,  758])
Epoch: 3572, Training Loss: 0.43, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3573 - Batch 1 ########################
IDs in batch 1: tensor([3126, 4119,  993, 3128, 3143, 2179, 2794, 1335,  357,  858, 2375, 3949,
        1994, 4016,  333, 3850])
Epoch: 3573, Training Loss: 0.07, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3574 - Batch 1 ########################
IDs in batch 1: tensor([1069, 4108, 3339, 1671, 2589, 4232, 1953,  181, 3624,  505, 2646,  214,
        3289, 2467,  312,  963])
Epoch: 3574, Training Loss: 0.03, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3575 - Batch 1 ########################
IDs in batch 1: tensor([3530, 3499, 2254, 2584, 4033, 1258, 1530, 3021, 2312,  106, 3074, 1921,
         639, 1252, 2925, 2709])
Epoch: 3575, Training Loss: 0.17, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3576 - Batch 1 ########################
IDs in batch 1: tensor([1356,  373, 2088, 2691, 3349,  471, 3092, 4101, 1993, 1702, 2212, 3120,
        4007, 3644, 2425, 3753])
Epoch: 3576, Training Loss: 0.29, Validation Loss: 0.89, accuracy = 0.70
######################## Epoch 3577 - Batch 1 ########################
IDs in batch 1: tensor([2081,  161, 2387, 1900, 3460, 2895, 1118,   32, 4030, 3839, 1731, 3404,
        4073,  978, 1672,  920])
Epoch: 3577, Training Loss: 0.02, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3578 - Batch 1 ########################
IDs in batch 1: tensor([3112, 2668,  778,  449, 1569, 3379,  449, 2783, 2595, 4258, 2521, 3952,
          42, 1384, 3798, 3079])
Epoch: 3578, Training Loss: 0.09, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3579 - Batch 1 ########################
IDs in batch 1: tensor([ 515, 3248, 3199, 2876,  968, 3084, 2812,  143, 1901,  287,  894, 2652,
        2511,  472, 3830, 2056])
Epoch: 3579, Training Loss: 0.31, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3580 - Batch 1 ########################
IDs in batch 1: tensor([2073,   52, 1770,  538,  282, 3284, 1356, 2414, 3071,  743, 4037, 2455,
        2086,  470, 2541,  733])
Epoch: 3580, Training Loss: 0.10, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3581 - Batch 1 ########################
IDs in batch 1: tensor([4149,  379, 2046, 4007, 3583, 1976, 3843, 3005,  351, 2091, 3259, 1328,
        1094,  531, 3074, 4197])
Epoch: 3581, Training Loss: 0.29, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3582 - Batch 1 ########################
IDs in batch 1: tensor([1277, 3705, 1442, 2131, 1041, 2482, 4134, 2149, 3589, 2798, 2540, 3912,
        3429, 3178,  262, 3905])
Epoch: 3582, Training Loss: 0.19, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3583 - Batch 1 ########################
IDs in batch 1: tensor([2453, 4116, 3506, 3891, 2193, 3553, 4159,  463,  154, 1315, 1200, 1881,
        2088,  181,  284,  729])
Epoch: 3583, Training Loss: 0.25, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3584 - Batch 1 ########################
IDs in batch 1: tensor([1604, 1310,  821, 3370, 2809, 1870, 3934,  896,  150, 1958,  552, 2970,
        1954,  369, 3712,  527])
Epoch: 3584, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3585 - Batch 1 ########################
IDs in batch 1: tensor([ 106, 2575, 3618, 3132,   88, 1745, 2783,  926, 2810, 2253, 1628, 3644,
        3842,  488, 2426, 1855])
Epoch: 3585, Training Loss: 0.04, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3586 - Batch 1 ########################
IDs in batch 1: tensor([4131, 2137, 1322, 1087, 1325, 1633, 3933,  295, 2477, 3216, 3458,  920,
        3160, 1381, 3329,  361])
Epoch: 3586, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3587 - Batch 1 ########################
IDs in batch 1: tensor([1476,   21, 3818, 3156, 3760, 1737,  511,  632,  256, 4166,  191, 3536,
        3105, 1613,  284, 3837])
Epoch: 3587, Training Loss: 0.14, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3588 - Batch 1 ########################
IDs in batch 1: tensor([ 475,  499, 3148, 4035, 3131, 1660, 2369, 3538,   70, 2907, 2821, 3102,
        1471, 1470, 2063, 1685])
Epoch: 3588, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3589 - Batch 1 ########################
IDs in batch 1: tensor([2924, 3710, 3655, 1248,  126, 4158,  854, 2226, 1130, 3065, 3676,  750,
        4127, 3187, 3073,  494])
Epoch: 3589, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3590 - Batch 1 ########################
IDs in batch 1: tensor([3196, 3379, 3441,  367, 1186, 2199, 4267, 2349, 3432,  191, 3936,   32,
          22, 1566, 3364, 2473])
Epoch: 3590, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3591 - Batch 1 ########################
IDs in batch 1: tensor([3658, 2993, 1330, 3035,  505, 3397,   19, 3471, 3503, 3303,  312, 1363,
        3603, 2432,  494, 1892])
Epoch: 3591, Training Loss: 0.13, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3592 - Batch 1 ########################
IDs in batch 1: tensor([2405, 3371,  833, 3251, 3313, 3240, 2645, 2907, 3834, 2154, 2822,  303,
        2755, 2619, 3029, 3465])
Epoch: 3592, Training Loss: 0.70, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3593 - Batch 1 ########################
IDs in batch 1: tensor([3199, 3683,  620, 3087, 1555, 1980,  523, 1291, 2797, 2480, 1364, 1120,
        3692, 3248, 2313,  131])
Epoch: 3593, Training Loss: 0.03, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3594 - Batch 1 ########################
IDs in batch 1: tensor([3479,   97, 1332, 2090, 4140, 3765,  407, 1588, 2656, 2181, 3159,  689,
         244, 3160, 3971, 1599])
Epoch: 3594, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3595 - Batch 1 ########################
IDs in batch 1: tensor([   4,  373, 2761, 1487, 3446, 2521,  398, 3772, 3624, 1579, 2370, 1116,
        3996, 3146, 2045, 3151])
Epoch: 3595, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3596 - Batch 1 ########################
IDs in batch 1: tensor([3829, 2429,  855, 2550, 1923,  852, 2376, 3808, 3152, 1756, 2760, 2104,
        1414, 1242,  442, 3391])
Epoch: 3596, Training Loss: 0.11, Validation Loss: 0.84, accuracy = 0.74
######################## Epoch 3597 - Batch 1 ########################
IDs in batch 1: tensor([ 792, 2666, 1139, 3762, 1724, 1171, 2672, 2751,   60,  623, 3833, 2309,
        2575, 3638,  411, 3636])
Epoch: 3597, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.74
######################## Epoch 3598 - Batch 1 ########################
IDs in batch 1: tensor([1808, 2159,  726, 1763,  316, 3470,  229, 2723,  477, 3475, 1309,  854,
        2287, 1415, 1388, 2405])
Epoch: 3598, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3599 - Batch 1 ########################
IDs in batch 1: tensor([2674, 1754, 4058, 3934, 1718, 1158, 2793, 3000, 3872,  284, 1121, 2942,
         183,  983, 3277, 2752])
Epoch: 3599, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3600 - Batch 1 ########################
IDs in batch 1: tensor([ 693,  508, 1118, 3769, 1052, 2027, 3525,  212, 3764, 1393, 3132, 2545,
        2854, 2851, 1630, 1850])
Epoch: 3600, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3601 - Batch 1 ########################
IDs in batch 1: tensor([2907,  276, 3996,  405, 2703,   32, 1613, 4158, 1166, 1343, 1384,  203,
        3211,  539, 3460, 2066])
Epoch: 3601, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3602 - Batch 1 ########################
IDs in batch 1: tensor([3640, 2181,  492,  191,  995, 2681,  603,  809, 2743, 4039,  989, 1641,
        3284,   30, 1134, 2354])
Epoch: 3602, Training Loss: 0.18, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3603 - Batch 1 ########################
IDs in batch 1: tensor([2391, 3108,  821,  320,  469, 1658,  305, 3783, 1275, 1224, 3203,   84,
        2451, 2829, 2508, 2879])
Epoch: 3603, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3604 - Batch 1 ########################
IDs in batch 1: tensor([2229, 2969,   43,   30, 3850, 1276, 1309, 4212, 2509, 4224, 4100, 3207,
        2770, 2030, 2108, 1186])
Epoch: 3604, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3605 - Batch 1 ########################
IDs in batch 1: tensor([2382,  814, 3299, 1981, 2509,  982, 3121, 2827, 1156, 4011, 2245, 2798,
        1599,  152, 1355, 1752])
Epoch: 3605, Training Loss: 0.09, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3606 - Batch 1 ########################
IDs in batch 1: tensor([3751, 1351, 1369, 2014,  610, 3211,  779, 1973, 4154,   35,  371, 3971,
        2074,  735, 3468, 3257])
Epoch: 3606, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3607 - Batch 1 ########################
IDs in batch 1: tensor([4200, 1345, 2231, 2989,  151, 1349,  517, 3973, 3037, 3604,  717, 1690,
        1921, 3647,   42, 3432])
Epoch: 3607, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3608 - Batch 1 ########################
IDs in batch 1: tensor([ 498, 4126, 2824, 1488,  302, 2898, 3785, 3211, 1299, 2102,  356, 3630,
        1038, 1291, 3838, 4223])
Epoch: 3608, Training Loss: 0.15, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3609 - Batch 1 ########################
IDs in batch 1: tensor([3642, 2599, 3971,  578, 2863, 3842, 1734, 3826,  239, 4099, 2098,  251,
        1617,   28,  604, 1289])
Epoch: 3609, Training Loss: 0.42, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3610 - Batch 1 ########################
IDs in batch 1: tensor([1377, 2027,  869, 2670, 3040, 2645, 1863, 3833,  945, 3415, 3119, 2517,
        1974, 1996, 1961, 2314])
Epoch: 3610, Training Loss: 0.62, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3611 - Batch 1 ########################
IDs in batch 1: tensor([1241,  445, 3895, 3656, 1390, 1178,  412,  281,  769, 3084,  569, 1594,
        4146, 2218, 2300, 1511])
Epoch: 3611, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3612 - Batch 1 ########################
IDs in batch 1: tensor([1161, 1734, 2680, 2242, 1381, 1216, 2364, 1599, 3969, 2832, 3035, 3601,
        4077, 3461, 4018, 2113])
Epoch: 3612, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3613 - Batch 1 ########################
IDs in batch 1: tensor([3648, 1277, 1144,  541, 4016, 2604, 1213,  132, 1965, 1644,  491, 2257,
         358, 1241,  640, 1506])
Epoch: 3613, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3614 - Batch 1 ########################
IDs in batch 1: tensor([2264, 1474,  137, 3827, 1005, 2111, 1034, 2791,   86, 3499,    7, 2520,
        2500, 1724, 3003, 3902])
Epoch: 3614, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3615 - Batch 1 ########################
IDs in batch 1: tensor([3202,  167,  565, 3608, 3958,  269, 2891,  828, 1812, 3688, 2470, 3014,
         382, 2765, 3523,  193])
Epoch: 3615, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3616 - Batch 1 ########################
IDs in batch 1: tensor([2953, 1162, 3151, 3367, 1070,  652, 1464, 1507, 1855, 1793,  684,    4,
        2075, 3147, 2018, 3369])
Epoch: 3616, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3617 - Batch 1 ########################
IDs in batch 1: tensor([2736, 2776, 1891, 1208, 2150, 1406, 3417, 2688, 2346, 1299,  792, 3726,
        1956, 2378,  345, 4077])
Epoch: 3617, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3618 - Batch 1 ########################
IDs in batch 1: tensor([3466, 2473, 4049, 3506, 3222, 3856, 3185,  750, 1084, 3926, 3875, 3458,
        2099,  181,  983, 1144])
Epoch: 3618, Training Loss: 0.11, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3619 - Batch 1 ########################
IDs in batch 1: tensor([2212, 2663, 3521, 1319, 1727, 3587, 3339,  532,  466, 1476, 1318,  682,
         217, 3057, 2743, 1798])
Epoch: 3619, Training Loss: 0.04, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3620 - Batch 1 ########################
IDs in batch 1: tensor([2391, 1499, 3036, 1970, 1881, 1420, 2003, 3632, 1072, 1583, 2412, 2857,
         538, 2280,  229, 2621])
Epoch: 3620, Training Loss: 0.17, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3621 - Batch 1 ########################
IDs in batch 1: tensor([1228,  578, 4265, 1004, 2046, 2805, 2789, 1414, 2879, 1734,  545, 3702,
        1636, 3749, 2870, 3490])
Epoch: 3621, Training Loss: 0.17, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3622 - Batch 1 ########################
IDs in batch 1: tensor([4060, 1022,  627, 2563,  455, 3859, 1599, 1128, 3593, 1318, 3782, 2177,
         915,  263, 3624, 1596])
Epoch: 3622, Training Loss: 0.29, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3623 - Batch 1 ########################
IDs in batch 1: tensor([2980, 2781,  511, 2367, 3098, 1474, 1910, 2009, 2348, 3031, 2237, 3592,
         524,  676, 1625, 3452])
Epoch: 3623, Training Loss: 0.29, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3624 - Batch 1 ########################
IDs in batch 1: tensor([3069, 1312, 3963, 3304, 2643, 3756, 2680, 2509, 3486, 3220,  496, 1879,
        1982, 2011, 2304, 3449])
Epoch: 3624, Training Loss: 0.47, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3625 - Batch 1 ########################
IDs in batch 1: tensor([3507, 3885, 2812, 2726, 2091, 3430, 3982, 3715, 3793, 1322, 1387, 2265,
        1420, 2655, 2835,  610])
Epoch: 3625, Training Loss: 0.26, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3626 - Batch 1 ########################
IDs in batch 1: tensor([4117,  377, 1286, 2284, 1015,  945, 2524, 1453, 3375, 3449,  455, 3842,
        3688,   97, 2102, 4156])
Epoch: 3626, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3627 - Batch 1 ########################
IDs in batch 1: tensor([1128, 3310, 2973, 1649,  839,  515, 3829,  949,  615, 1417, 2879, 2436,
        3130, 1469, 1125, 1017])
Epoch: 3627, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3628 - Batch 1 ########################
IDs in batch 1: tensor([ 491, 2219, 2754, 3600, 1381, 3601,   11, 3176, 2225, 2225, 3643,  441,
        3886,  205, 2504, 3786])
Epoch: 3628, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3629 - Batch 1 ########################
IDs in batch 1: tensor([1244, 2218, 1620,  848,  134, 2161, 1059, 3972,  758,  437,  120,  873,
        3290, 2742,  340, 2695])
Epoch: 3629, Training Loss: 0.29, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3630 - Batch 1 ########################
IDs in batch 1: tensor([ 260, 2949, 1730, 1753,  238, 2619, 4138, 1679, 2097, 1099, 3778, 1632,
        2701, 3052, 1423,  378])
Epoch: 3630, Training Loss: 0.28, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3631 - Batch 1 ########################
IDs in batch 1: tensor([1504, 1871, 3309, 4094,  876, 3381, 4097, 1311, 1563, 4184,  278, 4234,
        3193, 2199, 2004,  789])
Epoch: 3631, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3632 - Batch 1 ########################
IDs in batch 1: tensor([ 756, 3181, 2400,  986, 3286,  689, 3567, 1463, 3507,  994, 3368,  649,
        2978,  910, 3680, 1220])
Epoch: 3632, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3633 - Batch 1 ########################
IDs in batch 1: tensor([3695,  417, 3016, 1950,  505, 2519, 3433, 2295, 2276, 1525, 3434, 3940,
         102, 2103, 2829,   31])
Epoch: 3633, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3634 - Batch 1 ########################
IDs in batch 1: tensor([2237, 2687, 3154, 3276, 1630, 2514,  199, 2535, 3399, 2652, 2631, 3228,
        1255,   70, 2969, 2206])
Epoch: 3634, Training Loss: 0.30, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3635 - Batch 1 ########################
IDs in batch 1: tensor([ 449, 3270,  566, 3465, 4200, 2897, 4055,  913, 2209, 1675, 4073,  645,
        1315,   93,  729, 3831])
Epoch: 3635, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3636 - Batch 1 ########################
IDs in batch 1: tensor([2450, 2761,  314, 2695, 3221, 3146, 3417, 3654, 2103,  361,  128, 2362,
        3339, 1602, 1141, 2097])
Epoch: 3636, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3637 - Batch 1 ########################
IDs in batch 1: tensor([3812, 3756, 3989, 2645,  206,  693,  403,  863,  203, 2579, 3394, 3455,
         110, 2041, 1852, 1543])
Epoch: 3637, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3638 - Batch 1 ########################
IDs in batch 1: tensor([4122, 1267, 3964, 1059,  352, 1899, 1251, 3592, 3314, 1778, 2260, 1121,
         471, 3415, 2066, 2574])
Epoch: 3638, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3639 - Batch 1 ########################
IDs in batch 1: tensor([3638, 1914,  729, 1956,  740, 1219, 2050, 1302, 3256, 1007,  841, 3919,
        3133,  484, 3984, 3429])
Epoch: 3639, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3640 - Batch 1 ########################
IDs in batch 1: tensor([2092, 1845, 2886, 2706,  770,  858, 1331, 3460,  375, 3590, 1965,  373,
        1778, 1050,  874, 2967])
Epoch: 3640, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3641 - Batch 1 ########################
IDs in batch 1: tensor([3786,  282, 1931, 2483, 2636, 2301, 3152, 2018,  968, 2153, 2299,  332,
        3321, 3624, 3468, 2872])
Epoch: 3641, Training Loss: 0.35, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3642 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 1712,  171,   18,  200, 2537, 3945, 3785, 3255, 2682, 1108, 2121,
         797, 3133,  523, 3798])
Epoch: 3642, Training Loss: 0.03, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3643 - Batch 1 ########################
IDs in batch 1: tensor([1159, 2674, 2060, 2348,  534, 1343,  736, 3467,  758, 3553, 1390, 4088,
        3060, 1602, 1154, 2072])
Epoch: 3643, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3644 - Batch 1 ########################
IDs in batch 1: tensor([ 691, 2355, 1003, 4033, 2827,   95,  368, 3052, 1279, 4184, 4012, 3496,
        1793,  220, 3073, 3114])
Epoch: 3644, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3645 - Batch 1 ########################
IDs in batch 1: tensor([1214, 3385, 2746, 2230, 3395, 4204, 2437, 3228, 3239,  277, 3642, 3313,
         444,  238, 2296, 3592])
Epoch: 3645, Training Loss: 0.10, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3646 - Batch 1 ########################
IDs in batch 1: tensor([ 503, 1711,  628, 2825,  529, 2973, 1162, 3009, 2745,   15, 3640,  858,
        3938, 2254, 4138, 2192])
Epoch: 3646, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3647 - Batch 1 ########################
IDs in batch 1: tensor([2799, 3058, 2729, 2640,  653, 4110,  491,  818, 1052, 2614, 2968, 1488,
         172, 2414,   64, 2405])
Epoch: 3647, Training Loss: 0.04, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3648 - Batch 1 ########################
IDs in batch 1: tensor([1879, 1604, 1869,  265, 2499, 2890, 3981, 2231, 1897, 1568,  202, 1904,
        2022, 2805,  779, 1832])
Epoch: 3648, Training Loss: 0.25, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3649 - Batch 1 ########################
IDs in batch 1: tensor([  15, 3440,  752,  884, 2439, 2217, 1706, 3270, 2423, 1297, 2398, 3351,
        4046, 3188,  609,   97])
Epoch: 3649, Training Loss: 0.04, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3650 - Batch 1 ########################
IDs in batch 1: tensor([ 312, 2540,  213, 1281, 2841, 2793, 4065, 1181, 2116, 1812, 1360, 2978,
        4213, 1406, 2480, 3038])
Epoch: 3650, Training Loss: 0.10, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3651 - Batch 1 ########################
IDs in batch 1: tensor([1859, 2905, 3430,  837, 3777, 3621, 3516,  451, 1639, 1575,  739, 3330,
        2638, 2848, 2462, 1780])
Epoch: 3651, Training Loss: 0.22, Validation Loss: 0.89, accuracy = 0.70
######################## Epoch 3652 - Batch 1 ########################
IDs in batch 1: tensor([2410, 3989,  287,  401, 3870, 3496,  513, 1066, 4268, 4214, 3436, 1508,
        3498, 1186, 3354,  459])
Epoch: 3652, Training Loss: 0.20, Validation Loss: 0.90, accuracy = 0.70
######################## Epoch 3653 - Batch 1 ########################
IDs in batch 1: tensor([3083,  155, 2111, 1287,  283, 3326, 1364,  325,  978, 2301, 1343,  396,
         882, 1014, 3896, 2172])
Epoch: 3653, Training Loss: 0.26, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3654 - Batch 1 ########################
IDs in batch 1: tensor([3655, 1470,  377, 2299,  943, 3663, 2322, 1372, 1762, 1269, 2364,  822,
        1325,  274, 1414, 1914])
Epoch: 3654, Training Loss: 0.37, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3655 - Batch 1 ########################
IDs in batch 1: tensor([2902, 2993, 2559, 2742, 3894, 1784, 2249, 3732, 3472,  449, 2133, 2300,
          70, 3810, 3599, 4115])
Epoch: 3655, Training Loss: 0.10, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3656 - Batch 1 ########################
IDs in batch 1: tensor([ 841, 3790, 3417, 4143, 3792,  921, 1197, 2692, 3049, 1256, 3797, 3382,
        2172, 3421, 2418, 2782])
Epoch: 3656, Training Loss: 0.55, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3657 - Batch 1 ########################
IDs in batch 1: tensor([1252,  105, 1766, 4085, 1126, 3530, 1761, 3707, 1180, 1076, 3516, 2674,
        1782,  148, 3640, 3859])
Epoch: 3657, Training Loss: 0.28, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3658 - Batch 1 ########################
IDs in batch 1: tensor([ 394, 1976,  942, 3388, 2927, 3504, 3557, 2721,  367, 3863, 3284, 2582,
         849, 2802, 3218, 2161])
Epoch: 3658, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3659 - Batch 1 ########################
IDs in batch 1: tensor([2040, 1546,  282,  665, 1828, 2172, 1751, 1999, 3141, 1773, 1209,  207,
        1982,  425,  794, 1975])
Epoch: 3659, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3660 - Batch 1 ########################
IDs in batch 1: tensor([ 676, 3287, 2133, 2511, 3272, 2984, 3757, 3340, 4173,   47, 3863,  717,
         812, 2074, 1726, 3340])
Epoch: 3660, Training Loss: 0.02, Validation Loss: 0.82, accuracy = 0.71
######################## Epoch 3661 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 2687,  494,  295,  565, 3343, 3404, 1540, 2666,  165, 1373, 1104,
        1282, 3223, 3588, 3399])
Epoch: 3661, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3662 - Batch 1 ########################
IDs in batch 1: tensor([ 924,  276,  749, 1022, 3593, 4018, 4103, 1385, 3953, 1414, 3509,  672,
        3729, 4113, 2356, 1920])
Epoch: 3662, Training Loss: 0.32, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3663 - Batch 1 ########################
IDs in batch 1: tensor([2317, 3451, 2412, 3942, 1684, 4110, 2942, 1077, 3469, 1532, 3002,  250,
        3128, 3769,  321,  172])
Epoch: 3663, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3664 - Batch 1 ########################
IDs in batch 1: tensor([1182, 3991, 2393,  113, 3591, 1017, 4152, 1911, 1488, 1346, 1852, 1990,
        3030, 2255, 3971,  427])
Epoch: 3664, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3665 - Batch 1 ########################
IDs in batch 1: tensor([3998, 4078, 2069, 2254, 1756, 3862, 2737, 3640, 2676, 1866, 2604, 2304,
         615, 2845, 1861, 3258])
Epoch: 3665, Training Loss: 0.42, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3666 - Batch 1 ########################
IDs in batch 1: tensor([4122,  596, 1773, 1960, 3192,  673, 4215,  226, 2718, 3782, 1480, 4051,
        1772, 2097, 4220, 3330])
Epoch: 3666, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3667 - Batch 1 ########################
IDs in batch 1: tensor([3749, 3514, 4224, 3039, 2748,  974, 1201, 1147, 4126, 1860, 1343, 2545,
        3607, 1249, 3573, 1315])
Epoch: 3667, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3668 - Batch 1 ########################
IDs in batch 1: tensor([ 308,   81,  263,  373, 3624, 1647, 2204, 2863, 2005, 3984, 2453,   43,
        1404, 1610,  554, 4097])
Epoch: 3668, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3669 - Batch 1 ########################
IDs in batch 1: tensor([3113, 1234, 1707, 2265, 4009, 1186, 3667, 1590,  160,  886,  318,  902,
        2581, 3168, 3245, 2070])
Epoch: 3669, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3670 - Batch 1 ########################
IDs in batch 1: tensor([ 538, 1090, 3754,  855, 4168, 2423, 3384,  712, 2313, 3154,  170,  308,
        3984, 3340, 1680, 3780])
Epoch: 3670, Training Loss: 0.15, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3671 - Batch 1 ########################
IDs in batch 1: tensor([ 615,   31,  516, 1642, 2643, 3217,  880, 3108,  302,   18, 1050,  334,
        4254, 4224, 2581, 2188])
Epoch: 3671, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3672 - Batch 1 ########################
IDs in batch 1: tensor([ 529, 2235, 4264,  850, 3697,  133, 1612,  678, 1942, 2066, 1009, 1410,
        3701,  691, 1974,  280])
Epoch: 3672, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3673 - Batch 1 ########################
IDs in batch 1: tensor([2581, 2179, 1489,  926, 2847,  816, 1418,   44, 3608,  851,  674, 4107,
        3621, 3262, 2942,  829])
Epoch: 3673, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3674 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2616, 2764, 1199, 1218,  673, 3767, 2320, 1879,  258, 3115, 1540,
        1836,  183, 1913, 3858])
Epoch: 3674, Training Loss: 0.02, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3675 - Batch 1 ########################
IDs in batch 1: tensor([4148, 1111, 4032,  203,  924,  182, 3962, 1269, 3204,  467,  140, 1296,
        1439,  577,  659, 3664])
Epoch: 3675, Training Loss: 0.41, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3676 - Batch 1 ########################
IDs in batch 1: tensor([2009, 1605, 1745, 2719, 3970, 3856, 2643, 1927, 4218,  372, 2568,  915,
        2793, 3654, 3257, 1803])
Epoch: 3676, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3677 - Batch 1 ########################
IDs in batch 1: tensor([1144,  219, 3310, 3658, 2712, 3994, 3554, 1761,  490, 3217, 1057, 2614,
        3398, 4060, 4103,  474])
Epoch: 3677, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3678 - Batch 1 ########################
IDs in batch 1: tensor([1569, 1093, 4200, 3557, 1911, 2680, 4127, 2959, 1020,  781, 2995, 3569,
        2727, 3859, 3178, 1914])
Epoch: 3678, Training Loss: 0.31, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3679 - Batch 1 ########################
IDs in batch 1: tensor([1334, 3970, 4134,  139, 2295, 1594,  942, 1974, 2936,  620, 1996, 2802,
        2223, 1209, 1849, 3290])
Epoch: 3679, Training Loss: 0.18, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3680 - Batch 1 ########################
IDs in batch 1: tensor([ 975,  283, 2726, 3479, 2094, 3921, 3455, 2206, 2854, 3993, 2991, 1294,
        2070, 2908, 3822,  950])
Epoch: 3680, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3681 - Batch 1 ########################
IDs in batch 1: tensor([1235, 3404, 2106, 4053,  577, 3235, 1818, 3570, 1755, 1778,  874, 3971,
        1156, 2498, 2765,  949])
Epoch: 3681, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3682 - Batch 1 ########################
IDs in batch 1: tensor([4115,   85, 4214, 3047, 2462, 1942,  605, 2428, 4022,  975, 2579, 3444,
        2429,  822,  323,  523])
Epoch: 3682, Training Loss: 0.12, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3683 - Batch 1 ########################
IDs in batch 1: tensor([ 191, 3911,  205,  322, 2526, 1732,  318,  606,  476, 3771, 2807, 1214,
         625, 2112,   73, 3492])
Epoch: 3683, Training Loss: 0.23, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3684 - Batch 1 ########################
IDs in batch 1: tensor([2104, 1537, 1733,  908, 3532, 3635,  180,  194, 1949, 1026, 3927, 2727,
         594,  968, 3308, 2765])
Epoch: 3684, Training Loss: 0.22, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3685 - Batch 1 ########################
IDs in batch 1: tensor([1093, 1976, 1830, 1425, 1226, 1383, 2456, 1408, 2429, 2204, 2571, 1388,
        2292, 2833,  987, 2324])
Epoch: 3685, Training Loss: 0.11, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3686 - Batch 1 ########################
IDs in batch 1: tensor([  92, 1681, 3313, 2999,  377, 3900, 3601, 1632, 2467,  821, 3728, 1051,
        1470,  786, 1500,  312])
Epoch: 3686, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3687 - Batch 1 ########################
IDs in batch 1: tensor([4256, 3334, 3340,  108, 3663, 2995, 4006,  610, 1272,  804,  601,  330,
        3672,  607, 2551, 1532])
Epoch: 3687, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3688 - Batch 1 ########################
IDs in batch 1: tensor([1944, 3963, 2577, 2229, 3496, 1464, 2511,   63, 4185, 2517, 2712, 2005,
        1161, 3282, 1597, 3667])
Epoch: 3688, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3689 - Batch 1 ########################
IDs in batch 1: tensor([2287, 2066, 2003, 2793, 1361, 3364, 2278, 3423,  247,  721, 1043,  683,
         436, 1773,  657, 2036])
Epoch: 3689, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3690 - Batch 1 ########################
IDs in batch 1: tensor([2456, 3673,  723, 2692, 1438,  902, 1035, 4218, 2193, 2964, 2410, 4149,
        2251, 3701, 2262, 3888])
Epoch: 3690, Training Loss: 0.33, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3691 - Batch 1 ########################
IDs in batch 1: tensor([2230, 1041, 3683,  841,  411,  239,  533, 2583, 1530,  872, 1642, 3543,
         729, 1014, 2724, 1859])
Epoch: 3691, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3692 - Batch 1 ########################
IDs in batch 1: tensor([  52, 2743, 1437,  391, 2951, 2692, 3727, 2666, 3400, 3395, 3240,  774,
        3831, 3647, 3329,  236])
Epoch: 3692, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3693 - Batch 1 ########################
IDs in batch 1: tensor([3299,  181, 2475, 1067, 1680, 2031, 1573, 2371, 3112, 2798,  682, 2800,
        3974, 1746, 3501, 2229])
Epoch: 3693, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3694 - Batch 1 ########################
IDs in batch 1: tensor([ 132,  380, 3875, 2870, 2157,  451, 2693,  769,  371, 3583,   56,  147,
         573,  360, 3270,   56])
Epoch: 3694, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3695 - Batch 1 ########################
IDs in batch 1: tensor([ 262, 2151,  717, 3415, 2253,  971, 3830, 3176,  159, 4002, 3340,  673,
        1093, 2159,   42, 3818])
Epoch: 3695, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3696 - Batch 1 ########################
IDs in batch 1: tensor([1347,  646, 2210,  403, 2278,  626, 4265,  900, 1006,  751,  173, 4099,
        1319, 1356, 4025, 1767])
Epoch: 3696, Training Loss: 0.44, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3697 - Batch 1 ########################
IDs in batch 1: tensor([ 466, 1126, 4223, 1370,  976,  357, 3257,  617, 2521, 1594, 1991, 3772,
        2265, 1182, 3344, 2676])
Epoch: 3697, Training Loss: 0.13, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3698 - Batch 1 ########################
IDs in batch 1: tensor([2984, 3572,  384, 4007, 1124, 3255,  265, 3852, 2632, 1025,  515, 1212,
        2942, 2489, 2542,  568])
Epoch: 3698, Training Loss: 0.03, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3699 - Batch 1 ########################
IDs in batch 1: tensor([3265,  182,  121, 2190,  289, 3040,  583,  975, 3039,  833, 3146, 4140,
        1062, 3592,  454, 1216])
Epoch: 3699, Training Loss: 0.19, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3700 - Batch 1 ########################
IDs in batch 1: tensor([3355, 2798, 1676, 2324,  850, 1379,   42, 3214, 2014, 1061, 2172, 3935,
        3836, 1672, 3945, 4205])
Epoch: 3700, Training Loss: 0.12, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3701 - Batch 1 ########################
IDs in batch 1: tensor([1663,  850, 1379, 2581, 2902, 1277, 2255, 3299,   81, 3255, 4118, 2615,
        1862, 3267, 2078, 1027])
Epoch: 3701, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3702 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 2210, 1034, 3826, 2583, 4144, 1175,  944, 1031, 3831, 4038,  245,
        1526, 3987,  987, 4234])
Epoch: 3702, Training Loss: 0.43, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3703 - Batch 1 ########################
IDs in batch 1: tensor([2223, 3661, 1745,  505,  839, 2309,  513, 3964,  212, 1993, 2892, 1819,
        3732, 2799, 4006, 3952])
Epoch: 3703, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.74
######################## Epoch 3704 - Batch 1 ########################
IDs in batch 1: tensor([3769,  794, 4050, 1681, 2558, 3251, 2689,  220, 3203,  119, 3151, 2854,
        3049, 3060, 2617, 2271])
Epoch: 3704, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3705 - Batch 1 ########################
IDs in batch 1: tensor([3969, 1980,  426,  427,   38, 3014, 1702, 1660,  965, 2780, 3680,  368,
         750, 3681, 2943, 3222])
Epoch: 3705, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3706 - Batch 1 ########################
IDs in batch 1: tensor([1886, 1159, 4096, 1716, 2627,  223, 1445,  384, 1681, 3426, 3362, 1131,
        4236, 3699, 1849,  425])
Epoch: 3706, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3707 - Batch 1 ########################
IDs in batch 1: tensor([4097, 1811, 2320, 3859, 2295,  308, 2301, 2090, 1088, 1234, 1824, 3697,
        3105, 2423, 1681,  478])
Epoch: 3707, Training Loss: 0.17, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3708 - Batch 1 ########################
IDs in batch 1: tensor([3895,  974, 2516,   18,  371,  659, 2826, 2452,  991, 3222,  538, 2180,
        1625, 3360, 2605,  790])
Epoch: 3708, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3709 - Batch 1 ########################
IDs in batch 1: tensor([3746, 2844, 2876, 2265, 1443, 2081, 2860, 1180, 3484, 1794, 3863, 2447,
        3239, 3869, 1583, 4214])
Epoch: 3709, Training Loss: 0.29, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3710 - Batch 1 ########################
IDs in batch 1: tensor([ 851, 2035, 3382, 2088, 4214,  378, 2539, 3075, 3983, 2346, 2095, 3912,
        1482,  295, 3270, 3461])
Epoch: 3710, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3711 - Batch 1 ########################
IDs in batch 1: tensor([2008, 2719, 1933, 3807, 3917, 3650, 3226,  869,  574, 1374, 3476, 2917,
         173, 2606, 4203, 3218])
Epoch: 3711, Training Loss: 0.31, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3712 - Batch 1 ########################
IDs in batch 1: tensor([ 837, 2188, 3947, 4007, 1289, 3807, 2578, 2376, 3016,  915,  195,  547,
         111, 1154, 2483, 3443])
Epoch: 3712, Training Loss: 0.09, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3713 - Batch 1 ########################
IDs in batch 1: tensor([3590, 3236, 2023, 3132, 2419, 3020, 1507,   99, 1159, 1423, 1485, 2640,
        3400, 2998,   43, 2217])
Epoch: 3713, Training Loss: 0.22, Validation Loss: 0.89, accuracy = 0.69
######################## Epoch 3714 - Batch 1 ########################
IDs in batch 1: tensor([2826,   14, 3954, 1235, 1418, 3680, 3439, 3078, 2760, 3127, 4261, 2668,
        1892, 2550, 2238,  365])
Epoch: 3714, Training Loss: 0.11, Validation Loss: 0.90, accuracy = 0.69
######################## Epoch 3715 - Batch 1 ########################
IDs in batch 1: tensor([1887, 2242, 2661,  774, 3235, 2118, 3939, 1991, 1730, 1976, 2603,  154,
         552, 2519,  218,  337])
Epoch: 3715, Training Loss: 0.28, Validation Loss: 0.90, accuracy = 0.69
######################## Epoch 3716 - Batch 1 ########################
IDs in batch 1: tensor([3352, 1119, 1842,  858, 3148, 3963, 3444, 2913,  432,  684, 3271, 3567,
        1681, 3729, 3117, 1935])
Epoch: 3716, Training Loss: 0.07, Validation Loss: 0.89, accuracy = 0.69
######################## Epoch 3717 - Batch 1 ########################
IDs in batch 1: tensor([ 396, 2997,  862, 3423, 4180, 1677, 2680, 1371, 3810, 3802,  777, 3455,
        2743, 4165, 1736, 2246])
Epoch: 3717, Training Loss: 0.21, Validation Loss: 0.89, accuracy = 0.69
######################## Epoch 3718 - Batch 1 ########################
IDs in batch 1: tensor([3458, 3851, 4234, 4011, 4012,  981, 3327, 1952, 3541, 1656,  449, 2710,
        3217, 3503,  766, 2807])
Epoch: 3718, Training Loss: 0.11, Validation Loss: 0.89, accuracy = 0.69
######################## Epoch 3719 - Batch 1 ########################
IDs in batch 1: tensor([2640,  324, 1056, 1012, 2070, 1234,  826,  252, 1383, 1282, 1126, 1770,
        2957, 2555, 2027, 1487])
Epoch: 3719, Training Loss: 0.46, Validation Loss: 0.92, accuracy = 0.68
######################## Epoch 3720 - Batch 1 ########################
IDs in batch 1: tensor([1802,  779, 1390, 1306, 2631, 2562, 3726, 1711, 1140,  212, 1005,  321,
        4152, 3501, 2192, 4008])
Epoch: 3720, Training Loss: 0.04, Validation Loss: 0.93, accuracy = 0.68
######################## Epoch 3721 - Batch 1 ########################
IDs in batch 1: tensor([3010, 1656,   27, 3644,  221, 3182, 1562, 1985, 3498, 3984, 1097, 1255,
        1287, 1226, 2332, 1754])
Epoch: 3721, Training Loss: 0.05, Validation Loss: 0.95, accuracy = 0.67
######################## Epoch 3722 - Batch 1 ########################
IDs in batch 1: tensor([1959, 2199,  777, 3409, 2296, 1787, 1120, 1004,  110, 2357, 2298, 3376,
        2959,  332, 1200, 3831])
Epoch: 3722, Training Loss: 0.19, Validation Loss: 0.95, accuracy = 0.67
######################## Epoch 3723 - Batch 1 ########################
IDs in batch 1: tensor([2832, 2938,   92, 2114, 2767, 3444, 2204, 2272, 2913,  422, 3194,  358,
        2176, 2142,  462,  565])
Epoch: 3723, Training Loss: 0.22, Validation Loss: 0.95, accuracy = 0.67
######################## Epoch 3724 - Batch 1 ########################
IDs in batch 1: tensor([1102,  729,  170, 3996, 2568,  961, 3009, 4175,  300, 2166,  642, 3471,
         121, 1704, 1377,  900])
Epoch: 3724, Training Loss: 0.34, Validation Loss: 0.95, accuracy = 0.68
######################## Epoch 3725 - Batch 1 ########################
IDs in batch 1: tensor([1066,  113, 3968, 2465, 3240, 3726, 1892, 1968, 3136,  712, 2045, 1069,
        3558, 2190, 3527, 1596])
Epoch: 3725, Training Loss: 0.12, Validation Loss: 0.92, accuracy = 0.69
######################## Epoch 3726 - Batch 1 ########################
IDs in batch 1: tensor([2309, 2521, 2810, 3071,  499, 1389, 3962, 4050, 2446, 4217, 2161, 1257,
        4194, 3478,  738, 1883])
Epoch: 3726, Training Loss: 0.20, Validation Loss: 0.89, accuracy = 0.69
######################## Epoch 3727 - Batch 1 ########################
IDs in batch 1: tensor([ 257, 2517, 1439, 1360, 3790, 2278, 1881,  149, 2298, 3168, 1286, 1793,
        2199, 1914, 3863,  657])
Epoch: 3727, Training Loss: 0.04, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3728 - Batch 1 ########################
IDs in batch 1: tensor([2346, 1880, 1999, 4152,  159, 1016, 2605, 3267, 2477, 1789, 4105, 2358,
        2951, 1283, 1699, 2280])
Epoch: 3728, Training Loss: 0.14, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3729 - Batch 1 ########################
IDs in batch 1: tensor([2798, 4144, 1796,  300, 3024, 2296, 1087, 2003, 2567,  871, 1001, 3052,
        3671, 2848,  879, 2562])
Epoch: 3729, Training Loss: 0.06, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3730 - Batch 1 ########################
IDs in batch 1: tensor([ 236, 3630, 3485, 1399, 2953, 1399,  730,  266, 3206, 1566, 1470, 3161,
         606, 4032,  407,  135])
Epoch: 3730, Training Loss: 0.27, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3731 - Batch 1 ########################
IDs in batch 1: tensor([1870, 1055, 4000, 1408, 2173, 2112, 2915,  841,  913, 1985, 3675, 3018,
        3530, 3052, 3895, 2942])
Epoch: 3731, Training Loss: 0.12, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3732 - Batch 1 ########################
IDs in batch 1: tensor([ 396, 3795, 1473, 2245, 3529, 2509, 2746, 1124, 3701, 2806, 2252, 2356,
        3706, 1710, 3261, 2086])
Epoch: 3732, Training Loss: 0.25, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3733 - Batch 1 ########################
IDs in batch 1: tensor([ 450, 3039, 2797, 3446, 3133, 3357,  513, 2415, 1375, 2111, 3949, 3277,
        4180, 3875, 3102,  701])
Epoch: 3733, Training Loss: 0.13, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3734 - Batch 1 ########################
IDs in batch 1: tensor([1804,   92, 2666, 3949, 3617, 4124,  797,  983, 2378, 1568, 2492, 1499,
        3242,  243, 1279, 1824])
Epoch: 3734, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3735 - Batch 1 ########################
IDs in batch 1: tensor([2341,  630, 4204, 2776, 2305,  520, 3333,  237, 3494,  874, 3650,   77,
        3453, 3421,  180, 2999])
Epoch: 3735, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3736 - Batch 1 ########################
IDs in batch 1: tensor([3749, 1536,  524, 3330,  603, 1747, 3384, 1236,   81, 3793,  120, 2701,
        3729, 2537, 1438, 1555])
Epoch: 3736, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3737 - Batch 1 ########################
IDs in batch 1: tensor([2206, 3087, 2743, 2833,   68, 1026, 1699, 1824,  120, 2873, 1576, 3732,
        2536,  228, 2688, 1949])
Epoch: 3737, Training Loss: 0.11, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3738 - Batch 1 ########################
IDs in batch 1: tensor([1745,  869, 3654, 1942,  645, 1655, 3345, 2484, 3975, 1017, 2003, 2346,
         952, 1222,  844, 2279])
Epoch: 3738, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3739 - Batch 1 ########################
IDs in batch 1: tensor([ 588,  751, 2362, 1458, 2080, 3695, 2912, 1657, 4010, 2095, 3217, 2251,
        2274, 4120,  718,  773])
Epoch: 3739, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3740 - Batch 1 ########################
IDs in batch 1: tensor([2961, 2300, 2495, 3035, 4089,  660, 1160, 4139, 1051,  828, 3338, 3187,
        3673, 3133, 3394, 4240])
Epoch: 3740, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3741 - Batch 1 ########################
IDs in batch 1: tensor([2841, 4261, 1886, 2476, 1960, 2133,  348, 1208, 1463, 1073, 1111,  717,
        2894, 2246, 3591, 4135])
Epoch: 3741, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3742 - Batch 1 ########################
IDs in batch 1: tensor([2314, 4226,  835, 1175, 1232,  575, 1371, 1200, 1896, 1232, 2721, 2729,
        3873,  256, 3071, 2309])
Epoch: 3742, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3743 - Batch 1 ########################
IDs in batch 1: tensor([2989,  507, 2819, 3051, 1395, 3838, 1752, 4242, 2897, 4103, 2428, 2526,
        3338, 2125, 3226, 1882])
Epoch: 3743, Training Loss: 0.26, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3744 - Batch 1 ########################
IDs in batch 1: tensor([3852, 1014, 1990,   77, 4188,  811, 3310,  578, 2836,  312, 2290, 3057,
         155,   96, 1546,  384])
Epoch: 3744, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3745 - Batch 1 ########################
IDs in batch 1: tensor([2284, 1405, 4215,  478, 4068, 3591, 1226,  221, 2848, 1583, 2334, 1879,
        3440, 1070, 2371, 1123])
Epoch: 3745, Training Loss: 0.16, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3746 - Batch 1 ########################
IDs in batch 1: tensor([ 316, 3942, 3406,  878,  904, 3239,  454, 2098, 2715, 2857, 3039, 1200,
        2401, 2844,  691,  391])
Epoch: 3746, Training Loss: 0.14, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3747 - Batch 1 ########################
IDs in batch 1: tensor([3271, 1506,  985, 3853, 2964,  127, 1543, 4235, 2828, 4068, 1909, 1611,
        3353, 2433, 1107, 2019])
Epoch: 3747, Training Loss: 0.36, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3748 - Batch 1 ########################
IDs in batch 1: tensor([3564, 2159, 2780, 2648, 1850,  623, 2331,  547, 3053, 1292, 3484, 3479,
        3400, 1436, 2435, 3785])
Epoch: 3748, Training Loss: 0.40, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3749 - Batch 1 ########################
IDs in batch 1: tensor([ 871,  472, 3630, 1600, 1795,  897, 1620, 3902, 1120, 3489, 4203, 2072,
         342, 2104, 2036,   49])
Epoch: 3749, Training Loss: 0.15, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3750 - Batch 1 ########################
IDs in batch 1: tensor([1305, 1592,  322,  111, 1183, 2156, 1840, 3928, 1745, 4121, 2115, 2669,
        3030,  569, 1278,  445])
Epoch: 3750, Training Loss: 0.11, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3751 - Batch 1 ########################
IDs in batch 1: tensor([3589,  112, 3668, 1748, 2272, 4073, 2109,  187, 2872,  627, 1866, 3425,
        1499, 2462,  739, 3757])
Epoch: 3751, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3752 - Batch 1 ########################
IDs in batch 1: tensor([4069, 1962, 3920, 1600, 1834, 3351, 4133, 2521, 1022, 3505, 2265,  822,
         145, 2967, 1490,  470])
Epoch: 3752, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3753 - Batch 1 ########################
IDs in batch 1: tensor([3074,  172, 2281, 4039, 2787, 1809,  701,  226,  269, 3142,  823, 4165,
        2045,  732, 1355, 2945])
Epoch: 3753, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3754 - Batch 1 ########################
IDs in batch 1: tensor([1406, 1955, 2051, 3143, 2457, 2876, 2305, 4103,  750,  743,  434, 1752,
         953, 4165, 2108, 1641])
Epoch: 3754, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3755 - Batch 1 ########################
IDs in batch 1: tensor([2327, 3460, 3242, 4173,  451, 3635, 1274,  733,  974, 3762, 2788, 1756,
        3516, 4203, 3143, 2676])
Epoch: 3755, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3756 - Batch 1 ########################
IDs in batch 1: tensor([3514, 1177, 3427, 1130, 2980, 2938, 2141,  199, 3527, 3658, 3617, 2022,
        2039, 3534,  314, 1612])
Epoch: 3756, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3757 - Batch 1 ########################
IDs in batch 1: tensor([1760, 2112,  770, 1003,  211, 2403,  578,  507, 1139, 1774, 2118, 1604,
        1639, 3221, 3514, 3433])
Epoch: 3757, Training Loss: 0.38, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3758 - Batch 1 ########################
IDs in batch 1: tensor([ 970, 1124,  154,  808, 3214, 1232,  750, 1244, 2983, 2326,  688, 1076,
        1116,  214, 1405, 2399])
Epoch: 3758, Training Loss: 0.22, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3759 - Batch 1 ########################
IDs in batch 1: tensor([1967,  771,  591, 1641, 3192, 1153, 2088, 3599, 1062, 3667, 2412,  626,
         855, 4093, 3131, 2564])
Epoch: 3759, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3760 - Batch 1 ########################
IDs in batch 1: tensor([4124, 3370,  295, 2183, 4080, 1470,  350, 3803, 3123, 2772, 3357, 1859,
        2075, 2137, 3652, 2394])
Epoch: 3760, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3761 - Batch 1 ########################
IDs in batch 1: tensor([4165, 1787, 2849, 1360, 1663,  917, 2727, 2097, 1395, 2667, 3699, 2312,
        1999, 2423, 3940, 1498])
Epoch: 3761, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3762 - Batch 1 ########################
IDs in batch 1: tensor([2506, 3614, 2924, 3286, 2615, 3964, 2121, 1961, 1094, 1011, 1775, 2700,
        2821, 1251,  824,  661])
Epoch: 3762, Training Loss: 0.06, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3763 - Batch 1 ########################
IDs in batch 1: tensor([1647, 3071, 4094, 2251,  917, 1247, 1235,  415, 3120, 1072, 1784, 2620,
        3150, 1660,  358, 2442])
Epoch: 3763, Training Loss: 0.05, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3764 - Batch 1 ########################
IDs in batch 1: tensor([4012, 3553, 3051, 2695, 2467, 1198, 1610, 1478, 2452, 2206, 3500, 3425,
        2279, 1748, 1576, 1553])
Epoch: 3764, Training Loss: 0.08, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3765 - Batch 1 ########################
IDs in batch 1: tensor([ 895, 4242, 1594, 3975, 2742, 3693, 4009, 1121, 3953, 1027, 2945, 2248,
        3922, 3615,  387,  825])
Epoch: 3765, Training Loss: 0.48, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3766 - Batch 1 ########################
IDs in batch 1: tensor([1025, 3790, 1360, 1052, 2780, 1266, 3073, 1318,  855, 2125, 2712, 2015,
        3511, 3751, 1374, 1289])
Epoch: 3766, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3767 - Batch 1 ########################
IDs in batch 1: tensor([4255,  773,  738, 1270,  324, 2472, 4175, 2095, 3029, 1657, 3878, 4166,
        2314, 3677, 4199,  279])
Epoch: 3767, Training Loss: 0.23, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3768 - Batch 1 ########################
IDs in batch 1: tensor([1857, 2151,  217, 2977,  569, 1977,  688, 4143, 2457, 3836,  199,  129,
         513, 1552, 1774, 4082])
Epoch: 3768, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3769 - Batch 1 ########################
IDs in batch 1: tensor([4080, 1828, 2292, 3732, 1610, 3810, 2464, 1473, 1464,  726,  565, 1413,
        2122,  750, 3014, 1868])
Epoch: 3769, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3770 - Batch 1 ########################
IDs in batch 1: tensor([2800,  173, 3858, 2799, 2781, 3744, 3956,  688,  956,  106,  507, 2511,
        3143, 1882, 1010, 2278])
Epoch: 3770, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3771 - Batch 1 ########################
IDs in batch 1: tensor([2363,  676, 1395, 1795,  228, 1770, 3214, 3863, 2564,  244, 1470,  960,
        1984, 1380, 1980, 1147])
Epoch: 3771, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3772 - Batch 1 ########################
IDs in batch 1: tensor([2659, 2550, 1794, 2134, 3114, 1391,  462, 2171, 3098,  691, 1981, 3669,
         341, 3712, 3672, 1706])
Epoch: 3772, Training Loss: 0.13, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3773 - Batch 1 ########################
IDs in batch 1: tensor([2973, 3521,  463,  846, 3298, 2309, 1955, 1139, 3842, 1765,  779, 2535,
        1955,  317, 1959, 2045])
Epoch: 3773, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3774 - Batch 1 ########################
IDs in batch 1: tensor([1546, 2719,  672, 3021, 2064, 3287,   37, 3379, 1636,  350, 2463, 4172,
         701, 1976, 3872, 2258])
Epoch: 3774, Training Loss: 0.10, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3775 - Batch 1 ########################
IDs in batch 1: tensor([ 501, 3696, 1751, 2751, 1498, 4185, 1076,  864,  652, 3751, 2799, 2406,
         239,   60, 1420, 2281])
Epoch: 3775, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3776 - Batch 1 ########################
IDs in batch 1: tensor([3010, 2697, 2956, 1663, 1334, 3501, 1237, 1842, 3503, 1092, 1136, 1793,
        1869, 2337, 2959,  224])
Epoch: 3776, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3777 - Batch 1 ########################
IDs in batch 1: tensor([2355, 4061, 4197, 4050,  221, 3124, 3627, 2078, 1414, 1054, 2847, 1470,
        3785, 3321, 2740, 1443])
Epoch: 3777, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3778 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 3548, 1961, 2382, 3357, 1981, 3092, 3617, 1326, 2414,  968, 1498,
        3977, 2672, 3214, 1042])
Epoch: 3778, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3779 - Batch 1 ########################
IDs in batch 1: tensor([2132, 1009,  432, 1826, 1167, 2806, 1765, 2568, 4078, 2879, 1146,  751,
        3223, 1056, 2973, 2689])
Epoch: 3779, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3780 - Batch 1 ########################
IDs in batch 1: tensor([1918, 3896, 3404, 2678, 4159, 1168, 3680, 1965, 1585, 1720,  883,  913,
        3193, 3368, 2274,  511])
Epoch: 3780, Training Loss: 0.05, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3781 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 2974, 3660,  968,  305, 3408, 1957, 3187, 2234, 4136, 2237, 2229,
        1176,  879,  226, 1632])
Epoch: 3781, Training Loss: 0.07, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3782 - Batch 1 ########################
IDs in batch 1: tensor([1001, 2372, 1519, 2464, 2867, 3010,  320, 3243, 1273,  257, 3448, 3141,
         172, 1962, 3074, 2008])
Epoch: 3782, Training Loss: 0.16, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3783 - Batch 1 ########################
IDs in batch 1: tensor([3483,  503,   81, 2880, 3176, 3109, 3693, 3474, 1004, 3654, 3710, 1026,
         587, 2282,  401, 3644])
Epoch: 3783, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3784 - Batch 1 ########################
IDs in batch 1: tensor([2600,  191, 2375, 3306, 1155,  709, 3647, 3841, 3866, 2313, 2796,  289,
        2440, 4095, 2839, 3378])
Epoch: 3784, Training Loss: 0.26, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3785 - Batch 1 ########################
IDs in batch 1: tensor([2902, 3087, 2681, 3772, 2281, 2511,  547, 3532, 3650, 2110, 1444, 2932,
        1176, 2193,  494,  928])
Epoch: 3785, Training Loss: 0.11, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3786 - Batch 1 ########################
IDs in batch 1: tensor([4044, 2426, 1386,  363, 1980, 1249,  983,  808, 1313, 1274, 2347, 2678,
        2836,  892, 4249,  886])
Epoch: 3786, Training Loss: 0.17, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3787 - Batch 1 ########################
IDs in batch 1: tensor([3798,  943,  451,  699, 1628,  874,  422,  357,  277, 2306, 2390,  747,
         980, 3628, 2495, 1623])
Epoch: 3787, Training Loss: 0.31, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3788 - Batch 1 ########################
IDs in batch 1: tensor([3028,  601, 2156, 2687,  987, 3654, 2167, 1676,  417, 2169, 1349,  808,
         412, 3101,   37,  505])
Epoch: 3788, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3789 - Batch 1 ########################
IDs in batch 1: tensor([1655, 3441,  136, 2080, 3418, 3240, 2364, 1488, 2932, 3714,  426, 2159,
        2078, 1973, 3785,  900])
Epoch: 3789, Training Loss: 0.12, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3790 - Batch 1 ########################
IDs in batch 1: tensor([1181, 3699,  334, 1123,  837, 1921,  164, 1409,  962, 3778,  910,  220,
        4033,  498, 3525, 1017])
Epoch: 3790, Training Loss: 0.55, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3791 - Batch 1 ########################
IDs in batch 1: tensor([ 953, 1237, 2857, 3746,  154,  755, 1102, 1994,  997, 4173, 1459,  318,
        2210, 3303, 2578,  714])
Epoch: 3791, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3792 - Batch 1 ########################
IDs in batch 1: tensor([ 318,   19, 2237, 1746, 2614,   74, 3259,  568, 2723, 1410, 3655, 3888,
        1508, 2783, 2829, 2356])
Epoch: 3792, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3793 - Batch 1 ########################
IDs in batch 1: tensor([ 924,  862, 2927,  986, 3024,  631, 3239, 2927,  367, 1899, 2026, 3714,
         805, 1482, 2366,  667])
Epoch: 3793, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3794 - Batch 1 ########################
IDs in batch 1: tensor([3147, 4037, 1404, 3283, 3481, 2712, 2908,  262,  896, 2925,  395, 1242,
        1076,   47, 2961,  645])
Epoch: 3794, Training Loss: 0.20, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3795 - Batch 1 ########################
IDs in batch 1: tensor([2367,  966,  881, 1979, 2993, 2913,  694, 1186,   32, 1337,  816,  155,
        1402, 3792, 3081,  730])
Epoch: 3795, Training Loss: 0.15, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3796 - Batch 1 ########################
IDs in batch 1: tensor([ 923,  955,  881,  450, 2970,  202, 2265, 1882,  769, 1316, 3444, 1266,
         813, 2487,  515, 2582])
Epoch: 3796, Training Loss: 0.24, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3797 - Batch 1 ########################
IDs in batch 1: tensor([ 918, 4188,  880,  976, 2444, 3740,   34,  804,  217, 3394, 3282, 1130,
         936, 2548, 2584, 2342])
Epoch: 3797, Training Loss: 0.07, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3798 - Batch 1 ########################
IDs in batch 1: tensor([3241,  471, 1306, 2317, 3401,  649, 3051, 3989, 3718, 3762, 2436, 3677,
        1568,  928, 1024, 1429])
Epoch: 3798, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3799 - Batch 1 ########################
IDs in batch 1: tensor([1084, 1963, 1720, 1419, 3092,   24, 1016, 1294, 2111, 1315, 3340, 3372,
        3549,  165, 4108,  245])
Epoch: 3799, Training Loss: 0.15, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3800 - Batch 1 ########################
IDs in batch 1: tensor([2829,  554,  569, 3532, 2963,  594, 1855, 3253, 2777,  959, 4135, 3755,
        3265, 1455, 3767,  874])
Epoch: 3800, Training Loss: 0.03, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3801 - Batch 1 ########################
IDs in batch 1: tensor([  72, 3821, 2195, 1173, 3856, 1168, 3024, 2968, 2562, 3949, 3922, 1212,
        2137, 2505, 3486, 3414])
Epoch: 3801, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3802 - Batch 1 ########################
IDs in batch 1: tensor([2819, 3143, 3468,  863, 3528, 2143, 3023, 2254, 4189, 4108, 3344, 3474,
        2632, 3313, 1808, 2601])
Epoch: 3802, Training Loss: 0.92, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3803 - Batch 1 ########################
IDs in batch 1: tensor([1852, 3183,  211,  359,  407, 2264, 3291,  312,  487, 2601, 3377, 1490,
        3284, 1900, 1855, 1680])
Epoch: 3803, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3804 - Batch 1 ########################
IDs in batch 1: tensor([3161, 1540, 3582, 1284, 1824, 2548, 3536, 2956, 1419, 2298, 3139,  596,
        1076, 4220, 1844, 2156])
Epoch: 3804, Training Loss: 0.08, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3805 - Batch 1 ########################
IDs in batch 1: tensor([1723, 4224, 3535, 4194, 1953, 1780, 2448,  665, 2845, 3258,  466, 2696,
        3028, 1988,   74, 1642])
Epoch: 3805, Training Loss: 0.11, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3806 - Batch 1 ########################
IDs in batch 1: tensor([2274, 3973, 2738, 1374, 2127, 2733, 3598, 2145, 3545, 1685, 2879,  961,
        3996,  862, 2342, 3895])
Epoch: 3806, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3807 - Batch 1 ########################
IDs in batch 1: tensor([ 180, 3016,  904, 1067,  767, 4138,  400, 4067, 1267, 2746, 1552, 4050,
         289, 2005, 2829, 3196])
Epoch: 3807, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3808 - Batch 1 ########################
IDs in batch 1: tensor([ 129,  289, 2391, 2795, 4195, 2448,  526,  876, 3220, 2407, 2652, 2120,
        3308, 1190, 2648,  345])
Epoch: 3808, Training Loss: 0.35, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3809 - Batch 1 ########################
IDs in batch 1: tensor([3938, 2407, 2831, 2412, 2231, 3371,   82, 1611, 3733, 1954,   44, 3246,
        1369, 2236, 1020,  501])
Epoch: 3809, Training Loss: 0.33, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3810 - Batch 1 ########################
IDs in batch 1: tensor([ 739, 1786,  522,  646, 2855, 1469, 4127, 2304, 3453, 2640, 3339, 3950,
         632,  206, 1295, 3345])
Epoch: 3810, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3811 - Batch 1 ########################
IDs in batch 1: tensor([3782, 4050, 2856, 2322,  522, 4218, 3815, 2343,  483, 1363, 3003, 1140,
        2565, 1886, 4016, 4040])
Epoch: 3811, Training Loss: 0.39, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3812 - Batch 1 ########################
IDs in batch 1: tensor([ 928, 2444, 3833,  590,  753, 4149, 3467, 1991, 1176, 2109, 3733, 3115,
        3246, 3933, 1543, 2764])
Epoch: 3812, Training Loss: 0.05, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3813 - Batch 1 ########################
IDs in batch 1: tensor([1826, 3159, 3988, 2393, 3627, 1083, 1206, 3942, 1154, 2741, 3871, 3930,
        1711, 2641, 1485, 2882])
Epoch: 3813, Training Loss: 0.12, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3814 - Batch 1 ########################
IDs in batch 1: tensor([1885, 1032,  808, 3594,  292, 2114, 3648, 1047,  753, 2279, 2858, 3938,
        1032,  681, 1224, 2655])
Epoch: 3814, Training Loss: 0.04, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3815 - Batch 1 ########################
IDs in batch 1: tensor([1648, 2604, 3590, 2402, 4035, 2539,  568,  102, 2173, 3349,    5, 1634,
        1321, 2856,  796, 3378])
Epoch: 3815, Training Loss: 0.06, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3816 - Batch 1 ########################
IDs in batch 1: tensor([1183, 3261, 1947, 1455,  816,  426, 1177, 2265, 2582,  967, 1920,  513,
        2206, 1233, 2969,  141])
Epoch: 3816, Training Loss: 0.13, Validation Loss: 0.86, accuracy = 0.73
######################## Epoch 3817 - Batch 1 ########################
IDs in batch 1: tensor([3317, 2143,  667,  412, 1818, 1075,  172, 3124, 3777, 2517,  436,  869,
        4232, 2249, 1017,  555])
Epoch: 3817, Training Loss: 0.40, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3818 - Batch 1 ########################
IDs in batch 1: tensor([3505, 1570, 2682,  781,   95,  736, 2788, 1570, 2957, 3975, 2577, 3743,
         496,  510,  106, 2709])
Epoch: 3818, Training Loss: 0.03, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3819 - Batch 1 ########################
IDs in batch 1: tensor([ 505, 3530, 2189, 1159, 2638, 3391, 4050, 2080, 4227, 1840, 2666, 1633,
        3769,  837,  832,  750])
Epoch: 3819, Training Loss: 0.11, Validation Loss: 0.86, accuracy = 0.73
######################## Epoch 3820 - Batch 1 ########################
IDs in batch 1: tensor([1103, 2265, 1249, 3534, 1186,   24, 1140, 2539, 1457, 1794,  335, 2457,
         572,  738, 4184,  875])
Epoch: 3820, Training Loss: 0.16, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3821 - Batch 1 ########################
IDs in batch 1: tensor([1082, 3338,  196, 2015, 2377, 2358, 2984, 2178,  727, 2483, 2176, 3841,
        4119, 2592, 1553, 2026])
Epoch: 3821, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3822 - Batch 1 ########################
IDs in batch 1: tensor([3194, 3787, 4158, 2081, 1496, 2176, 3262, 2479, 2809, 1062, 4067, 4053,
         676, 1195, 3827, 3486])
Epoch: 3822, Training Loss: 0.38, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3823 - Batch 1 ########################
IDs in batch 1: tensor([4061, 1937, 1980,  816, 3091, 2049, 2120, 3025, 4018,  573, 3035, 2274,
        4085, 1487, 1617, 3516])
Epoch: 3823, Training Loss: 0.37, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3824 - Batch 1 ########################
IDs in batch 1: tensor([3166,  131, 1137, 4117,  899,  882,  256, 2595, 2387, 1512,  333, 3487,
        3763,  622, 3298, 2663])
Epoch: 3824, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3825 - Batch 1 ########################
IDs in batch 1: tensor([1333, 1965,  989, 2555, 1404, 2739, 3176,  646, 3599, 1317, 1589, 3505,
        2385, 1090, 3369, 3514])
Epoch: 3825, Training Loss: 0.04, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3826 - Batch 1 ########################
IDs in batch 1: tensor([4022, 3793, 1001,  665, 4184, 1267,  873, 4203, 4157,  354, 1384, 3214,
        2519, 1158, 1294, 2372])
Epoch: 3826, Training Loss: 0.26, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3827 - Batch 1 ########################
IDs in batch 1: tensor([ 277,  639, 2192, 3839,  892, 3673, 1244, 4060,   13, 2188, 1101, 1237,
         466, 2198,  756,  573])
Epoch: 3827, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3828 - Batch 1 ########################
IDs in batch 1: tensor([2964, 1081, 1260, 1118, 3069, 3238,  953,  670, 3058, 3600, 1760, 2695,
         237, 2950, 1163,  921])
Epoch: 3828, Training Loss: 0.17, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3829 - Batch 1 ########################
IDs in batch 1: tensor([1927, 2189, 2226, 3313, 1619, 4184, 4080, 1487, 1057, 2656, 1859, 2964,
        2959,  247, 3444, 1141])
Epoch: 3829, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3830 - Batch 1 ########################
IDs in batch 1: tensor([1627, 2957, 1500, 1084, 3242,  490,  985,  352, 2968, 3481, 3077, 1025,
        3695, 3778,  575, 2924])
Epoch: 3830, Training Loss: 0.08, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3831 - Batch 1 ########################
IDs in batch 1: tensor([3219, 1745,  455, 2648, 1069, 3194, 2322, 3551, 1853, 2446,  762, 2784,
        1963,  245,  487, 3458])
Epoch: 3831, Training Loss: 0.37, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3832 - Batch 1 ########################
IDs in batch 1: tensor([3389,   46, 2179, 2738, 2258, 1004, 2098, 3333, 2943, 2458, 2348, 1270,
        3438, 3996, 3778, 2615])
Epoch: 3832, Training Loss: 0.54, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3833 - Batch 1 ########################
IDs in batch 1: tensor([2664,  689, 2701, 2193, 2182, 3136,  848, 1291, 4078, 1351, 1490, 3235,
         544,  659, 1707, 3279])
Epoch: 3833, Training Loss: 0.06, Validation Loss: 0.90, accuracy = 0.70
######################## Epoch 3834 - Batch 1 ########################
IDs in batch 1: tensor([2091, 2860, 1155,  642, 3535, 3353, 4200, 1611, 3127, 2898, 1153, 3261,
        1038,  330,  439, 2809])
Epoch: 3834, Training Loss: 0.13, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3835 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 1775,  365, 1552,  743,  557, 3072, 4225, 1341,  848, 2385,  971,
        3792, 1975, 3446, 2990])
Epoch: 3835, Training Loss: 0.24, Validation Loss: 0.89, accuracy = 0.70
######################## Epoch 3836 - Batch 1 ########################
IDs in batch 1: tensor([2760, 1896, 2150, 1364, 2990, 2449,  401, 1718, 2954, 3655, 1563, 1604,
         263,  160,  919, 3634])
Epoch: 3836, Training Loss: 0.12, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3837 - Batch 1 ########################
IDs in batch 1: tensor([ 950, 1470, 2938, 1271, 3408,  583,  190, 2035, 1049, 2178, 1055, 2666,
        1256, 3593, 1830,  184])
Epoch: 3837, Training Loss: 0.14, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3838 - Batch 1 ########################
IDs in batch 1: tensor([3272, 2417, 2989, 2423, 1810, 1921, 1625,  627, 2997,  537, 2598,  693,
        2605, 1015, 3672, 2123])
Epoch: 3838, Training Loss: 0.13, Validation Loss: 0.91, accuracy = 0.69
######################## Epoch 3839 - Batch 1 ########################
IDs in batch 1: tensor([ 182, 1726, 2371,  532, 2669, 1828, 2559, 2156, 2181, 3409, 1271, 2645,
        1012, 3537, 3117, 2154])
Epoch: 3839, Training Loss: 0.33, Validation Loss: 0.92, accuracy = 0.69
######################## Epoch 3840 - Batch 1 ########################
IDs in batch 1: tensor([2591,  763, 2275,  238, 1578, 2262, 1680, 1442, 2552, 1684,   11, 2049,
        4115, 2106, 2880, 2616])
Epoch: 3840, Training Loss: 0.11, Validation Loss: 0.92, accuracy = 0.70
######################## Epoch 3841 - Batch 1 ########################
IDs in batch 1: tensor([ 199,  721, 2348, 2446, 2113, 1633,   52, 2065,  138, 3353, 1287,   37,
        2998, 2643, 3131, 2094])
Epoch: 3841, Training Loss: 0.20, Validation Loss: 0.91, accuracy = 0.70
######################## Epoch 3842 - Batch 1 ########################
IDs in batch 1: tensor([1372, 1540, 1206, 3211,  975, 1369, 1685, 1952, 2492,  150, 2943, 3831,
         577, 3729,  937,  501])
Epoch: 3842, Training Loss: 0.18, Validation Loss: 0.87, accuracy = 0.70
######################## Epoch 3843 - Batch 1 ########################
IDs in batch 1: tensor([3700, 1784, 3451, 1772,  338, 3888, 1942, 1373, 4152,  723, 4026, 1782,
        3704, 1292, 2577,  436])
Epoch: 3843, Training Loss: 0.47, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3844 - Batch 1 ########################
IDs in batch 1: tensor([2338, 2822, 3479, 1779, 3083,  159, 4212, 3150, 2276, 1508, 2447, 2925,
        1325,  757,  544, 2108])
Epoch: 3844, Training Loss: 0.04, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3845 - Batch 1 ########################
IDs in batch 1: tensor([3027, 2977, 3875,  961,  362, 1414, 3675,  512, 2449, 3846, 3922, 3948,
        2350, 2680, 3135, 2121])
Epoch: 3845, Training Loss: 0.33, Validation Loss: 0.89, accuracy = 0.70
######################## Epoch 3846 - Batch 1 ########################
IDs in batch 1: tensor([2052, 3810, 3478, 4223, 3398, 3374, 2372, 2777,  721, 1266, 2034,  382,
        3615, 1967, 1039,   30])
Epoch: 3846, Training Loss: 0.11, Validation Loss: 0.90, accuracy = 0.70
######################## Epoch 3847 - Batch 1 ########################
IDs in batch 1: tensor([1052, 2382, 1123, 3942, 1562, 3121,  207,  100, 3251, 1075, 3676,  488,
         292, 3554, 3349,  721])
Epoch: 3847, Training Loss: 0.17, Validation Loss: 0.88, accuracy = 0.70
######################## Epoch 3848 - Batch 1 ########################
IDs in batch 1: tensor([1089, 2837, 1484, 2670, 3003, 3094,  229, 2683, 2892, 3257, 1984, 3872,
        3507, 2420, 2327, 2468])
Epoch: 3848, Training Loss: 0.16, Validation Loss: 0.91, accuracy = 0.71
######################## Epoch 3849 - Batch 1 ########################
IDs in batch 1: tensor([2524, 3516, 4186, 1224,  674, 4121, 3437, 1377, 2066,  523, 1737, 3180,
        1887, 2551, 3894,  679])
Epoch: 3849, Training Loss: 0.05, Validation Loss: 0.91, accuracy = 0.71
######################## Epoch 3850 - Batch 1 ########################
IDs in batch 1: tensor([2442,  403, 2603, 3328, 3658, 2827, 3100, 2316, 3743, 2827, 2535, 3100,
        2854, 3700, 1559, 3368])
Epoch: 3850, Training Loss: 0.39, Validation Loss: 0.94, accuracy = 0.71
######################## Epoch 3851 - Batch 1 ########################
IDs in batch 1: tensor([ 354, 1925, 3577,  283, 1796, 2783, 2161, 3964, 2738,  887, 3005,  558,
         786, 2125,  661,  322])
Epoch: 3851, Training Loss: 0.10, Validation Loss: 0.91, accuracy = 0.71
######################## Epoch 3852 - Batch 1 ########################
IDs in batch 1: tensor([3740,  436,  563,  422, 3147, 2999, 3087,  839, 3928,  900,  445, 1530,
        2863, 2150, 3279,  623])
Epoch: 3852, Training Loss: 0.07, Validation Loss: 0.89, accuracy = 0.72
######################## Epoch 3853 - Batch 1 ########################
IDs in batch 1: tensor([3786, 1445, 3024,  519,  352, 1480, 1092, 2791, 1612, 3222, 3395, 3534,
        1881, 1566,  908,  327])
Epoch: 3853, Training Loss: 0.03, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3854 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 3797, 3798, 3053, 3256, 4016,  434, 2606, 1472, 1233, 2969, 1685,
         229, 3830, 3314, 3282])
Epoch: 3854, Training Loss: 0.05, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3855 - Batch 1 ########################
IDs in batch 1: tensor([1590, 1957, 1661, 3132, 3940, 1507,  563,  308, 3711, 2652, 1537, 1158,
        3648,  113, 1432,  968])
Epoch: 3855, Training Loss: 0.26, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3856 - Batch 1 ########################
IDs in batch 1: tensor([1618, 3793, 3706, 1059, 1315, 1429,  527, 1900,  944,  499, 1158, 1850,
        2368, 1334, 3872,  334])
Epoch: 3856, Training Loss: 0.17, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3857 - Batch 1 ########################
IDs in batch 1: tensor([3483, 2695, 2678, 3552, 3711,   95,  372,  919, 1901, 2085, 2385, 1255,
         758, 2498,  265, 1336])
Epoch: 3857, Training Loss: 0.21, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3858 - Batch 1 ########################
IDs in batch 1: tensor([ 545, 2011, 2484, 1830, 3483, 2723, 3866, 3866, 3614,  221, 1147,  914,
        3717, 4051,  513, 2177])
Epoch: 3858, Training Loss: 0.21, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3859 - Batch 1 ########################
IDs in batch 1: tensor([3587, 1110, 4099, 1604, 1232, 4016, 1994, 3501, 1511, 4149, 4084, 4082,
        2416, 2947, 1082, 3131])
Epoch: 3859, Training Loss: 0.30, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3860 - Batch 1 ########################
IDs in batch 1: tensor([2745,  842, 1369, 1597, 3452, 2701, 3536, 3287, 1035, 1459, 4038, 2845,
        4196, 1057, 3757, 2876])
Epoch: 3860, Training Loss: 0.10, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3861 - Batch 1 ########################
IDs in batch 1: tensor([3478, 2419, 3718,  609,  535, 3782,  109, 2262, 1063, 1821, 3487,  318,
         617, 3343, 2220, 1082])
Epoch: 3861, Training Loss: 0.03, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3862 - Batch 1 ########################
IDs in batch 1: tensor([3697, 3362, 1967, 3133, 1093, 3628, 1886, 1673, 3318, 2150, 3119, 1476,
          78,  886, 1795, 2723])
Epoch: 3862, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3863 - Batch 1 ########################
IDs in batch 1: tensor([1589, 1139,  250, 3996, 1360, 3313, 2272, 1140, 2806, 1916, 1886,  572,
        1712,  982,  610, 3764])
Epoch: 3863, Training Loss: 0.06, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3864 - Batch 1 ########################
IDs in batch 1: tensor([ 274, 2737, 3261, 1283, 3530, 1364, 1232, 1138, 3318, 3469, 2461,  482,
         435, 3526, 3049, 4181])
Epoch: 3864, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3865 - Batch 1 ########################
IDs in batch 1: tensor([2758,  682, 2806, 3940,  111, 4108, 4088, 1778,  644, 1369, 3334, 1643,
        2223,  145, 1543, 2591])
Epoch: 3865, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3866 - Batch 1 ########################
IDs in batch 1: tensor([ 434, 1700, 1643, 2511, 1121,  740, 2743,  171,  375,  595, 3465, 2784,
         636, 2884,  183,   11])
Epoch: 3866, Training Loss: 0.24, Validation Loss: 0.84, accuracy = 0.70
######################## Epoch 3867 - Batch 1 ########################
IDs in batch 1: tensor([3779, 3241, 2545, 1397, 2189,   98, 3772, 1545,  724,  243, 1437, 2246,
        3154, 1054,  547,  557])
Epoch: 3867, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3868 - Batch 1 ########################
IDs in batch 1: tensor([ 402, 2056,  487, 4031, 3336, 1110, 3764, 2274, 1237,  463, 3793, 2334,
        3926, 2668, 1459,   25])
Epoch: 3868, Training Loss: 0.09, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3869 - Batch 1 ########################
IDs in batch 1: tensor([3496, 2777, 3688, 2898, 3220, 2484, 2391, 1592, 2661, 1229, 2429, 2523,
        2562,  276, 1958, 2960])
Epoch: 3869, Training Loss: 0.46, Validation Loss: 0.85, accuracy = 0.70
######################## Epoch 3870 - Batch 1 ########################
IDs in batch 1: tensor([3465, 3589, 1665, 3214, 2956, 2997, 2895, 3053,  970, 2367, 1828,  970,
        3248,  283, 3123, 1354])
Epoch: 3870, Training Loss: 0.22, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3871 - Batch 1 ########################
IDs in batch 1: tensor([1321, 3192,  749,  501, 1685,  369, 4235, 3593, 1154, 2966, 1770,   61,
         553,  121,   25, 2368])
Epoch: 3871, Training Loss: 0.19, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3872 - Batch 1 ########################
IDs in batch 1: tensor([2942, 2591,  953, 3541, 1436,  113,  890,  426, 2383, 2777, 2776,  779,
        1959, 3961, 1591, 2715])
Epoch: 3872, Training Loss: 0.13, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3873 - Batch 1 ########################
IDs in batch 1: tensor([1673, 2016,  356, 2839, 1745, 2606, 1404, 1786, 2103, 3472, 1651,  538,
        1979,  723,   78, 3782])
Epoch: 3873, Training Loss: 0.06, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3874 - Batch 1 ########################
IDs in batch 1: tensor([3306, 1562, 2892, 3184,  762, 1276,   14,  149, 4189,  945, 1031,  844,
        3194, 3421, 3185, 2553])
Epoch: 3874, Training Loss: 0.06, Validation Loss: 0.86, accuracy = 0.70
######################## Epoch 3875 - Batch 1 ########################
IDs in batch 1: tensor([1198, 4268, 2314,  933, 4154, 2784, 2365, 3469, 2696,  920, 1996, 1356,
        3832, 4223, 3911,  653])
Epoch: 3875, Training Loss: 0.28, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3876 - Batch 1 ########################
IDs in batch 1: tensor([4184, 1649,  718, 2643, 2241, 3779, 4220, 2781, 1017, 3030, 2087,  950,
         993,  839, 2703, 3057])
Epoch: 3876, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3877 - Batch 1 ########################
IDs in batch 1: tensor([3439, 3251, 3994, 3069, 3156, 2752, 3745, 2727, 1818, 3862,  467,  499,
        2783, 2600,   32, 1849])
Epoch: 3877, Training Loss: 0.19, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3878 - Batch 1 ########################
IDs in batch 1: tensor([3627, 4226, 3753, 3311, 1405, 3663,  709,  986, 2488, 2537,  223, 1383,
        3616,    7,  419, 3658])
Epoch: 3878, Training Loss: 0.48, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3879 - Batch 1 ########################
IDs in batch 1: tensor([ 721, 2286, 1956,  530,    5, 3516, 2341, 4184, 3409, 2968, 1489, 1882,
        3432, 2015, 3913, 2177])
Epoch: 3879, Training Loss: 0.29, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3880 - Batch 1 ########################
IDs in batch 1: tensor([2346, 3452, 1313, 1108, 1014,  534,  519,  442, 1037, 3521, 2313, 1921,
         882, 1011, 3101,  870])
Epoch: 3880, Training Loss: 0.12, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3881 - Batch 1 ########################
IDs in batch 1: tensor([1088, 2371, 1657,  832, 3344,  872, 3072, 3083, 3802, 3136, 2482,  975,
        3128,  710, 1388, 1271])
Epoch: 3881, Training Loss: 0.07, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3882 - Batch 1 ########################
IDs in batch 1: tensor([3424, 3506, 3802, 3438, 1975, 2632,  635,  673, 1313, 2176, 2473,  234,
        1841, 2299,  117, 3117])
Epoch: 3882, Training Loss: 0.11, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3883 - Batch 1 ########################
IDs in batch 1: tensor([2724, 3238, 2224, 3039, 1119,  382, 2583, 3939, 1590, 3998, 3700, 3014,
         981, 3852,   70, 3110])
Epoch: 3883, Training Loss: 0.08, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3884 - Batch 1 ########################
IDs in batch 1: tensor([ 718,  120, 4065, 3681, 3537, 3114, 3548, 4199, 3681, 3715, 2558, 4006,
        2953, 2741, 3354, 2836])
Epoch: 3884, Training Loss: 0.26, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3885 - Batch 1 ########################
IDs in batch 1: tensor([3952,  452, 2701, 3751, 1067, 3900, 3790, 1960, 2495, 3866,  148, 2060,
        3593, 2292, 4110, 1636])
Epoch: 3885, Training Loss: 0.13, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3886 - Batch 1 ########################
IDs in batch 1: tensor([2348, 2719, 2452,  848, 2166,  108,  833, 1965, 3589, 1961, 3505, 3015,
        3109,  818, 4230,  120])
Epoch: 3886, Training Loss: 0.05, Validation Loss: 0.85, accuracy = 0.73
######################## Epoch 3887 - Batch 1 ########################
IDs in batch 1: tensor([1328, 2025, 3204, 1960, 3960, 2581,  282,  844, 1260,  878, 3738, 3321,
        2758, 2524,  558, 2116])
Epoch: 3887, Training Loss: 0.31, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3888 - Batch 1 ########################
IDs in batch 1: tensor([1317, 2119,  645, 2691, 1493, 3418, 1250, 1517, 3009, 3255, 2592, 1372,
         418, 4174,  441, 1289])
Epoch: 3888, Training Loss: 0.08, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3889 - Batch 1 ########################
IDs in batch 1: tensor([1225,  944, 2544, 2986,  505,  438, 2028, 3885, 3047, 4228, 2980, 3920,
        3905,  223, 3587, 4101])
Epoch: 3889, Training Loss: 0.21, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3890 - Batch 1 ########################
IDs in batch 1: tensor([2652, 1037, 2265,  701, 2412, 3489, 4170,  755, 3496,  411,  243, 1897,
        1878, 1778, 2353, 2616])
Epoch: 3890, Training Loss: 0.14, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3891 - Batch 1 ########################
IDs in batch 1: tensor([1979, 3886,  646, 1073, 1421, 2851, 2659,  721, 3250, 2224, 3469, 3022,
         181, 1294,  190, 2218])
Epoch: 3891, Training Loss: 0.06, Validation Loss: 0.87, accuracy = 0.71
######################## Epoch 3892 - Batch 1 ########################
IDs in batch 1: tensor([ 262, 1297, 3369, 1481, 2141, 1107,  193, 3251, 3071, 3674, 4097,  623,
         755,  346, 1232, 3900])
Epoch: 3892, Training Loss: 0.11, Validation Loss: 0.88, accuracy = 0.71
######################## Epoch 3893 - Batch 1 ########################
IDs in batch 1: tensor([3721, 3935, 2035, 1360, 3980, 2748, 2619, 3126,  133, 2134, 1012,  194,
         688,  100, 3531,  284])
Epoch: 3893, Training Loss: 0.10, Validation Loss: 0.90, accuracy = 0.71
######################## Epoch 3894 - Batch 1 ########################
IDs in batch 1: tensor([1077, 2144, 2394, 2226, 1017, 2627, 2737, 1364, 3234,  818, 2313, 2522,
          96,  637, 3336, 3961])
Epoch: 3894, Training Loss: 0.05, Validation Loss: 0.89, accuracy = 0.71
######################## Epoch 3895 - Batch 1 ########################
IDs in batch 1: tensor([3920, 2339,  368, 1200, 3521, 3698, 1299, 2235, 1655, 3349,  896, 3697,
        3988, 1440, 2520,  691])
Epoch: 3895, Training Loss: 0.21, Validation Loss: 0.90, accuracy = 0.72
######################## Epoch 3896 - Batch 1 ########################
IDs in batch 1: tensor([ 679, 1272, 1247, 2059, 3354, 2845,  568, 1409,  322, 3188, 1802,  821,
        1569,  350,  709, 4222])
Epoch: 3896, Training Loss: 0.22, Validation Loss: 0.91, accuracy = 0.72
######################## Epoch 3897 - Batch 1 ########################
IDs in batch 1: tensor([3073, 1131, 2680,  346, 3527, 2719, 1478, 2017, 1618, 2701, 1985, 2016,
        2025, 1851, 3544, 3661])
Epoch: 3897, Training Loss: 0.19, Validation Loss: 0.89, accuracy = 0.73
######################## Epoch 3898 - Batch 1 ########################
IDs in batch 1: tensor([2085, 1832, 2536, 3700, 3608, 2791, 3407, 3132, 3336, 2745, 4230, 3933,
        4179, 2982, 2444,  139])
Epoch: 3898, Training Loss: 0.62, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3899 - Batch 1 ########################
IDs in batch 1: tensor([3351, 2420, 2616, 1391,  130,  109, 1199, 2125, 2348, 1716, 1420, 1287,
        4189, 1234,  151,  503])
Epoch: 3899, Training Loss: 0.16, Validation Loss: 0.89, accuracy = 0.73
######################## Epoch 3900 - Batch 1 ########################
IDs in batch 1: tensor([1406, 3933, 1286, 1764, 2459, 1069, 1073,  993, 4116, 3272,  105, 2420,
        2359, 2131,  275, 3743])
Epoch: 3900, Training Loss: 0.15, Validation Loss: 0.90, accuracy = 0.72
######################## Epoch 3901 - Batch 1 ########################
IDs in batch 1: tensor([1767, 1168,  583,  820, 2982, 2355, 2567, 4190,  188, 2328, 4128, 2327,
         946, 3053,  920, 3643])
Epoch: 3901, Training Loss: 0.07, Validation Loss: 0.89, accuracy = 0.72
######################## Epoch 3902 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 1949, 4049, 2306, 3385, 3807, 2126, 1778, 1731,  112, 3802, 1024,
          34,  401, 3328, 4075])
Epoch: 3902, Training Loss: 0.18, Validation Loss: 0.89, accuracy = 0.72
######################## Epoch 3903 - Batch 1 ########################
IDs in batch 1: tensor([ 893, 1226, 1200, 2262, 1990, 1804, 4115, 2410, 3530, 3399, 1143, 3223,
        3472, 1225,  203, 4025])
Epoch: 3903, Training Loss: 0.06, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3904 - Batch 1 ########################
IDs in batch 1: tensor([1143,  337, 1668, 1866,  727,  413, 1356,  535, 1290, 2102, 1421, 2717,
        2959, 2927, 1809,  455])
Epoch: 3904, Training Loss: 0.13, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3905 - Batch 1 ########################
IDs in batch 1: tensor([ 777,  516, 3180, 2518, 1206, 1044, 1235, 2280, 1935, 3118, 3321, 2509,
         588, 3352,   25, 4158])
Epoch: 3905, Training Loss: 0.11, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3906 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 3299, 1988,  854, 3480, 3469,  276,  524,  709, 4099, 4107, 3795,
         844, 1213,  819,  966])
Epoch: 3906, Training Loss: 0.09, Validation Loss: 0.87, accuracy = 0.73
######################## Epoch 3907 - Batch 1 ########################
IDs in batch 1: tensor([1779, 3618, 2925,   49, 2999, 2620, 1131, 3977, 3537, 3618, 3275, 1154,
        1712, 1267, 4165,  134])
Epoch: 3907, Training Loss: 0.08, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3908 - Batch 1 ########################
IDs in batch 1: tensor([1267, 2925, 4065, 1065, 1241,  575, 1761, 2378, 3358,  251,  610, 3973,
         902, 3999, 2629,  964])
Epoch: 3908, Training Loss: 0.22, Validation Loss: 0.89, accuracy = 0.72
######################## Epoch 3909 - Batch 1 ########################
IDs in batch 1: tensor([2137, 2997, 4125, 4018, 3382, 2468, 4077, 1720, 3255, 2519,  869,  656,
        3878, 4251, 2653, 1570])
Epoch: 3909, Training Loss: 0.12, Validation Loss: 0.90, accuracy = 0.72
######################## Epoch 3910 - Batch 1 ########################
IDs in batch 1: tensor([3318, 3177, 1389, 3528, 4235,  588, 3648, 2799,  477, 1123,  904, 4213,
        1439,   82,  171, 2869])
Epoch: 3910, Training Loss: 0.06, Validation Loss: 0.90, accuracy = 0.72
######################## Epoch 3911 - Batch 1 ########################
IDs in batch 1: tensor([3364,  794, 1500, 1087, 1152, 4035, 4046,  388, 1294, 4118, 2841, 1493,
        4075, 2885, 3159, 1861])
Epoch: 3911, Training Loss: 0.08, Validation Loss: 0.89, accuracy = 0.72
######################## Epoch 3912 - Batch 1 ########################
IDs in batch 1: tensor([1647,  171, 3040, 1173, 4016, 2034,  955,  683, 3905, 3029,  730,  415,
         440,  436, 3049,  120])
Epoch: 3912, Training Loss: 0.13, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3913 - Batch 1 ########################
IDs in batch 1: tensor([ 439, 2636, 2617, 1755, 3601, 2901, 3859, 1580, 1324, 1951, 2367, 2809,
        2107, 1108, 3286, 3636])
Epoch: 3913, Training Loss: 0.02, Validation Loss: 0.88, accuracy = 0.72
######################## Epoch 3914 - Batch 1 ########################
IDs in batch 1: tensor([2641, 3498, 1781, 1116, 3121,   73,  172,   25,  767, 3135,  419, 2804,
        3677, 4067, 2950,  320])
Epoch: 3914, Training Loss: 0.10, Validation Loss: 0.87, accuracy = 0.72
######################## Epoch 3915 - Batch 1 ########################
IDs in batch 1: tensor([ 666, 1767,  405, 3357,  886,  332,  747, 1886, 1174,  317,  637, 2334,
         194, 2505,   10, 3495])
Epoch: 3915, Training Loss: 0.27, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3916 - Batch 1 ########################
IDs in batch 1: tensor([3006, 2360, 4010,  781, 1796, 2919, 2366, 4057, 3037,  188, 1225,   60,
        3120, 4258, 3384, 2365])
Epoch: 3916, Training Loss: 0.48, Validation Loss: 0.86, accuracy = 0.72
######################## Epoch 3917 - Batch 1 ########################
IDs in batch 1: tensor([1573,  213, 3384, 4213, 2030, 2157, 2383,   46,  794, 1085,  807, 3506,
        3610, 2219, 2334,  109])
Epoch: 3917, Training Loss: 0.18, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3918 - Batch 1 ########################
IDs in batch 1: tensor([3698, 2764, 4050, 3815, 4103, 2964, 2605, 3179, 3184, 3652, 1418,   41,
         852, 1945, 3087, 3157])
Epoch: 3918, Training Loss: 0.14, Validation Loss: 0.86, accuracy = 0.71
######################## Epoch 3919 - Batch 1 ########################
IDs in batch 1: tensor([1028, 1242, 1675, 3278,  786,  279,   50, 4011,   26, 2886, 2550, 3765,
        1802, 1799,  380,   20])
Epoch: 3919, Training Loss: 0.20, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3920 - Batch 1 ########################
IDs in batch 1: tensor([1325, 2189,  957, 2863, 3940,  320,  896, 3569,  345, 3194, 1638, 3233,
        1671, 3836,  490, 2249])
Epoch: 3920, Training Loss: 0.05, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3921 - Batch 1 ########################
IDs in batch 1: tensor([2052, 2291, 1910, 2754, 2592, 4255, 1567, 3518, 1599, 3582,  950,  165,
          73, 1397, 2473, 1330])
Epoch: 3921, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3922 - Batch 1 ########################
IDs in batch 1: tensor([3220, 1171, 1043, 3882, 3964,  119,   32, 2924, 2193, 1432, 1548, 3706,
         368, 1627, 1602, 1374])
Epoch: 3922, Training Loss: 0.09, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3923 - Batch 1 ########################
IDs in batch 1: tensor([ 593, 3532,  375,  198, 2161,   59, 3947,  937, 3052, 3079, 3947, 3385,
        4018,  943, 3456, 1746])
Epoch: 3923, Training Loss: 0.02, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3924 - Batch 1 ########################
IDs in batch 1: tensor([4050, 3178, 2350, 3534, 2761,  649, 4235, 3638, 3081,  941, 2261,  139,
        2504, 2207, 2590, 3057])
Epoch: 3924, Training Loss: 0.18, Validation Loss: 0.84, accuracy = 0.71
######################## Epoch 3925 - Batch 1 ########################
IDs in batch 1: tensor([4253, 1072,  220, 2237, 2841, 1975, 1624, 2755,  224, 3839, 3478,  684,
        2614, 2419, 3821, 4242])
Epoch: 3925, Training Loss: 0.09, Validation Loss: 0.85, accuracy = 0.71
######################## Epoch 3926 - Batch 1 ########################
IDs in batch 1: tensor([ 639, 1381,   37, 1651, 1042,  211, 3628,  788,  946,  125,  812,   20,
        3558,  602, 2806,   98])
Epoch: 3926, Training Loss: 0.59, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3927 - Batch 1 ########################
IDs in batch 1: tensor([2938, 2120, 2151, 2761,  483, 1041, 1239, 2286, 3648, 1363,  995,  566,
        4149,  967, 2589, 2791])
Epoch: 3927, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3928 - Batch 1 ########################
IDs in batch 1: tensor([2499, 1096, 1007,  184, 1050, 1451, 4257, 3798, 3932, 3530, 1088, 2727,
        1437, 1782, 1406,  394])
Epoch: 3928, Training Loss: 0.21, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3929 - Batch 1 ########################
IDs in batch 1: tensor([2970,  520, 2885, 1699, 3120, 3078, 2064, 1032, 2606, 2624, 2683,  432,
        2627,  384, 2652, 1043])
Epoch: 3929, Training Loss: 0.06, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3930 - Batch 1 ########################
IDs in batch 1: tensor([2740, 3564, 3505,  348, 3022,  341, 1224, 3719, 2715, 1860, 2065, 3474,
        1399, 1284, 1671, 3148])
Epoch: 3930, Training Loss: 0.02, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3931 - Batch 1 ########################
IDs in batch 1: tensor([2990, 2653, 1026, 3463, 2111,  882,  924, 2260, 1344, 3430, 3948, 1677,
        1311, 1472,  442, 1727])
Epoch: 3931, Training Loss: 0.07, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3932 - Batch 1 ########################
IDs in batch 1: tensor([ 445, 3244, 2299, 1844,  537, 1737, 1796, 1469, 2860,  824, 1931, 1588,
        2982, 1835, 2272, 4156])
Epoch: 3932, Training Loss: 0.09, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3933 - Batch 1 ########################
IDs in batch 1: tensor([2815, 1263, 3885, 3663, 2870, 4255, 3960, 2487,   81, 3734, 1955, 2382,
        3990, 1693, 3702, 1296])
Epoch: 3933, Training Loss: 0.81, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3934 - Batch 1 ########################
IDs in batch 1: tensor([2051, 1594,   25, 2899, 1200,   19, 2869, 4146,  741, 2170, 2745, 2244,
         358, 2761, 1196, 3126])
Epoch: 3934, Training Loss: 0.10, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3935 - Batch 1 ########################
IDs in batch 1: tensor([2063, 2832, 4105, 1657, 2519, 2741, 2506,  758,  228, 2177, 1351, 2112,
        1443, 1555, 1974, 3885])
Epoch: 3935, Training Loss: 0.02, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3936 - Batch 1 ########################
IDs in batch 1: tensor([3764, 2822, 3668, 3608, 3859, 2298, 1372, 3793,  400, 3793, 2169, 2708,
        3950, 2856,  950, 3859])
Epoch: 3936, Training Loss: 0.46, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3937 - Batch 1 ########################
IDs in batch 1: tensor([2353, 2099,  316, 3289,   19, 1434, 2567, 1233,  656, 2465, 2565, 1497,
        2969, 2180, 2489,  444])
Epoch: 3937, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3938 - Batch 1 ########################
IDs in batch 1: tensor([3932, 3599, 4073,   49, 3733,  200, 2927, 3581,  121, 3942, 2040, 1413,
        1421,  594, 3786,  497])
Epoch: 3938, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3939 - Batch 1 ########################
IDs in batch 1: tensor([2291,  586, 2245, 2984, 2180, 4245, 1732, 1887, 3330, 2453, 3084,  238,
        1569,  652, 3214, 4267])
Epoch: 3939, Training Loss: 0.16, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 3940 - Batch 1 ########################
IDs in batch 1: tensor([4245, 1247,  434, 3398, 3397, 2917, 2473, 2343,  763, 1900, 3876, 3147,
         305, 3866,   21, 4000])
Epoch: 3940, Training Loss: 0.12, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 3941 - Batch 1 ########################
IDs in batch 1: tensor([2448, 4057, 2435,  330, 4214, 2195, 4172, 3127, 1081,  224, 3004, 2207,
         471, 2966, 2279, 1283])
Epoch: 3941, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.73
######################## Epoch 3942 - Batch 1 ########################
IDs in batch 1: tensor([ 547, 3256, 1720, 1364,  462, 2315, 2052, 1525, 4143,  950,  337,  980,
         284,  389, 1218, 3298])
Epoch: 3942, Training Loss: 0.23, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3943 - Batch 1 ########################
IDs in batch 1: tensor([1496, 4051,  956, 2953, 2798,  279, 2437, 3339,   49, 1154, 1138, 3333,
        2401, 2505, 1289, 2485])
Epoch: 3943, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3944 - Batch 1 ########################
IDs in batch 1: tensor([1767,  218,  789, 1341, 2701, 2564, 3497, 3973,  199, 2758,  200, 2487,
         378, 3318, 3523, 1275])
Epoch: 3944, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3945 - Batch 1 ########################
IDs in batch 1: tensor([ 434, 4215,  993, 2542, 2338, 3248, 3539,   42,  427, 1123, 1070, 3954,
        3460, 3349, 2386,  902])
Epoch: 3945, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3946 - Batch 1 ########################
IDs in batch 1: tensor([3843, 2178,  952, 2621, 1022, 3038, 1083, 1297, 2767, 3257, 3014, 4144,
        1132, 2286, 3188, 1869])
Epoch: 3946, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3947 - Batch 1 ########################
IDs in batch 1: tensor([ 360, 3953, 3832,  430, 1935,  557, 1789, 2403,  351, 1491,  982, 3194,
         397, 3204,  683, 1125])
Epoch: 3947, Training Loss: 0.08, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3948 - Batch 1 ########################
IDs in batch 1: tensor([3795, 2886, 1548, 2018, 2354,   13, 2725, 3392,  658,  950, 1351, 3037,
         558,  534, 1405, 3203])
Epoch: 3948, Training Loss: 0.14, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3949 - Batch 1 ########################
IDs in batch 1: tensor([1067, 2798, 3218,   51, 1061, 1049, 2111, 3952, 4050, 1093,  937, 2943,
        1277,  994,  795, 3803])
Epoch: 3949, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3950 - Batch 1 ########################
IDs in batch 1: tensor([ 440, 4189, 4008, 1493, 3473, 1543, 2290, 2260, 3590, 2802, 3259, 2046,
        3336,   96, 1201, 3635])
Epoch: 3950, Training Loss: 0.19, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3951 - Batch 1 ########################
IDs in batch 1: tensor([2678, 2402, 1824, 3394,  430, 3049, 1632, 3042, 2436, 1934,  376, 2156,
        2254,  996, 3278, 1655])
Epoch: 3951, Training Loss: 0.47, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3952 - Batch 1 ########################
IDs in batch 1: tensor([ 996, 4246, 1396, 3594, 2229,  963, 3083, 3024, 1553, 3879,  482, 1920,
        3065, 1803,  191, 1634])
Epoch: 3952, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.73
######################## Epoch 3953 - Batch 1 ########################
IDs in batch 1: tensor([1255, 1872, 4139, 4103, 1175, 2461, 4222,  356, 1247,  607, 3216, 1439,
        1274,  403, 3647, 2209])
Epoch: 3953, Training Loss: 0.12, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3954 - Batch 1 ########################
IDs in batch 1: tensor([1381,  642, 2764, 3428, 2346, 1181, 3598,  813, 1290, 1802, 1375, 1351,
         265, 3680, 2022, 1063])
Epoch: 3954, Training Loss: 0.07, Validation Loss: 0.85, accuracy = 0.72
######################## Epoch 3955 - Batch 1 ########################
IDs in batch 1: tensor([3540, 2133, 3005, 4127,  956, 3812, 1775, 3990, 3668, 1216, 3275, 4185,
        1841,  995, 4017, 2848])
Epoch: 3955, Training Loss: 0.33, Validation Loss: 0.84, accuracy = 0.73
######################## Epoch 3956 - Batch 1 ########################
IDs in batch 1: tensor([3148, 2822, 3518,  552, 1994, 3789,  508, 2789, 4267, 1077, 3250, 3317,
        3148,  963,  832,  371])
Epoch: 3956, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3957 - Batch 1 ########################
IDs in batch 1: tensor([ 944, 1383, 1313, 3882, 2882, 3091, 3328, 3371, 3648,  138,  553, 3636,
        2063,  463,  740, 1260])
Epoch: 3957, Training Loss: 0.04, Validation Loss: 0.83, accuracy = 0.73
######################## Epoch 3958 - Batch 1 ########################
IDs in batch 1: tensor([1656, 1136,  314,  615, 3356, 1927, 3141,  569, 2039, 3267, 1271, 3334,
        2966,  653, 2225, 3321])
Epoch: 3958, Training Loss: 0.07, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3959 - Batch 1 ########################
IDs in batch 1: tensor([ 491, 1480, 2228,   21, 1147, 1325, 3203, 2840, 3928, 2415,  451, 1649,
        2725,  218, 3856, 2693])
Epoch: 3959, Training Loss: 0.03, Validation Loss: 0.84, accuracy = 0.72
######################## Epoch 3960 - Batch 1 ########################
IDs in batch 1: tensor([2070,  941, 1967, 1391, 2582, 3105, 3036, 3780, 2494,  236, 1251, 3251,
        2537, 2088,  756, 1566])
Epoch: 3960, Training Loss: 0.16, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3961 - Batch 1 ########################
IDs in batch 1: tensor([ 243, 1292, 3397,  555, 3401, 3421, 3466, 1956,  632,  547, 2278, 2435,
        3789, 1493, 2423, 1077])
Epoch: 3961, Training Loss: 0.10, Validation Loss: 0.83, accuracy = 0.71
######################## Epoch 3962 - Batch 1 ########################
IDs in batch 1: tensor([ 539, 4232, 1168, 2754,  332, 2091, 2253, 2008,  854, 2341, 3368, 3952,
        2452, 3243,  277, 1580])
Epoch: 3962, Training Loss: 0.04, Validation Loss: 0.82, accuracy = 0.72
######################## Epoch 3963 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 4146, 3204,   63, 4157, 1935, 1306, 4223, 3732, 2500, 1951,   78,
         340, 1236, 3876, 1179])
Epoch: 3963, Training Loss: 0.27, Validation Loss: 0.83, accuracy = 0.72
######################## Epoch 3964 - Batch 1 ########################
IDs in batch 1: tensor([3698,  785, 2836, 3534, 3250, 3723, 4134,  992, 1732,  886, 2789, 2248,
        3156,  180, 2193, 2798])
Epoch: 3964, Training Loss: 0.05, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3965 - Batch 1 ########################
IDs in batch 1: tensor([3934, 3121, 3000, 1902, 3283,   41, 1295, 4058, 3717, 3192, 3660, 2959,
        1760, 4131,  276, 2137])
Epoch: 3965, Training Loss: 0.28, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3966 - Batch 1 ########################
IDs in batch 1: tensor([ 535, 2253,  603, 3049, 3951, 3806, 3933, 3993, 2431, 1137,  259, 3079,
        2379,  445,  983,  518])
Epoch: 3966, Training Loss: 0.30, Validation Loss: 0.81, accuracy = 0.72
######################## Epoch 3967 - Batch 1 ########################
IDs in batch 1: tensor([2902, 2605, 3339, 4214, 1005, 3261, 2974, 2794, 1834, 1511, 1545, 2597,
        2356, 2113, 2831,  344])
Epoch: 3967, Training Loss: 0.36, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3968 - Batch 1 ########################