######################## Epoch 0 - Batch 1 ########################
IDs in batch 1: tensor([3573,  756, 2887,  718,   25, 3035, 2824,  873, 2721, 3650, 2223, 3127,
        2185, 1521, 1676, 2370])
Epoch: 0, Training Loss: 0.74, Validation Loss: 0.71, accuracy = 0.43
######################## Epoch 1 - Batch 1 ########################
IDs in batch 1: tensor([2890, 3414, 3368, 2059, 4203, 3492,  596, 3257, 1010,  824,  701, 1143,
        2915, 3330,  926, 1310])
Epoch: 1, Training Loss: 0.74, Validation Loss: 0.70, accuracy = 0.43
######################## Epoch 2 - Batch 1 ########################
IDs in batch 1: tensor([2383, 1834, 2629, 2767, 2619, 3689, 3395, 3239, 3588, 1015,  228, 3390,
        2410, 2970,  949, 2734])
Epoch: 2, Training Loss: 0.76, Validation Loss: 0.70, accuracy = 0.44
######################## Epoch 3 - Batch 1 ########################
IDs in batch 1: tensor([1277, 2462, 2110,  537,  724, 3696, 2206, 3496, 1628, 3568,  682, 2108,
        1571, 3992,  679, 2463])
Epoch: 3, Training Loss: 0.71, Validation Loss: 0.70, accuracy = 0.45
######################## Epoch 4 - Batch 1 ########################
IDs in batch 1: tensor([1308,  873, 2901, 4070, 1223, 2442, 1285, 2323,  738, 2229, 2234, 1708,
        1469, 3644, 1723, 3308])
Epoch: 4, Training Loss: 0.71, Validation Loss: 0.70, accuracy = 0.46
######################## Epoch 5 - Batch 1 ########################
IDs in batch 1: tensor([3371, 1410, 2775,  136,  685, 3663,  776, 1895, 3570, 2241,  590, 3496,
        1024, 1287, 4115,  247])
Epoch: 5, Training Loss: 0.70, Validation Loss: 0.70, accuracy = 0.47
######################## Epoch 6 - Batch 1 ########################
IDs in batch 1: tensor([3822, 3932, 3534,  202,  456,  485, 1128, 3485, 3808, 2767, 1250, 1934,
        3272, 1423, 1921, 1047])
Epoch: 6, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.47
######################## Epoch 7 - Batch 1 ########################
IDs in batch 1: tensor([2806, 3615, 1267,  895, 2385, 2035, 4135, 2919,  665, 1426, 3960,   71,
        2529,  769, 2999, 2717])
Epoch: 7, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.50
######################## Epoch 8 - Batch 1 ########################
IDs in batch 1: tensor([2052, 3785, 1133, 2697, 3798, 3009, 2835, 1421,  732, 2189, 2661, 4268,
        1228, 2775, 3781, 3207])
Epoch: 8, Training Loss: 0.74, Validation Loss: 0.69, accuracy = 0.51
######################## Epoch 9 - Batch 1 ########################
IDs in batch 1: tensor([2721, 2272, 3344, 3995,  547, 3114, 2137, 1490,  943, 3299, 1668, 2080,
        3181, 3300,  195, 2018])
Epoch: 9, Training Loss: 0.76, Validation Loss: 0.69, accuracy = 0.54
######################## Epoch 10 - Batch 1 ########################
IDs in batch 1: tensor([3310,  894,  471, 3354, 3344, 2035, 3192, 1968,  747,   38, 1374, 3406,
         550,  982, 3111, 2590])
Epoch: 10, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.56
######################## Epoch 11 - Batch 1 ########################
IDs in batch 1: tensor([ 218,   71, 4180,  622,  657, 1716,   30,  305, 2018, 3326,  135,  609,
         880, 4061, 1381,  691])
Epoch: 11, Training Loss: 0.65, Validation Loss: 0.69, accuracy = 0.56
######################## Epoch 12 - Batch 1 ########################
IDs in batch 1: tensor([2045, 1858, 3674, 1052, 3514, 1050, 3635,   98,  601,  717, 3755, 1437,
        2473, 2577, 1328, 4118])
Epoch: 12, Training Loss: 0.71, Validation Loss: 0.69, accuracy = 0.56
######################## Epoch 13 - Batch 1 ########################
IDs in batch 1: tensor([2035, 1252, 2081, 2009, 3648, 3238, 2170, 2326, 1186,  612, 3876,  155,
        3860, 2998, 4012,  884])
Epoch: 13, Training Loss: 0.75, Validation Loss: 0.69, accuracy = 0.56
######################## Epoch 14 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 3673, 3511, 2063, 2648,   99, 3287,  993, 1731, 2274, 1214, 3597,
         508, 3409, 2516,  733])
Epoch: 14, Training Loss: 0.73, Validation Loss: 0.69, accuracy = 0.56
######################## Epoch 15 - Batch 1 ########################
IDs in batch 1: tensor([2690, 1756, 3772, 4118,  333, 3812, 2667, 3530, 2553, 3950,  777, 1498,
        3949, 2674,   49, 1866])
Epoch: 15, Training Loss: 0.74, Validation Loss: 0.69, accuracy = 0.57
######################## Epoch 16 - Batch 1 ########################
IDs in batch 1: tensor([1472, 2644,  290,  351,  188,  134,  952, 3995, 1602, 4204, 2649, 2264,
        1281, 1519, 3781, 1556])
Epoch: 16, Training Loss: 0.64, Validation Loss: 0.69, accuracy = 0.58
######################## Epoch 17 - Batch 1 ########################
IDs in batch 1: tensor([2671, 2483, 2367, 2072, 3406, 1952, 3860,  186, 2970, 3778, 2315, 4089,
        1526, 1927, 2978, 2406])
Epoch: 17, Training Loss: 0.72, Validation Loss: 0.69, accuracy = 0.59
######################## Epoch 18 - Batch 1 ########################
IDs in batch 1: tensor([3399,  412, 3112,  327, 2851, 3624, 2548, 1660, 2369, 3567, 1493, 3993,
        3500, 3344, 1320,  681])
Epoch: 18, Training Loss: 0.74, Validation Loss: 0.68, accuracy = 0.59
######################## Epoch 19 - Batch 1 ########################
IDs in batch 1: tensor([3718, 4118, 3815, 2927, 1511, 2135, 4121, 2475, 3710, 1904,  594, 3384,
         727, 1958, 3984, 3719])
Epoch: 19, Training Loss: 0.73, Validation Loss: 0.68, accuracy = 0.61
######################## Epoch 20 - Batch 1 ########################
IDs in batch 1: tensor([3765,  907,  591, 1574, 1469, 1707, 1017, 3541, 3190,  344, 3553,  390,
        1650,   72, 3582, 2350])
Epoch: 20, Training Loss: 0.73, Validation Loss: 0.68, accuracy = 0.61
######################## Epoch 21 - Batch 1 ########################
IDs in batch 1: tensor([3624, 3132, 3834,  485, 1984, 2605, 4093, 3557, 3271, 3798, 1204,  295,
        1518, 2977, 2192, 2504])
Epoch: 21, Training Loss: 0.69, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 22 - Batch 1 ########################
IDs in batch 1: tensor([2388, 2309, 3150,  855, 2708,  492, 2696, 4199, 2742, 3397, 3075, 4046,
        4049,  743, 3882, 1665])
Epoch: 22, Training Loss: 0.72, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 23 - Batch 1 ########################
IDs in batch 1: tensor([1016, 2680, 3843, 3241, 3139,   62, 4093, 1580,  741, 3222, 2291, 2775,
          78, 2921, 2060, 1957])
Epoch: 23, Training Loss: 0.70, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 24 - Batch 1 ########################
IDs in batch 1: tensor([2328, 2500, 3719, 1878,  344, 3582, 3156,  682, 4067, 2016,  815, 2410,
         365, 1961, 3421, 1834])
Epoch: 24, Training Loss: 0.72, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 25 - Batch 1 ########################
IDs in batch 1: tensor([1122, 2653, 2193, 2052,  442, 3590,  490, 2479, 2575,  282,  245, 2603,
        2619, 4078,  448,  133])
Epoch: 25, Training Loss: 0.67, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 26 - Batch 1 ########################
IDs in batch 1: tensor([2960, 2159, 1220,  687, 3492,  438, 2324, 2586, 1670, 2192, 2733, 2938,
        1957, 3545,  427, 1374])
Epoch: 26, Training Loss: 0.71, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 27 - Batch 1 ########################
IDs in batch 1: tensor([  98, 1309,  574, 1252, 4017,  583,  159, 3600, 2473,  324,  888, 3504,
        1125, 2537,   49,  332])
Epoch: 27, Training Loss: 0.70, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 28 - Batch 1 ########################
IDs in batch 1: tensor([2253,  887,  145, 3047, 3410, 3792, 3254, 1237, 1088, 2453, 2605, 3142,
         688,  324,  245,  959])
Epoch: 28, Training Loss: 0.65, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 29 - Batch 1 ########################
IDs in batch 1: tensor([1736, 2446, 1157, 1213, 1640, 2868, 1710, 3077, 1365, 1282, 3286,  874,
        3661, 1069,  324, 3176])
Epoch: 29, Training Loss: 0.73, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 30 - Batch 1 ########################
IDs in batch 1: tensor([3634,  820, 1868,  915, 3632, 2253, 2476,  214, 3713, 4157, 3146,  763,
        3590, 2332, 2866,  185])
Epoch: 30, Training Loss: 0.66, Validation Loss: 0.68, accuracy = 0.60
######################## Epoch 31 - Batch 1 ########################
IDs in batch 1: tensor([4232,  378, 2469, 2568,  252,  378, 3991, 1456, 1892, 3842, 3015, 1811,
        2872, 1306, 1161, 2391])
Epoch: 31, Training Loss: 0.66, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 32 - Batch 1 ########################
IDs in batch 1: tensor([3970, 2670, 3896,  921, 2863, 2363, 1136,  709, 3514, 3060, 1216, 2354,
         545, 1892, 2951, 1384])
Epoch: 32, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 33 - Batch 1 ########################
IDs in batch 1: tensor([3188,  727, 1166, 2725, 3896, 1617, 1971, 1156,  165,  943, 1927, 2420,
        3836, 2883, 2016, 2826])
Epoch: 33, Training Loss: 0.75, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 34 - Batch 1 ########################
IDs in batch 1: tensor([2357, 1767, 2244,  947, 4256, 4187,  726, 2418, 1080, 1347,  269, 2932,
        3144, 4017,  491, 2123])
Epoch: 34, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 35 - Batch 1 ########################
IDs in batch 1: tensor([2063, 1326, 1363, 2405, 2854, 2754, 3051, 4018,  947, 1639, 2516, 4187,
          43, 1676, 3003, 2693])
Epoch: 35, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 36 - Batch 1 ########################
IDs in batch 1: tensor([3196,   21, 3956, 3888,  550, 3243,  474, 1279, 1026, 3908,  499,  358,
         148, 1389, 2925,  469])
Epoch: 36, Training Loss: 0.69, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 37 - Batch 1 ########################
IDs in batch 1: tensor([3785,  538, 4061, 2144, 1170,  236,   62,   50, 1980,   27,  725, 2350,
        4263, 2597, 2448, 3779])
Epoch: 37, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 38 - Batch 1 ########################
IDs in batch 1: tensor([ 652, 2365, 3548,  689, 2287, 3135, 2681, 2627, 2693, 2085,  228, 1553,
        2724, 2696,  833, 1180])
Epoch: 38, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 39 - Batch 1 ########################
IDs in batch 1: tensor([ 498, 3418, 3410, 1354, 2638, 1552, 3254, 1855, 4229, 3159, 2271, 1212,
         391,  890, 2296, 1285])
Epoch: 39, Training Loss: 0.64, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 40 - Batch 1 ########################
IDs in batch 1: tensor([2477,  326,  778, 1682, 2719, 2419,  459, 1084, 3731, 1823, 4166, 1255,
        2519, 2742, 3984, 1804])
Epoch: 40, Training Loss: 0.70, Validation Loss: 0.67, accuracy = 0.59
######################## Epoch 41 - Batch 1 ########################
IDs in batch 1: tensor([3362, 4115, 4014,  488, 1255, 2496, 2915,  325, 1231, 2870, 3051, 3832,
        2583, 3150, 2791, 2510])
Epoch: 41, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 42 - Batch 1 ########################
IDs in batch 1: tensor([2367,  789, 1950,  137, 2217, 3395, 3139, 3488, 2299, 2171,  507, 1256,
        1147, 3444, 3897,  933])
Epoch: 42, Training Loss: 0.65, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 43 - Batch 1 ########################
IDs in batch 1: tensor([  56,  105, 3719,  688, 2081,  462, 2519,  481, 2741, 4124, 1176, 3947,
        1583, 1146, 2652, 3407])
Epoch: 43, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 44 - Batch 1 ########################
IDs in batch 1: tensor([ 100,  828,  120, 3394, 1025, 1685, 3133, 1684, 3587, 2387, 1612,  143,
        2620, 3660, 1252, 2169])
Epoch: 44, Training Loss: 0.64, Validation Loss: 0.67, accuracy = 0.59
######################## Epoch 45 - Batch 1 ########################
IDs in batch 1: tensor([ 957, 3745, 3652, 1574,  957, 3216, 1870, 4122, 1656, 3671,  795, 3514,
        1396,  439, 1082, 3942])
Epoch: 45, Training Loss: 0.67, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 46 - Batch 1 ########################
IDs in batch 1: tensor([3907, 3603,  101, 3542, 2341, 2045, 3368, 3479, 1708,  899, 1321, 2495,
        1330, 2154,  536,  895])
Epoch: 46, Training Loss: 0.66, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 47 - Batch 1 ########################
IDs in batch 1: tensor([4073, 3669, 3815,   20, 3985, 1094, 3872, 4060, 3327, 1054, 3583, 3415,
        2359, 3859, 1248,   47])
Epoch: 47, Training Loss: 0.63, Validation Loss: 0.67, accuracy = 0.60
######################## Epoch 48 - Batch 1 ########################
IDs in batch 1: tensor([1623, 4073, 2927, 3264, 1911,  957, 2727,  721, 2708, 1371, 2951, 2562,
        1454, 3663, 3926, 3886])
Epoch: 48, Training Loss: 0.63, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 49 - Batch 1 ########################
IDs in batch 1: tensor([ 893, 3610, 3934, 3891, 3354, 3993, 3974, 3121,  276,  238, 2015, 3704,
        2618,  967, 3194, 2251])
Epoch: 49, Training Loss: 0.67, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 50 - Batch 1 ########################
IDs in batch 1: tensor([2797, 1224, 3123, 4213, 3000,  104, 3031, 1026,  167, 2782,  642, 2113,
        3971, 3744, 2247, 3303])
Epoch: 50, Training Loss: 0.61, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 51 - Batch 1 ########################
IDs in batch 1: tensor([1024, 2297,  790, 1870, 3577, 1647, 1859,  688, 1670, 1925, 3885,  382,
         102, 1891,  335,  320])
Epoch: 51, Training Loss: 0.69, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 52 - Batch 1 ########################
IDs in batch 1: tensor([1650,  994, 1147, 2353, 1855, 2171, 1445, 3585, 1070, 2947,  904, 1680,
        2225, 2437, 1504, 2116])
Epoch: 52, Training Loss: 0.67, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 53 - Batch 1 ########################
IDs in batch 1: tensor([2810,  767, 2044, 1167, 2453,  766, 1144, 1884, 3732, 3793, 2402,  827,
        2553, 2448, 1712,  360])
Epoch: 53, Training Loss: 0.65, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 54 - Batch 1 ########################
IDs in batch 1: tensor([ 919, 2104, 1545,    4, 2620,  949, 2343, 3710, 3441,  750, 3839,  713,
        2741, 2732, 1474, 1062])
Epoch: 54, Training Loss: 0.70, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 55 - Batch 1 ########################
IDs in batch 1: tensor([3143, 2989, 1385,  367, 1747, 3739, 3822, 1558,  177,  199,   61, 1610,
        2726, 2907, 4136, 1519])
Epoch: 55, Training Loss: 0.66, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 56 - Batch 1 ########################
IDs in batch 1: tensor([3398,  693, 3922, 2207, 1588, 3151, 2394, 2551, 3803, 2902, 2656, 2017,
        2606, 2347, 2134, 1467])
Epoch: 56, Training Loss: 0.61, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 57 - Batch 1 ########################
IDs in batch 1: tensor([1604,  361,  663, 2650, 1083, 2845, 2838, 4069,  513, 2853, 2780, 4032,
        1121, 3268,  909, 3743])
Epoch: 57, Training Loss: 0.68, Validation Loss: 0.66, accuracy = 0.59
######################## Epoch 58 - Batch 1 ########################
IDs in batch 1: tensor([3577, 1573, 1060, 2312, 3533,  670,  472, 2199,  388, 3567, 1676, 2435,
        3970,  848,  322, 4046])
Epoch: 58, Training Loss: 0.69, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 59 - Batch 1 ########################
IDs in batch 1: tensor([2912,  646, 3426, 2652, 3755,  359,  851, 2890,  637, 3073, 1452, 2691,
        1009, 2440, 3157,   19])
Epoch: 59, Training Loss: 0.66, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 60 - Batch 1 ########################
IDs in batch 1: tensor([3728, 2815, 2615,  489, 2195,  959, 1016, 1195, 3852,  282,  769, 1770,
         356,  794, 3583, 3531])
Epoch: 60, Training Loss: 0.67, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 61 - Batch 1 ########################
IDs in batch 1: tensor([1610, 2285, 3745, 4010, 2822, 3340,  834,  496, 3842, 1216,  533, 2544,
        3342,  382, 2097,  790])
Epoch: 61, Training Loss: 0.59, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 62 - Batch 1 ########################
IDs in batch 1: tensor([ 323,  338, 3256, 1173, 2974, 1918, 1092, 4149, 3410, 2579,  229, 3370,
        3904,  122, 2316, 2672])
Epoch: 62, Training Loss: 0.68, Validation Loss: 0.66, accuracy = 0.60
######################## Epoch 63 - Batch 1 ########################
IDs in batch 1: tensor([2696, 4157,  225, 1473,  361, 2825, 2866, 2993, 2246, 2086, 3373, 2687,
        2995,  290, 1927, 1343])
Epoch: 63, Training Loss: 0.61, Validation Loss: 0.65, accuracy = 0.60
######################## Epoch 64 - Batch 1 ########################
IDs in batch 1: tensor([3475, 2103, 3838,  792, 1763, 3764, 3569, 1685,  148, 1566, 3154, 3309,
        1559, 2860, 3094, 2113])
Epoch: 64, Training Loss: 0.59, Validation Loss: 0.65, accuracy = 0.60
######################## Epoch 65 - Batch 1 ########################
IDs in batch 1: tensor([2241, 1679, 2286, 4050,  874, 2763, 3333, 1647, 2028, 1247, 2230, 3470,
        2013, 3187, 2412, 2375])
Epoch: 65, Training Loss: 0.59, Validation Loss: 0.65, accuracy = 0.61
######################## Epoch 66 - Batch 1 ########################
IDs in batch 1: tensor([3072,  673, 3518, 1772, 4103, 3127, 2671, 1859, 1130,   30, 1126,  826,
         992, 3451, 1711,  983])
Epoch: 66, Training Loss: 0.70, Validation Loss: 0.65, accuracy = 0.61
######################## Epoch 67 - Batch 1 ########################
IDs in batch 1: tensor([ 594, 3802, 1222, 2499, 1478, 1562,  234,  150,  631, 3572,  499,  261,
        3659, 4120, 1272, 1410])
Epoch: 67, Training Loss: 0.68, Validation Loss: 0.65, accuracy = 0.60
######################## Epoch 68 - Batch 1 ########################
IDs in batch 1: tensor([4044,  900, 1556,  261, 2669, 2917,  883,   82, 3414,  849, 2727, 2666,
        1034, 3255, 1027, 3287])
Epoch: 68, Training Loss: 0.64, Validation Loss: 0.65, accuracy = 0.61
######################## Epoch 69 - Batch 1 ########################
IDs in batch 1: tensor([3535, 2046, 2691, 3551,  881, 3337, 2120, 2013,  340, 4268, 4024,  388,
         320, 1600, 2449,  262])
Epoch: 69, Training Loss: 0.61, Validation Loss: 0.65, accuracy = 0.62
######################## Epoch 70 - Batch 1 ########################
IDs in batch 1: tensor([3504, 1836,  883, 1364, 4138, 1332, 1146, 2332, 2287, 1878, 3473, 2070,
        2666, 1933, 1681, 4040])
Epoch: 70, Training Loss: 0.60, Validation Loss: 0.65, accuracy = 0.62
######################## Epoch 71 - Batch 1 ########################
IDs in batch 1: tensor([4058,  896, 2237, 1812, 2520,  262, 1623,  418, 2879, 2899, 1507, 2248,
        3963,  105, 2161,  512])
Epoch: 71, Training Loss: 0.66, Validation Loss: 0.65, accuracy = 0.62
######################## Epoch 72 - Batch 1 ########################
IDs in batch 1: tensor([3943,  302, 2189, 3744, 2126, 2276, 2606, 1075, 3327, 1389,  138, 3101,
         418, 1173, 2204, 2572])
Epoch: 72, Training Loss: 0.59, Validation Loss: 0.65, accuracy = 0.62
######################## Epoch 73 - Batch 1 ########################
IDs in batch 1: tensor([3971, 3681, 1351,  503, 3338, 1543, 1869, 1826, 3987, 2620, 3456,  344,
        4015, 1686, 1761, 2178])
Epoch: 73, Training Loss: 0.59, Validation Loss: 0.65, accuracy = 0.62
######################## Epoch 74 - Batch 1 ########################
IDs in batch 1: tensor([2990,  887, 2373, 4039, 1493, 1552,   62,  266, 1754, 3886, 1981,  605,
         284, 1103, 4264, 3526])
Epoch: 74, Training Loss: 0.66, Validation Loss: 0.64, accuracy = 0.63
######################## Epoch 75 - Batch 1 ########################
IDs in batch 1: tensor([3667, 4117,  566, 2668, 3903, 4050, 3363, 3850,  923, 2870, 2568, 2927,
        1388, 1485,  387,  425])
Epoch: 75, Training Loss: 0.60, Validation Loss: 0.64, accuracy = 0.63
######################## Epoch 76 - Batch 1 ########################
IDs in batch 1: tensor([1315, 1720, 2024, 4189,  584,  934, 3053, 4085, 1482, 1708, 3453, 3248,
        3933, 2492,   30, 1601])
Epoch: 76, Training Loss: 0.65, Validation Loss: 0.64, accuracy = 0.64
######################## Epoch 77 - Batch 1 ########################
IDs in batch 1: tensor([1640, 4218,  463, 2780,  923, 3551, 1649, 3841, 1916, 2220, 2244, 2417,
        3988, 3060, 3733, 2452])
Epoch: 77, Training Loss: 0.61, Validation Loss: 0.64, accuracy = 0.64
######################## Epoch 78 - Batch 1 ########################
IDs in batch 1: tensor([1444,  812,   49, 2092, 1343, 1041, 2980, 1354, 2369, 2689, 1421,  362,
        3113, 1834, 1789,  937])
Epoch: 78, Training Loss: 0.70, Validation Loss: 0.64, accuracy = 0.64
######################## Epoch 79 - Batch 1 ########################
IDs in batch 1: tensor([  28, 2912, 3105, 2356, 4067, 1045, 1947, 3279, 1099, 1252, 2797, 3329,
        2209, 1011, 4051, 3930])
Epoch: 79, Training Loss: 0.55, Validation Loss: 0.64, accuracy = 0.64
######################## Epoch 80 - Batch 1 ########################
IDs in batch 1: tensor([1740,  103, 2776, 3148, 3473, 1977, 3434, 3240, 4238, 3472, 1511, 4096,
         658,  740, 1005,  330])
Epoch: 80, Training Loss: 0.70, Validation Loss: 0.64, accuracy = 0.64
######################## Epoch 81 - Batch 1 ########################
IDs in batch 1: tensor([3592,  513,  795, 1125, 1518, 3284, 1443, 1397, 2433, 1672,  552, 1770,
         883, 3705,  832, 2148])
Epoch: 81, Training Loss: 0.66, Validation Loss: 0.64, accuracy = 0.65
Save best Model_1 @ epoch 81 acc: 0.6506447831184057
Email sent!
######################## Epoch 82 - Batch 1 ########################
IDs in batch 1: tensor([1035, 3381, 2511, 2600, 1124, 3570, 1904, 3136, 2420, 2095, 1385, 1097,
        3218, 2209, 2002, 2137])
Epoch: 82, Training Loss: 0.63, Validation Loss: 0.63, accuracy = 0.67
Save best Model_1 @ epoch 82 acc: 0.6658851113716295
Email sent!
######################## Epoch 83 - Batch 1 ########################
IDs in batch 1: tensor([2106,  119, 4113, 2600,  995, 3926, 1639, 1452, 3839, 3376,  736, 1170,
         503, 2019, 1195, 3719])
Epoch: 83, Training Loss: 0.66, Validation Loss: 0.63, accuracy = 0.66
######################## Epoch 84 - Batch 1 ########################
IDs in batch 1: tensor([ 730, 3642, 1467, 1850, 2331,  870, 2839, 1754, 4069, 3077, 2827, 1116,
        2354, 2487, 1802,  418])
Epoch: 84, Training Loss: 0.65, Validation Loss: 0.63, accuracy = 0.67
Save best Model_1 @ epoch 84 acc: 0.6670574443141852
Email sent!
######################## Epoch 85 - Batch 1 ########################
IDs in batch 1: tensor([  82, 2485, 2458, 1471, 2749,  921, 1450, 2763, 2660, 2963, 2244,  220,
        1493, 3345,  710, 2752])
Epoch: 85, Training Loss: 0.66, Validation Loss: 0.63, accuracy = 0.67
Save best Model_1 @ epoch 85 acc: 0.671746776084408
Email sent!
######################## Epoch 86 - Batch 1 ########################
IDs in batch 1: tensor([2144, 2022, 4235, 4084,  826, 2960, 3115, 1553,  964, 1707, 2373,  422,
        1336, 2717, 2620, 1213])
Epoch: 86, Training Loss: 0.61, Validation Loss: 0.63, accuracy = 0.68
Save best Model_1 @ epoch 86 acc: 0.675263774912075
Email sent!
######################## Epoch 87 - Batch 1 ########################
IDs in batch 1: tensor([1996, 2003, 3327, 2356, 3037, 2495, 2642, 4068, 2309,  871, 1297,  418,
         259, 3467, 3964,  841])
Epoch: 87, Training Loss: 0.68, Validation Loss: 0.63, accuracy = 0.68
Save best Model_1 @ epoch 87 acc: 0.6764361078546307
Email sent!
######################## Epoch 88 - Batch 1 ########################
IDs in batch 1: tensor([2484, 1635,  357,  530, 4084,  269,  148, 2689, 3321, 3526, 1671, 3160,
        1296, 1883, 3985, 3162])
Epoch: 88, Training Loss: 0.56, Validation Loss: 0.63, accuracy = 0.67
######################## Epoch 89 - Batch 1 ########################
IDs in batch 1: tensor([4163, 2609, 1540, 2034, 3397, 3407, 3042,  907, 3642, 1925,  188, 3833,
        2898, 3570, 2145, 3763])
Epoch: 89, Training Loss: 0.62, Validation Loss: 0.63, accuracy = 0.67
######################## Epoch 90 - Batch 1 ########################
IDs in batch 1: tensor([ 752, 3498, 2116, 1657, 2405, 1925,  194,  135, 3023, 3637, 3486, 4013,
         529, 4223, 1080, 3483])
Epoch: 90, Training Loss: 0.67, Validation Loss: 0.63, accuracy = 0.67
######################## Epoch 91 - Batch 1 ########################
IDs in batch 1: tensor([ 281, 2431, 1574,  787, 2359, 1911, 3733, 3356,  750,  751, 2913, 1284,
        1481, 3919, 1181, 1937])
Epoch: 91, Training Loss: 0.65, Validation Loss: 0.62, accuracy = 0.67
######################## Epoch 92 - Batch 1 ########################
IDs in batch 1: tensor([ 450, 3408, 4179, 4127, 4101,  133, 3783, 1611, 2895, 3214, 1681, 4033,
        3713, 3535, 2697, 2087])
Epoch: 92, Training Loss: 0.57, Validation Loss: 0.62, accuracy = 0.68
Save best Model_1 @ epoch 92 acc: 0.6776084407971864
Email sent!
######################## Epoch 93 - Batch 1 ########################
IDs in batch 1: tensor([3547, 1290,  545, 3705,  769, 1222, 1247, 2156, 1035,  771, 2799, 3277,
        2386, 2577, 1646, 3693])
Epoch: 93, Training Loss: 0.62, Validation Loss: 0.62, accuracy = 0.67
######################## Epoch 94 - Batch 1 ########################
IDs in batch 1: tensor([2356, 1162, 2465, 3553, 4186, 2346, 3655, 4212,  891, 4168, 3291, 3870,
        1611,  874,  120, 3286])
Epoch: 94, Training Loss: 0.58, Validation Loss: 0.62, accuracy = 0.68
Save best Model_1 @ epoch 94 acc: 0.6799531066822978
Email sent!
######################## Epoch 95 - Batch 1 ########################
IDs in batch 1: tensor([ 946, 2328, 3166, 3132, 2406, 2871, 1488, 3804, 3898,  620, 1574,  917,
        2456, 1212,  448, 1942])
Epoch: 95, Training Loss: 0.68, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 96 - Batch 1 ########################
IDs in batch 1: tensor([2414, 2489, 2074, 1650,  569, 3970, 3039, 1131, 3616, 1976, 2500, 2866,
        1390, 3921, 1137, 1381])
Epoch: 96, Training Loss: 0.61, Validation Loss: 0.62, accuracy = 0.69
Save best Model_1 @ epoch 96 acc: 0.6893317702227433
Email sent!
######################## Epoch 97 - Batch 1 ########################
IDs in batch 1: tensor([ 432, 2051, 1432, 1214, 1001, 2999,  657, 3826,  937, 4126, 3245, 2154,
         183, 2465,  795, 4044])
Epoch: 97, Training Loss: 0.57, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 98 - Batch 1 ########################
IDs in batch 1: tensor([2251,  777, 1668, 1852, 3027, 1434,  941, 3542, 2591, 2014, 1326, 3472,
        2416, 2034, 4056,  278])
Epoch: 98, Training Loss: 0.71, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 99 - Batch 1 ########################
IDs in batch 1: tensor([3353, 2621, 2926, 1324, 1189,  155,  727, 2741, 2373,  642,  804, 1375,
        2468, 2106, 2131, 1073])
Epoch: 99, Training Loss: 0.59, Validation Loss: 0.62, accuracy = 0.69
######################## Epoch 100 - Batch 1 ########################
IDs in batch 1: tensor([ 975, 2457, 4197, 1881, 3731, 1556, 2040, 1200, 1812, 4263, 2402, 3851,
        1397, 4222, 4187, 2241])
Epoch: 100, Training Loss: 0.56, Validation Loss: 0.62, accuracy = 0.69
######################## Epoch 101 - Batch 1 ########################
IDs in batch 1: tensor([1567, 2038, 3376, 2415, 1189, 2905, 1766, 1313,  554, 1733,  217, 2931,
        1647, 3087, 3894, 4255])
Epoch: 101, Training Loss: 0.61, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 102 - Batch 1 ########################
IDs in batch 1: tensor([ 445, 1434,  187,  870, 3549, 3009, 3962, 2736, 2110, 2217, 2857, 4186,
        4245, 1509, 1524,  657])
Epoch: 102, Training Loss: 0.65, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 103 - Batch 1 ########################
IDs in batch 1: tensor([1640, 2804,  674,  450,  834, 1509, 1558, 4097, 3587, 1113, 2015, 1756,
        2254, 2455, 4185,  340])
Epoch: 103, Training Loss: 0.59, Validation Loss: 0.62, accuracy = 0.69
######################## Epoch 104 - Batch 1 ########################
IDs in batch 1: tensor([3257, 2771, 3014,   70, 3417, 1833, 2858, 1671, 3731, 1385,  198, 2724,
        4190, 2467, 1470, 3428])
Epoch: 104, Training Loss: 0.63, Validation Loss: 0.62, accuracy = 0.68
######################## Epoch 105 - Batch 1 ########################
IDs in batch 1: tensor([2234, 1892, 1133, 3871, 2682, 2457,  326,  804, 1469, 1774, 3214, 3227,
        4149,  138, 4258, 1914])
Epoch: 105, Training Loss: 0.62, Validation Loss: 0.61, accuracy = 0.69
######################## Epoch 106 - Batch 1 ########################
IDs in batch 1: tensor([2041,  704, 3448, 1006, 3241, 3088,  983, 1670, 2510,   72, 1862, 1070,
         821, 4135, 2825,  150])
Epoch: 106, Training Loss: 0.61, Validation Loss: 0.61, accuracy = 0.69
######################## Epoch 107 - Batch 1 ########################
IDs in batch 1: tensor([2874, 2300, 3430,  566, 3778,  914, 3289,  484, 1306, 3904, 1487, 3985,
        1658, 3261,  949,  849])
Epoch: 107, Training Loss: 0.59, Validation Loss: 0.61, accuracy = 0.69
######################## Epoch 108 - Batch 1 ########################
IDs in batch 1: tensor([ 160, 2688, 1385,  678, 1180,  797, 2969, 2772, 2520, 3366,  688, 3077,
         699, 3945, 2366, 2403])
Epoch: 108, Training Loss: 0.62, Validation Loss: 0.61, accuracy = 0.69
######################## Epoch 109 - Batch 1 ########################
IDs in batch 1: tensor([1592,  397, 2224,  897,   97,  941,  556,  400, 3410, 3534, 1271, 3935,
        1931, 1953,  644, 1650])
Epoch: 109, Training Loss: 0.73, Validation Loss: 0.61, accuracy = 0.69
######################## Epoch 110 - Batch 1 ########################
IDs in batch 1: tensor([ 941,  830, 1728,  207, 2256, 3616, 2030, 3202, 4033, 2821, 3218,  835,
        1355, 3544, 2244,  688])
Epoch: 110, Training Loss: 0.63, Validation Loss: 0.61, accuracy = 0.70
Save best Model_1 @ epoch 110 acc: 0.6951934349355217
Email sent!
######################## Epoch 111 - Batch 1 ########################
IDs in batch 1: tensor([4085,  591, 4003, 3945, 2285,  788, 2617, 1034,  180, 1087, 1761, 2002,
        1628, 2912, 4258, 2789])
Epoch: 111, Training Loss: 0.56, Validation Loss: 0.61, accuracy = 0.70
######################## Epoch 112 - Batch 1 ########################
IDs in batch 1: tensor([ 685, 2423, 2285,  792, 4173,  449, 2095, 1336, 2410, 1426,   42,   22,
        1347, 3136,  198,  709])
Epoch: 112, Training Loss: 0.63, Validation Loss: 0.61, accuracy = 0.70
Save best Model_1 @ epoch 112 acc: 0.6975381008206331
Email sent!
######################## Epoch 113 - Batch 1 ########################
IDs in batch 1: tensor([ 245,  361,   37,  907, 1239, 3885, 2355, 1408, 4254, 4224, 2989,  756,
        2974,   60,  953, 3156])
Epoch: 113, Training Loss: 0.63, Validation Loss: 0.61, accuracy = 0.70
######################## Epoch 114 - Batch 1 ########################
IDs in batch 1: tensor([1481, 1001,  725, 1684, 2476, 2755, 1413,  390, 2817, 1559,  300, 3947,
        2723, 3818, 3714, 3207])
Epoch: 114, Training Loss: 0.52, Validation Loss: 0.61, accuracy = 0.70
Save best Model_1 @ epoch 114 acc: 0.7033997655334114
Email sent!
######################## Epoch 115 - Batch 1 ########################
IDs in batch 1: tensor([ 382, 1931, 1089, 4100, 2672, 1955, 2968,  846, 1185, 3449, 3290,  896,
        1235, 3541, 1830, 2636])
Epoch: 115, Training Loss: 0.71, Validation Loss: 0.61, accuracy = 0.70
######################## Epoch 116 - Batch 1 ########################
IDs in batch 1: tensor([3604, 1076, 3499,  125, 2940, 2478, 4082, 1760,  450,  351, 3463, 2462,
         777, 3717,  602, 1482])
Epoch: 116, Training Loss: 0.57, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 117 - Batch 1 ########################
IDs in batch 1: tensor([4263, 3178, 2627, 2672, 4246,  306, 2353, 3470, 3345,  902, 3976, 2224,
        2870,  596, 2291, 3490])
Epoch: 117, Training Loss: 0.49, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 118 - Batch 1 ########################
IDs in batch 1: tensor([ 488, 2483, 3532, 2674,  804,  536, 1414, 2978, 3628, 1075, 1656, 2746,
         544, 3786, 3589, 2819])
Epoch: 118, Training Loss: 0.66, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 119 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 3988,  767, 1833, 3755, 4215, 3185, 3460,  150,  964, 1853, 1628,
        1375, 3997,  963, 3998])
Epoch: 119, Training Loss: 0.73, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 120 - Batch 1 ########################
IDs in batch 1: tensor([2475, 2375,  481, 4040, 4057,  934, 2529, 4006, 2912, 3130, 3922, 4141,
        4172,  683, 2420, 3973])
Epoch: 120, Training Loss: 0.63, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 121 - Batch 1 ########################
IDs in batch 1: tensor([2070,  472, 3222,  881, 4218, 2781, 1459,  777,  575, 1030, 3439, 2758,
         437,  170, 2435, 3644])
Epoch: 121, Training Loss: 0.65, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 122 - Batch 1 ########################
IDs in batch 1: tensor([2733, 1965, 2717,   77, 1332,  994, 2731, 3922, 1175,  182,  988, 1965,
        2869, 4212, 3873, 2822])
Epoch: 122, Training Loss: 0.61, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 123 - Batch 1 ########################
IDs in batch 1: tensor([4056, 4084, 2711, 3743, 2008,  891, 3388, 2102, 1163, 1388, 2885, 1059,
        2984, 1154, 3160, 1413])
Epoch: 123, Training Loss: 0.44, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 124 - Batch 1 ########################
IDs in batch 1: tensor([ 586,  277,  684, 3161, 3002, 2749, 2457, 3049,  407,  738,  512, 3238,
        3345,  232, 3479, 2827])
Epoch: 124, Training Loss: 0.50, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 125 - Batch 1 ########################
IDs in batch 1: tensor([3558,  987,  412, 2683, 3856, 1052, 3618, 2664, 2459, 3951, 3651, 3429,
        2238,  323,  160,  900])
Epoch: 125, Training Loss: 0.66, Validation Loss: 0.60, accuracy = 0.70
######################## Epoch 126 - Batch 1 ########################
IDs in batch 1: tensor([3615, 1991,  151, 2697, 3018,  704, 3017, 2078,  558, 1180,  710, 2540,
         821,  335, 2815, 2505])
Epoch: 126, Training Loss: 0.62, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 127 - Batch 1 ########################
IDs in batch 1: tensor([ 909, 2798,  749,  841, 3542, 3252,  887, 3291, 1604,  983, 1501,  827,
        2520, 3912, 2343, 2442])
Epoch: 127, Training Loss: 0.57, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 128 - Batch 1 ########################
IDs in batch 1: tensor([ 591, 3253,  111, 3036, 2442,   96, 2913,  921, 1390, 4053, 1271, 3956,
          42,  292, 2098, 3696])
Epoch: 128, Training Loss: 0.54, Validation Loss: 0.59, accuracy = 0.70
Save best Model_1 @ epoch 128 acc: 0.7045720984759671
Email sent!
######################## Epoch 129 - Batch 1 ########################
IDs in batch 1: tensor([ 519, 2241, 2053, 3947, 2617, 2854, 1287, 2636,  892,  400, 1957, 1734,
        1612,  982, 4121, 1228])
Epoch: 129, Training Loss: 0.50, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 130 - Batch 1 ########################
IDs in batch 1: tensor([ 601, 1770, 1716, 1282, 1396, 4149, 3853, 1185, 3358, 1780, 2024, 3713,
        3912, 1558, 1840, 1404])
Epoch: 130, Training Loss: 0.70, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 131 - Batch 1 ########################
IDs in batch 1: tensor([3592,  788, 2281, 2959, 2050, 4184, 1693,  591, 1671,  120, 1944, 3196,
         826, 2609, 3757, 1295])
Epoch: 131, Training Loss: 0.51, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 132 - Batch 1 ########################
IDs in batch 1: tensor([ 544, 2795, 3786, 2193, 2414, 1994, 2552, 2103, 2488, 1375, 2262,  264,
        3065, 1857,  934,  928])
Epoch: 132, Training Loss: 0.57, Validation Loss: 0.59, accuracy = 0.71
Save best Model_1 @ epoch 132 acc: 0.7057444314185228
Email sent!
######################## Epoch 133 - Batch 1 ########################
IDs in batch 1: tensor([2049, 2299, 3474, 2990, 2641, 2996,  159, 1132, 3661, 1399,   52,   78,
         789,  995, 2860, 1085])
Epoch: 133, Training Loss: 0.59, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 134 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 2085, 1344, 3327, 1684, 3765, 4072, 3079, 1413, 3456, 3650, 3651,
        2450, 2558, 1379,  264])
Epoch: 134, Training Loss: 0.52, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 135 - Batch 1 ########################
IDs in batch 1: tensor([2682, 2718, 1367, 2148, 3179,  613,  691, 1885, 2660, 3136, 4227, 3005,
        1672, 1201, 4198, 2442])
Epoch: 135, Training Loss: 0.48, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 136 - Batch 1 ########################
IDs in batch 1: tensor([1812, 2056, 1176, 2746, 4166, 2433, 4121, 1481, 2046, 1811, 1158, 3545,
        3133,   31, 3948, 2472])
Epoch: 136, Training Loss: 0.61, Validation Loss: 0.59, accuracy = 0.71
######################## Epoch 137 - Batch 1 ########################
IDs in batch 1: tensor([ 425, 4199, 3495,  185, 3601, 1419,  917, 1297, 2755, 3891,  933, 1700,
         113,  280, 1414, 1502])
Epoch: 137, Training Loss: 0.66, Validation Loss: 0.59, accuracy = 0.70
######################## Epoch 138 - Batch 1 ########################
IDs in batch 1: tensor([2449, 2969,  226, 2725,  878,  741, 2108, 4035,  595, 2849, 3919, 3592,
        2770, 3747, 3226, 3533])
Epoch: 138, Training Loss: 0.62, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 139 - Batch 1 ########################
IDs in batch 1: tensor([2258, 1798, 3154,  609, 3569, 4060, 2887, 3236, 1947, 3993,  713, 1633,
        2499, 3912, 2183, 1004])
Epoch: 139, Training Loss: 0.54, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 140 - Batch 1 ########################
IDs in batch 1: tensor([ 630,  135, 2348, 2388,  606, 3806, 1862, 1371, 2746, 3778, 1526, 2711,
        2748,  830, 3257, 3919])
Epoch: 140, Training Loss: 0.59, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 141 - Batch 1 ########################
IDs in batch 1: tensor([1482,  401, 3603, 2109,   30, 2271, 2156, 2349, 3754, 1077, 3731, 3051,
        2245, 1085, 3907,  659])
Epoch: 141, Training Loss: 0.60, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 142 - Batch 1 ########################
IDs in batch 1: tensor([3286, 2451,  839, 3780,   30, 3681, 2028, 1747, 2882, 2156,  100,  466,
        3782, 2905, 1851, 1996])
Epoch: 142, Training Loss: 0.61, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 143 - Batch 1 ########################
IDs in batch 1: tensor([3897, 3421, 3927, 2791, 1404, 3616, 1436, 1895, 1061, 2517, 1810, 3896,
        2730, 3414, 4076, 1384])
Epoch: 143, Training Loss: 0.79, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 144 - Batch 1 ########################
IDs in batch 1: tensor([ 594, 1830, 2433, 2346, 2857, 2572, 1306,   73, 3015, 2309, 1755, 2791,
        3831, 2086, 2103, 3211])
Epoch: 144, Training Loss: 0.57, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 145 - Batch 1 ########################
IDs in batch 1: tensor([2249,  771,  202,  530,  970, 2450,  554, 4256, 3329, 3453, 3006, 4255,
        2075, 4197, 2736, 3253])
Epoch: 145, Training Loss: 0.53, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 146 - Batch 1 ########################
IDs in batch 1: tensor([ 994, 3390, 3511, 1727, 2494, 1440, 3787,  682, 1197, 1387,  219, 3147,
        2189, 3697, 2316,  557])
Epoch: 146, Training Loss: 0.70, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 147 - Batch 1 ########################
IDs in batch 1: tensor([4010, 2124, 2416, 1766,  226, 3192, 1996, 3621, 4119,  113, 1784, 3308,
         384, 2156, 3513, 3356])
Epoch: 147, Training Loss: 0.67, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 148 - Batch 1 ########################
IDs in batch 1: tensor([   7, 3935,   97,   63, 3452, 4032, 1840, 1012,  850,   13, 1267, 1862,
         282, 2838, 1495, 3663])
Epoch: 148, Training Loss: 0.68, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 149 - Batch 1 ########################
IDs in batch 1: tensor([2287,  917, 3592, 3223, 4084, 2224, 1508, 2963, 2468, 3459, 2489, 3751,
        3875, 2805, 3604, 3367])
Epoch: 149, Training Loss: 0.45, Validation Loss: 0.58, accuracy = 0.71
Save best Model_1 @ epoch 149 acc: 0.712778429073857
Email sent!
######################## Epoch 150 - Batch 1 ########################
IDs in batch 1: tensor([1390, 1186, 1346,  915, 4263, 4073, 4093,  398, 3015, 2717, 1052, 1132,
        2479,  684, 1575,  530])
Epoch: 150, Training Loss: 0.61, Validation Loss: 0.58, accuracy = 0.72
Save best Model_1 @ epoch 150 acc: 0.7186400937866354
Email sent!
######################## Epoch 151 - Batch 1 ########################
IDs in batch 1: tensor([1804,  444, 1764, 1536, 3836, 2281, 3381, 3705, 2350,  497, 2926, 2356,
        3265, 1310, 1415,  303])
Epoch: 151, Training Loss: 0.46, Validation Loss: 0.58, accuracy = 0.72
######################## Epoch 152 - Batch 1 ########################
IDs in batch 1: tensor([2508,   10, 2514,  212, 2316, 2945, 2305, 2067, 3082, 2598,  808,  743,
         318, 1128, 2621, 1883])
Epoch: 152, Training Loss: 0.49, Validation Loss: 0.58, accuracy = 0.72
######################## Epoch 153 - Batch 1 ########################
IDs in batch 1: tensor([ 936, 2925, 1024, 3073,  145,  355, 1313,  148, 1872, 2767,  206, 3355,
        2737,  644, 3037, 1082])
Epoch: 153, Training Loss: 0.57, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 154 - Batch 1 ########################
IDs in batch 1: tensor([ 685, 3221, 2709, 2882, 3968, 2024, 1628, 1948, 2305, 3838, 1408, 4099,
         205, 1679,  769,  228])
Epoch: 154, Training Loss: 0.57, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 155 - Batch 1 ########################
IDs in batch 1: tensor([1708, 4185, 1857, 2892, 3594, 2009,  343, 4099,  145, 2274, 1682, 2429,
        2493, 1799, 3548, 3441])
Epoch: 155, Training Loss: 0.49, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 156 - Batch 1 ########################
IDs in batch 1: tensor([2226, 1949, 3151, 1517, 1346, 2431, 4121, 1322, 3680, 2188,  128, 3037,
        1733, 1075, 2617, 1292])
Epoch: 156, Training Loss: 0.56, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 157 - Batch 1 ########################
IDs in batch 1: tensor([3960, 4205, 1895,  306,  380,  397, 3668, 1176, 2085, 1467, 4184, 1632,
        4072, 2921, 3183, 2951])
Epoch: 157, Training Loss: 0.59, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 158 - Batch 1 ########################
IDs in batch 1: tensor([2708, 1993, 3516, 2195, 3404, 3439, 4026, 1318,  967,  914, 1882, 1775,
        3020, 3150,  126, 3495])
Epoch: 158, Training Loss: 0.52, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 159 - Batch 1 ########################
IDs in batch 1: tensor([ 595, 2582, 3088, 1099,  490, 1732, 2363, 3636, 3425, 3073,  934, 1283,
         357,  130, 1937, 2965])
Epoch: 159, Training Loss: 0.49, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 160 - Batch 1 ########################
IDs in batch 1: tensor([2040, 3363, 3298, 3254, 1097,  357, 2291, 3024, 2844, 1636, 1519, 3739,
        1385, 2567, 2365, 2363])
Epoch: 160, Training Loss: 0.57, Validation Loss: 0.58, accuracy = 0.71
######################## Epoch 161 - Batch 1 ########################
IDs in batch 1: tensor([  72, 3667, 1732, 3738, 2432, 2398,  747,  445,  481, 1500, 1038, 1221,
        2229, 3485, 2125, 3637])
Epoch: 161, Training Loss: 0.49, Validation Loss: 0.58, accuracy = 0.70
######################## Epoch 162 - Batch 1 ########################
IDs in batch 1: tensor([3870,  247, 3204, 4257, 3950, 4266, 1050, 2450,  326, 2540, 2385, 2970,
        2261, 2236, 4173,  326])
Epoch: 162, Training Loss: 0.47, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 163 - Batch 1 ########################
IDs in batch 1: tensor([2435, 4217, 4110,  340,  185, 3793, 3777, 1897, 1482, 3343,  261,  583,
        2924, 2257,  199, 4022])
Epoch: 163, Training Loss: 0.47, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 164 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 2116, 3414, 3638, 1438,  134, 2103, 4159, 1590, 1043,  857, 1216,
        3238, 1845,  305,  563])
Epoch: 164, Training Loss: 0.58, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 165 - Batch 1 ########################
IDs in batch 1: tensor([ 651, 3638, 4249,  858, 2577, 1583,  489, 1911, 2339, 2919, 2610, 2388,
         259, 1545,  361, 1812])
Epoch: 165, Training Loss: 0.55, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 166 - Batch 1 ########################
IDs in batch 1: tensor([1221, 1885, 1294, 2908, 3940, 4263,  388, 3329, 3740, 1573,  971, 3401,
         558, 3782,   61, 3176])
Epoch: 166, Training Loss: 0.55, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 167 - Batch 1 ########################
IDs in batch 1: tensor([ 682,  656, 3184, 3570,  459, 4228, 2485, 3676,  375,  679, 4144,  683,
        3785, 3025, 3894, 3497])
Epoch: 167, Training Loss: 0.51, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 168 - Batch 1 ########################
IDs in batch 1: tensor([4073, 1173, 3040, 2149, 3905, 2776, 1950, 1870,  942, 1458,   22, 1504,
        4174,  954,  104, 4003])
Epoch: 168, Training Loss: 0.56, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 169 - Batch 1 ########################
IDs in batch 1: tensor([ 976,  747,  496,  459, 3060, 1508, 1179, 1558, 2098, 2870, 3469, 1156,
        4226,  781, 2936, 2984])
Epoch: 169, Training Loss: 0.58, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 170 - Batch 1 ########################
IDs in batch 1: tensor([2088, 2418, 4125,  769,  481, 3030,  785, 1235, 2589, 1556, 2708, 2729,
        1932, 1218, 1626, 1016])
Epoch: 170, Training Loss: 0.63, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 171 - Batch 1 ########################
IDs in batch 1: tensor([3053, 1386, 3444,  391, 2230, 1274,  547, 2629, 1931,  218, 3743,  727,
        1857,  863, 2176, 3728])
Epoch: 171, Training Loss: 0.58, Validation Loss: 0.57, accuracy = 0.71
######################## Epoch 172 - Batch 1 ########################
IDs in batch 1: tensor([1166, 2341, 1299,  459, 3958, 3958,  159, 1330,  950,  219, 1308, 3126,
         735, 3368, 3219, 3202])
Epoch: 172, Training Loss: 0.55, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 173 - Batch 1 ########################
IDs in batch 1: tensor([ 390, 1052, 2256, 2997, 2331, 3996, 3980, 3427, 1123, 1963, 1777, 3217,
        2590, 1589, 2668, 2181])
Epoch: 173, Training Loss: 0.55, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 174 - Batch 1 ########################
IDs in batch 1: tensor([2457, 2080,  417, 2301, 2798, 3878, 1168, 3509, 1252, 1131, 2169, 1880,
        3764,  789, 1780,  111])
Epoch: 174, Training Loss: 0.50, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 175 - Batch 1 ########################
IDs in batch 1: tensor([3676, 2809, 2250,  508,  837, 1042,  365, 3241, 2519, 4143, 1060,  419,
        1763,  762,   51, 1247])
Epoch: 175, Training Loss: 0.66, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 176 - Batch 1 ########################
IDs in batch 1: tensor([ 679, 3875, 3523, 2195,   92, 3127, 3058, 2610, 2011, 2292, 1509, 2252,
        3726, 3271, 3904, 4163])
Epoch: 176, Training Loss: 0.52, Validation Loss: 0.56, accuracy = 0.70
######################## Epoch 177 - Batch 1 ########################
IDs in batch 1: tensor([ 766, 1833, 4061, 1440, 3939, 2145, 3815, 4004,  281, 3881,  426, 3326,
        3473, 3094, 1216, 1909])
Epoch: 177, Training Loss: 0.67, Validation Loss: 0.56, accuracy = 0.70
######################## Epoch 178 - Batch 1 ########################
IDs in batch 1: tensor([2358, 1993, 2729, 4163,  658, 3235, 3353, 3006, 3495, 2281, 2748, 1731,
        2680,   59, 3780,  324])
Epoch: 178, Training Loss: 0.52, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 179 - Batch 1 ########################
IDs in batch 1: tensor([2827, 2780, 3898,  438, 2401, 2548,  996,  919, 1766, 2568, 2876, 2218,
        1413,  990, 1702, 3471])
Epoch: 179, Training Loss: 0.55, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 180 - Batch 1 ########################
IDs in batch 1: tensor([ 971,  199,  969, 1344, 3192, 4158,  497, 3032, 1003, 2859, 2226, 3272,
         828, 2452,  735, 2115])
Epoch: 180, Training Loss: 0.41, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 181 - Batch 1 ########################
IDs in batch 1: tensor([3762, 2653, 2692, 1745,  849, 3895, 2182, 3463, 2280, 2974,   99, 3253,
        1877, 2171, 1718, 2618])
Epoch: 181, Training Loss: 0.45, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 182 - Batch 1 ########################
IDs in batch 1: tensor([1661, 3253, 4265, 1832, 1899, 3650, 1625, 1612, 2869, 2291, 1902, 2379,
        2646, 3866, 3406, 1795])
Epoch: 182, Training Loss: 0.55, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 183 - Batch 1 ########################
IDs in batch 1: tensor([ 485,  676, 4025, 1204, 2592,  572, 3343, 2956, 2365, 1034, 3049, 2951,
        3634, 2873, 2185, 1849])
Epoch: 183, Training Loss: 0.49, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 184 - Batch 1 ########################
IDs in batch 1: tensor([ 338, 2582, 1086, 2652, 2552, 2326, 3478, 3235, 3760, 3994, 3447, 2974,
        3728, 2277, 1770, 2561])
Epoch: 184, Training Loss: 0.49, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 185 - Batch 1 ########################
IDs in batch 1: tensor([2400, 2245, 1104,  909, 4116, 1497, 2577, 3025, 3194, 2545, 2996, 1965,
        1137,  456, 2291,   73])
Epoch: 185, Training Loss: 0.56, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 186 - Batch 1 ########################
IDs in batch 1: tensor([1853, 4013, 3397, 3930, 3952, 1231, 3381, 2942, 1413, 2949, 2833, 3667,
        3744, 3996,  159, 1328])
Epoch: 186, Training Loss: 0.42, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 187 - Batch 1 ########################
IDs in batch 1: tensor([4115, 2111, 3099, 2943,  994,  990, 2805, 3523, 2592, 2014,  276, 3971,
        1942, 3392, 1248, 1399])
Epoch: 187, Training Loss: 0.41, Validation Loss: 0.55, accuracy = 0.72
Save best Model_1 @ epoch 187 acc: 0.7209847596717468
Email sent!
######################## Epoch 188 - Batch 1 ########################
IDs in batch 1: tensor([ 776,  662, 3547, 1698, 3458, 3870, 2290, 4254,   46, 2542, 2157, 2248,
         194, 3401, 1385, 3888])
Epoch: 188, Training Loss: 0.50, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 189 - Batch 1 ########################
IDs in batch 1: tensor([ 822,  403, 1061, 3016, 1343, 1871, 1457, 1005,  159, 1849, 3226, 3659,
        4158, 2176, 3715, 1190])
Epoch: 189, Training Loss: 0.54, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 190 - Batch 1 ########################
IDs in batch 1: tensor([2134, 2600, 2034, 1746, 1003, 2415,  978, 3278, 1896, 3509,  284, 3261,
          61, 3018, 4004, 1031])
Epoch: 190, Training Loss: 0.47, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 191 - Batch 1 ########################
IDs in batch 1: tensor([3745, 3441, 3707, 1826, 2783,  104, 3934, 1345, 1982, 2505,  281, 3832,
        2638, 2807, 2879, 3636])
Epoch: 191, Training Loss: 0.55, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 192 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 3196, 1481, 2127,  663,  785, 3572, 2017, 3961, 1377, 3874, 4080,
         864, 1252,  988, 1756])
Epoch: 192, Training Loss: 0.70, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 193 - Batch 1 ########################
IDs in batch 1: tensor([2458, 1927, 4149, 4100, 2256,  106, 3051,  670, 1508,  435, 3789,  172,
        2039, 3196, 1822, 2568])
Epoch: 193, Training Loss: 0.42, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 194 - Batch 1 ########################
IDs in batch 1: tensor([1124, 3723, 4157, 1121, 3161, 2670, 1732, 4053,   31,  550, 1007, 4217,
        2459, 4114, 3747, 3395])
Epoch: 194, Training Loss: 0.48, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 195 - Batch 1 ########################
IDs in batch 1: tensor([2546, 3015, 1933, 1070, 1189, 1732,  108, 3632, 3192,  223,  321, 1636,
        3530, 3372, 4065, 1961])
Epoch: 195, Training Loss: 0.49, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 196 - Batch 1 ########################
IDs in batch 1: tensor([1406, 1035,  778,  245, 1349,  105,  432, 3692,  786, 3983, 2231,  320,
        3310, 3573, 3533,  976])
Epoch: 196, Training Loss: 0.67, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 197 - Batch 1 ########################
IDs in batch 1: tensor([1510, 2323, 4135, 3394, 2733, 1110, 1241, 4065, 2177,   11, 3734, 2113,
         605,  513, 2463, 3919])
Epoch: 197, Training Loss: 0.53, Validation Loss: 0.56, accuracy = 0.70
######################## Epoch 198 - Batch 1 ########################
IDs in batch 1: tensor([1223,  130, 2940, 3997,  539, 1458, 1599, 3695,  659, 4187, 2144, 1429,
          42,  753, 2300, 1504])
Epoch: 198, Training Loss: 0.51, Validation Loss: 0.56, accuracy = 0.70
######################## Epoch 199 - Batch 1 ########################
IDs in batch 1: tensor([3304, 1646, 3754, 1899, 3027, 1365, 1035, 3975, 3897, 1341, 1252, 3056,
        3702, 1789, 3582,  822])
Epoch: 199, Training Loss: 0.57, Validation Loss: 0.57, accuracy = 0.70
######################## Epoch 200 - Batch 1 ########################
IDs in batch 1: tensor([2487,  434,  575, 2645, 3732, 3489, 2008, 2926, 1671, 2429, 2791, 3265,
        3379,  354, 2687, 3286])
Epoch: 200, Training Loss: 0.40, Validation Loss: 0.56, accuracy = 0.70
######################## Epoch 201 - Batch 1 ########################
IDs in batch 1: tensor([2401, 2176, 3119, 2882, 1011, 3424, 3907, 3143, 3270,  211, 1408, 4215,
         796,  262, 1824, 2125])
Epoch: 201, Training Loss: 0.53, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 202 - Batch 1 ########################
IDs in batch 1: tensor([4196, 3598, 3591, 3547, 2156, 3601, 2449,  206, 2416, 1471, 3207, 3757,
        1712, 1432, 1900,  689])
Epoch: 202, Training Loss: 0.41, Validation Loss: 0.56, accuracy = 0.71
######################## Epoch 203 - Batch 1 ########################
IDs in batch 1: tensor([3437, 1524, 1126, 2429, 1947, 3154,  465, 2555,  290, 1568, 2938, 1488,
        2505, 3650, 1789,  382])
Epoch: 203, Training Loss: 0.48, Validation Loss: 0.55, accuracy = 0.71
######################## Epoch 204 - Batch 1 ########################
IDs in batch 1: tensor([2326, 3894, 1004, 2360, 3608, 2887,  956, 1121,  303, 1901, 1857,  256,
         926,  277, 2223, 2069])
Epoch: 204, Training Loss: 0.72, Validation Loss: 0.55, accuracy = 0.72
######################## Epoch 205 - Batch 1 ########################
IDs in batch 1: tensor([3334, 2746,   84, 3071,  963, 3060, 1684, 2285, 2745, 3713, 4004, 1054,
        3836, 3581, 3674, 2028])
Epoch: 205, Training Loss: 0.56, Validation Loss: 0.54, accuracy = 0.72
######################## Epoch 206 - Batch 1 ########################
IDs in batch 1: tensor([1899, 4057, 2088,  781, 1445,  459, 2931, 1772,  880, 3663, 1453, 2081,
        2974, 1235, 3222, 3975])
Epoch: 206, Training Loss: 0.61, Validation Loss: 0.54, accuracy = 0.72
Save best Model_1 @ epoch 206 acc: 0.7233294255568582
Email sent!
######################## Epoch 207 - Batch 1 ########################
IDs in batch 1: tensor([ 758, 1098, 1931, 3490,   44, 2407, 2150,  813,  900, 2656,  723,  455,
        3181, 3816, 1509, 1077])
Epoch: 207, Training Loss: 0.50, Validation Loss: 0.54, accuracy = 0.72
######################## Epoch 208 - Batch 1 ########################
IDs in batch 1: tensor([1525,  658,  321,  529, 3853,  841, 2597, 3392, 2781,  317, 2655,  427,
          18, 2371, 3427, 1404])
Epoch: 208, Training Loss: 0.63, Validation Loss: 0.54, accuracy = 0.72
######################## Epoch 209 - Batch 1 ########################
IDs in batch 1: tensor([1434, 3863, 3604, 3894, 4009, 1731,   44, 1891, 3823, 3866, 4094, 3465,
        1545,  387, 3624, 4179])
Epoch: 209, Training Loss: 0.41, Validation Loss: 0.54, accuracy = 0.72
######################## Epoch 210 - Batch 1 ########################
IDs in batch 1: tensor([2013, 3157, 2192,  140, 1371, 1185, 2166, 2510, 1634, 2298,  470, 1118,
        3299, 2711, 1708,  631])
Epoch: 210, Training Loss: 0.44, Validation Loss: 0.53, accuracy = 0.72
######################## Epoch 211 - Batch 1 ########################
IDs in batch 1: tensor([  61, 3207, 2996, 1439, 1690, 3509, 1960, 3488, 2695, 2733, 2346,  601,
        3049, 4069, 3127, 1722])
Epoch: 211, Training Loss: 0.50, Validation Loss: 0.53, accuracy = 0.73
Save best Model_1 @ epoch 211 acc: 0.7256740914419695
Email sent!
######################## Epoch 212 - Batch 1 ########################
IDs in batch 1: tensor([3448,  368, 3252, 1869,  691,  723,  281, 3600,  137,  164, 2284,  955,
        4257, 1685, 4024, 3456])
Epoch: 212, Training Loss: 0.60, Validation Loss: 0.53, accuracy = 0.73
######################## Epoch 213 - Batch 1 ########################
IDs in batch 1: tensor([ 132, 1332,  750,  535, 4261, 1824, 3094, 2362, 1034, 1753, 1504, 3609,
         872, 3938,  726,  214])
Epoch: 213, Training Loss: 0.69, Validation Loss: 0.53, accuracy = 0.73
Save best Model_1 @ epoch 213 acc: 0.7291910902696366
Email sent!
######################## Epoch 214 - Batch 1 ########################
IDs in batch 1: tensor([2343, 1472, 4264, 2545, 4136, 2810,  596, 1160, 2692, 2552, 1146,  789,
         996, 3587, 3911, 1022])
Epoch: 214, Training Loss: 0.53, Validation Loss: 0.53, accuracy = 0.73
######################## Epoch 215 - Batch 1 ########################
IDs in batch 1: tensor([ 636, 1017, 3430, 3029,  212, 1374, 2996, 1292,  572, 3746, 3387, 2348,
         455,  950, 3499,  256])
Epoch: 215, Training Loss: 0.47, Validation Loss: 0.53, accuracy = 0.73
######################## Epoch 216 - Batch 1 ########################
IDs in batch 1: tensor([1320,  656, 1753, 1761, 2249, 4108, 2741, 2317,  368, 3953, 1302, 3513,
        3330, 1453, 2420, 3299])
Epoch: 216, Training Loss: 0.44, Validation Loss: 0.53, accuracy = 0.73
Save best Model_1 @ epoch 216 acc: 0.7338804220398594
Email sent!
######################## Epoch 217 - Batch 1 ########################
IDs in batch 1: tensor([3183, 3386,  213, 1937, 2223, 1156, 2831, 2559,  413, 2936, 1454, 3399,
         442, 1643, 2589,  752])
Epoch: 217, Training Loss: 0.46, Validation Loss: 0.53, accuracy = 0.73
######################## Epoch 218 - Batch 1 ########################
IDs in batch 1: tensor([ 134,  321,  777, 2730, 3139, 2586, 2841,  726,  902, 3513, 4031, 2855,
        3961, 3871, 1524,  558])
Epoch: 218, Training Loss: 0.48, Validation Loss: 0.52, accuracy = 0.74
Save best Model_1 @ epoch 218 acc: 0.735052754982415
Email sent!
######################## Epoch 219 - Batch 1 ########################
IDs in batch 1: tensor([ 712,  976, 3199, 1644, 2231, 3390, 1263, 2217, 1006, 3552, 2627, 1444,
        1199, 3985, 3500, 2643])
Epoch: 219, Training Loss: 0.54, Validation Loss: 0.52, accuracy = 0.74
Save best Model_1 @ epoch 219 acc: 0.7362250879249707
Email sent!
######################## Epoch 220 - Batch 1 ########################
IDs in batch 1: tensor([2316, 2619, 1463, 3436, 2196, 1321, 3659,   62, 2014, 1716,  717, 1753,
        2470,  287,  930, 1493])
Epoch: 220, Training Loss: 0.57, Validation Loss: 0.52, accuracy = 0.74
Save best Model_1 @ epoch 220 acc: 0.7444314185228605
Email sent!
######################## Epoch 221 - Batch 1 ########################
IDs in batch 1: tensor([2983,  503, 1571, 3499, 4105, 1665, 2599, 2902,  334, 4108, 2726, 3876,
         789, 2349, 3446, 3734])
Epoch: 221, Training Loss: 0.42, Validation Loss: 0.52, accuracy = 0.75
Save best Model_1 @ epoch 221 acc: 0.7467760844079718
Email sent!
######################## Epoch 222 - Batch 1 ########################
IDs in batch 1: tensor([3604, 1373,  134,  841, 4148, 3485,   88, 2739,  640, 2151, 1772, 2772,
        2088, 1596,  224,  753])
Epoch: 222, Training Loss: 0.52, Validation Loss: 0.52, accuracy = 0.75
Save best Model_1 @ epoch 222 acc: 0.7491207502930832
Email sent!
######################## Epoch 223 - Batch 1 ########################
IDs in batch 1: tensor([1982, 3495, 4158, 3504, 2837, 1644, 1072, 2051, 2968, 1925, 4258, 2927,
         553, 3832, 3552,   93])
Epoch: 223, Training Loss: 0.51, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 224 - Batch 1 ########################
IDs in batch 1: tensor([ 498, 2327, 3689, 1379, 3753, 3871, 2764, 1167, 3974, 1310,  644, 2603,
         552, 3711, 3472, 3004])
Epoch: 224, Training Loss: 0.47, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 225 - Batch 1 ########################
IDs in batch 1: tensor([1745, 2088,  723,  663, 1414, 3197, 1772, 4228, 2406, 3472, 4014,  439,
        3516, 1977,  757, 4087])
Epoch: 225, Training Loss: 0.47, Validation Loss: 0.52, accuracy = 0.75
Save best Model_1 @ epoch 225 acc: 0.753810082063306
Email sent!
######################## Epoch 226 - Batch 1 ########################
IDs in batch 1: tensor([3258,  733, 2327, 2854,  630, 2600, 3585, 2366,  822,  639, 2837, 2338,
        3463, 3194, 2413,  140])
Epoch: 226, Training Loss: 0.41, Validation Loss: 0.52, accuracy = 0.75
Save best Model_1 @ epoch 226 acc: 0.7549824150058617
Email sent!
######################## Epoch 227 - Batch 1 ########################
IDs in batch 1: tensor([2260, 2011, 3878,  878, 3771, 3120, 4136, 2945, 1439, 2368, 1027, 2161,
        1765, 3499, 3939, 3797])
Epoch: 227, Training Loss: 0.58, Validation Loss: 0.52, accuracy = 0.76
Save best Model_1 @ epoch 227 acc: 0.7608440797186401
Email sent!
######################## Epoch 228 - Batch 1 ########################
IDs in batch 1: tensor([3434, 1901, 2517,  380,  218,   74,   74, 1406, 4032, 1551, 1885, 3644,
         673, 3746, 1808, 3715])
Epoch: 228, Training Loss: 0.56, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 229 - Batch 1 ########################
IDs in batch 1: tensor([1269, 1817, 3470, 3448, 3436,  143, 3956, 2385,  363,  221, 2180, 2437,
        1444,  887, 1340, 1387])
Epoch: 229, Training Loss: 0.47, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 230 - Batch 1 ########################
IDs in batch 1: tensor([3504, 1636, 2108,  511, 3385, 4080, 2442, 3370, 2880, 3739, 2429,  219,
        3118, 1910,  363, 2228])
Epoch: 230, Training Loss: 0.38, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 231 - Batch 1 ########################
IDs in batch 1: tensor([2026, 3921, 4115, 3221,  362, 1913, 2667, 1798,  591, 3847,  342, 1708,
        3689,  786,  282, 4134])
Epoch: 231, Training Loss: 0.49, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 232 - Batch 1 ########################
IDs in batch 1: tensor([ 879,  264, 4228, 3930, 4101, 1255, 1049, 4077, 3882, 3608,  954,  276,
        2604, 2235, 3398, 1548])
Epoch: 232, Training Loss: 0.56, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 233 - Batch 1 ########################
IDs in batch 1: tensor([1473, 1975, 2589, 2017,  449,  226, 1657,  201, 1397, 1945,  190, 3000,
        1499, 1113, 2718, 2036])
Epoch: 233, Training Loss: 0.56, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 234 - Batch 1 ########################
IDs in batch 1: tensor([4002,  463, 1082, 1312,  191,  505, 2529, 3719, 2857, 3524, 3866, 3833,
        2350, 4080, 3492, 1041])
Epoch: 234, Training Loss: 0.43, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 235 - Batch 1 ########################
IDs in batch 1: tensor([2551, 2795, 1306, 4200,  949, 3362, 2945, 4084, 3709, 1518,  968,  217,
        1370, 2701, 1396,  469])
Epoch: 235, Training Loss: 0.45, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 236 - Batch 1 ########################
IDs in batch 1: tensor([3525, 3846, 1053, 4258, 3617, 3876,  472, 4267, 3091,  875, 1009,   19,
         918, 2915, 2451, 1108])
Epoch: 236, Training Loss: 0.42, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 237 - Batch 1 ########################
IDs in batch 1: tensor([1804,  880, 2953, 4024,  751, 1386, 4263,  475, 1140, 3217, 3816, 2595,
         478, 1844, 1170,   71])
Epoch: 237, Training Loss: 0.52, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 238 - Batch 1 ########################
IDs in batch 1: tensor([3254, 2156, 3256, 3040,  102, 1886, 3891,   63, 3375, 2666, 1393, 2181,
         523, 4016, 2678, 1305])
Epoch: 238, Training Loss: 0.46, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 239 - Batch 1 ########################
IDs in batch 1: tensor([4044, 4005,  673, 2847,   59, 2094, 4027,  819, 2712, 2844, 2038, 3094,
        2897, 1081, 1008, 2166])
Epoch: 239, Training Loss: 0.40, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 240 - Batch 1 ########################
IDs in batch 1: tensor([2696,  730,  305,  398, 1445,  229,   85, 1197, 1984, 2500,  733, 2681,
         187, 2469, 3342,  976])
Epoch: 240, Training Loss: 0.51, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 241 - Batch 1 ########################
IDs in batch 1: tensor([3782, 2982, 2957, 1222, 1578, 2298, 2213,  387, 3342, 2323, 1916, 1469,
        2488, 3767, 3154, 2008])
Epoch: 241, Training Loss: 0.31, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 242 - Batch 1 ########################
IDs in batch 1: tensor([3601, 2851, 1700,  503, 3356, 1428, 4067, 2412,  886,  466,   49, 1599,
        1803,  340, 4026, 2044])
Epoch: 242, Training Loss: 0.54, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 243 - Batch 1 ########################
IDs in batch 1: tensor([3655, 1551, 2660, 1056, 3958, 3847, 1923, 1722,  946, 1775,   11,  717,
        2479, 1061, 3468, 3271])
Epoch: 243, Training Loss: 0.64, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 244 - Batch 1 ########################
IDs in batch 1: tensor([2053, 1610, 4163, 2023, 2245, 1189,  625, 3567,  469, 2691, 1945,  952,
        3108,    4, 3077, 3658])
Epoch: 244, Training Loss: 0.51, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 245 - Batch 1 ########################
IDs in batch 1: tensor([4222, 2967, 1251, 3114, 3693,  372, 3102, 2546, 2619, 3414, 2876, 1517,
        2309, 1502, 1562, 3342])
Epoch: 245, Training Loss: 0.42, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 246 - Batch 1 ########################
IDs in batch 1: tensor([2898,  900, 4031, 3495,  649,  584, 2912, 2961, 2995, 1789,  368, 2400,
         601, 3557, 2167, 3607])
Epoch: 246, Training Loss: 0.54, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 247 - Batch 1 ########################
IDs in batch 1: tensor([2668, 3065, 2927, 2052, 1823,  946, 2656, 3874, 4223,  341, 3311, 3020,
        2306, 3328, 1900, 2642])
Epoch: 247, Training Loss: 0.55, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 248 - Batch 1 ########################
IDs in batch 1: tensor([2544,  601,  670, 2148,  193,  612, 1131, 2783, 4065, 3551, 1406, 2418,
        3282, 2300,  110, 4085])
Epoch: 248, Training Loss: 0.39, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 249 - Batch 1 ########################
IDs in batch 1: tensor([3036, 2235, 3057, 2701, 2966, 2926,  591, 2733, 1042, 3193, 1335,  511,
        2719,  946,  811, 1672])
Epoch: 249, Training Loss: 0.35, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 250 - Batch 1 ########################
IDs in batch 1: tensor([ 474, 3876, 3569,  878, 3858, 1493,  363, 3632, 3182,  154, 2326, 3920,
        1614, 3850,  797, 2426])
Epoch: 250, Training Loss: 0.49, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 251 - Batch 1 ########################
IDs in batch 1: tensor([3634, 4006, 1183,  334,  332, 3399, 3658, 2327, 3366, 3591, 1551, 3669,
        3594, 4200, 3738,  250])
Epoch: 251, Training Loss: 0.41, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 252 - Batch 1 ########################
IDs in batch 1: tensor([2443,  496,  221,  316, 2080, 3568, 3127,  190, 3972,  488,  264, 1902,
        3933,  839, 3585,  348])
Epoch: 252, Training Loss: 0.66, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 253 - Batch 1 ########################
IDs in batch 1: tensor([3084, 3020, 3856, 3709,  839,   42, 3430, 2388, 1663, 3815,  260, 1828,
        2590, 2342, 2475,  265])
Epoch: 253, Training Loss: 0.39, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 254 - Batch 1 ########################
IDs in batch 1: tensor([4159, 1271, 2428, 1452, 3340, 2871,  649, 2977, 1576,  738, 2193,  499,
        2252, 2378, 1858,  214])
Epoch: 254, Training Loss: 0.39, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 255 - Batch 1 ########################
IDs in batch 1: tensor([ 183, 3478, 2659,  538, 3630, 3369, 2236, 3581, 4087,  391, 4266, 3615,
        3472, 1835,  109,  325])
Epoch: 255, Training Loss: 0.37, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 256 - Batch 1 ########################
IDs in batch 1: tensor([1834, 3756, 3099, 3452, 3002,  572, 3859,  909, 1448, 3914, 3133,  316,
        1780, 3262, 2798, 2103])
Epoch: 256, Training Loss: 0.54, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 257 - Batch 1 ########################
IDs in batch 1: tensor([ 399,  595, 2825, 2166, 3505, 3859,  342,  640, 4114, 2777, 1232, 2378,
         393, 3351, 4185, 3162])
Epoch: 257, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 258 - Batch 1 ########################
IDs in batch 1: tensor([4057, 3598, 4166, 3500, 1787, 2561,  678, 2030, 1450, 2331, 1450,  218,
        2295, 1025, 2959, 2934])
Epoch: 258, Training Loss: 0.39, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 259 - Batch 1 ########################
IDs in batch 1: tensor([4235,  752, 1279, 2724, 2272, 4196, 2285, 4072, 4133, 1789, 2796,  726,
         459, 2789, 1575, 1055])
Epoch: 259, Training Loss: 0.34, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 260 - Batch 1 ########################
IDs in batch 1: tensor([ 326,  346,  797, 3640, 3143, 3440, 1525,  387,  196, 3699, 1384,   39,
        1844, 1076, 2104,  196])
Epoch: 260, Training Loss: 0.63, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 261 - Batch 1 ########################
IDs in batch 1: tensor([3726, 3952,  990, 1857, 2571, 3029, 3392, 1361, 3081, 3448, 3427, 3783,
        1429, 4146, 3242, 1789])
Epoch: 261, Training Loss: 0.46, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 262 - Batch 1 ########################
IDs in batch 1: tensor([4018, 2108, 1859, 3471, 3654, 1489,  854, 1132,  333, 1410,   98, 2810,
        1160, 3573, 2562, 3289])
Epoch: 262, Training Loss: 0.53, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 263 - Batch 1 ########################
IDs in batch 1: tensor([ 644,  797, 1736, 1942, 3729, 1663, 3513, 3717, 1638, 1444,  699, 3542,
        4235, 1459, 3270, 1511])
Epoch: 263, Training Loss: 0.56, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 264 - Batch 1 ########################
IDs in batch 1: tensor([ 604,  188,  781, 1502, 4085,  681, 2127, 3485,  792,  368, 3896, 3156,
         990,  749, 2901, 3661])
Epoch: 264, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 265 - Batch 1 ########################
IDs in batch 1: tensor([1258, 3604, 1234, 1428, 1745, 1985, 2088, 3051, 4143, 3254, 4215, 2615,
        1655, 2577, 1755,  823])
Epoch: 265, Training Loss: 0.52, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 266 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 2228, 2555, 2584,  258, 3875, 1508, 1580, 3643, 2448, 1811,  758,
          11, 4010, 2606, 2492])
Epoch: 266, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 267 - Batch 1 ########################
IDs in batch 1: tensor([4144,  283, 1760, 3695,  838, 1032, 4009, 3381,  205, 4095, 1668,  887,
        3643, 2450, 3141,  173])
Epoch: 267, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 268 - Batch 1 ########################
IDs in batch 1: tensor([3870, 2733, 1510, 4138, 2286, 2943, 2897, 1388, 2733, 2024, 3500, 4006,
        1463, 1138, 3988, 1167])
Epoch: 268, Training Loss: 0.39, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 269 - Batch 1 ########################
IDs in batch 1: tensor([ 794, 2281,  489, 2226, 2863, 3504, 1951, 3023, 4203,  112,  236,  100,
         896, 1676, 2467, 2653])
Epoch: 269, Training Loss: 0.35, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 270 - Batch 1 ########################
IDs in batch 1: tensor([ 514, 2990, 1762, 2887,  740, 2366, 2370, 1573,  409,  361,  245, 1347,
        1500, 2440,  553, 1275])
Epoch: 270, Training Loss: 0.70, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 271 - Batch 1 ########################
IDs in batch 1: tensor([1405, 1973, 2041, 3022, 1146, 2401, 1351, 1347, 3689, 3659, 1425, 1374,
        2794, 3071,  261, 1163])
Epoch: 271, Training Loss: 0.48, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 272 - Batch 1 ########################
IDs in batch 1: tensor([3607,  211, 1852,  257,  538, 2810, 1784,  228, 3525,  195, 1229, 3303,
        3871, 2234, 2255,  933])
Epoch: 272, Training Loss: 0.56, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 273 - Batch 1 ########################
IDs in batch 1: tensor([4026, 2297, 1054, 3443, 3117, 3408, 2264, 3872, 2603, 1590, 2169,  422,
        2480, 2942, 3513, 3640])
Epoch: 273, Training Loss: 0.45, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 274 - Batch 1 ########################
IDs in batch 1: tensor([2056, 3312, 1846, 1937, 3593, 1976, 3056, 2748,   77, 1388, 3378, 3399,
         200, 3185, 2209, 2860])
Epoch: 274, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 275 - Batch 1 ########################
IDs in batch 1: tensor([2109, 4097, 1118, 3842,  516,  488, 2815, 4013,  843, 1640, 1117, 3762,
        2348,  985,  324,   43])
Epoch: 275, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 276 - Batch 1 ########################
IDs in batch 1: tensor([3025,  357, 2993,  992, 1257, 2368,   44, 3692, 3227, 2286, 2771, 3624,
         352, 3336, 1942,  566])
Epoch: 276, Training Loss: 0.35, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 277 - Batch 1 ########################
IDs in batch 1: tensor([2205, 2970,  829, 3381, 1665, 3998,  792, 1199, 1660, 2446, 4234, 2678,
        4138, 1271, 2018, 3040])
Epoch: 277, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 278 - Batch 1 ########################
IDs in batch 1: tensor([ 276, 2126, 2899,  969,   50,  646, 3188,  615, 1536,  811,  724, 1047,
        1316, 2446,  384, 2005])
Epoch: 278, Training Loss: 0.49, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 279 - Batch 1 ########################
IDs in batch 1: tensor([ 435, 1947,  670,  610, 3693, 1774, 2516,  605, 1636, 2807,   62, 1450,
          22, 1646,  578,  517])
Epoch: 279, Training Loss: 0.70, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 280 - Batch 1 ########################
IDs in batch 1: tensor([ 625, 1761, 3486, 3216, 2837, 4013,  918, 3283, 2731, 3544, 3938, 3651,
        4035, 2591, 2812,  992])
Epoch: 280, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 281 - Batch 1 ########################
IDs in batch 1: tensor([4225,  135, 3874,  203, 2529, 4253, 2752,   68, 1313,  300, 1319, 1208,
        1914, 3329, 2031,  358])
Epoch: 281, Training Loss: 0.41, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 282 - Batch 1 ########################
IDs in batch 1: tensor([3839, 2113,  470, 1480,  893,  593, 3463,  661, 1008, 1469, 3317, 3228,
         112,   28, 3674, 1024])
Epoch: 282, Training Loss: 0.55, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 283 - Batch 1 ########################
IDs in batch 1: tensor([2905, 3962, 1224, 2053, 2856, 3235, 2853, 1948, 2085, 1090, 1971, 2324,
         610, 2231, 3803, 1879])
Epoch: 283, Training Loss: 0.60, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 284 - Batch 1 ########################
IDs in batch 1: tensor([ 956, 2108,  814, 1712,  434, 1698,  767,  289, 4067, 2823, 2390, 2842,
        3181,   41, 2466, 2177])
Epoch: 284, Training Loss: 0.44, Validation Loss: 0.50, accuracy = 0.74
######################## Epoch 285 - Batch 1 ########################
IDs in batch 1: tensor([2341, 1473, 3680, 2848, 2661,  143, 3832, 3183,  965, 2851,  726,  466,
        2382,   19, 3478, 2799])
Epoch: 285, Training Loss: 0.30, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 286 - Batch 1 ########################
IDs in batch 1: tensor([1299,  111, 2277,  356, 2592, 3751, 2476,  749, 1201, 3414, 3474, 2213,
        1027,  265,  942, 3226])
Epoch: 286, Training Loss: 0.50, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 287 - Batch 1 ########################
IDs in batch 1: tensor([3425, 2897, 1206, 2828, 2109,  790, 1451,  965,  851, 1507,  591, 1974,
         225, 1059, 1077, 3810])
Epoch: 287, Training Loss: 0.55, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 288 - Batch 1 ########################
IDs in batch 1: tensor([2056, 1367, 3217, 1381,  292, 1948, 1914, 1146, 3518, 2365, 2135, 2229,
         164, 4165, 2371,  804])
Epoch: 288, Training Loss: 0.43, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 289 - Batch 1 ########################
IDs in batch 1: tensor([2295, 3467,  399, 1014, 4007,  478, 3913,  382, 4268, 1321, 3238, 3652,
        3834, 1290, 1897,  335])
Epoch: 289, Training Loss: 0.53, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 290 - Batch 1 ########################
IDs in batch 1: tensor([4267, 2063,  425, 3257,  400,  117,  713, 3541, 3447, 2022,  462, 3395,
        2056, 3184,  769, 4039])
Epoch: 290, Training Loss: 0.44, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 291 - Batch 1 ########################
IDs in batch 1: tensor([1734,  274,  113, 1379,  456, 2730, 3150, 1157, 3615, 2953,  274, 2810,
        3245, 1361, 4053,  736])
Epoch: 291, Training Loss: 0.41, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 292 - Batch 1 ########################
IDs in batch 1: tensor([ 888, 1784, 1156, 2960, 1354, 3428, 3228, 1718, 3299, 3157,  649,  826,
        3240,   42, 2371,  434])
Epoch: 292, Training Loss: 0.33, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 293 - Batch 1 ########################
IDs in batch 1: tensor([2443, 2448, 1235,  921, 4117,  183, 3787, 3983, 3718, 3406, 3283, 4110,
        1107, 3009,  259, 3513])
Epoch: 293, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 294 - Batch 1 ########################
IDs in batch 1: tensor([1642, 4154,  770, 2026, 1204, 1196, 3617,  390, 3308, 2838, 2755, 3290,
        1279, 3652,  361, 1632])
Epoch: 294, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.76
Save best Model_1 @ epoch 294 acc: 0.7620164126611958
Email sent!
######################## Epoch 295 - Batch 1 ########################
IDs in batch 1: tensor([3536, 3638,   21, 2153, 2842, 2529, 1285, 3706, 1283,  691, 2166, 2258,
        2605, 4008, 2475, 3777])
Epoch: 295, Training Loss: 0.44, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 296 - Batch 1 ########################
IDs in batch 1: tensor([ 467, 3927,  126, 3154, 3376, 1495,   35, 1189, 2727, 3152, 2511,  403,
         262, 1532, 3458, 2858])
Epoch: 296, Training Loss: 0.32, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 297 - Batch 1 ########################
IDs in batch 1: tensor([2447,  863, 3553,  808,  908, 1389, 1189,  237, 3459, 1016,  891, 1311,
          30, 2204, 2653, 3812])
Epoch: 297, Training Loss: 0.64, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 298 - Batch 1 ########################
IDs in batch 1: tensor([2666, 4006, 1104, 3135, 1676, 2956, 2109, 2709, 4256,  888, 4224,  147,
         252,  960, 1636, 2190])
Epoch: 298, Training Loss: 0.38, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 299 - Batch 1 ########################
IDs in batch 1: tensor([3762,  913, 2280, 2371, 1833, 2202, 2331, 2887, 3638, 2377, 2945, 2111,
        2106, 3261,   85, 1640])
Epoch: 299, Training Loss: 0.43, Validation Loss: 0.50, accuracy = 0.76
Save best Model_1 @ epoch 299 acc: 0.7631887456037515
Email sent!
######################## Epoch 300 - Batch 1 ########################
IDs in batch 1: tensor([2177, 2282, 4197, 1017, 1332, 1656, 2671, 3599, 3113,  607, 2617, 2279,
        1851, 1396, 3337,  229])
Epoch: 300, Training Loss: 0.41, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 301 - Batch 1 ########################
IDs in batch 1: tensor([1825, 3057,  749, 1396, 1795,  644, 3644,  439, 4205, 3326, 2947,  511,
        1490, 1330, 1649,  250])
Epoch: 301, Training Loss: 0.66, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 302 - Batch 1 ########################
IDs in batch 1: tensor([2285, 1481, 3094, 3154,  183, 2688, 2446, 1011, 3284, 1442, 3017, 2857,
        2255,   15, 2876, 4039])
Epoch: 302, Training Loss: 0.40, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 303 - Batch 1 ########################
IDs in batch 1: tensor([3832, 1443, 3664, 2601, 3902, 1765, 1273, 1177, 1249,    4, 3484, 1200,
         262, 3092, 3767, 1292])
Epoch: 303, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 304 - Batch 1 ########################
IDs in batch 1: tensor([ 851, 3262, 3425, 3831, 2520, 2575, 2132, 2558, 3870, 2964, 3146, 2176,
         508,  789, 3409, 2546])
Epoch: 304, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 305 - Batch 1 ########################
IDs in batch 1: tensor([2159, 2587, 2403,  411, 3005,  632,  870, 1975, 3388, 1619, 2282, 3926,
        1405, 2921, 4261, 1645])
Epoch: 305, Training Loss: 0.43, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 306 - Batch 1 ########################
IDs in batch 1: tensor([1556, 1247,  701, 2338, 1176, 2095,  930, 1752, 3047, 3248, 2210, 2489,
        1146,  936, 3228, 1931])
Epoch: 306, Training Loss: 0.36, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 307 - Batch 1 ########################
IDs in batch 1: tensor([  22, 2610,  200, 2099,  809, 3651, 2905, 3353, 1017, 4157, 3654, 1140,
         456, 4236, 1832, 1614])
Epoch: 307, Training Loss: 0.35, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 308 - Batch 1 ########################
IDs in batch 1: tensor([2120, 1625, 1160, 3032, 2088, 1331, 1125, 1376, 1124,  678, 3014, 2689,
        1540, 4249, 3702, 1579])
Epoch: 308, Training Loss: 0.51, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 309 - Batch 1 ########################
IDs in batch 1: tensor([2229, 2578, 3615, 3993, 1244,  805, 2117, 4103, 2575, 4076, 1454, 1212,
        1810,  572, 1762,  119])
Epoch: 309, Training Loss: 0.36, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 310 - Batch 1 ########################
IDs in batch 1: tensor([4267, 2292,  455, 3132, 2377, 1306, 3160, 3930, 3981, 1031,  452, 1311,
        2636, 1060,  883, 3154])
Epoch: 310, Training Loss: 0.61, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 311 - Batch 1 ########################
IDs in batch 1: tensor([3541, 3913,  387, 1733, 3222, 2969,  747,  220, 3777, 3094, 2252, 1841,
        2498, 1566, 2991,  149])
Epoch: 311, Training Loss: 0.35, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 312 - Batch 1 ########################
IDs in batch 1: tensor([4223, 4240, 4024,  814, 1643, 2692, 3600, 2479, 1406,  269, 1942, 3853,
        1119, 4125, 1947, 3798])
Epoch: 312, Training Loss: 0.40, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 313 - Batch 1 ########################
IDs in batch 1: tensor([2418,  714, 2371,  617, 1279, 3953, 2450, 2035, 1273, 2171, 1030,  333,
         255, 2224,  471, 1818])
Epoch: 313, Training Loss: 0.54, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 314 - Batch 1 ########################
IDs in batch 1: tensor([ 627,  684, 2150,  590,  481, 2646, 3894, 3597,  863, 3845, 3401, 4015,
         469,  376,  921, 4002])
Epoch: 314, Training Loss: 0.41, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 315 - Batch 1 ########################
IDs in batch 1: tensor([2059, 3729, 2650, 1579,  143, 2587, 1282, 1988, 4127, 2645,  536, 3628,
        2104, 3925, 2385, 2995])
Epoch: 315, Training Loss: 0.46, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 316 - Batch 1 ########################
IDs in batch 1: tensor([2123, 3778, 4099, 2505,  835, 4144, 1256, 3922,  387,  882,  897, 1374,
         113, 2582, 1076, 4075])
Epoch: 316, Training Loss: 0.60, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 317 - Batch 1 ########################
IDs in batch 1: tensor([  24, 2604, 1273, 3551,  147, 3886, 3710, 2109,  245,   25, 3421, 3793,
         172,  832, 1540, 2046])
Epoch: 317, Training Loss: 0.45, Validation Loss: 0.53, accuracy = 0.74
######################## Epoch 318 - Batch 1 ########################
IDs in batch 1: tensor([3337,  573, 2894, 3102,  610, 2565, 1585, 4234, 1589, 2539, 3860, 2135,
        3114,  980, 1157,  238])
Epoch: 318, Training Loss: 0.25, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 319 - Batch 1 ########################
IDs in batch 1: tensor([1335, 1773,  685, 2668, 1871, 3749, 4049, 4161, 2031, 3465,  790, 3207,
        3738, 2281, 3255, 1156])
Epoch: 319, Training Loss: 0.49, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 320 - Batch 1 ########################
IDs in batch 1: tensor([2535, 1755,   60, 3077, 3731, 1236, 1038,  172, 3339, 2394, 1247, 4032,
         985, 2936, 3689, 4172])
Epoch: 320, Training Loss: 0.35, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 321 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 1457, 2090, 1956, 1851,  352, 3082, 3680, 1918, 3303,  644, 2126,
         152, 1724, 2022, 1894])
Epoch: 321, Training Loss: 0.43, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 322 - Batch 1 ########################
IDs in batch 1: tensor([ 723, 2943,  527,  263, 1144, 2277, 1846, 1836, 3298, 1444, 3392,  681,
        3397, 3142, 3182, 1489])
Epoch: 322, Training Loss: 0.45, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 323 - Batch 1 ########################
IDs in batch 1: tensor([ 382, 4000,  850,  568, 2667, 1949, 1235,  488, 3262, 1406, 2689, 3568,
         636, 1160,  758,  165])
Epoch: 323, Training Loss: 0.43, Validation Loss: 0.52, accuracy = 0.73
######################## Epoch 324 - Batch 1 ########################
IDs in batch 1: tensor([4022, 1132,  640, 1753, 2496, 1197,  102,  274, 3088, 3434, 1404, 2092,
         177, 1973, 2425, 3157])
Epoch: 324, Training Loss: 0.62, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 325 - Batch 1 ########################
IDs in batch 1: tensor([2110, 3423, 2959, 3279,  332,  335, 2011, 1722,  682, 2857, 1345, 3200,
        1178, 3075, 4261, 2378])
Epoch: 325, Training Loss: 0.45, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 326 - Batch 1 ########################
IDs in batch 1: tensor([ 104, 1612, 3044,  201, 1185, 1163, 3094, 1315,  788, 3999, 3503,  378,
        2743, 1051, 1326,  658])
Epoch: 326, Training Loss: 0.65, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 327 - Batch 1 ########################
IDs in batch 1: tensor([2112,  373, 4053, 2212,   71, 3778, 4030, 1787, 1387, 2242, 3055, 2897,
         432,  391, 3358, 3077])
Epoch: 327, Training Loss: 0.38, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 328 - Batch 1 ########################
IDs in batch 1: tensor([2400, 3463, 3002,  794, 2740, 3907,  333, 1491,   62, 2584, 3484,  667,
        2799, 2734,  878, 1180])
Epoch: 328, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 329 - Batch 1 ########################
IDs in batch 1: tensor([2730,  743, 1817,   93,   38, 3349,  434, 1871, 2188,  652, 1094, 2496,
        2689,  425, 1214, 4214])
Epoch: 329, Training Loss: 0.52, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 330 - Batch 1 ########################
IDs in batch 1: tensor([3039, 2107,   21, 3323,  498, 1290, 3021,  104, 1779, 4080, 1330,  770,
         797, 1081, 1092, 2802])
Epoch: 330, Training Loss: 0.51, Validation Loss: 0.50, accuracy = 0.76
Save best Model_1 @ epoch 330 acc: 0.7643610785463072
Email sent!
######################## Epoch 331 - Batch 1 ########################
IDs in batch 1: tensor([ 721, 1920, 4234, 1932,  132, 3674, 1335,  828, 3251, 3468, 2927,  841,
        1084,  888, 2691, 1052])
Epoch: 331, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 332 - Batch 1 ########################
IDs in batch 1: tensor([2173, 3797, 2412, 3912,   38, 2039, 2668, 1220, 1644, 3208, 3617, 4088,
        3549, 3181, 2272,  260])
Epoch: 332, Training Loss: 0.55, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 333 - Batch 1 ########################
IDs in batch 1: tensor([ 172, 3373, 2915,  736, 1375, 3976, 1032, 4181, 3246,  893, 4154, 1612,
        1166, 3025, 3963, 3648])
Epoch: 333, Training Loss: 0.45, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 334 - Batch 1 ########################
IDs in batch 1: tensor([ 751,  367,  139, 2207, 1605, 1337, 2687, 1222,  751, 3797, 2610, 3831,
        3762, 3142, 1793,  277])
Epoch: 334, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 335 - Batch 1 ########################
IDs in batch 1: tensor([ 642, 4232,  964, 3479,  788,  796,  751, 4027, 2277,   98, 2604, 2629,
        3275, 1596,  437, 1740])
Epoch: 335, Training Loss: 0.53, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 336 - Batch 1 ########################
IDs in batch 1: tensor([2355, 2315,  229,  316, 3299, 3102, 3767, 1313,  214,   38,  584, 2249,
        2436,   84, 1740, 2314])
Epoch: 336, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 337 - Batch 1 ########################
IDs in batch 1: tensor([1022, 3326, 1980,    5, 2291, 2103,   85,   43, 1355, 1443, 3105, 3436,
        1923, 2787, 1309, 3344])
Epoch: 337, Training Loss: 0.30, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 338 - Batch 1 ########################
IDs in batch 1: tensor([ 237,  572, 1281,  956, 4082,  689, 1835,  662,   18, 3975, 3278, 2464,
        3787,  250, 3351, 2559])
Epoch: 338, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.74
######################## Epoch 339 - Batch 1 ########################
IDs in batch 1: tensor([ 890,  173, 3554,  729, 1266, 2812, 3583, 1996, 4226, 3114, 1673,  876,
         723, 1119, 2964, 1053])
Epoch: 339, Training Loss: 0.60, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 340 - Batch 1 ########################
IDs in batch 1: tensor([ 191, 3470, 1702, 3826, 1751, 3262, 2376,  583, 2599, 1665, 3563, 2898,
        4113, 2548, 3721, 1951])
Epoch: 340, Training Loss: 0.65, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 341 - Batch 1 ########################
IDs in batch 1: tensor([3485, 3368, 2242,  378, 3557, 3236, 2257, 1360, 3017, 4149, 2764, 3751,
        1877,  726, 3290, 3304])
Epoch: 341, Training Loss: 0.52, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 342 - Batch 1 ########################
IDs in batch 1: tensor([2473,   51, 3843,  628,  926, 1804, 1823, 1698, 2751, 2951, 4125,  953,
        3216, 1249,  959, 4246])
Epoch: 342, Training Loss: 0.33, Validation Loss: 0.49, accuracy = 0.77
Save best Model_1 @ epoch 342 acc: 0.7655334114888629
Email sent!
######################## Epoch 343 - Batch 1 ########################
IDs in batch 1: tensor([2980, 3105,  557,  687, 2859,  797, 1971, 3953,  212, 2119,  200, 2217,
        1066, 1003,  819, 3717])
Epoch: 343, Training Loss: 0.38, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 344 - Batch 1 ########################
IDs in batch 1: tensor([1732, 4181, 2732,  609, 3406, 1612, 1294, 2087, 4180,  282,  223, 3640,
        2458, 3459,  964,  590])
Epoch: 344, Training Loss: 0.38, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 345 - Batch 1 ########################
IDs in batch 1: tensor([ 556, 3424,  149, 2346, 2087, 1720, 4085, 3852, 3418,  120, 3762,  986,
        1062,  682, 2712,  721])
Epoch: 345, Training Loss: 0.41, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 346 - Batch 1 ########################
IDs in batch 1: tensor([2157, 3032,  850, 3242, 4185, 3996, 2627, 3732, 1711, 1960, 3504, 1859,
        3740, 2711, 2103, 2354])
Epoch: 346, Training Loss: 0.58, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 347 - Batch 1 ########################
IDs in batch 1: tensor([3456, 4080, 2477, 1271, 3375, 1287, 2298, 1601, 3071,  466, 3568, 4158,
        2114, 3113, 1057, 2954])
Epoch: 347, Training Loss: 0.40, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 348 - Batch 1 ########################
IDs in batch 1: tensor([2572, 2668,  138,  138, 2342, 1825, 2451,  325, 2934, 3421, 3358, 3219,
         625, 1681, 2991, 2459])
Epoch: 348, Training Loss: 0.35, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 349 - Batch 1 ########################
IDs in batch 1: tensor([ 111, 3474, 4141, 2376,  437, 3398, 1469, 3969, 2250, 2094,  850,  755,
         656, 2529, 3458, 2897])
Epoch: 349, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 350 - Batch 1 ########################
IDs in batch 1: tensor([3827, 3577, 3181, 2322, 1885, 4053, 1047, 3098, 1315, 1944, 2024, 2255,
        1512, 3407, 1525, 3162])
Epoch: 350, Training Loss: 0.38, Validation Loss: 0.50, accuracy = 0.77
Save best Model_1 @ epoch 350 acc: 0.7690504103165299
Email sent!
######################## Epoch 351 - Batch 1 ########################
IDs in batch 1: tensor([4053,  408, 3778, 2511, 2873, 2030, 2435,   26, 1866, 4143, 3483, 4220,
        1399, 3640, 1778, 3032])
Epoch: 351, Training Loss: 0.37, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 352 - Batch 1 ########################
IDs in batch 1: tensor([ 147,  507, 1871, 2346, 1796, 2968,  125, 4087, 1444, 2291, 1409, 3947,
        2758, 3156, 3146, 1456])
Epoch: 352, Training Loss: 0.36, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 353 - Batch 1 ########################
IDs in batch 1: tensor([2840, 3334,  805, 4121, 4014,  213,  738, 3470, 3859, 3943,   97,  993,
        1020, 3092, 1170,  407])
Epoch: 353, Training Loss: 0.56, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 354 - Batch 1 ########################
IDs in batch 1: tensor([1638, 3177, 2334,  718,  218, 1258, 1213, 2488,  325, 2870, 2414, 2052,
        1887, 2717,  259, 1524])
Epoch: 354, Training Loss: 0.41, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 355 - Batch 1 ########################
IDs in batch 1: tensor([ 778,   82, 2765, 1747, 2117, 2099, 3991,  449, 2456, 3398, 3312,  954,
        3767, 2536, 3264, 2050])
Epoch: 355, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 356 - Batch 1 ########################
IDs in batch 1: tensor([ 919, 2829,   72, 3573,  676, 4057, 3199, 1070, 2743, 4223, 1646, 1451,
        3780, 3715, 3826, 2461])
Epoch: 356, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 357 - Batch 1 ########################
IDs in batch 1: tensor([ 987, 3248, 2887,  751,  681, 3233, 1063, 1509, 4261, 1585, 1372, 2880,
        3810, 2331, 2899, 1755])
Epoch: 357, Training Loss: 0.35, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 358 - Batch 1 ########################
IDs in batch 1: tensor([1952, 1274,  631, 3023,  515, 2689,  627, 1592, 1950, 2925, 3214, 2312,
        2519, 3493, 2853, 1649])
Epoch: 358, Training Loss: 0.17, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 359 - Batch 1 ########################
IDs in batch 1: tensor([1962, 2650, 2018, 1803,  910,  489, 1980, 3032,  317, 3988, 3876, 4022,
        2737, 1016,  566, 3264])
Epoch: 359, Training Loss: 0.52, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 360 - Batch 1 ########################
IDs in batch 1: tensor([ 170, 3010, 2180, 3943, 2809,  959, 3858, 3234, 4187, 2198, 1067, 4099,
        2725,  813,  409, 1649])
Epoch: 360, Training Loss: 0.27, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 361 - Batch 1 ########################
IDs in batch 1: tensor([ 308, 3081, 2767, 2804, 1333, 3453, 3492, 1645, 2499,  512, 3823, 3771,
        1635, 3634, 4060, 3656])
Epoch: 361, Training Loss: 0.40, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 362 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 1748, 3950,  150, 2018, 2947, 2537,  214,   77, 2117, 3996, 3587,
        3538,   39, 3310, 3779])
Epoch: 362, Training Loss: 0.20, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 363 - Batch 1 ########################
IDs in batch 1: tensor([4101,  160, 1913, 3935,  112, 3950, 3548, 3128, 2542, 3425, 3245, 2151,
        1668,  572, 1552,  467])
Epoch: 363, Training Loss: 0.40, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 364 - Batch 1 ########################
IDs in batch 1: tensor([ 714, 4234,  203,  781, 3943, 1313,  180, 4143, 1180, 2898, 3812, 2851,
        1496, 1370, 3850, 2732])
Epoch: 364, Training Loss: 0.33, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 365 - Batch 1 ########################
IDs in batch 1: tensor([1270,  266, 1773, 3233,  826, 1578, 2961, 1824, 3987, 1086,  753,  337,
        3497, 3467,  913, 3632])
Epoch: 365, Training Loss: 0.43, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 366 - Batch 1 ########################
IDs in batch 1: tensor([1162, 3360, 1866,  995, 1159, 2640, 3306, 3705, 1154, 1025,  976, 2431,
        4053, 2468, 1221,  950])
Epoch: 366, Training Loss: 0.48, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 367 - Batch 1 ########################
IDs in batch 1: tensor([3583, 2428, 1248, 2781, 2550, 3032, 3789, 1981, 2809, 1305, 3492, 1154,
        1612, 2049, 3029, 1180])
Epoch: 367, Training Loss: 0.36, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 368 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 3993, 1497, 1118,  815, 4125, 1872, 2539, 3780, 1158,  595, 1069,
        3695,  778,  356, 3056])
Epoch: 368, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 369 - Batch 1 ########################
IDs in batch 1: tensor([1443, 3514, 2765,  952,  924, 3503,  180, 2519, 2179, 3836, 2603,  530,
        3415,  620, 1022, 2106])
Epoch: 369, Training Loss: 0.58, Validation Loss: 0.50, accuracy = 0.77
Save best Model_1 @ epoch 369 acc: 0.7702227432590856
Email sent!
######################## Epoch 370 - Batch 1 ########################
IDs in batch 1: tensor([1428, 3526, 1086, 2892, 2615, 4234, 3375,  149, 1892, 3938,  583, 2807,
        3506, 1489, 4097, 3585])
Epoch: 370, Training Loss: 0.55, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 371 - Batch 1 ########################
IDs in batch 1: tensor([ 275, 1012, 1030, 1832,  688, 3862, 3187,  968, 1270, 3337, 3219,  773,
        4114, 1530, 2118,  642])
Epoch: 371, Training Loss: 0.63, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 372 - Batch 1 ########################
IDs in batch 1: tensor([3381, 1244, 2921,  191, 2710,  244, 2582,  154, 1988, 3141, 2823, 1193,
        1937, 1524,  537, 3932])
Epoch: 372, Training Loss: 0.38, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 373 - Batch 1 ########################
IDs in batch 1: tensor([2290,  824,  113, 3340, 2927, 1318, 3777, 1796, 2883, 2090, 1644, 3746,
        1321,  387, 4030, 1146])
Epoch: 373, Training Loss: 0.22, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 374 - Batch 1 ########################
IDs in batch 1: tensor([3523, 1345,  472, 3330,  435, 1472, 1104, 2942,  750, 2169,  797, 3465,
        1289, 1126, 2968, 1256])
Epoch: 374, Training Loss: 0.37, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 375 - Batch 1 ########################
IDs in batch 1: tensor([ 713, 2552,  274, 1959, 2489, 1404, 3211, 3751, 4220, 3233,  919, 3102,
         844,  180, 1178, 2472])
Epoch: 375, Training Loss: 0.46, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 376 - Batch 1 ########################
IDs in batch 1: tensor([2357, 3648, 1835, 1134, 1737, 1967, 3261, 2751, 1110, 1830, 4122, 3010,
        1824, 2242, 3372, 1098])
Epoch: 376, Training Loss: 0.29, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 377 - Batch 1 ########################
IDs in batch 1: tensor([  93, 3357, 3040,  552,  644,  371, 1892,  753, 1686, 2832, 4146, 2496,
        1678,  484, 3299, 2455])
Epoch: 377, Training Loss: 0.49, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 378 - Batch 1 ########################
IDs in batch 1: tensor([ 530, 1413, 2207, 2230, 3837,  818, 4030, 2257, 2691,   47,  615, 3536,
        1636,  967,  105, 3394])
Epoch: 378, Training Loss: 0.30, Validation Loss: 0.50, accuracy = 0.77
Save best Model_1 @ epoch 378 acc: 0.7713950762016413
Email sent!
######################## Epoch 379 - Batch 1 ########################
IDs in batch 1: tensor([4131,  110,  596,  936, 2258, 2299,  474,  343, 2300, 3360, 3311, 1620,
        2072, 4213,  238,  147])
Epoch: 379, Training Loss: 0.29, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 380 - Batch 1 ########################
IDs in batch 1: tensor([3743,  529, 3839, 3188, 4022, 3098,  308, 2172, 2343,  341, 2251, 3339,
        4006, 3079, 2821, 1485])
Epoch: 380, Training Loss: 0.44, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 381 - Batch 1 ########################
IDs in batch 1: tensor([3032, 3651, 1428, 3754,  198, 3745,  773,  660,  895, 1970, 3371,  603,
        2598, 3349,  993, 1671])
Epoch: 381, Training Loss: 0.65, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 382 - Batch 1 ########################
IDs in batch 1: tensor([3074, 1548, 2013,  823, 4089, 2995, 1143, 1588, 3528, 1993,  739, 2324,
        4065, 3240,   39, 1386])
Epoch: 382, Training Loss: 0.50, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 383 - Batch 1 ########################
IDs in batch 1: tensor([2462,  553, 1264, 1003, 3187, 2661, 3879, 4103, 3749,  713,  739, 2965,
        3598, 2508, 3830, 2177])
Epoch: 383, Training Loss: 0.40, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 384 - Batch 1 ########################
IDs in batch 1: tensor([1287, 3581,  487, 1450,  893,  848, 1050, 4245, 2468, 3600, 2290, 3193,
        2452, 3236, 3220,   30])
Epoch: 384, Training Loss: 0.54, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 385 - Batch 1 ########################
IDs in batch 1: tensor([ 818, 2499, 4093, 3423, 2506, 2959, 1563, 2282, 2998, 4068, 1453,  785,
        2359, 3624, 1595, 2798])
Epoch: 385, Training Loss: 0.36, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 386 - Batch 1 ########################
IDs in batch 1: tensor([ 252,  317, 2279, 2142,  465,  591, 2832,  712, 2600, 2148, 3234, 1937,
        1551, 1337,  985, 2127])
Epoch: 386, Training Loss: 0.32, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 387 - Batch 1 ########################
IDs in batch 1: tensor([3640, 3712,  160, 3644, 2571, 4110,  323,  658, 3105, 1476, 1746, 1649,
        3101, 3812, 2429, 3709])
Epoch: 387, Training Loss: 0.40, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 388 - Batch 1 ########################
IDs in batch 1: tensor([2995, 1223, 2150, 3020,  956, 2868, 2264, 4173, 1976,  512, 1894,  356,
        2765, 1551, 1451, 3286])
Epoch: 388, Training Loss: 0.44, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 389 - Batch 1 ########################
IDs in batch 1: tensor([ 837, 2350, 2342, 3480,  127, 3456,  482, 2776,  977, 4073, 1590, 1060,
         603,  356, 3463,  214])
Epoch: 389, Training Loss: 0.41, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 390 - Batch 1 ########################
IDs in batch 1: tensor([ 807,  969,  180, 1463, 2822, 3038, 1981, 3366, 3878, 2385, 3976, 2305,
          96,  851, 4033, 1993])
Epoch: 390, Training Loss: 0.45, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 391 - Batch 1 ########################
IDs in batch 1: tensor([3751, 1986, 1980, 3847, 3461,  247, 2817, 2442, 3091, 4078, 3065,  520,
        3668, 1704,  981,  882])
Epoch: 391, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 392 - Batch 1 ########################
IDs in batch 1: tensor([1004,   70, 3024,  869, 2787, 1562, 3709,  924, 2711, 2316, 1787, 2172,
        3839,  400, 1553,  327])
Epoch: 392, Training Loss: 0.25, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 393 - Batch 1 ########################
IDs in batch 1: tensor([2449, 1102, 3453, 2730, 3053,  111, 4204, 1008,  322, 1156, 2523, 3742,
        1001, 2506, 1292, 2832])
Epoch: 393, Training Loss: 0.58, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 394 - Batch 1 ########################
IDs in batch 1: tensor([ 292, 1242, 1070, 1706, 3498,  247, 3545, 2377, 1062, 1408, 1387, 2116,
        2700,  627,  834, 2934])
Epoch: 394, Training Loss: 0.49, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 395 - Batch 1 ########################
IDs in batch 1: tensor([1673, 3451, 3272,  259,  733, 2137, 1228, 3635, 1970,  390, 1185, 2754,
        2775, 1932, 3495, 1110])
Epoch: 395, Training Loss: 0.58, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 396 - Batch 1 ########################
IDs in batch 1: tensor([2565, 4118, 2522, 3778, 2373, 1796,   93,   35, 2376,  552,   77, 3282,
        2610, 3674, 3157, 1872])
Epoch: 396, Training Loss: 0.30, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 397 - Batch 1 ########################
IDs in batch 1: tensor([3358,  661,  736, 2118, 1882, 2038,  732, 2011, 2897, 2831, 3693, 1214,
        3354, 1448, 2681, 1613])
Epoch: 397, Training Loss: 0.61, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 398 - Batch 1 ########################
IDs in batch 1: tensor([1076, 4218,  488, 2964, 3427,  843, 2931, 1660, 4220,  740, 3180, 4189,
        4095,  813, 2965, 1065])
Epoch: 398, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 399 - Batch 1 ########################
IDs in batch 1: tensor([4254, 1111, 3866,  225, 4026, 1228, 2146, 4031, 3680, 2413,  841, 3004,
        1408, 2646, 2344, 3553])
Epoch: 399, Training Loss: 0.38, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 400 - Batch 1 ########################
IDs in batch 1: tensor([3718, 3023, 4180, 3157, 1224,  508, 1081, 1567, 2854, 3743, 3860, 3898,
        3851, 2447, 1439, 2965])
Epoch: 400, Training Loss: 0.26, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 401 - Batch 1 ########################
IDs in batch 1: tensor([4213, 2712,  334,  651, 3803,  346, 2282, 1891,  181, 4128, 2463, 2087,
        2462,  617,   43, 2368])
Epoch: 401, Training Loss: 0.18, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 402 - Batch 1 ########################
IDs in batch 1: tensor([2550, 3397, 1950, 1685, 2485, 1789, 3664, 1871, 4076, 3608, 3744, 3808,
          35,  846, 3188,  658])
Epoch: 402, Training Loss: 0.57, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 403 - Batch 1 ########################
IDs in batch 1: tensor([4097, 4175, 3279,  104, 1937, 2036, 1935, 2777, 4267, 3049, 4044,  944,
        4005, 2872, 1704, 1037])
Epoch: 403, Training Loss: 0.45, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 404 - Batch 1 ########################
IDs in batch 1: tensor([ 980, 2484, 3119, 1354, 1289, 3756, 2824, 4168,  857, 2561, 3102, 1463,
         660, 3912, 2743, 2815])
Epoch: 404, Training Loss: 0.43, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 405 - Batch 1 ########################
IDs in batch 1: tensor([3036, 1370,  658, 4082, 2963,  752, 2354, 1794, 2224, 3913, 4190, 1784,
        3424, 1500, 1661, 3765])
Epoch: 405, Training Loss: 0.44, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 406 - Batch 1 ########################
IDs in batch 1: tensor([1391, 2520, 1124, 2265, 2451, 2317, 1632, 1160, 1390,  136, 1450, 3214,
        4163, 2514, 3444, 3207])
Epoch: 406, Training Loss: 0.25, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 407 - Batch 1 ########################
IDs in batch 1: tensor([4015, 2741, 3014, 1509,  476, 3222,  393, 3289, 3143, 3632, 1660, 2279,
        3123, 3568, 2118, 3797])
Epoch: 407, Training Loss: 0.29, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 408 - Batch 1 ########################
IDs in batch 1: tensor([2789, 2898, 2931,  582,  718, 3525, 3772, 3587, 3621, 2379, 2031, 2751,
        2983, 1020,   31, 3856])
Epoch: 408, Training Loss: 0.40, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 409 - Batch 1 ########################
IDs in batch 1: tensor([3038,  883, 1491,  523,  891, 1047, 2536,  321, 1762, 2482,  605,  111,
        1519, 1871, 1316, 1218])
Epoch: 409, Training Loss: 0.57, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 410 - Batch 1 ########################
IDs in batch 1: tensor([1367,  110, 3219, 4232, 2656, 1657, 1982,  917, 4115, 1393, 4080, 1357,
        1279, 1685, 3378, 1485])
Epoch: 410, Training Loss: 0.40, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 411 - Batch 1 ########################
IDs in batch 1: tensor([ 758, 1024,  944, 1113, 2417, 3493,  127, 3400, 2571, 2317, 4268,  921,
        2173, 1277, 4068, 1883])
Epoch: 411, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 412 - Batch 1 ########################
IDs in batch 1: tensor([3961, 3487,  312, 3271, 2452, 3159, 2193, 3706, 1684, 2885, 2433,  639,
        2346, 1573, 2195, 1139])
Epoch: 412, Training Loss: 0.36, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 413 - Batch 1 ########################
IDs in batch 1: tensor([3194, 3377, 3732,  143, 4131, 2990, 4080, 3105, 1871, 1782, 2394,   92,
        2736, 1218, 2399,  352])
Epoch: 413, Training Loss: 0.44, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 414 - Batch 1 ########################
IDs in batch 1: tensor([ 440,  884, 3069, 2638, 1850, 1012,   27, 3637, 1521, 2181, 3025, 2729,
        2359, 1639, 1881, 3939])
Epoch: 414, Training Loss: 0.65, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 415 - Batch 1 ########################
IDs in batch 1: tensor([2646, 3345,  740, 1104,  402,  814,  218, 1730,  575,  544, 1399, 3710,
        2489, 2416, 1044, 3216])
Epoch: 415, Training Loss: 0.44, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 416 - Batch 1 ########################
IDs in batch 1: tensor([1931, 3539, 1421, 4008, 3318,  646, 3102,  373, 1935,  334,  325, 3638,
        2465, 1497, 3208, 1421])
Epoch: 416, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 417 - Batch 1 ########################
IDs in batch 1: tensor([1684, 2964, 2195, 1489, 4265, 2097, 3371, 2274, 3398, 2567, 1123, 2224,
        2833, 4213, 1551, 2097])
Epoch: 417, Training Loss: 0.31, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 418 - Batch 1 ########################
IDs in batch 1: tensor([4168, 1049, 3952, 2337, 1731, 2153, 3091, 2423, 3427, 2339, 3136,  108,
         631, 2234,  355, 2798])
Epoch: 418, Training Loss: 0.25, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 419 - Batch 1 ########################
IDs in batch 1: tensor([1463, 1857, 2706, 4058, 3630, 3723, 2692, 3731, 4008, 1614, 1619, 3072,
        1578,   14, 2583, 1660])
Epoch: 419, Training Loss: 0.34, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 420 - Batch 1 ########################
IDs in batch 1: tensor([3985, 3438, 1911, 1627,  965, 2616, 3785, 2355, 2253, 2579, 2212,  485,
        3343, 2344, 3409,  844])
Epoch: 420, Training Loss: 0.32, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 421 - Batch 1 ########################
IDs in batch 1: tensor([1679, 1862, 1159, 1325, 3872, 3539,  934, 1334, 3490, 1663,  459,  920,
        3381, 1485, 3458,  897])
Epoch: 421, Training Loss: 0.53, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 422 - Batch 1 ########################
IDs in batch 1: tensor([ 918, 1677, 2443, 4036, 3310,  704,  377, 3435,  376, 3166, 3935, 2624,
        1884, 3286, 3705, 4048])
Epoch: 422, Training Loss: 0.35, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 423 - Batch 1 ########################
IDs in batch 1: tensor([4031,  685, 3451, 4078, 1155, 2300,   32, 2648, 3654, 1396, 2712, 4161,
         974, 3053,  323,  947])
Epoch: 423, Training Loss: 0.29, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 424 - Batch 1 ########################
IDs in batch 1: tensor([1472, 2117, 2313,   64, 2559, 3501, 4158, 1193, 2334, 2499,  989, 4026,
           7, 1458, 1387, 1901])
Epoch: 424, Training Loss: 0.32, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 425 - Batch 1 ########################
IDs in batch 1: tensor([ 274, 2914, 3671, 3549, 4050, 3590, 3636, 3436, 3065, 1274, 2859, 1102,
        3071, 2564, 2046, 3126])
Epoch: 425, Training Loss: 0.63, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 426 - Batch 1 ########################
IDs in batch 1: tensor([3786, 1760, 1123,  952, 2217, 1858, 2537, 1706, 1345,  265, 2884, 3729,
        2743, 3276, 4235, 4166])
Epoch: 426, Training Loss: 0.29, Validation Loss: 0.52, accuracy = 0.74
######################## Epoch 427 - Batch 1 ########################
IDs in batch 1: tensor([ 445,  335, 1536,  160, 1673, 1124, 3370, 2157, 3410, 3787, 3845, 2126,
        2890, 3154, 3718, 2701])
Epoch: 427, Training Loss: 0.21, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 428 - Batch 1 ########################
IDs in batch 1: tensor([1844,  535,  713, 1271, 3279, 1047,  117, 4126, 2028,  474, 3262, 3203,
        1914, 1859,  236, 2002])
Epoch: 428, Training Loss: 0.33, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 429 - Batch 1 ########################
IDs in batch 1: tensor([1384, 1948, 1017, 1001, 2600, 1951, 3448, 1782,  981, 3321, 1063, 1281,
         807, 3945,  740, 3259])
Epoch: 429, Training Loss: 0.45, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 430 - Batch 1 ########################
IDs in batch 1: tensor([3958, 3587, 2123, 3284,  102, 3728, 1485,  917,  134,  653, 3634, 1562,
        1937,  367, 1678, 3544])
Epoch: 430, Training Loss: 0.42, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 431 - Batch 1 ########################
IDs in batch 1: tensor([ 667, 2664, 1345, 2627, 4119,  237,  828, 1821, 2797, 1945, 3040, 1613,
          93, 3813, 2697, 2826])
Epoch: 431, Training Loss: 0.36, Validation Loss: 0.51, accuracy = 0.74
######################## Epoch 432 - Batch 1 ########################
IDs in batch 1: tensor([ 627, 3668, 1177,  312,  539, 3712,  811, 3466,  941, 1271, 1426, 3357,
        3518, 1830, 3261, 3733])
Epoch: 432, Training Loss: 0.49, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 433 - Batch 1 ########################
IDs in batch 1: tensor([1171,  767, 3265, 1612, 3044, 3126, 1650, 1399,  277, 3859, 1092,  632,
        4110,  909,   43,  207])
Epoch: 433, Training Loss: 0.88, Validation Loss: 0.50, accuracy = 0.75
######################## Epoch 434 - Batch 1 ########################
IDs in batch 1: tensor([2767,  730, 4261, 3972, 2324, 3417, 1902,  792,  824, 3010, 1916, 2154,
        2464, 3591,  610, 3925])
Epoch: 434, Training Loss: 0.52, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 435 - Batch 1 ########################
IDs in batch 1: tensor([1954, 1859, 3534, 2619, 2732, 1113, 2223,  902, 2080, 3139, 1375, 3135,
        4265, 3060, 3511, 2661])
Epoch: 435, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.75
######################## Epoch 436 - Batch 1 ########################
IDs in batch 1: tensor([2980, 1069, 1984,  276, 4067, 2729,  530, 3833, 2118, 2027,  287, 3233,
        2352,  337, 2691, 1897])
Epoch: 436, Training Loss: 0.48, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 437 - Batch 1 ########################
IDs in batch 1: tensor([3577,   47,  683, 3782, 3693, 1576, 3591, 1880, 1133,   24, 2377,  992,
        3304, 2150, 3055,  693])
Epoch: 437, Training Loss: 0.66, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 438 - Batch 1 ########################
IDs in batch 1: tensor([3500, 1312, 1144,  536,  966, 3873, 3777, 1143, 3058,  103, 1878, 2419,
        3378, 3404, 1209, 3349])
Epoch: 438, Training Loss: 0.45, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 439 - Batch 1 ########################
IDs in batch 1: tensor([1042, 1008, 3353, 2437, 1504, 2838, 1810, 1319, 1141, 1986,  789, 1605,
          20, 3303,  102, 2991])
Epoch: 439, Training Loss: 0.34, Validation Loss: 0.49, accuracy = 0.77
Save best Model_1 @ epoch 439 acc: 0.772567409144197
Email sent!
######################## Epoch 440 - Batch 1 ########################
IDs in batch 1: tensor([3200, 3977, 2212, 3117,  308,  685, 2337, 1802, 2535, 2795, 3616, 2721,
        1007, 1110, 1310, 3496])
Epoch: 440, Training Loss: 0.33, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 441 - Batch 1 ########################
IDs in batch 1: tensor([3374, 2386, 3642,  886,  477, 1602, 3370, 4131, 2209, 2664, 1141, 3993,
        2867, 3128, 4038,  879])
Epoch: 441, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 442 - Batch 1 ########################
IDs in batch 1: tensor([3330, 2106, 2344,  591, 3178, 1242, 1178, 3108, 2782,  656, 1223, 2306,
         786,  127, 1098, 1980])
Epoch: 442, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.77
Save best Model_1 @ epoch 442 acc: 0.7749120750293084
Email sent!
######################## Epoch 443 - Batch 1 ########################
IDs in batch 1: tensor([4086, 3529, 3463, 2833, 1613, 2406,   97, 2365, 3651, 3079, 4196, 1081,
        3291,  584, 2851, 3547])
Epoch: 443, Training Loss: 0.26, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 444 - Batch 1 ########################
IDs in batch 1: tensor([1671, 3391, 3847, 3298, 1042, 3262,  630, 1183, 1670,  173, 4184, 4039,
        3847, 1432, 1005, 3533])
Epoch: 444, Training Loss: 0.44, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 445 - Batch 1 ########################
IDs in batch 1: tensor([2809,  377, 2483, 2347, 4099, 3697,  863, 2258, 1646,  679, 1117,  693,
        2118, 1154, 2498, 3668])
Epoch: 445, Training Loss: 0.37, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 446 - Batch 1 ########################
IDs in batch 1: tensor([ 350, 3732, 1126,  127, 2793, 1170, 3895,  529, 3284, 3379, 1927, 1225,
        2482, 4036, 1122, 3326])
Epoch: 446, Training Loss: 0.35, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 447 - Batch 1 ########################
IDs in batch 1: tensor([3866,  300,  626,  591, 2733,  112, 3710, 3617, 2536, 2234, 1434, 2064,
        2847, 3268,  773, 3278])
Epoch: 447, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 448 - Batch 1 ########################
IDs in batch 1: tensor([2286, 1244, 2645, 1934, 2693, 3438,  809,  872, 2542,  626, 2132, 2959,
        1155, 1131, 3601,  225])
Epoch: 448, Training Loss: 0.45, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 449 - Batch 1 ########################
IDs in batch 1: tensor([1269, 1497, 3731, 2177,  835, 1084, 3996, 3206, 3751,  258, 1590,  604,
        3278, 3524,  952, 4228])
Epoch: 449, Training Loss: 0.60, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 450 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 3982, 1716, 3875, 1892, 1601, 2341, 1467, 3351,  462, 3964, 1146,
        2746, 3829, 1861, 1961])
Epoch: 450, Training Loss: 0.34, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 451 - Batch 1 ########################
IDs in batch 1: tensor([3495, 1282, 3648, 2011, 1248, 2359, 3926, 4181, 2853, 3533, 4056,  359,
        3374, 3427,  438, 1204])
Epoch: 451, Training Loss: 0.58, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 452 - Batch 1 ########################
IDs in batch 1: tensor([1256, 1027,  947, 2408, 1440, 4077, 1155, 1309, 3956, 2574, 2453, 2746,
        3618, 1391,  672, 1005])
Epoch: 452, Training Loss: 0.56, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 453 - Batch 1 ########################
IDs in batch 1: tensor([3144,  102, 2883,   56, 2388, 3304,  369, 3284, 4014, 2104, 3588, 1967,
        2419,  333,  994, 2650])
Epoch: 453, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 454 - Batch 1 ########################
IDs in batch 1: tensor([3256, 3738,  536, 3154, 3954,  985, 4068, 2956, 1073,  910, 2589, 3228,
        1909, 3514, 2579, 2476])
Epoch: 454, Training Loss: 0.34, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 455 - Batch 1 ########################
IDs in batch 1: tensor([1877,  320, 2856, 2645, 3914, 3997,  961, 3970, 1518, 1263,  805, 1351,
        4223, 3987, 1134,  673])
Epoch: 455, Training Loss: 0.66, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 456 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 3900, 2124, 3278, 3526, 1147, 1818, 2252, 2106, 1027, 1551, 1077,
          62, 1720, 2874,  529])
Epoch: 456, Training Loss: 0.42, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 457 - Batch 1 ########################
IDs in batch 1: tensor([ 557,  442, 2558, 4174, 3650,  106, 2815, 4004, 3872, 3375,  809, 3003,
        1526, 1153, 2524, 1239])
Epoch: 457, Training Loss: 0.25, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 458 - Batch 1 ########################
IDs in batch 1: tensor([1731, 2341, 3131, 3146, 3082, 2248, 1012, 4065, 3417,  426, 3142, 1110,
        2066, 2995, 2178,  110])
Epoch: 458, Training Loss: 0.35, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 459 - Batch 1 ########################
IDs in batch 1: tensor([2286, 3016, 4152,   39, 3343,  477, 3583, 2090, 3547,  524, 1087, 3706,
        2676,  513, 1634, 3976])
Epoch: 459, Training Loss: 0.21, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 460 - Batch 1 ########################
IDs in batch 1: tensor([ 591, 3072, 2134, 1269, 3069, 3060,  333,  101, 2010,  398, 4012, 1726,
        3573, 1193, 1221, 4013])
Epoch: 460, Training Loss: 0.23, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 461 - Batch 1 ########################
IDs in batch 1: tensor([4181, 3071, 3617, 1923,  332, 3836, 2229, 3952, 1069,  459, 3656, 2036,
        1225, 3099, 4036, 1748])
Epoch: 461, Training Loss: 0.30, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 462 - Batch 1 ########################
IDs in batch 1: tensor([1558, 1380, 2431, 3786, 2027, 2248, 1781, 3778, 2078, 2676, 2493, 1878,
        2725, 3930, 3451,  469])
Epoch: 462, Training Loss: 0.35, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 463 - Batch 1 ########################
IDs in batch 1: tensor([3401, 1285,  789,  348, 3936, 2347,  846, 1589, 2711,  100,  405, 2040,
         264, 2600, 2419,  701])
Epoch: 463, Training Loss: 0.49, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 464 - Batch 1 ########################
IDs in batch 1: tensor([ 472, 1381, 4229, 1870, 1979, 4141, 3239, 2439, 1882, 3953, 4118, 1563,
        1088, 1732,  451, 3763])
Epoch: 464, Training Loss: 0.41, Validation Loss: 0.54, accuracy = 0.74
######################## Epoch 465 - Batch 1 ########################
IDs in batch 1: tensor([2126, 1117,  591, 1437, 3926,  132,  752, 3101, 3563,  492,   52, 3656,
        3355,  239, 2700,  290])
Epoch: 465, Training Loss: 0.35, Validation Loss: 0.54, accuracy = 0.74
######################## Epoch 466 - Batch 1 ########################
IDs in batch 1: tensor([2648, 2073, 2412,  967,  519, 3284, 2237, 1451,  981, 4170, 3934, 3214,
        3701,  507, 2196,  357])
Epoch: 466, Training Loss: 0.29, Validation Loss: 0.54, accuracy = 0.74
######################## Epoch 467 - Batch 1 ########################
IDs in batch 1: tensor([3692, 1812, 4185, 3183, 3564, 3567,  300,  206, 3496,  736, 3392, 3984,
        2332, 1881, 3479, 3513])
Epoch: 467, Training Loss: 0.48, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 468 - Batch 1 ########################
IDs in batch 1: tensor([  43, 3236, 2644, 2161, 1372,  167, 2973, 2466, 2123,  991, 4257, 2844,
         147, 2797, 1965,  557])
Epoch: 468, Training Loss: 0.50, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 469 - Batch 1 ########################
IDs in batch 1: tensor([1798,  688, 1510,  161,  108, 3203, 2442, 3898,  274,  723,  554, 2485,
        3159, 3039, 3040, 3506])
Epoch: 469, Training Loss: 0.32, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 470 - Batch 1 ########################
IDs in batch 1: tensor([2868,  989, 2629, 2697,  340, 2347,  232, 2461, 2833, 1291, 1157, 2014,
         975, 4101, 1414, 1133])
Epoch: 470, Training Loss: 0.32, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 471 - Batch 1 ########################
IDs in batch 1: tensor([3493, 2127, 1001, 3651,  255,  223,  586, 2853, 1730, 2978, 3695, 2887,
          31, 3056, 4186, 1147])
Epoch: 471, Training Loss: 0.15, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 472 - Batch 1 ########################
IDs in batch 1: tensor([3378,   77, 1045, 3475, 1397, 2783,  300, 1377, 3433, 2117,  804,   38,
        1828, 1432, 1647,  265])
Epoch: 472, Training Loss: 0.53, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 473 - Batch 1 ########################
IDs in batch 1: tensor([3934, 2749,  688, 3415, 3218, 1933,  573, 2410,  320, 1060, 3208, 2428,
         279,  920,  262,  757])
Epoch: 473, Training Loss: 0.34, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 474 - Batch 1 ########################
IDs in batch 1: tensor([1428, 3664, 3962, 2718, 2578,  683, 3101,  135, 2331,  640, 2112, 4033,
          10, 1481, 3509, 2587])
Epoch: 474, Training Loss: 0.30, Validation Loss: 0.49, accuracy = 0.78
Save best Model_1 @ epoch 474 acc: 0.776084407971864
Email sent!
######################## Epoch 475 - Batch 1 ########################
IDs in batch 1: tensor([1017, 2306, 4122, 3962, 2365,  323, 3111, 4013, 2777, 2663, 1904, 4184,
        3740, 3945, 2868, 1963])
Epoch: 475, Training Loss: 0.42, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 476 - Batch 1 ########################
IDs in batch 1: tensor([1374,  613, 3876,   47, 1887, 3949, 1591, 3837, 1519,  732, 4187,  832,
        1098, 2956, 1685, 3729])
Epoch: 476, Training Loss: 0.42, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 477 - Batch 1 ########################
IDs in batch 1: tensor([2691,  950, 2610, 3781, 3507, 1305,  587,   51, 1857, 2376, 1406,   49,
        1209,  498, 2619,   95])
Epoch: 477, Training Loss: 0.44, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 478 - Batch 1 ########################
IDs in batch 1: tensor([3874, 3407, 2789, 4189, 2183,   42, 1498,  547,  996,  388, 3683,  900,
        1724,  203, 3726, 2908])
Epoch: 478, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 479 - Batch 1 ########################
IDs in batch 1: tensor([3124,  897,  828, 3300, 4067, 1949, 2056, 3399,  915,  212, 3157, 1131,
        3862,  472, 2339, 2276])
Epoch: 479, Training Loss: 0.47, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 480 - Batch 1 ########################
IDs in batch 1: tensor([3446, 4228,  345,  104, 2099,  372, 1122, 3516, 4224, 3808, 2230, 4003,
        3762, 3932, 1337,  105])
Epoch: 480, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 481 - Batch 1 ########################
IDs in batch 1: tensor([3962, 2806, 3656, 3945, 2224,  757,  635, 1176,  395, 1287, 1810, 2510,
        1434, 3898, 2148, 3016])
Epoch: 481, Training Loss: 0.52, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 482 - Batch 1 ########################
IDs in batch 1: tensor([1425, 1745,  487, 2835, 3821, 3961,  462,  920,  896,  626, 1011, 3228,
         490, 4125, 4213, 3437])
Epoch: 482, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 483 - Batch 1 ########################
IDs in batch 1: tensor([2925, 4080, 2721,   68, 1583, 1949, 1128, 2400, 1291, 2094, 4235,  727,
        3952,  501,  354, 2974])
Epoch: 483, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 484 - Batch 1 ########################
IDs in batch 1: tensor([2473, 4005,  418, 3920,  781,  896, 1634, 1963, 1971, 1660, 2256, 3976,
          49, 2791, 3563, 2118])
Epoch: 484, Training Loss: 0.31, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 485 - Batch 1 ########################
IDs in batch 1: tensor([2359,  430, 2347,  412,  155, 3398, 3423, 1979, 2632, 2791, 1226, 2419,
        3002,  657, 3038, 2072])
Epoch: 485, Training Loss: 0.27, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 486 - Batch 1 ########################
IDs in batch 1: tensor([2995, 2703, 2963, 3440, 3999, 2250, 4266, 3022, 1456, 3997, 3521, 2413,
        1084, 1062,  572, 1968])
Epoch: 486, Training Loss: 0.65, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 487 - Batch 1 ########################
IDs in batch 1: tensor([1537,  177,  510, 3706,   73, 1681,  524, 3513, 4061, 2315, 3543,   93,
        2763,  890, 1143, 3435])
Epoch: 487, Training Loss: 0.50, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 488 - Batch 1 ########################
IDs in batch 1: tensor([3663, 3541, 2295,  477, 4093, 3159, 2253, 2118, 3401, 2524,  907, 1658,
        1835, 1948,  607, 3243])
Epoch: 488, Training Loss: 0.35, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 489 - Batch 1 ########################
IDs in batch 1: tensor([1611, 2092, 1619, 2993, 1158, 1136, 3487, 3704, 2495, 1197, 1583,  440,
         626,  450, 3919, 2980])
Epoch: 489, Training Loss: 0.38, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 490 - Batch 1 ########################
IDs in batch 1: tensor([3466, 2966, 3618, 3040,  735, 3084, 2008,  432, 2030,  981, 4053,    5,
         558, 4076, 2426, 2148])
Epoch: 490, Training Loss: 0.28, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 491 - Batch 1 ########################
IDs in batch 1: tensor([2868,  645,  432,  730, 4204,  738,  724, 2966,  844, 3846,  139, 2034,
        3110,  340, 4214, 1955])
Epoch: 491, Training Loss: 0.51, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 492 - Batch 1 ########################
IDs in batch 1: tensor([2346,   85, 1356, 2548,  409, 3132, 3432, 1332, 3488, 3114, 3993, 3514,
        1980, 1221, 3961, 3443])
Epoch: 492, Training Loss: 0.21, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 493 - Batch 1 ########################
IDs in batch 1: tensor([1297, 2256, 1226, 2198, 2117, 2739, 1661,  110, 3981,  844, 1858, 4225,
        2497,  172,  256, 1884])
Epoch: 493, Training Loss: 0.36, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 494 - Batch 1 ########################
IDs in batch 1: tensor([1685,  712, 1010,  181, 3883, 2680, 2833,  680,  710, 1007, 1044,  405,
        1367,  928, 1734,  908])
Epoch: 494, Training Loss: 0.90, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 495 - Batch 1 ########################
IDs in batch 1: tensor([2435, 4146, 2506, 2739, 2853, 2182, 2986,  989, 4225, 4025,  337, 3157,
        3182, 3780, 3183, 3368])
Epoch: 495, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 496 - Batch 1 ########################
IDs in batch 1: tensor([4080, 1512, 3953, 3875, 1419, 1591,  881, 2874, 4165, 1022, 2300,  733,
        1200,  881, 1731, 2837])
Epoch: 496, Training Loss: 0.21, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 497 - Batch 1 ########################
IDs in batch 1: tensor([3829, 1085, 1619, 3599, 1673, 2236, 1054,  141, 3705,  899, 3404, 4007,
         640,  105,  937, 2511])
Epoch: 497, Training Loss: 0.53, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 498 - Batch 1 ########################
IDs in batch 1: tensor([3806, 3886, 2724,  960, 3917, 3112, 2426, 1895, 4035, 2565, 2431, 3651,
        2327, 1932,  803,  891])
Epoch: 498, Training Loss: 0.52, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 499 - Batch 1 ########################
IDs in batch 1: tensor([2676,  135, 1315, 1999, 1656, 1779, 1453, 2334, 3548,  337,  134, 3961,
        3689,  873,  945, 1863])
Epoch: 499, Training Loss: 0.46, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 500 - Batch 1 ########################
IDs in batch 1: tensor([2432,  167,  738, 2638, 1334, 1511, 1938, 3976, 3572, 2736, 4124,  771,
        2544,  673, 1897, 1410])
Epoch: 500, Training Loss: 0.26, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 501 - Batch 1 ########################
IDs in batch 1: tensor([3441,  848,  165, 2276,  574,  359,  322, 2578,   60, 2737, 1294, 2668,
         713, 1179, 2711, 1957])
Epoch: 501, Training Loss: 0.46, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 502 - Batch 1 ########################
IDs in batch 1: tensor([1365, 1991, 4060, 3609,  236, 1034, 2484, 1197, 1232, 2306, 3279,  694,
        2425, 2144, 3109, 1452])
Epoch: 502, Training Loss: 0.26, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 503 - Batch 1 ########################
IDs in batch 1: tensor([1066, 1263, 2247, 2423, 1344, 1682, 3650,  478, 2287, 1927,   46, 2552,
        1770,  219,   13,  755])
Epoch: 503, Training Loss: 0.64, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 504 - Batch 1 ########################
IDs in batch 1: tensor([1289, 3113, 3252, 3650, 3930, 2494, 2809,  289,  774, 2538, 1745,  558,
        1264, 2085, 2116, 1056])
Epoch: 504, Training Loss: 0.33, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 505 - Batch 1 ########################
IDs in batch 1: tensor([ 531, 3960, 2763, 2253, 3874, 1562, 1626, 3143, 3020, 2220, 2706, 2581,
        3291, 1525,  816, 1918])
Epoch: 505, Training Loss: 0.32, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 506 - Batch 1 ########################
IDs in batch 1: tensor([1182, 2296, 3521, 1229,  424,  531, 2680, 1134, 2564, 3608,  444, 3530,
        1077, 2967, 2510, 2954])
Epoch: 506, Training Loss: 0.22, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 507 - Batch 1 ########################
IDs in batch 1: tensor([  25,  642, 1779, 3654, 2414,  482,  140, 2478, 3704,  838, 1469,   44,
        1410, 3900, 2894, 3921])
Epoch: 507, Training Loss: 0.32, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 508 - Batch 1 ########################
IDs in batch 1: tensor([3943,  977, 1283, 3926, 2451, 3707, 3525, 2005, 2986, 3592,  753, 2405,
        2833, 3917, 3726, 1181])
Epoch: 508, Training Loss: 0.39, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 509 - Batch 1 ########################
IDs in batch 1: tensor([ 212, 2046, 2990,  388, 2478, 2582, 2146, 2149, 3847,  749, 1356,   96,
         974, 2776, 2726, 2245])
Epoch: 509, Training Loss: 0.27, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 510 - Batch 1 ########################
IDs in batch 1: tensor([1357, 1397,  822, 2232, 1773, 2462, 2568, 1627, 3384, 3542, 1199, 1110,
         218, 3672, 2349, 4076])
Epoch: 510, Training Loss: 0.34, Validation Loss: 0.46, accuracy = 0.77
######################## Epoch 511 - Batch 1 ########################
IDs in batch 1: tensor([1399, 1009, 3385,  874,    7, 3544, 2504, 1611, 2167, 3505,  594,   56,
        4257, 1279, 3524,   82])
Epoch: 511, Training Loss: 0.26, Validation Loss: 0.46, accuracy = 0.77
######################## Epoch 512 - Batch 1 ########################
IDs in batch 1: tensor([2950, 4223, 1883, 1008, 3374,  842,   73, 2670,  317, 3328, 1588,  866,
        2854, 1752,  615,  670])
Epoch: 512, Training Loss: 0.49, Validation Loss: 0.46, accuracy = 0.78
Save best Model_1 @ epoch 512 acc: 0.779601406799531
Email sent!
######################## Epoch 513 - Batch 1 ########################
IDs in batch 1: tensor([2610, 3299,  394, 1504, 2589, 2723, 1321, 3588, 2019, 2247, 3220,  317,
        3789, 2072,  640,  871])
Epoch: 513, Training Loss: 0.36, Validation Loss: 0.46, accuracy = 0.78
Save best Model_1 @ epoch 513 acc: 0.7819460726846424
Email sent!
######################## Epoch 514 - Batch 1 ########################
IDs in batch 1: tensor([3553, 1437, 3091, 4238, 2213, 3594, 1793, 4011, 2024, 2581,  593,  955,
        1136,  219, 3147, 3400])
Epoch: 514, Training Loss: 0.65, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 515 - Batch 1 ########################
IDs in batch 1: tensor([2461, 2632, 4095,  667, 2393, 1160,  996, 3866, 3498, 1381, 1180, 2828,
        3427,  607, 3850, 1089])
Epoch: 515, Training Loss: 0.22, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 516 - Batch 1 ########################
IDs in batch 1: tensor([3081, 3597, 1640,  977, 1927,  895, 2828, 2619, 2860, 3223, 1060,  829,
        3497, 3147,  753, 1082])
Epoch: 516, Training Loss: 0.32, Validation Loss: 0.46, accuracy = 0.79
Save best Model_1 @ epoch 516 acc: 0.7854630715123095
Email sent!
######################## Epoch 517 - Batch 1 ########################
IDs in batch 1: tensor([2739, 3838, 2676, 3837, 2788,  191,  823,  127, 3124,  470, 2848, 2526,
        3100, 1682, 1273, 1944])
Epoch: 517, Training Loss: 0.26, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 518 - Batch 1 ########################
IDs in batch 1: tensor([3303,  152, 3637, 3617, 3270, 4258, 1670,  435, 1137,  710, 3255, 3314,
        3351, 1324, 3659, 2388])
Epoch: 518, Training Loss: 0.17, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 519 - Batch 1 ########################
IDs in batch 1: tensor([2360,   84, 1844, 2429, 1882, 3862,  727, 2827, 4053,  503, 1402, 4127,
        2249, 1822, 1950, 1347])
Epoch: 519, Training Loss: 0.23, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 520 - Batch 1 ########################
IDs in batch 1: tensor([3448,  848, 2189, 2004, 2342,    7, 1266, 4044, 2148, 3530, 1271, 1163,
        2448, 2150,  530, 3022])
Epoch: 520, Training Loss: 0.51, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 521 - Batch 1 ########################
IDs in batch 1: tensor([1386, 2646, 3177, 3345,  361, 3275, 3845, 2304, 3326,  797,  921,  758,
        1178,  915, 2153, 3207])
Epoch: 521, Training Loss: 0.25, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 522 - Batch 1 ########################
IDs in batch 1: tensor([ 606, 2866, 1208, 1782, 2671, 2291,   39, 3738, 3640, 2331, 3151, 2234,
         949, 1551,  263,  469])
Epoch: 522, Training Loss: 0.34, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 523 - Batch 1 ########################
IDs in batch 1: tensor([2025,  375, 1425, 3071,  778, 2235, 4039,  427, 1762, 2088, 1952, 3826,
        2696, 3360, 1136, 2489])
Epoch: 523, Training Loss: 0.23, Validation Loss: 0.46, accuracy = 0.78
######################## Epoch 524 - Batch 1 ########################
IDs in batch 1: tensor([3006, 3528, 1958, 2615, 3156,   72, 2949, 3728, 3692, 1502, 2426, 2413,
         321, 2017, 2369, 3964])
Epoch: 524, Training Loss: 0.33, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 525 - Batch 1 ########################
IDs in batch 1: tensor([ 577, 2968,  807, 2059,  201, 2710, 2357, 2036, 3971,  566, 4056, 2783,
        1949, 1732,  750, 3382])
Epoch: 525, Training Loss: 0.26, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 526 - Batch 1 ########################
IDs in batch 1: tensor([2925, 3356, 2746, 2124, 2425, 3534,  735, 4055, 3802, 3108,   39, 3400,
        1545, 1195, 3252, 2470])
Epoch: 526, Training Loss: 0.44, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 527 - Batch 1 ########################
IDs in batch 1: tensor([4258, 1702, 2541, 3507, 2064, 3671,  766, 3914,  314, 3035, 1480, 3443,
        1512, 2706,  346, 1497])
Epoch: 527, Training Loss: 0.58, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 528 - Batch 1 ########################
IDs in batch 1: tensor([2484,  418,  724, 2449, 3379, 1289,  538, 2390, 1568, 1257, 2914,  259,
        1417,  245,  593,  607])
Epoch: 528, Training Loss: 0.51, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 529 - Batch 1 ########################
IDs in batch 1: tensor([3197, 1310, 1568, 1537, 4006, 2132, 3860, 4148, 3208, 2343,  841, 2300,
        3242,  884, 4158, 3123])
Epoch: 529, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 530 - Batch 1 ########################
IDs in batch 1: tensor([3429,  346, 1841,  360, 2516, 4010, 3374, 1610, 1279, 4127, 2749, 2423,
        1130,  207, 1822,  355])
Epoch: 530, Training Loss: 0.43, Validation Loss: 0.48, accuracy = 0.79
Save best Model_1 @ epoch 530 acc: 0.7878077373974208
Email sent!
######################## Epoch 531 - Batch 1 ########################
IDs in batch 1: tensor([3950, 2734, 2927, 1128, 3995, 1347, 3376, 1614, 1419,  418, 1354, 1693,
        1467, 2687, 1733,  965])
Epoch: 531, Training Loss: 0.34, Validation Loss: 0.48, accuracy = 0.79
Save best Model_1 @ epoch 531 acc: 0.7924970691676436
Email sent!
######################## Epoch 532 - Batch 1 ########################
IDs in batch 1: tensor([3630, 4126, 1642, 2285,  415, 2433, 1047, 4168,  407,  714,  368, 3287,
        3430, 3441, 1980, 2648])
Epoch: 532, Training Loss: 0.20, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 533 - Batch 1 ########################
IDs in batch 1: tensor([1731, 3664, 3636, 4256, 2563, 2925,  730, 3738,  451, 2182, 3940,  870,
        4196, 3823, 2317, 1319])
Epoch: 533, Training Loss: 0.51, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 534 - Batch 1 ########################
IDs in batch 1: tensor([3184, 2387, 2703, 2643, 2652,  852, 1891, 4245, 1179, 2571,  584, 3386,
        1765, 3488, 1318, 1116])
Epoch: 534, Training Loss: 0.43, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 535 - Batch 1 ########################
IDs in batch 1: tensor([2377, 3563, 1812, 1842, 3525, 3875, 1322, 4196, 2646, 1945, 1256, 2740,
        1286, 1015,  452, 2956])
Epoch: 535, Training Loss: 0.36, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 536 - Batch 1 ########################
IDs in batch 1: tensor([2009, 2483, 1084, 1236, 2323, 2783, 1935,  354, 2344, 3075, 1296, 2060,
        1146, 2764,  321, 3534])
Epoch: 536, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 537 - Batch 1 ########################
IDs in batch 1: tensor([  71, 2070, 3392,  553, 2456,  902, 1495, 1894, 1518, 4013,  181, 1760,
        2773, 1974, 3455, 3661])
Epoch: 537, Training Loss: 0.51, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 538 - Batch 1 ########################
IDs in batch 1: tensor([3795, 1525, 1406,  513, 2670,  899,  535,  659, 2169, 2262, 3110, 3969,
        2063, 3985, 3733, 2051])
Epoch: 538, Training Loss: 0.50, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 539 - Batch 1 ########################
IDs in batch 1: tensor([  64, 1675, 1845, 1948, 2838, 2793, 3356,  165, 3714, 1794, 3117, 1510,
        1799, 2002, 1473, 3248])
Epoch: 539, Training Loss: 0.28, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 540 - Batch 1 ########################
IDs in batch 1: tensor([3912,   14, 3742, 2069, 3207, 2250, 2832, 1782, 2328,  261, 1543, 1525,
         243, 4115,  985, 2925])
Epoch: 540, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 541 - Batch 1 ########################
IDs in batch 1: tensor([2180, 1600, 3755, 1201,  195, 1330, 2410, 3279,  350,  902, 3545, 2883,
        1294, 2761, 1089, 1830])
Epoch: 541, Training Loss: 0.37, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 542 - Batch 1 ########################
IDs in batch 1: tensor([4134, 3554, 3977, 1675,  818, 1017, 3194, 2338,   44,  239,  522, 4173,
         474,  327, 3712, 1281])
Epoch: 542, Training Loss: 0.45, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 543 - Batch 1 ########################
IDs in batch 1: tensor([1548, 3475, 3340,  405, 2940, 1221, 2869, 3883, 2539, 2225,  515, 3939,
        2907, 1233, 3098, 2806])
Epoch: 543, Training Loss: 0.36, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 544 - Batch 1 ########################
IDs in batch 1: tensor([3051, 3908, 3706, 1026, 3753, 4163, 2432, 1363,  961, 2738, 3538, 2375,
        3669, 3744, 3135,  214])
Epoch: 544, Training Loss: 0.51, Validation Loss: 0.46, accuracy = 0.79
######################## Epoch 545 - Batch 1 ########################
IDs in batch 1: tensor([1481, 3688,  466,  266, 3781, 2667,  371,  693, 4165,  771, 2773, 1962,
        3235, 2524,  864, 1103])
Epoch: 545, Training Loss: 0.32, Validation Loss: 0.46, accuracy = 0.79
######################## Epoch 546 - Batch 1 ########################
IDs in batch 1: tensor([1999, 1161,    7,  899, 3938,  582, 4226, 4214, 1830, 1154,  526, 3608,
        1833, 3451, 3486, 2142])
Epoch: 546, Training Loss: 0.54, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 547 - Batch 1 ########################
IDs in batch 1: tensor([2114, 3733, 4179, 3459,  371, 3746, 2244,  206,  689, 3192, 3655,  161,
        3721, 1846, 3321, 1984])
Epoch: 547, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 548 - Batch 1 ########################
IDs in batch 1: tensor([2648, 1675,  316,  838, 3306,  778, 1810, 2595, 2949, 2740, 2919, 3406,
         682, 1495, 1982, 3601])
Epoch: 548, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 549 - Batch 1 ########################
IDs in batch 1: tensor([ 187, 1081, 1963, 2542, 3987, 2562,  425, 2963, 2848, 4035, 1850, 1650,
         155,  685, 1840, 3299])
Epoch: 549, Training Loss: 0.27, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 550 - Batch 1 ########################
IDs in batch 1: tensor([  15, 3268, 1474, 3152, 3754, 4003, 1548, 3974, 1406, 2331, 4245, 2977,
        1774, 3439, 1258, 4038])
Epoch: 550, Training Loss: 0.31, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 551 - Batch 1 ########################
IDs in batch 1: tensor([1035, 3558, 4218, 1093, 2956, 1278,   14,  721, 3733,  341, 3878, 1408,
        2966,  257, 3217, 3304])
Epoch: 551, Training Loss: 0.51, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 552 - Batch 1 ########################
IDs in batch 1: tensor([1822, 2206,  531, 4173, 1650,  498, 1591, 3030, 1993, 3329, 1472, 3308,
        1226,  923, 1233, 3157])
Epoch: 552, Training Loss: 0.36, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 553 - Batch 1 ########################
IDs in batch 1: tensor([3216,  991,   85, 2965, 2771, 1070, 2393, 2144, 3313,  878, 3473, 1810,
        2940, 1900, 3604,  219])
Epoch: 553, Training Loss: 0.24, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 554 - Batch 1 ########################
IDs in batch 1: tensor([ 426, 3390, 1740, 3962,  522, 1386, 3700, 1487,  753, 1834, 3083, 1455,
        2480, 4095, 3334, 1702])
Epoch: 554, Training Loss: 0.37, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 555 - Batch 1 ########################
IDs in batch 1: tensor([ 617,  844,  373, 2181, 2203, 3349, 1796,  305, 4138,  854,  902, 2516,
        1041, 1354, 3976, 3797])
Epoch: 555, Training Loss: 0.36, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 556 - Batch 1 ########################
IDs in batch 1: tensor([ 815,  876, 1661, 2072, 2282, 1066, 2094,  120, 2280, 1335, 2050, 2008,
        2046, 1519, 2388, 2605])
Epoch: 556, Training Loss: 0.30, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 557 - Batch 1 ########################
IDs in batch 1: tensor([4253,  842,  699, 3016, 3501, 2272,  689, 3744, 4261, 2299, 2387, 3338,
         666, 3141, 2312, 3726])
Epoch: 557, Training Loss: 0.41, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 558 - Batch 1 ########################
IDs in batch 1: tensor([1991, 4087, 1385, 1868, 1122, 1679, 3366,  587,  773, 3430, 3705, 1123,
         733, 1488, 2868,  321])
Epoch: 558, Training Loss: 0.33, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 559 - Batch 1 ########################
IDs in batch 1: tensor([2545, 2822, 1470, 1495, 2723, 2170, 2219, 2721, 3534, 3885, 1361, 4040,
         928,  520, 2171, 2586])
Epoch: 559, Training Loss: 0.26, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 560 - Batch 1 ########################
IDs in batch 1: tensor([ 876, 1225, 3014, 2544, 3121, 2028, 3197, 1751, 1161, 2967, 1103, 3731,
         186, 2956, 4006, 3745])
Epoch: 560, Training Loss: 0.35, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 561 - Batch 1 ########################
IDs in batch 1: tensor([1734,  766,  496,  848,  154,  617, 3194, 3642, 3094, 1970, 3719, 3898,
        1158,  674, 1833,   22])
Epoch: 561, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 562 - Batch 1 ########################
IDs in batch 1: tensor([1082, 2810, 3029, 3083, 3876, 1850, 3275, 1772, 2453, 1017, 2213, 2277,
        3675, 3719, 2149, 3480])
Epoch: 562, Training Loss: 0.28, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 563 - Batch 1 ########################
IDs in batch 1: tensor([1051, 4089, 4159,  642,  295, 3829, 2090, 3542, 3102, 1248, 1212, 2365,
        4161,  822,  212, 1490])
Epoch: 563, Training Loss: 0.32, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 564 - Batch 1 ########################
IDs in batch 1: tensor([ 970, 3640, 2280, 2739,  649, 4251, 2712,  425, 1160, 1724, 1255, 3471,
         434,  758, 2522, 1219])
Epoch: 564, Training Loss: 0.24, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 565 - Batch 1 ########################
IDs in batch 1: tensor([ 830, 1700, 1984, 3486, 1828, 3326, 4257,  538, 1950, 4055, 1604, 2151,
        1421, 1138, 2320, 2559])
Epoch: 565, Training Loss: 0.32, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 566 - Batch 1 ########################
IDs in batch 1: tensor([ 952, 4055, 4087, 2583, 2219, 1886, 2745, 2674,  610, 3027, 3222, 2968,
        3112, 2670,  358, 2469])
Epoch: 566, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 567 - Batch 1 ########################
IDs in batch 1: tensor([1498, 3616,  218,  844, 3238, 3313, 1408,  956, 1081,  683, 2376,  517,
         848,  276,  725, 1578])
Epoch: 567, Training Loss: 0.68, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 568 - Batch 1 ########################
IDs in batch 1: tensor([3658, 3531, 2176,  112, 3321, 3161, 2891,  510, 1795, 3395, 2536, 3696,
        2969, 2132,  395, 1634])
Epoch: 568, Training Loss: 0.51, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 569 - Batch 1 ########################
IDs in batch 1: tensor([3996, 3256, 1096, 3888,  878,  988,  483,  682,  263,  710, 1933, 3375,
        1491, 1511, 4087, 2285])
Epoch: 569, Training Loss: 0.28, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 570 - Batch 1 ########################
IDs in batch 1: tensor([4258, 1236, 3628, 1073, 3954, 2682, 3207,  187, 2262, 1035,  106, 2740,
        3261, 2732,  844, 1796])
Epoch: 570, Training Loss: 0.16, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 571 - Batch 1 ########################
IDs in batch 1: tensor([ 126, 1825, 3998, 1519, 3409,  534,  134, 3216, 1545, 3744, 1569, 4232,
         970,  673,  482, 1440])
Epoch: 571, Training Loss: 0.55, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 572 - Batch 1 ########################
IDs in batch 1: tensor([ 126, 2777, 1458, 3846, 2973, 2871, 3051, 1611,  673, 1067, 1852, 3552,
        1774,  823, 2938, 1979])
Epoch: 572, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 573 - Batch 1 ########################
IDs in batch 1: tensor([1751, 3928, 3969, 1418, 3485, 3618, 3745, 2921, 3473,  869,  332, 1037,
         544,  532,  637, 1444])
Epoch: 573, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 574 - Batch 1 ########################
IDs in batch 1: tensor([2771, 4258, 1974,  587, 1103, 2391,  183, 3039, 1004, 3455, 2299, 1558,
         842, 1733,  160, 1124])
Epoch: 574, Training Loss: 0.21, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 575 - Batch 1 ########################
IDs in batch 1: tensor([ 805,  396, 2652, 3745,  263, 3524, 2408, 1233,  967, 1851, 2514, 3435,
          72, 2965, 1312, 1438])
Epoch: 575, Training Loss: 0.30, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 576 - Batch 1 ########################
IDs in batch 1: tensor([2741,  584, 1309,  971, 3098, 2251, 3715, 2797,  274, 2561, 2509,  350,
         970, 3194, 3253,  488])
Epoch: 576, Training Loss: 0.24, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 577 - Batch 1 ########################
IDs in batch 1: tensor([4018, 4122,  862, 3010, 1546, 3822, 1067, 2433, 3267, 1803,  610, 3757,
        4067, 1802, 1434, 1618])
Epoch: 577, Training Loss: 0.37, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 578 - Batch 1 ########################
IDs in batch 1: tensor([1344, 1519, 2229, 3879,  213,  956, 1420, 2799,   70, 1016, 3384,   61,
        4050, 2775,  195, 1600])
Epoch: 578, Training Loss: 0.45, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 579 - Batch 1 ########################
IDs in batch 1: tensor([3786,  854, 3764, 3674, 2831, 1116,  287, 1881, 2775, 1579, 1311, 3731,
        3497, 1973, 2800, 3652])
Epoch: 579, Training Loss: 0.33, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 580 - Batch 1 ########################
IDs in batch 1: tensor([ 363,  612, 3827,  332, 3938,  340, 2773, 1256,  957, 3842, 1578,  143,
        2571, 3786,  213, 3942])
Epoch: 580, Training Loss: 0.40, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 581 - Batch 1 ########################
IDs in batch 1: tensor([ 651, 3516, 3539, 1120,  936, 3573, 3142, 1263, 3601, 2609, 1882, 2758,
        3268, 4212,  109, 1355])
Epoch: 581, Training Loss: 0.22, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 582 - Batch 1 ########################
IDs in batch 1: tensor([1022,  965, 2244, 2817, 1089, 3812, 2968, 1656, 4056, 3680, 1626,  494,
         587,   63,  470,  405])
Epoch: 582, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 583 - Batch 1 ########################
IDs in batch 1: tensor([  46, 4223,  573, 4266, 3407,  776, 2997, 2674, 2391, 3321, 1760, 2433,
        4146, 1965, 3152, 2025])
Epoch: 583, Training Loss: 0.42, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 584 - Batch 1 ########################
IDs in batch 1: tensor([3087, 2821, 1297, 2970,  167, 2415, 2697, 1440,  501, 2542, 2403, 1961,
        2196, 1341, 1818,  818])
Epoch: 584, Training Loss: 0.22, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 585 - Batch 1 ########################
IDs in batch 1: tensor([2650, 1023, 1795, 2854, 3453,  444,  843, 1012, 2290,  954, 2859, 3223,
        1133, 1163, 2794, 2015])
Epoch: 585, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 586 - Batch 1 ########################
IDs in batch 1: tensor([ 683, 2868,  796, 3836, 3558,  864, 2114, 3856, 2342, 2891, 1180, 1952,
        3071, 3255, 1326,  295])
Epoch: 586, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 587 - Batch 1 ########################
IDs in batch 1: tensor([2354,  807, 1439, 1081,  721, 2115, 4236, 2552, 2582, 3408, 2120, 1918,
         117, 4051,  376, 1803])
Epoch: 587, Training Loss: 0.29, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 588 - Batch 1 ########################
IDs in batch 1: tensor([ 862, 1056, 2498, 4220, 3689, 3539, 1614, 1102,  587, 1555, 3369,  489,
         897, 2051, 3351, 2627])
Epoch: 588, Training Loss: 0.45, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 589 - Batch 1 ########################
IDs in batch 1: tensor([4146, 1909, 1592, 2483,  279, 3168, 1526, 2669, 2232, 1512, 1251, 3529,
        3744,  915, 1383, 2346])
Epoch: 589, Training Loss: 0.24, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 590 - Batch 1 ########################
IDs in batch 1: tensor([2378, 2567,  485, 1803, 3996, 2023, 2869, 3152, 2185, 1509, 2156, 3228,
        1162, 1746, 2674, 3437])
Epoch: 590, Training Loss: 0.29, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 591 - Batch 1 ########################
IDs in batch 1: tensor([3313, 2018, 1963, 3239, 1753, 3190, 4157, 2709, 3707, 3278, 2132, 2831,
        2508, 2418, 2244, 1546])
Epoch: 591, Training Loss: 0.50, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 592 - Batch 1 ########################
IDs in batch 1: tensor([3277, 1497, 3378,  602, 1414, 2812, 3797, 3056, 3108, 4013, 1209, 2804,
        1753,  375,  334, 4168])
Epoch: 592, Training Loss: 0.32, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 593 - Batch 1 ########################
IDs in batch 1: tensor([2983,  302, 2598, 2039, 4119, 4139, 2149, 2166, 2582,  134, 1214, 2456,
        3409, 1373, 2776, 3543])
Epoch: 593, Training Loss: 0.49, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 594 - Batch 1 ########################
IDs in batch 1: tensor([3418, 3534,  177, 1402,  557,  508, 3787, 1222, 1852,  362, 1454,   28,
        1370,  356, 2398,  756])
Epoch: 594, Training Loss: 0.56, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 595 - Batch 1 ########################
IDs in batch 1: tensor([1321, 1949, 2646,  547, 1103,  218,  280, 3250,  264, 2403, 3221, 3286,
        3964, 2603, 1089,  141])
Epoch: 595, Training Loss: 0.26, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 596 - Batch 1 ########################
IDs in batch 1: tensor([2652, 2691, 3049, 4168, 2504,  786, 1177, 1500, 2643,  256, 2668,  219,
        2562, 1681, 1960, 2575])
Epoch: 596, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 597 - Batch 1 ########################
IDs in batch 1: tensor([3452, 2970, 1804, 2099, 1491, 1480, 3778, 2219,  846,  586, 3942,  943,
        3974,  952, 1341,   44])
Epoch: 597, Training Loss: 0.43, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 598 - Batch 1 ########################
IDs in batch 1: tensor([1239, 1030,  699, 1601, 3921, 1766, 1766, 3548, 2407, 3982, 1463, 1108,
         547, 1589,   32,  324])
Epoch: 598, Training Loss: 0.50, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 599 - Batch 1 ########################
IDs in batch 1: tensor([3609, 3079,  946, 2497,  797,  830,   35, 1957, 3922, 2780,  631, 1984,
        2369,  503, 2292, 2367])
Epoch: 599, Training Loss: 0.30, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 600 - Batch 1 ########################
IDs in batch 1: tensor([3659, 2207, 3079, 3587, 1605, 3718, 2483,  620, 3236, 3018,  287, 2466,
        1321, 2279, 2643, 2299])
Epoch: 600, Training Loss: 0.29, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 601 - Batch 1 ########################
IDs in batch 1: tensor([2349,  602, 1521, 3627, 3922, 3874, 1634, 1152,  635, 2912,  733, 3449,
         456, 2098, 2689, 1045])
Epoch: 601, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 602 - Batch 1 ########################
IDs in batch 1: tensor([1136, 3738,  917, 3494, 3136, 3159,  739, 3391, 1973, 3159, 2700, 4196,
         804, 3136,  372,  557])
Epoch: 602, Training Loss: 0.18, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 603 - Batch 1 ########################
IDs in batch 1: tensor([3146, 1263, 3187, 4226, 1073, 2499,  680, 2726, 2412, 3037,  994, 2346,
        1916, 3882,  171,   27])
Epoch: 603, Training Loss: 0.33, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 604 - Batch 1 ########################
IDs in batch 1: tensor([ 101,  121, 1614, 4099, 1649, 1015, 1264,  199, 3541, 1069, 1073, 4013,
        3277, 1604,  138, 1803])
Epoch: 604, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 605 - Batch 1 ########################
IDs in batch 1: tensor([ 767, 2689, 1821, 1360, 1500, 2990, 3497,  682, 3038, 4172, 1958,  978,
        4035, 3871, 3334,  478])
Epoch: 605, Training Loss: 0.45, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 606 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 1381, 2229, 4220, 2899, 3227, 4080, 2899, 1321,  680,  797,  873,
         572, 3507, 3151,  838])
Epoch: 606, Training Loss: 0.24, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 607 - Batch 1 ########################
IDs in batch 1: tensor([1367, 3458, 1263,  866, 2272, 1180, 3640,  651, 2256,  895,  523,  419,
        3945,    5, 3723,   49])
Epoch: 607, Training Loss: 0.37, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 608 - Batch 1 ########################
IDs in batch 1: tensor([2529, 3463, 1330, 3726, 1204, 1027, 4138,   93, 3290,  196,  658, 4228,
        1808, 3749, 2664, 3460])
Epoch: 608, Training Loss: 0.77, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 609 - Batch 1 ########################
IDs in batch 1: tensor([3328, 3118, 3197,   42, 1663, 1981, 2775, 2791, 1256, 3485, 2312, 1955,
         534,  870, 1249, 4120])
Epoch: 609, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 610 - Batch 1 ########################
IDs in batch 1: tensor([1282,  620, 2681, 1065, 3754, 2838, 1273,  790, 1417, 2145, 4016, 3181,
        3056,  129, 2248, 1263])
Epoch: 610, Training Loss: 0.30, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 611 - Batch 1 ########################
IDs in batch 1: tensor([3860, 3161, 1925, 1415, 3487, 2880,  375, 4176, 3744,  395, 1045,  474,
        3030, 3518, 3634, 3362])
Epoch: 611, Training Loss: 0.15, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 612 - Batch 1 ########################
IDs in batch 1: tensor([1200, 3473, 2316,  422, 4105, 3842, 2451, 2472, 2383, 4065, 1222, 3352,
        2729,  434, 2261, 1081])
Epoch: 612, Training Loss: 0.31, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 613 - Batch 1 ########################
IDs in batch 1: tensor([3415, 1318, 2754, 1094,  950, 3498, 2472, 1297,  792, 3710, 1108, 3981,
        4004, 4265,  148, 1395])
Epoch: 613, Training Loss: 0.26, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 614 - Batch 1 ########################
IDs in batch 1: tensor([ 930,  170, 3588, 3637,  450, 1346,  205, 1451, 3713, 1306, 2406,  316,
        1137, 2776,  475, 2372])
Epoch: 614, Training Loss: 0.33, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 615 - Batch 1 ########################
IDs in batch 1: tensor([ 282, 4053,  832, 1809, 3874, 3126,  130,  753,  752, 3554, 1277, 4065,
        3695, 3051, 1006, 3949])
Epoch: 615, Training Loss: 0.58, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 616 - Batch 1 ########################
IDs in batch 1: tensor([3948, 4126, 1642, 3196, 3453,  824, 3022, 4200, 1037,  787, 2156,  252,
        1316,  110,  133, 1632])
Epoch: 616, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 617 - Batch 1 ########################
IDs in batch 1: tensor([2770, 1707, 1680, 1440, 2487,  289,  126, 2258, 1276, 4161, 2003,  774,
        1902, 3762, 2287, 3567])
Epoch: 617, Training Loss: 0.21, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 618 - Batch 1 ########################
IDs in batch 1: tensor([2758, 3366, 1309, 1857, 3030, 1501,  196, 2504, 1467,  653, 4149, 4119,
         827, 3239, 2984, 2891])
Epoch: 618, Training Loss: 0.30, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 619 - Batch 1 ########################
IDs in batch 1: tensor([1661,  873, 1591, 3858,  439, 3589, 1563, 1276, 2206,  402,  914, 3329,
        4163, 3339,  129, 1961])
Epoch: 619, Training Loss: 0.28, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 620 - Batch 1 ########################
IDs in batch 1: tensor([3982, 1934, 3674, 1645,  483,  247,  694, 3603, 1024, 3488, 2777, 3563,
        2262, 2934, 3615,  287])
Epoch: 620, Training Loss: 0.35, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 621 - Batch 1 ########################
IDs in batch 1: tensor([2141, 1186, 2360, 1470, 1346,  983, 2949, 3860, 2681, 2368,  133, 3003,
          51, 2292, 2905, 1823])
Epoch: 621, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 622 - Batch 1 ########################
IDs in batch 1: tensor([2378,   44, 3438, 2724,  244,  649, 2038, 1406,  238, 4099, 1866,  546,
         237, 2053, 4096, 2291])
Epoch: 622, Training Loss: 0.24, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 623 - Batch 1 ########################
IDs in batch 1: tensor([3300, 2536,   18, 2977, 1077, 4058,  422, 3640, 2440, 1802,  280, 1123,
        2520, 4061,  477, 1706])
Epoch: 623, Training Loss: 0.38, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 624 - Batch 1 ########################
IDs in batch 1: tensor([3318,  858, 3440, 3264,  824, 3778, 4007, 3253,  875, 1167, 3404, 2458,
        1795, 1778, 2614, 1380])
Epoch: 624, Training Loss: 0.27, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 625 - Batch 1 ########################
IDs in batch 1: tensor([1625, 1376, 3152,   14, 4022, 4108, 2226, 2823, 1658, 4136, 2577, 1961,
          28,  926, 1818, 2709])
Epoch: 625, Training Loss: 0.21, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 626 - Batch 1 ########################
IDs in batch 1: tensor([3798,  122, 2326, 1911, 4240, 2734,  257, 1284, 3528, 3581, 3460,  505,
        2030, 3139, 2322, 3471])
Epoch: 626, Training Loss: 0.50, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 627 - Batch 1 ########################
IDs in batch 1: tensor([ 281, 4107, 1950, 2508, 3108,  119, 2030,  639, 2041, 3841, 3897, 4235,
        4149, 1312, 3942, 2251])
Epoch: 627, Training Loss: 0.41, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 628 - Batch 1 ########################
IDs in batch 1: tensor([2794, 1950, 3336, 2388,  858, 3587, 3583,  180, 4166, 2291, 3342, 1432,
        1710, 2993, 1459, 1084])
Epoch: 628, Training Loss: 0.44, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 629 - Batch 1 ########################
IDs in batch 1: tensor([2324, 4154,  371, 3058, 4251,  459, 3668, 2832,  148, 1682, 3447, 3879,
        3242, 2500, 2291, 3920])
Epoch: 629, Training Loss: 0.25, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 630 - Batch 1 ########################
IDs in batch 1: tensor([3081, 1428, 3287, 1154, 2798, 2188, 2402, 3357,  165, 1066, 2255, 1635,
         569, 3723, 2111, 1510])
Epoch: 630, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 631 - Batch 1 ########################
IDs in batch 1: tensor([ 359, 2815,  584, 1162, 2446, 3207,  673, 2841, 1041, 3275,  526,  450,
         609, 1639, 2431, 1770])
Epoch: 631, Training Loss: 0.37, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 632 - Batch 1 ########################
IDs in batch 1: tensor([2198,  147, 3911, 2956, 4070,  964, 3582, 3821, 1367, 2552, 1766, 3480,
        4218, 1324,  332, 2784])
Epoch: 632, Training Loss: 0.31, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 633 - Batch 1 ########################
IDs in batch 1: tensor([3654, 1336, 3585,  352, 1879, 3521, 3914, 3190,  260, 2401, 2871, 3214,
         229, 2959,  184, 2226])
Epoch: 633, Training Loss: 0.28, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 634 - Batch 1 ########################
IDs in batch 1: tensor([1580,  566, 2629, 1069, 1789, 1911,  201, 1811, 1482, 1708,  733,  220,
         813, 3727, 2983, 4173])
Epoch: 634, Training Loss: 0.60, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 635 - Batch 1 ########################
IDs in batch 1: tensor([ 606, 2874, 1144,  965, 2921, 2455, 1131, 1950, 3485, 1321,  943, 2097,
        4007,  622, 3723,  419])
Epoch: 635, Training Loss: 0.32, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 636 - Batch 1 ########################
IDs in batch 1: tensor([2782, 3192, 1698,  541,  368, 1863, 3398, 3617, 4165,  775, 1377, 1195,
        2044, 3552,  186, 2693])
Epoch: 636, Training Loss: 0.28, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 637 - Batch 1 ########################
IDs in batch 1: tensor([3423,  568,   18, 3617, 2603, 3226, 3706, 3248, 1107, 1347, 3375, 2509,
        3656, 2752, 1819, 2265])
Epoch: 637, Training Loss: 0.17, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 638 - Batch 1 ########################
IDs in batch 1: tensor([3278, 1793,  351, 3384,  154,   19, 4213, 3654,  987, 2413, 2135, 2749,
        1596,  594, 4085,  378])
Epoch: 638, Training Loss: 0.37, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 639 - Batch 1 ########################
IDs in batch 1: tensor([1880,  743, 1644, 2746,  314, 2485,  517, 1190, 2199, 4119,  588, 2428,
         594, 3490, 3017, 4072])
Epoch: 639, Training Loss: 0.38, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 640 - Batch 1 ########################
IDs in batch 1: tensor([1028, 3238,  324,  775, 2592, 3139, 1562, 2451, 3489, 1553, 2299, 2107,
         804,  918,  583,  444])
Epoch: 640, Training Loss: 0.34, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 641 - Batch 1 ########################
IDs in batch 1: tensor([2478, 3199, 2913, 2272, 1823, 3102, 4100, 1767, 2363,  356, 4024, 1965,
        2559, 1897, 4025, 1032])
Epoch: 641, Training Loss: 0.73, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 642 - Batch 1 ########################
IDs in batch 1: tensor([4055, 4033, 1639, 1892, 1418, 2822, 2715, 3557, 3385, 1883, 1588, 4107,
          63, 3500, 1294, 1009])
Epoch: 642, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 643 - Batch 1 ########################
IDs in batch 1: tensor([4168, 1835, 2891, 2828, 1371, 2950, 3379, 3351, 3675, 3542, 3233, 2740,
        1107, 1895, 3507,  636])
Epoch: 643, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 644 - Batch 1 ########################
IDs in batch 1: tensor([4143, 4077, 2545, 2826, 2853, 3647,  753, 1884, 2402, 1793, 1957, 2741,
        2524, 3529, 2856, 3795])
Epoch: 644, Training Loss: 0.61, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 645 - Batch 1 ########################
IDs in batch 1: tensor([1414, 2219, 3647, 2181,  879, 3695, 3484, 2794, 1977, 1381, 1731, 2761,
          61, 2954, 3553, 4118])
Epoch: 645, Training Loss: 0.22, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 646 - Batch 1 ########################
IDs in batch 1: tensor([2148, 3218, 4101, 2956,  413, 2913, 4022,  425, 3709, 3749, 2682, 1723,
        3821, 2245, 2115, 3190])
Epoch: 646, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 647 - Batch 1 ########################
IDs in batch 1: tensor([ 287, 3005, 3099, 2246, 2819, 2609, 1175,  907, 3739, 1569,  773, 1305,
        3913,  322, 3963, 1710])
Epoch: 647, Training Loss: 0.40, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 648 - Batch 1 ########################
IDs in batch 1: tensor([2670,  679, 1840, 3640, 3582, 2157, 1982, 4084, 2467, 3712, 3683, 1588,
         327, 2375, 1084,  139])
Epoch: 648, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 649 - Batch 1 ########################
IDs in batch 1: tensor([ 883, 2444,  897, 3807, 2542, 1620, 3786, 2246,  371, 1278, 1794, 2334,
         795,  632, 1122, 4033])
Epoch: 649, Training Loss: 0.35, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 650 - Batch 1 ########################
IDs in batch 1: tensor([ 594,  450,  523, 1665,  238, 3945, 1277, 2229,  125, 3083, 2258,   14,
         699, 3448, 3822, 1970])
Epoch: 650, Training Loss: 0.26, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 651 - Batch 1 ########################
IDs in batch 1: tensor([1566, 1175,  960, 2316, 3632, 2154, 3000,  788, 1438, 3448, 2113, 3591,
        3677, 4057, 1182, 2052])
Epoch: 651, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 652 - Batch 1 ########################
IDs in batch 1: tensor([1414, 1247, 3984,   43, 1471, 2098, 3760, 2262, 3692, 2712, 1111, 2827,
         365, 2386,   96, 1833])
Epoch: 652, Training Loss: 0.26, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 653 - Batch 1 ########################
IDs in batch 1: tensor([1325,  954, 1746, 1770,  587, 3435, 2320,  818,  100, 4000,  314, 4031,
        3816,  575, 2161, 2287])
Epoch: 653, Training Loss: 0.39, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 654 - Batch 1 ########################
IDs in batch 1: tensor([ 182, 2030, 2618, 1264,  613, 2363, 2520,  196, 2751, 3051, 4258, 2099,
        3476, 3340, 3573, 2858])
Epoch: 654, Training Loss: 0.30, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 655 - Batch 1 ########################
IDs in batch 1: tensor([1132, 2953, 2526, 4121, 2539, 1507, 3928, 3648, 1089, 3771, 2823, 3659,
        2442,  815, 1832, 2538])
Epoch: 655, Training Loss: 0.26, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 656 - Batch 1 ########################
IDs in batch 1: tensor([3486, 2815,  623,  191, 1507, 2475,  796,  352, 3055, 3971, 2073, 2627,
         358, 4214,  203,  143])
Epoch: 656, Training Loss: 0.65, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 657 - Batch 1 ########################
IDs in batch 1: tensor([1390, 4268, 1047,  483, 3436, 3652, 3357, 1727, 1279, 3284,  944,  251,
        3647,  688, 1518, 1500])
Epoch: 657, Training Loss: 0.49, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 658 - Batch 1 ########################
IDs in batch 1: tensor([3786, 3259, 2343, 3005, 3055, 1982, 1601, 3577, 3051,  632,  718, 3264,
         483, 3732,  788, 1502])
Epoch: 658, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 659 - Batch 1 ########################
IDs in batch 1: tensor([ 628, 1699, 2291, 2448, 2568, 1921,  978,  200,  980,   97, 3878,  332,
        1409, 3358, 3005, 1042])
Epoch: 659, Training Loss: 0.39, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 660 - Batch 1 ########################
IDs in batch 1: tensor([1933, 2477, 3196, 3859, 2111, 4190, 3078, 3144, 1017, 1891, 4234, 3589,
         524, 2155, 2825, 2198])
Epoch: 660, Training Loss: 0.33, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 661 - Batch 1 ########################
IDs in batch 1: tensor([1171, 3256,  615, 2349, 2207, 2857, 3874, 4173,  170,  886, 2498, 2645,
        2890, 3523, 2669,  928])
Epoch: 661, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 662 - Batch 1 ########################
IDs in batch 1: tensor([2010, 1085, 2514, 1218,  852,  532, 2360,  776,  632,  110, 2854, 2088,
        4107,  645, 1402, 1173])
Epoch: 662, Training Loss: 0.52, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 663 - Batch 1 ########################
IDs in batch 1: tensor([1305, 3084, 1761,  326, 3408, 1716, 3303, 1693,  523, 2477, 2272, 2957,
        3991, 2196, 2046,  141])
Epoch: 663, Training Loss: 0.13, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 664 - Batch 1 ########################
IDs in batch 1: tensor([4008, 2617,  160, 1196, 1448, 2207, 3733, 1737,   81, 3236,  684, 1970,
         368,  340, 1024,  941])
Epoch: 664, Training Loss: 0.54, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 665 - Batch 1 ########################
IDs in batch 1: tensor([2295,  139,  967, 3469, 2835, 1345, 1053, 3851, 2494, 2866,  795, 1650,
        3160, 1620, 1082, 2937])
Epoch: 665, Training Loss: 0.19, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 666 - Batch 1 ########################
IDs in batch 1: tensor([ 211, 2701, 3236, 2980, 2449, 1436,  306,  403, 1921, 2788, 3717, 2894,
        2949,  333, 3807, 2176])
Epoch: 666, Training Loss: 0.15, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 667 - Batch 1 ########################
IDs in batch 1: tensor([4181,  555,  574, 1484, 1121,  735, 3558, 1726, 2181, 1437,  165, 1700,
        2217, 3917,  658, 3984])
Epoch: 667, Training Loss: 0.64, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 668 - Batch 1 ########################
IDs in batch 1: tensor([1957, 3514, 1374, 1233,  920, 1442, 2317, 1747, 1270,  736,  224, 1390,
        3692,  526, 1171, 2230])
Epoch: 668, Training Loss: 0.60, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 669 - Batch 1 ########################
IDs in batch 1: tensor([3441, 2118, 2581, 3838, 2859, 2376, 1223, 3895, 1083, 4073, 1406, 3168,
        2023, 3220,  942, 2504])
Epoch: 669, Training Loss: 0.36, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 670 - Batch 1 ########################
IDs in batch 1: tensor([1937, 4060,   96, 1049, 3459, 1131,  259, 4238, 3110, 3527, 2328, 2027,
        4158, 4048,  804,  563])
Epoch: 670, Training Loss: 0.28, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 671 - Batch 1 ########################
IDs in batch 1: tensor([2617, 1868,  680, 3318, 3444,  403, 4069, 1216, 3128, 3888, 2737, 2204,
         615, 1195,  816, 1312])
Epoch: 671, Training Loss: 0.22, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 672 - Batch 1 ########################
IDs in batch 1: tensor([3148, 4051,   34, 2086,  326, 2025,  537, 2897, 1787,  947, 2791, 1671,
         260, 1711, 2327, 1388])
Epoch: 672, Training Loss: 0.29, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 673 - Batch 1 ########################
IDs in batch 1: tensor([1517,  471, 3573, 2291,  555, 1825, 1546, 2316, 1599, 2690, 1555, 1968,
        4078, 4128, 2741, 2579])
Epoch: 673, Training Loss: 0.12, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 674 - Batch 1 ########################
IDs in batch 1: tensor([2966, 2777,   63,  379, 1612, 3181, 3314, 2176,  829, 2934, 3032,  318,
        1428, 2791, 1711, 1945])
Epoch: 674, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 675 - Batch 1 ########################
IDs in batch 1: tensor([ 101, 2250, 1592, 3907, 3133, 3058, 1566, 1499, 1440, 4044, 1024,  435,
        3200, 2805, 3976, 2065])
Epoch: 675, Training Loss: 0.24, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 676 - Batch 1 ########################
IDs in batch 1: tensor([2264, 2099, 1901,   59, 1543, 1678, 3256, 2854, 2198, 1870, 2442, 1671,
        2355, 2621,  407,  989])
Epoch: 676, Training Loss: 0.24, Validation Loss: 0.46, accuracy = 0.79
######################## Epoch 677 - Batch 1 ########################
IDs in batch 1: tensor([3883, 2961,  652, 2908, 1076,  405,  419, 1644, 3705, 1289,  594, 4236,
        3492, 2873, 1229, 1146])
Epoch: 677, Training Loss: 0.34, Validation Loss: 0.46, accuracy = 0.79
Save best Model_1 @ epoch 677 acc: 0.7936694021101993
Email sent!
######################## Epoch 678 - Batch 1 ########################
IDs in batch 1: tensor([2354,  755, 3506, 3778, 3243, 1748,  439, 2841, 2176, 2551, 2189, 2899,
        3192,  120,  896, 4267])
Epoch: 678, Training Loss: 0.46, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 679 - Batch 1 ########################
IDs in batch 1: tensor([2141, 4266, 1141,  857,  786, 2731, 3747, 1061,  106, 1892, 2003, 2102,
         986, 4266, 2203, 4117])
Epoch: 679, Training Loss: 0.56, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 680 - Batch 1 ########################
IDs in batch 1: tensor([3798,  779, 3409, 3592, 1663,  207, 3203,  284, 2435, 1980,  781,  630,
        1849, 1102,  749, 3954])
Epoch: 680, Training Loss: 0.26, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 681 - Batch 1 ########################
IDs in batch 1: tensor([2548,  326, 3200, 2572, 1070, 3042, 1470, 4113, 3713, 2468, 2712, 2191,
        2664, 2731, 1289, 4154])
Epoch: 681, Training Loss: 0.28, Validation Loss: 0.47, accuracy = 0.79
Save best Model_1 @ epoch 681 acc: 0.794841735052755
Email sent!
######################## Epoch 682 - Batch 1 ########################
IDs in batch 1: tensor([  35,  284, 2555, 2402, 1913,  399,  324, 3507, 2280, 3683, 1773, 3439,
         586, 2064, 1620, 4139])
Epoch: 682, Training Loss: 0.13, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 683 - Batch 1 ########################
IDs in batch 1: tensor([ 773,  723, 4108, 1975, 2155, 3549, 4099, 1083,  971, 3807, 1537, 1731,
        1294, 1402,  402, 2246])
Epoch: 683, Training Loss: 0.19, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 684 - Batch 1 ########################
IDs in batch 1: tensor([4268, 2842, 3461, 2331,  361, 4194, 2839, 2664, 1147,  823, 1583, 3243,
        3176, 2632, 3437, 2504])
Epoch: 684, Training Loss: 0.21, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 685 - Batch 1 ########################
IDs in batch 1: tensor([3060, 1321,   52, 2767, 2991,  755,  747,  609,  129,  499, 1444,  890,
        2934, 1081, 2376, 1349])
Epoch: 685, Training Loss: 0.39, Validation Loss: 0.47, accuracy = 0.77
######################## Epoch 686 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 3055, 3856,  962, 1065, 1965, 3567, 4161, 3989, 3787,  755, 2697,
        1500, 1204, 2567, 1195])
Epoch: 686, Training Loss: 0.48, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 687 - Batch 1 ########################
IDs in batch 1: tensor([3141, 1732, 2298, 3465, 1668, 3544, 2104, 3258, 4032, 4166, 2015, 1967,
        3423, 2278, 2229, 2641])
Epoch: 687, Training Loss: 0.62, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 688 - Batch 1 ########################
IDs in batch 1: tensor([ 371, 1573, 3523, 1373,  369, 2798, 3949, 2226, 3977, 1512, 2709, 3648,
        3804, 3795, 2414, 2781])
Epoch: 688, Training Loss: 0.22, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 689 - Batch 1 ########################
IDs in batch 1: tensor([ 537, 1660, 4157,  475, 3451, 3783, 2207, 2064,  120,  636, 3621, 2680,
        3827, 3846,  384, 4220])
Epoch: 689, Training Loss: 0.18, Validation Loss: 0.48, accuracy = 0.76
######################## Epoch 690 - Batch 1 ########################
IDs in batch 1: tensor([1270, 1017, 2492, 1171, 2126, 3763,  625, 2274,  247, 1158, 1879, 2315,
         967, 2320, 2604, 1811])
Epoch: 690, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 691 - Batch 1 ########################
IDs in batch 1: tensor([ 185, 3193, 1778, 2980, 3133,  882, 2584, 2193, 3827, 2545, 2609, 3105,
        2982,   27, 3481, 3222])
Epoch: 691, Training Loss: 0.24, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 692 - Batch 1 ########################
IDs in batch 1: tensor([2339, 2442, 1263,   34, 1347, 2304, 3627, 3342, 3753, 2442,   28,  583,
        1372, 3284, 2226, 1377])
Epoch: 692, Training Loss: 0.15, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 693 - Batch 1 ########################
IDs in batch 1: tensor([4026,  550,  444,  340, 1661, 1008, 3538,  985, 2787, 1069, 3132, 1161,
        3674, 4240, 3109, 1502])
Epoch: 693, Training Loss: 0.20, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 694 - Batch 1 ########################
IDs in batch 1: tensor([2446, 2039, 3813, 3258,  582, 2064, 3323, 3933,   41, 1681,  403, 2405,
        3616, 1286, 1524, 1390])
Epoch: 694, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 695 - Batch 1 ########################
IDs in batch 1: tensor([1252, 1722, 1020, 2030, 3597, 3781, 2749,  333, 2064, 1884, 1597, 1097,
        3120, 2663, 2752, 1453])
Epoch: 695, Training Loss: 0.36, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 696 - Batch 1 ########################
IDs in batch 1: tensor([3471, 4165, 4006, 2135,  886,  639,  967,   44,  159,  411, 3461,   86,
         277, 3962, 2968, 3373])
Epoch: 696, Training Loss: 0.14, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 697 - Batch 1 ########################
IDs in batch 1: tensor([1093, 1500,  914, 3871,  251,  295, 3300, 2616,  583, 3797, 2123, 1842,
        2693, 3542, 3268,  729])
Epoch: 697, Training Loss: 0.33, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 698 - Batch 1 ########################
IDs in batch 1: tensor([4194, 1313, 1677, 3252, 3999, 1551,   73, 1855, 3547,  823, 2004,  154,
        3299,  751, 1386, 3283])
Epoch: 698, Training Loss: 0.31, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 699 - Batch 1 ########################
IDs in batch 1: tensor([2193, 1643,   64, 1605,  211, 3664, 1967, 2771, 3391,   64, 1103,  203,
        1216, 2546, 2771, 1201])
Epoch: 699, Training Loss: 0.23, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 700 - Batch 1 ########################
IDs in batch 1: tensor([  44, 3664, 2314,  924, 4058,  892, 3446, 3644, 3311, 2999, 4218, 1178,
        2831, 3847, 3648, 4227])
Epoch: 700, Training Loss: 0.43, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 701 - Batch 1 ########################
IDs in batch 1: tensor([ 529, 3590, 3436, 2973, 2499, 3017, 4060,  327, 4061, 2989, 1024, 1147,
        3102, 1370, 2073, 4048])
Epoch: 701, Training Loss: 0.31, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 702 - Batch 1 ########################
IDs in batch 1: tensor([ 141, 2205,  322, 2423,  881, 2090, 2655, 1981,  422,  376, 2120, 1131,
        1313, 3964, 1076, 1753])
Epoch: 702, Training Loss: 0.28, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 703 - Batch 1 ########################
IDs in batch 1: tensor([2772, 3271, 2179, 1448, 3742,  749, 1830, 4049, 1375, 2231, 1291,  359,
        4016, 3148, 1878, 2017])
Epoch: 703, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 704 - Batch 1 ########################
IDs in batch 1: tensor([3021,  279,  588, 1140, 1406, 1183,   63, 4166, 3960, 2984, 2587, 2497,
         133, 1872, 1632,   31])
Epoch: 704, Training Loss: 0.21, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 705 - Batch 1 ########################
IDs in batch 1: tensor([4110, 1585,  960, 4072, 1895, 2771, 3239, 2192, 1453, 1121, 2942,  870,
        2597,  511,  214, 1633])
Epoch: 705, Training Loss: 0.18, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 706 - Batch 1 ########################
IDs in batch 1: tensor([3197,  557, 3466, 3675, 1041, 2482,   41, 3197, 2902, 2823, 1056, 3739,
        2418, 2659, 2225,  981])
Epoch: 706, Training Loss: 0.13, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 707 - Batch 1 ########################
IDs in batch 1: tensor([  49, 2091, 1171, 1706, 3223, 2403, 4105, 3182, 1985, 1233,  494,  489,
        1601, 3714, 2799, 3804])
Epoch: 707, Training Loss: 0.14, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 708 - Batch 1 ########################
IDs in batch 1: tensor([1754,   15, 2358, 1711, 1974, 1372,  262,  892, 3499,  182, 1097, 4110,
         822, 3058, 4186, 1842])
Epoch: 708, Training Loss: 0.28, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 709 - Batch 1 ########################
IDs in batch 1: tensor([ 578,  477,  919, 1866,  946,  532, 1495, 3244, 4251, 2094, 1885, 1793,
        3214,  766, 4242, 3366])
Epoch: 709, Training Loss: 0.24, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 710 - Batch 1 ########################
IDs in batch 1: tensor([2724, 3818, 2171, 1962, 3121, 2003, 3071,  367, 1117,   70, 3896, 3970,
        2328, 2334, 1726,  213])
Epoch: 710, Training Loss: 0.22, Validation Loss: 0.49, accuracy = 0.76
######################## Epoch 711 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 2954, 2809, 1340, 1218,  942, 2487, 4125, 3373, 2353, 4120, 3594,
        1260, 2629, 3109, 3680])
Epoch: 711, Training Loss: 0.31, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 712 - Batch 1 ########################
IDs in batch 1: tensor([1682,  508, 1952, 1426,  125,  534, 1496,  467, 1766, 4012, 2783, 3939,
        2274,  531, 2464, 1799])
Epoch: 712, Training Loss: 0.17, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 713 - Batch 1 ########################
IDs in batch 1: tensor([1530, 1375, 2553,  154, 2798, 3834, 2949,  976, 1537, 4140, 4031, 2078,
        4051, 3081,  717, 2045])
Epoch: 713, Training Loss: 0.32, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 714 - Batch 1 ########################
IDs in batch 1: tensor([1490,  928, 3674, 1647, 1305, 2783, 1428, 3196,  962, 1102,   95,   27,
        2198, 2901,  954, 2691])
Epoch: 714, Training Loss: 0.25, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 715 - Batch 1 ########################
IDs in batch 1: tensor([ 821, 2973,  554, 1920, 2711,  568, 3971, 4113,  846, 1767, 3057, 3850,
        1248, 4040, 1736,  465])
Epoch: 715, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 716 - Batch 1 ########################
IDs in batch 1: tensor([ 295,  112, 1185, 2045, 3352, 1162, 2343,  595,  519,  372, 4010, 1213,
        1793,  120, 1589, 1196])
Epoch: 716, Training Loss: 0.52, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 717 - Batch 1 ########################
IDs in batch 1: tensor([3969, 2189,  919, 1084, 2067, 3921, 2477,  546, 1825,  415,  649,  526,
        2947, 3905, 4120, 3495])
Epoch: 717, Training Loss: 0.20, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 718 - Batch 1 ########################
IDs in batch 1: tensor([2670, 1845, 3311, 2891, 3453, 4100, 1632, 1605, 1510, 2099, 4267, 2249,
        3423,  670, 2125, 1017])
Epoch: 718, Training Loss: 0.17, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 719 - Batch 1 ########################
IDs in batch 1: tensor([2595, 1159, 1179, 3181, 1507, 3065, 3551,  732, 1464, 1396, 1761, 1506,
        4080, 3277,  367, 2065])
Epoch: 719, Training Loss: 0.28, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 720 - Batch 1 ########################
IDs in batch 1: tensor([3414, 1297, 1370, 1551,  160, 2998, 3088, 1795, 1388, 4198,  341, 4205,
        2695, 3627,   43,  743])
Epoch: 720, Training Loss: 0.18, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 721 - Batch 1 ########################
IDs in batch 1: tensor([2831, 1495, 2155, 2940, 3878, 3121, 4218, 2723, 2022, 4084,  419, 3489,
        2736, 2097, 3698, 2879])
Epoch: 721, Training Loss: 0.50, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 722 - Batch 1 ########################
IDs in batch 1: tensor([1543, 3488, 2882, 1139, 1389, 1525,  325,  926,  870, 2458, 1189, 3179,
         201, 1780, 1646, 2064])
Epoch: 722, Training Loss: 0.35, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 723 - Batch 1 ########################
IDs in batch 1: tensor([1490,  584, 2367, 3246, 2281,  583, 1883, 2456, 2924, 2353, 3660, 1521,
        3366, 3676, 3115, 3683])
Epoch: 723, Training Loss: 0.32, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 724 - Batch 1 ########################
IDs in batch 1: tensor([3651,  586, 1724, 1386, 3423, 1610, 1563, 3121, 3911, 2469, 2687, 3632,
        1369, 1373, 2949, 2617])
Epoch: 724, Training Loss: 0.24, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 725 - Batch 1 ########################
IDs in batch 1: tensor([ 148, 4010, 1484, 2938, 1762, 1155, 2990,  680,  220, 4126,  665, 2091,
        2506,  274, 2970,  466])
Epoch: 725, Training Loss: 0.36, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 726 - Batch 1 ########################
IDs in batch 1: tensor([1894, 1333, 2492, 1766, 2572, 3102, 1337, 3850, 1573, 4057,  989, 1062,
        1083, 2049, 2463, 2087])
Epoch: 726, Training Loss: 0.21, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 727 - Batch 1 ########################
IDs in batch 1: tensor([2643, 3051,  130,  526, 3926, 1614, 2252, 3563,  975, 2495, 2737,  530,
        3072, 3896, 1310,  239])
Epoch: 727, Training Loss: 0.36, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 728 - Batch 1 ########################
IDs in batch 1: tensor([1111,   56, 1186, 2145, 3547,  445,  418,  785, 2730, 1055, 3199, 3627,
        2523, 2587,  415, 3381])
Epoch: 728, Training Loss: 0.25, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 729 - Batch 1 ########################
IDs in batch 1: tensor([3984, 1038, 2683,  171, 1085, 2676,  694, 2183, 1784, 1349, 1645,  919,
        1162, 2869,  891, 2966])
Epoch: 729, Training Loss: 0.19, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 730 - Batch 1 ########################
IDs in batch 1: tensor([2455, 3369, 2443, 3456, 2238, 1116, 3040, 3378, 2584, 2338,   50,  913,
        3499, 3597, 2117, 2982])
Epoch: 730, Training Loss: 0.46, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 731 - Batch 1 ########################
IDs in batch 1: tensor([2176, 2795, 1450, 2401, 3525, 2848, 1508,    7, 2027, 3382,  441, 2835,
        3962, 2592, 1682, 1176])
Epoch: 731, Training Loss: 0.12, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 732 - Batch 1 ########################
IDs in batch 1: tensor([1451, 4232,  526, 4007, 1559,  573,  471, 4163,  649, 3407,  196, 1252,
        3121, 2015, 4245, 2338])
Epoch: 732, Training Loss: 0.12, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 733 - Batch 1 ########################
IDs in batch 1: tensor([1220, 3265, 1620, 2746,  155,  261, 3180, 1346, 4085,  445, 1258, 3092,
        1385, 2749, 2516, 2584])
Epoch: 733, Training Loss: 0.19, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 734 - Batch 1 ########################
IDs in batch 1: tensor([ 459, 4014, 3871,  426, 1866, 3600,  343, 2461, 1869, 2574,  769,  206,
        2997, 3668, 2346, 1570])
Epoch: 734, Training Loss: 0.41, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 735 - Batch 1 ########################
IDs in batch 1: tensor([3673, 2065, 2668,  333, 2379, 2433,  930,  139,  970, 3465,  202, 2312,
        1445, 3040, 2758,  871])
Epoch: 735, Training Loss: 0.39, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 736 - Batch 1 ########################
IDs in batch 1: tensor([3466, 1899,  691,  530, 3010, 3939, 4199,  612, 2387, 1388, 3954, 1644,
         408, 2161, 1185, 3428])
Epoch: 736, Training Loss: 0.24, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 737 - Batch 1 ########################
IDs in batch 1: tensor([3217, 1524, 1718, 3808, 2099, 3779, 2601, 4234, 2154, 3398, 2274,   98,
        1500, 1728, 3917,  269])
Epoch: 737, Training Loss: 0.20, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 738 - Batch 1 ########################
IDs in batch 1: tensor([4200,  483, 2776, 3192, 3999,  136,  866,  424, 2088, 3433, 2748, 1519,
        2449,  894, 2332, 1777])
Epoch: 738, Training Loss: 0.28, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 739 - Batch 1 ########################
IDs in batch 1: tensor([1899, 1680, 3398, 2825,  260, 2171, 4168,  864, 3688, 3637, 3192, 2386,
        2205,  452, 1124, 2995])
Epoch: 739, Training Loss: 0.19, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 740 - Batch 1 ########################
IDs in batch 1: tensor([1387, 1092, 3484, 1031, 2522, 3238, 1618,  487, 2872, 1904,  991, 3961,
        3284, 1802, 1176, 3418])
Epoch: 740, Training Loss: 0.20, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 741 - Batch 1 ########################
IDs in batch 1: tensor([3896, 3323, 3681,  937, 4253, 3179, 3053, 2262, 4218, 2429, 3132, 2548,
        3902,  943, 3823, 2369])
Epoch: 741, Training Loss: 0.63, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 742 - Batch 1 ########################
IDs in batch 1: tensor([ 830, 2518, 1101, 1904,  934, 2356, 1157, 2435, 3739, 2963, 3617,  701,
        3696, 4119, 3250,  607])
Epoch: 742, Training Loss: 0.38, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 743 - Batch 1 ########################
IDs in batch 1: tensor([2193, 2932, 1347, 1153, 2413, 1784, 2229, 1981, 2414, 4087, 3091,  837,
        3446, 3456,  376, 3740])
Epoch: 743, Training Loss: 0.19, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 744 - Batch 1 ########################
IDs in batch 1: tensor([2492, 2644,  632, 2353,  623, 1044, 2770, 3480, 3829,  131, 2469,  417,
        3344, 3421, 1624, 3449])
Epoch: 744, Training Loss: 0.29, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 745 - Batch 1 ########################
IDs in batch 1: tensor([4230, 1282, 2799, 4119, 4199, 1097, 3785, 1892, 2124, 3211, 1960, 3656,
        4185, 3087,   77,  126])
Epoch: 745, Training Loss: 0.35, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 746 - Batch 1 ########################
IDs in batch 1: tensor([3400,  415,  795, 3176,  501, 2178, 3233, 2456, 1065, 2148, 1317,  888,
        1086,  954, 3787, 3228])
Epoch: 746, Training Loss: 0.33, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 747 - Batch 1 ########################
IDs in batch 1: tensor([3391, 3418, 1162, 3251, 3160, 2405, 2296, 2563,  477,  785,  125, 1017,
        1060, 1399, 3398, 2193])
Epoch: 747, Training Loss: 0.17, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 748 - Batch 1 ########################
IDs in batch 1: tensor([4138, 2868,  789, 2620,  978, 1308, 3989, 4008,  275, 3303, 2571, 1670,
        2469,  396, 1420, 3111])
Epoch: 748, Training Loss: 0.27, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 749 - Batch 1 ########################
IDs in batch 1: tensor([3812, 1098, 3415, 1097, 4254, 3075, 1732,  812, 2378, 2723, 3270, 1311,
        3902, 1823, 4032, 4085])
Epoch: 749, Training Loss: 0.20, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 750 - Batch 1 ########################
IDs in batch 1: tensor([4185, 1493, 1810,  886, 1784, 2251, 1645,  394, 2926, 2499, 1413, 1944,
        2755, 1119, 2415, 4022])
Epoch: 750, Training Loss: 0.43, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 751 - Batch 1 ########################
IDs in batch 1: tensor([2849,  813,  365, 2601, 2034, 2874, 1467, 4088, 4046, 1916, 1747, 2371,
        3381, 1200, 1244, 3501])
Epoch: 751, Training Loss: 0.40, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 752 - Batch 1 ########################
IDs in batch 1: tensor([3436, 1555, 3504, 1271, 3858, 3082,  224, 1012,  821, 2579, 1498, 3410,
        3216, 2063, 3150, 1302])
Epoch: 752, Training Loss: 0.23, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 753 - Batch 1 ########################
IDs in batch 1: tensor([1855, 3470, 1555, 1415,  106, 2919, 1444, 1131, 2991, 1249, 3410,  894,
        3253, 1117,  463,  968])
Epoch: 753, Training Loss: 0.50, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 754 - Batch 1 ########################
IDs in batch 1: tensor([2631,  907, 3391, 3632, 1263,  563, 3778, 3114, 2388, 4194, 4033, 3655,
        1861, 1134, 3970,  315])
Epoch: 754, Training Loss: 0.18, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 755 - Batch 1 ########################
IDs in batch 1: tensor([1474, 2437, 2817, 3569, 2641, 1237,  312, 2950, 2086, 2437, 1605, 3504,
        2365, 1958, 2334,  652])
Epoch: 755, Training Loss: 0.29, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 756 - Batch 1 ########################
IDs in batch 1: tensor([3265, 2771, 4134, 1650, 1740, 1982, 1752, 2854,  487, 3603, 3793, 3367,
        2252,  159,  839,  888])
Epoch: 756, Training Loss: 0.27, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 757 - Batch 1 ########################
IDs in batch 1: tensor([1011, 1421, 4204, 4161, 4176,  947, 1281,  393,  258, 3489, 2391,  344,
        2638, 1041,  445, 2323])
Epoch: 757, Training Loss: 0.27, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 758 - Batch 1 ########################
IDs in batch 1: tensor([2188, 2371, 4113,  975, 2271,  625, 3714, 1576, 2706, 3463, 1638, 1724,
        3495, 3112,  239,  699])
Epoch: 758, Training Loss: 0.12, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 759 - Batch 1 ########################
IDs in batch 1: tensor([ 164, 1711, 2151, 2681,  880, 2669, 3444, 1065, 3531,  358, 1932,  967,
        1118, 1506,  718, 2413])
Epoch: 759, Training Loss: 0.52, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 760 - Batch 1 ########################
IDs in batch 1: tensor([2219,  105, 2326, 2181, 3615, 3526,  133, 2362, 1899, 2110, 1228, 3839,
        1175, 3394,  224, 1216])
Epoch: 760, Training Loss: 0.14, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 761 - Batch 1 ########################
IDs in batch 1: tensor([ 721, 1266,  389, 3738, 2529, 3128, 2373, 3749, 1308, 3157, 1012,   88,
        1732, 4022, 3845, 1258])
Epoch: 761, Training Loss: 0.19, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 762 - Batch 1 ########################
IDs in batch 1: tensor([4181, 1592, 2448,  380, 1973, 3421, 1920,  921, 2695, 1226, 1708, 2884,
        3456,  620,  834,  820])
Epoch: 762, Training Loss: 0.31, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 763 - Batch 1 ########################
IDs in batch 1: tensor([3058, 4033,   25, 3401, 3147, 1371, 4060, 2060,  835, 2383, 1221, 2514,
         489, 1869, 4076, 3114])
Epoch: 763, Training Loss: 0.28, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 764 - Batch 1 ########################
IDs in batch 1: tensor([3797, 1087, 4212,  533, 2376, 3276, 3489, 2457,  837, 4135,  159,  418,
         225, 2249, 3446, 2991])
Epoch: 764, Training Loss: 0.15, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 765 - Batch 1 ########################
IDs in batch 1: tensor([3202, 4128,  821, 3563, 2856,  857, 2812, 2697, 2890,  100,  510,  462,
         185, 2390, 1228,  962])
Epoch: 765, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 766 - Batch 1 ########################
IDs in batch 1: tensor([ 680,  617,  317, 2727, 2990, 3379, 2403, 3447, 1096, 1957, 3704, 1408,
        1201,  149,  122, 1755])
Epoch: 766, Training Loss: 0.41, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 767 - Batch 1 ########################
IDs in batch 1: tensor([ 852, 1644, 1823, 3181, 3039, 3514, 3040, 1949, 2867, 3475, 3344,  967,
        3769, 4138, 1871,  896])
Epoch: 767, Training Loss: 0.36, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 768 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 2104, 1189,  588,  100, 2894, 2013, 2616, 3389, 1991, 3860,  652,
         202, 1256, 2437,  426])
Epoch: 768, Training Loss: 0.24, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 769 - Batch 1 ########################
IDs in batch 1: tensor([2425, 2450, 3474, 2493, 3683, 1333, 3925, 1677,  930,  382, 1508, 3532,
        2925, 3334,  640,  517])
Epoch: 769, Training Loss: 0.12, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 770 - Batch 1 ########################
IDs in batch 1: tensor([ 786, 2295, 4026,  981, 2155, 2655, 1030, 2982, 4099, 3617, 1471, 1102,
        2616, 1784, 1655,  769])
Epoch: 770, Training Loss: 0.40, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 771 - Batch 1 ########################
IDs in batch 1: tensor([4152,  871, 1882, 1170, 2919,  224, 4105, 3132, 3042,  553,  657,  403,
        1938, 1415,  555, 2642])
Epoch: 771, Training Loss: 0.27, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 772 - Batch 1 ########################
IDs in batch 1: tensor([2655, 3614, 1576, 4113,  710,  501, 3379, 2866, 1190,  159, 3975, 3467,
         919,  852, 2519, 3779])
Epoch: 772, Training Loss: 0.41, Validation Loss: 0.52, accuracy = 0.75
######################## Epoch 773 - Batch 1 ########################
IDs in batch 1: tensor([ 322, 1882, 2849,  530, 1144, 1489, 1179,  112,  418, 3182, 2316, 1077,
        2883, 1803, 3648, 3000])
Epoch: 773, Training Loss: 0.34, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 774 - Batch 1 ########################
IDs in batch 1: tensor([1337,  147, 2755,  445, 1380, 4257, 2228, 3006, 2791, 2314, 2581, 1755,
        1610, 3290, 3692, 1289])
Epoch: 774, Training Loss: 0.16, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 775 - Batch 1 ########################
IDs in batch 1: tensor([ 260,  511, 1097, 1482, 3940,  280, 3439, 3381, 3692, 4134, 1171,  275,
        2640,  535, 2284, 1081])
Epoch: 775, Training Loss: 0.27, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 776 - Batch 1 ########################
IDs in batch 1: tensor([2122, 1080, 4120,  150, 3135, 1851, 1275, 2870, 3372, 2185, 4057, 1387,
        2661, 3863,  417, 4234])
Epoch: 776, Training Loss: 0.24, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 777 - Batch 1 ########################
IDs in batch 1: tensor([2401, 1183, 3767, 3342, 1556,  601,  625,  221,   25, 1994, 1755,  211,
         141, 3995, 2131, 3765])
Epoch: 777, Training Loss: 0.31, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 778 - Batch 1 ########################
IDs in batch 1: tensor([2301, 3853, 1003, 2695, 3673,  630,  367, 3960, 2290, 1158, 2541, 2603,
        1681, 3951, 4188,  673])
Epoch: 778, Training Loss: 0.26, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 779 - Batch 1 ########################
IDs in batch 1: tensor([ 243,  572, 1451, 3102, 3806, 2178, 3058, 2822, 3838, 1309, 3490, 4115,
        4170,  617, 1651, 2098])
Epoch: 779, Training Loss: 0.14, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 780 - Batch 1 ########################
IDs in batch 1: tensor([3718, 3214, 1716, 3084, 2777, 2276,  740, 2238, 1773, 3723, 3476, 2867,
        2726, 3780,   72, 1197])
Epoch: 780, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 781 - Batch 1 ########################
IDs in batch 1: tensor([  84, 3206,  388, 1377, 3401, 2366, 4138, 1250, 1642, 2840,  826, 2982,
         122, 2367, 3463, 4266])
Epoch: 781, Training Loss: 0.19, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 782 - Batch 1 ########################
IDs in batch 1: tensor([ 899, 2087, 2697, 4085, 1281, 2798,  569, 3699, 3282, 3290, 1870, 3030,
        3667, 1645, 3755, 1365])
Epoch: 782, Training Loss: 0.41, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 783 - Batch 1 ########################
IDs in batch 1: tensor([1222,  277, 3615, 1957, 3264,   47,  811,  640, 3838, 2587,  130, 1590,
        3052,  372, 3279, 1126])
Epoch: 783, Training Loss: 0.21, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 784 - Batch 1 ########################
IDs in batch 1: tensor([3279, 1452, 2328, 3429, 1174, 1322,  785, 1824,  989, 3597, 2601, 2868,
        2416, 1938, 3220, 2328])
Epoch: 784, Training Loss: 0.19, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 785 - Batch 1 ########################
IDs in batch 1: tensor([ 205, 3190, 3287,  855, 3974, 2516, 2125, 2856,  459, 3544, 1334, 3333,
        1545, 4012, 1006, 1175])
Epoch: 785, Training Loss: 0.15, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 786 - Batch 1 ########################
IDs in batch 1: tensor([3262, 1780,  533,  324, 3621, 2497,  622, 3976,  264, 4249,  489,  680,
        3763, 3449,  775,  205])
Epoch: 786, Training Loss: 0.24, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 787 - Batch 1 ########################
IDs in batch 1: tensor([1011,  930,  180, 4072, 2874, 3756, 2848,  321,  678, 3003,  844, 1712,
         419, 3563, 1069, 2853])
Epoch: 787, Training Loss: 0.36, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 788 - Batch 1 ########################
IDs in batch 1: tensor([ 684, 1137, 3478, 2261, 1635, 4025, 3954, 3981, 2648, 1965,  198, 3782,
         892, 3493, 2234, 1963])
Epoch: 788, Training Loss: 0.37, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 789 - Batch 1 ########################
IDs in batch 1: tensor([4190, 1764, 1467, 1136, 1463,  205, 2567, 3219, 1247, 2708, 2364, 1182,
        2721, 2375, 1417, 4027])
Epoch: 789, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 790 - Batch 1 ########################
IDs in batch 1: tensor([1604, 3084, 4124,  217, 1617, 3203, 2244, 2980, 2230, 2271, 2276, 2016,
        4108, 4039,  642, 2010])
Epoch: 790, Training Loss: 0.26, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 791 - Batch 1 ########################
IDs in batch 1: tensor([3436, 2721,  255, 1556, 3535,  982, 4255, 3696, 3308,  612,  435,  202,
        1510,  550, 2996, 3673])
Epoch: 791, Training Loss: 0.15, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 792 - Batch 1 ########################
IDs in batch 1: tensor([ 452, 3362, 4165, 2800, 3441, 1967, 3609, 2290,  930, 3357, 2965, 3117,
        1748, 1727, 2727, 2598])
Epoch: 792, Training Loss: 0.38, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 793 - Batch 1 ########################
IDs in batch 1: tensor([3330, 2709, 1062, 3463, 3511, 3267, 1251, 3475,  450, 2094, 3181, 4179,
        2692, 1017, 1453, 3349])
Epoch: 793, Training Loss: 0.18, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 794 - Batch 1 ########################
IDs in batch 1: tensor([ 456, 1343, 2095,  513, 4070, 1914, 1500, 3497, 3942, 3432, 3547,  389,
        2980, 2475, 2291, 2590])
Epoch: 794, Training Loss: 0.21, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 795 - Batch 1 ########################
IDs in batch 1: tensor([ 808, 1904, 2590, 3284, 1177, 3120,  620,  857,  337,  305, 2663, 1146,
        1347, 2231, 1044, 1849])
Epoch: 795, Training Loss: 0.27, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 796 - Batch 1 ########################
IDs in batch 1: tensor([1053,  466, 3185, 2229, 3035, 3238, 3549,  900, 2177, 2868, 1214, 2978,
        4120, 1484, 1967,  352])
Epoch: 796, Training Loss: 0.33, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 797 - Batch 1 ########################
IDs in batch 1: tensor([2069, 3181, 3911, 2997,  203,  449, 3056, 2470, 1294,  904, 3672, 1143,
        2218,  732, 2840, 1699])
Epoch: 797, Training Loss: 0.21, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 798 - Batch 1 ########################
IDs in batch 1: tensor([1855,  937, 3035,  109, 3397,  887, 3932, 2514,  466, 1372, 2995, 3568,
          78, 2406,  503,  466])
Epoch: 798, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 799 - Batch 1 ########################
IDs in batch 1: tensor([3852,  897, 2317, 2415, 1746, 2097,  818, 2150, 4149, 2874, 2664, 2536,
         755, 2205, 1628,  770])
Epoch: 799, Training Loss: 0.20, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 800 - Batch 1 ########################
IDs in batch 1: tensor([1459,  489,  897, 1474, 3706,  741,   32, 1133, 1810, 1596, 1999, 2110,
        1469, 1638, 2584, 1059])
Epoch: 800, Training Loss: 0.59, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 801 - Batch 1 ########################
IDs in batch 1: tensor([3991, 3698, 4005, 3654, 2025, 2467, 3437, 3792, 1676,  572, 3905,  807,
        3581,  854, 1178, 2479])
Epoch: 801, Training Loss: 0.23, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 802 - Batch 1 ########################
IDs in batch 1: tensor([3998, 2964, 2260, 2433, 2344, 3216, 2905, 1999, 3721,  766,  155, 2145,
        3827,  108, 1974, 3939])
Epoch: 802, Training Loss: 0.34, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 803 - Batch 1 ########################
IDs in batch 1: tensor([1931, 1861,  212, 4033, 4075,  444, 3141, 2390, 3111, 2755, 1364,  541,
        3282, 1025, 2802,  687])
Epoch: 803, Training Loss: 0.12, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 804 - Batch 1 ########################
IDs in batch 1: tensor([3751,   71, 2851,  968, 3989,  359, 3803, 3726,  795, 2170, 2599, 3052,
        1020,  327, 2676, 1871])
Epoch: 804, Training Loss: 0.37, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 805 - Batch 1 ########################
IDs in batch 1: tensor([2088, 1299, 2649, 1139, 3697, 2276, 2706, 2894, 3418,  910,  323, 2185,
        2511,  623, 2183,  949])
Epoch: 805, Training Loss: 0.29, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 806 - Batch 1 ########################
IDs in batch 1: tensor([3740, 3589, 4017,  607, 4175, 2494, 1434, 1190, 2517, 3193, 3881, 1199,
        1094, 3418, 3002, 3785])
Epoch: 806, Training Loss: 0.23, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 807 - Batch 1 ########################
IDs in batch 1: tensor([2248, 2306, 2943, 3905, 1428, 2691, 3778,  330,  882, 2989,   68, 3243,
         712, 1496,  965, 4218])
Epoch: 807, Training Loss: 0.18, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 808 - Batch 1 ########################
IDs in batch 1: tensor([2094, 4046, 2473,  379, 2577, 3882, 1026, 2550, 1782, 1756, 2980, 4223,
        1567,  478, 2619, 2953])
Epoch: 808, Training Loss: 0.59, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 809 - Batch 1 ########################
IDs in batch 1: tensor([2599, 1063, 1855, 3802,  466, 1185,  658, 3132, 2339,  393,  501, 2571,
        3634,  320,  424, 1077])
Epoch: 809, Training Loss: 0.25, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 810 - Batch 1 ########################
IDs in batch 1: tensor([1073,  284,  363, 1944, 3484, 2943,  617, 2081, 1299, 3705,  350, 1583,
        4176, 1130, 4194, 3404])
Epoch: 810, Training Loss: 0.36, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 811 - Batch 1 ########################
IDs in batch 1: tensor([4165, 3108, 1600,  904,  649, 4070, 3235, 3538, 3991, 2562, 3443, 1491,
        2912,  843,  869,  942])
Epoch: 811, Training Loss: 0.19, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 812 - Batch 1 ########################
IDs in batch 1: tensor([ 930, 3075,   19,  435, 1803,  658, 2342, 4266, 1663, 2575,  591,  602,
        4119,  612,  335,  419])
Epoch: 812, Training Loss: 0.36, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 813 - Batch 1 ########################
IDs in batch 1: tensor([4004, 3642, 4217, 1047, 1320, 2003, 1291,  316, 3962, 3156, 2493, 3010,
        1242, 2974, 3397, 2370])
Epoch: 813, Training Loss: 0.28, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 814 - Batch 1 ########################
IDs in batch 1: tensor([ 628, 1287, 1047, 1636, 2169, 4118, 3131, 2420, 2615, 3429, 3960, 1633,
         482, 2817, 2015, 2993])
Epoch: 814, Training Loss: 0.14, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 815 - Batch 1 ########################
IDs in batch 1: tensor([4120, 1216, 3697, 4223, 3873, 3268,  732, 2324,  265,  839, 2796, 3590,
        3810, 4138, 3060, 2109])
Epoch: 815, Training Loss: 0.21, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 816 - Batch 1 ########################
IDs in batch 1: tensor([3782, 2137, 2126, 3194,  732, 2439, 1877, 3077,  448, 4108, 1126, 2005,
        1147, 3427, 3391, 3692])
Epoch: 816, Training Loss: 0.21, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 817 - Batch 1 ########################
IDs in batch 1: tensor([ 387, 1313, 1971, 1231, 1271, 1979,  620,  988, 2327,  899, 1024, 1578,
        2621, 2964, 1138, 1419])
Epoch: 817, Training Loss: 0.47, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 818 - Batch 1 ########################
IDs in batch 1: tensor([3860, 3643, 1464,   43, 1330, 1251, 2436, 2212,  358, 3802, 3192, 1680,
        3610, 2715,  512, 4263])
Epoch: 818, Training Loss: 0.42, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 819 - Batch 1 ########################
IDs in batch 1: tensor([ 552, 3872, 1809, 1498,  544, 2467, 2650,  615, 2565, 1294, 3535, 2652,
        4184,  583, 3006, 1754])
Epoch: 819, Training Loss: 0.07, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 820 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 3669, 2960, 2989,  601,  606, 3882, 1384, 1676, 3481, 3700,  651,
        2260, 2238, 3058,  225])
Epoch: 820, Training Loss: 0.31, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 821 - Batch 1 ########################
IDs in batch 1: tensor([3878, 1256, 3343,  234, 2479, 2715, 2736, 1767, 4230, 2748, 2180,  284,
        2457,   42, 4251, 2798])
Epoch: 821, Training Loss: 0.16, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 822 - Batch 1 ########################
IDs in batch 1: tensor([2151,  255,  670, 2051, 4186, 2497, 3589, 1569, 4053, 1818,  133, 4257,
        2170, 2009, 2072, 2793])
Epoch: 822, Training Loss: 0.16, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 823 - Batch 1 ########################
IDs in batch 1: tensor([1011,  774, 1234, 3778, 3222,  519, 1793, 2126, 3932, 3132, 1681,  474,
         921, 2524, 1853, 3448])
Epoch: 823, Training Loss: 0.13, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 824 - Batch 1 ########################
IDs in batch 1: tensor([2874, 1294, 1482,  492,  387, 2350, 1356, 4173, 1059, 4149, 2601,  434,
        1948, 3718, 1971,  150])
Epoch: 824, Training Loss: 0.25, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 825 - Batch 1 ########################
IDs in batch 1: tensor([4012, 2264, 1881, 1923,  871, 1333,  212, 1755, 2299, 3441, 3635,  714,
        2990, 2344, 3718, 1558])
Epoch: 825, Training Loss: 0.53, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 826 - Batch 1 ########################
IDs in batch 1: tensor([2161, 2546, 4249, 2296,  704, 1464,  941,  821, 1038,  733, 1067,  335,
         899, 1796, 2674,  398])
Epoch: 826, Training Loss: 0.25, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 827 - Batch 1 ########################
IDs in batch 1: tensor([2691, 4007, 3157,  316, 3551, 2959, 3728, 2446, 3083, 1256, 2358, 1094,
        2842, 1383,  217, 1913])
Epoch: 827, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 828 - Batch 1 ########################
IDs in batch 1: tensor([2802, 1868, 3499, 1436, 3600,  986,  126, 3928, 2621, 3585,  259, 3060,
        1731, 3042, 3969,  417])
Epoch: 828, Training Loss: 0.55, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 829 - Batch 1 ########################
IDs in batch 1: tensor([ 395, 4139, 4086, 3971, 1933, 1754,  992,  373, 1125, 1437, 1767, 1282,
        1868,  963, 2080,  378])
Epoch: 829, Training Loss: 0.64, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 830 - Batch 1 ########################
IDs in batch 1: tensor([ 820, 3394,  565,  833,   61, 3548, 3743, 2568, 2038, 1311, 3744,  966,
        2721,  982,  503,  636])
Epoch: 830, Training Loss: 0.23, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 831 - Batch 1 ########################
IDs in batch 1: tensor([1716,  743,  527, 2045, 3176, 2989, 3851, 3627, 1740,  355, 3156, 3018,
        2064, 2236,  687, 3888])
Epoch: 831, Training Loss: 0.19, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 832 - Batch 1 ########################
IDs in batch 1: tensor([ 900,   43, 3493,  444, 3246, 1171, 3771,  387, 2383, 1242, 3999, 3747,
        2559,  950, 3577,  991])
Epoch: 832, Training Loss: 0.51, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 833 - Batch 1 ########################
IDs in batch 1: tensor([3771, 1139,  823, 3290,   26,   10, 2467, 3781, 2462, 1097, 2514, 2615,
        3692,  983, 3415, 1443])
Epoch: 833, Training Loss: 0.12, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 834 - Batch 1 ########################
IDs in batch 1: tensor([3876, 3587,  139, 3841, 3779,  348,  674, 2027, 4030,  263,  869, 1015,
         904, 1026, 2884, 3182])
Epoch: 834, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 835 - Batch 1 ########################
IDs in batch 1: tensor([  85, 2056, 1311,  910, 3427, 3490, 1134, 2357, 1937, 3016, 2196, 4174,
        4204,  649, 1213,  361])
Epoch: 835, Training Loss: 0.49, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 836 - Batch 1 ########################
IDs in batch 1: tensor([3789, 4159, 2945, 2926,  725, 2408, 3676, 1212, 1931, 2220, 4117, 3042,
        3185, 2067,  132, 1324])
Epoch: 836, Training Loss: 0.20, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 837 - Batch 1 ########################
IDs in batch 1: tensor([3534, 3432,  193, 3489,  774,  155, 1789, 1772, 3795, 3792, 4253, 3762,
        1976, 3105, 3933, 2968])
Epoch: 837, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 838 - Batch 1 ########################
IDs in batch 1: tensor([ 649, 2809,  936, 1010, 2696, 3425, 4012, 1730, 1269,  942, 1650, 1784,
         145,  517, 1370,  341])
Epoch: 838, Training Loss: 0.45, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 839 - Batch 1 ########################
IDs in batch 1: tensor([3933, 3976, 3371, 2277, 4135, 1613, 3992, 3035, 3203, 3238,  709, 1098,
        3188, 2618,  507, 1546])
Epoch: 839, Training Loss: 0.09, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 840 - Batch 1 ########################
IDs in batch 1: tensor([4032, 2823, 4030, 2286, 1844, 3780, 2687, 3548, 1084, 3381, 3860, 1900,
        1809, 2366, 3109, 2386])
Epoch: 840, Training Loss: 0.78, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 841 - Batch 1 ########################
IDs in batch 1: tensor([1336, 4107, 3616, 4149,  855, 1066,  391, 1160, 1141, 4187, 2606, 2927,
        1793, 2373, 2109, 1736])
Epoch: 841, Training Loss: 0.27, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 842 - Batch 1 ########################
IDs in batch 1: tensor([3823, 4180, 3291,  430, 1896, 3953,  132,  330, 2914, 2767,   44, 1453,
        1509,  354, 2884, 3834])
Epoch: 842, Training Loss: 0.17, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 843 - Batch 1 ########################
IDs in batch 1: tensor([ 968,  475,  503,  224, 3183, 3497, 4046, 4133,  492, 1409, 2645,   99,
        1974, 3264,  969, 4053])
Epoch: 843, Training Loss: 0.13, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 844 - Batch 1 ########################
IDs in batch 1: tensor([3460, 2636, 2466, 1231, 3593, 1661, 4141, 4158,  895, 4116, 3438, 4032,
        3279, 1099, 3539,  372])
Epoch: 844, Training Loss: 0.24, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 845 - Batch 1 ########################
IDs in batch 1: tensor([1855, 3333,  264, 1343, 1834, 2107, 3176, 3179,  615, 3188, 2039,  824,
        1641, 3208, 4254, 1092])
Epoch: 845, Training Loss: 0.14, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 846 - Batch 1 ########################
IDs in batch 1: tensor([4007, 2272,  256, 2114, 2448,  190, 1793, 2167, 1962, 3644, 2682, 3334,
        3823,  342, 3345, 2447])
Epoch: 846, Training Loss: 0.31, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 847 - Batch 1 ########################
IDs in batch 1: tensor([2436,  866,    4, 3240, 1404,  262, 2743, 2159, 2354, 1921, 3621, 2609,
        2791, 3823, 3222, 2772])
Epoch: 847, Training Loss: 0.26, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 848 - Batch 1 ########################
IDs in batch 1: tensor([ 682, 3042, 2410, 2107,  945,  260, 2161, 1287, 1636, 1442, 3667,  644,
         409,  333, 4003, 3543])
Epoch: 848, Training Loss: 0.47, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 849 - Batch 1 ########################
IDs in batch 1: tensor([3439,  396, 1248, 3609, 3780, 3216,  788,  858, 1116,  978, 3902, 2951,
        4094, 3432,  306, 1328])
Epoch: 849, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 850 - Batch 1 ########################
IDs in batch 1: tensor([ 850, 2989, 4022, 2731, 2115, 2718, 3157, 1173, 3552,  749,  125, 2099,
        4006, 1062,  387,  375])
Epoch: 850, Training Loss: 0.23, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 851 - Batch 1 ########################
IDs in batch 1: tensor([1634, 2740, 3543, 2466, 1754,  276, 2693, 4146, 3053,  891, 1352, 4097,
         160, 4181, 3326,  388])
Epoch: 851, Training Loss: 0.21, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 852 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 3286, 1770, 2045, 3764, 1199,  516,  181, 3317, 1272,  338, 2717,
        2010, 3590, 4186, 2465])
Epoch: 852, Training Loss: 0.26, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 853 - Batch 1 ########################
IDs in batch 1: tensor([1267, 2872,  306, 1086, 2291, 4245, 2848, 2666, 2476,  952, 3673, 2620,
        1015, 1851, 3417, 4007])
Epoch: 853, Training Loss: 0.13, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 854 - Batch 1 ########################
IDs in batch 1: tensor([ 514, 2489,  344,  830,  524, 3912,  535, 1763, 2050, 3577, 1745, 2228,
        2788,  846, 2621, 3194])
Epoch: 854, Training Loss: 0.31, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 855 - Batch 1 ########################
IDs in batch 1: tensor([1828,  350,  281, 4076, 1660, 2060, 1144, 2871, 1644,  882,  121,  251,
        2676, 4258, 2965,   68])
Epoch: 855, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 856 - Batch 1 ########################
IDs in batch 1: tensor([1718, 1163, 1537, 1316,  348, 1063, 1990, 3449, 2433, 3927,  582,  382,
        1960, 3176,  441, 2003])
Epoch: 856, Training Loss: 0.22, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 857 - Batch 1 ########################
IDs in batch 1: tensor([ 324, 3624, 1885, 2545,  804, 3897, 1900, 4077,  830, 2119, 3432,   37,
        2604,  375,   46, 4014])
Epoch: 857, Training Loss: 0.31, Validation Loss: 0.51, accuracy = 0.75
######################## Epoch 858 - Batch 1 ########################
IDs in batch 1: tensor([3925, 3202, 1138, 4187, 1051, 3695, 2081,  871, 3795, 3279,   88, 4099,
        2444,  369, 2899,  941])
Epoch: 858, Training Loss: 0.17, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 859 - Batch 1 ########################
IDs in batch 1: tensor([2362,  244, 3074, 2370, 3582, 3553, 1567,  852,  854,  909, 3960, 2600,
        1334, 4088, 3168, 3808])
Epoch: 859, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 860 - Batch 1 ########################
IDs in batch 1: tensor([ 792,  785, 2905, 3395, 3588, 2810, 1020, 3338, 2487, 3897,  683,  183,
        3557,  833, 3521, 1891])
Epoch: 860, Training Loss: 0.30, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 861 - Batch 1 ########################
IDs in batch 1: tensor([4180,  481, 3888, 4263, 2153, 2195, 3148,  494, 3394, 2883, 1332, 1724,
        3384, 1130, 2121,  526])
Epoch: 861, Training Loss: 0.37, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 862 - Batch 1 ########################
IDs in batch 1: tensor([3190, 4009, 3336, 2754, 1101, 2822,  917, 2349, 1632, 1965, 2627, 3318,
        2264,  306,  855,  928])
Epoch: 862, Training Loss: 0.23, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 863 - Batch 1 ########################
IDs in batch 1: tensor([3069,  258, 1803, 3838, 1809, 3836, 1123, 1067, 2312, 2732,  678, 1900,
        2423,  442, 2664, 2982])
Epoch: 863, Training Loss: 0.10, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 864 - Batch 1 ########################
IDs in batch 1: tensor([2090, 3655, 3994,  892, 4170, 1076, 1171, 3362,  914, 1331, 2391, 2137,
        2810, 2997, 4141, 3808])
Epoch: 864, Training Loss: 0.19, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 865 - Batch 1 ########################
IDs in batch 1: tensor([2117, 2354, 1707, 3463, 1296, 3528, 3102, 1297, 1287, 2974, 4161,  992,
        3783, 3765, 3767, 1932])
Epoch: 865, Training Loss: 0.35, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 866 - Batch 1 ########################
IDs in batch 1: tensor([ 190, 1698, 1672, 2974,  787, 2352, 1224, 3223,  537, 4181, 2199, 3101,
         190, 1309,  439,  582])
Epoch: 866, Training Loss: 0.37, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 867 - Batch 1 ########################
IDs in batch 1: tensor([1170, 1317, 3648, 3712, 3900, 1712, 1712, 1155, 2353,  105,  382, 1985,
        3885, 2376, 1916, 2498])
Epoch: 867, Training Loss: 0.14, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 868 - Batch 1 ########################
IDs in batch 1: tensor([2275, 3786, 3543, 3009, 1026,  980,  292,  344, 1774, 2448, 3333, 3695,
         843, 3787, 3480, 3659])
Epoch: 868, Training Loss: 0.12, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 869 - Batch 1 ########################
IDs in batch 1: tensor([2871,  530, 1196, 3663, 2967, 1181, 4027, 3075, 2364, 1085,  557,  846,
        3168, 3742, 1892,  363])
Epoch: 869, Training Loss: 0.29, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 870 - Batch 1 ########################
IDs in batch 1: tensor([2984, 3511, 2309,  159, 1363, 2522,  653,  601, 1804, 2797, 2095, 4050,
        1490, 2874,  517, 3838])
Epoch: 870, Training Loss: 0.26, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 871 - Batch 1 ########################
IDs in batch 1: tensor([4088, 3544, 1855, 2191, 3334, 3740, 2824, 3415,  483, 3241, 3197,  133,
        2337, 1117, 3787, 3404])
Epoch: 871, Training Loss: 0.41, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 872 - Batch 1 ########################
IDs in batch 1: tensor([1796, 2050, 4184, 2253, 1037,  101, 2153, 3940,  475,  881,  983, 3243,
        1335, 3337, 3309,  263])
Epoch: 872, Training Loss: 0.09, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 873 - Batch 1 ########################
IDs in batch 1: tensor([ 456, 1083, 3601,   10,  753, 3284, 3084, 1428, 2204, 1405, 1173, 3888,
        1219, 1122, 2732, 2914])
Epoch: 873, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 874 - Batch 1 ########################
IDs in batch 1: tensor([3989,  658, 3449,   60,   61, 1611,  333, 1525, 2356, 1869, 3217,   60,
         812, 3585, 3826, 3827])
Epoch: 874, Training Loss: 0.31, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 875 - Batch 1 ########################
IDs in batch 1: tensor([1209, 2693, 3956, 3424, 3437, 1053,  814, 3991, 1305, 4246, 2354, 1795,
         274, 3807,  775,  941])
Epoch: 875, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 876 - Batch 1 ########################
IDs in batch 1: tensor([2309, 1328, 4128, 1328, 2464, 3673, 3980, 1476,  887, 3016, 1655, 3180,
        2652, 2924,  603, 1543])
Epoch: 876, Training Loss: 0.16, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 877 - Batch 1 ########################
IDs in batch 1: tensor([1887, 1260,  988, 2737,  324, 2907,  243, 3514,  969,  482, 3688, 3489,
        2700, 1092, 4133, 2869])
Epoch: 877, Training Loss: 0.09, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 878 - Batch 1 ########################
IDs in batch 1: tensor([1027, 1932, 2106, 4003,   60, 3040,  632, 3049,  556, 2653, 1731, 1315,
        2669, 1340, 3711, 3871])
Epoch: 878, Training Loss: 0.29, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 879 - Batch 1 ########################
IDs in batch 1: tensor([3489, 3822, 1990,  785, 1152, 1404,  891, 1361, 2912,  825, 3984,   85,
        1251, 2957, 3087, 1704])
Epoch: 879, Training Loss: 0.22, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 880 - Batch 1 ########################
IDs in batch 1: tensor([1096, 3084, 1459,   86, 1138, 3589, 4046, 3342, 3721, 1139, 3109, 1857,
        1999, 2664, 1773, 1670])
Epoch: 880, Training Loss: 0.37, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 881 - Batch 1 ########################
IDs in batch 1: tensor([3638,  455,  121,  127,  274, 1242,  980, 2181,  630, 2826, 4265, 3949,
        2344, 4212, 1931,  964])
Epoch: 881, Training Loss: 0.47, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 882 - Batch 1 ########################
IDs in batch 1: tensor([2667, 2998, 1649, 1977, 3257,  277, 3850, 2844, 4035, 3286, 4174, 3518,
        4255,  612, 1933, 3378])
Epoch: 882, Training Loss: 0.26, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 883 - Batch 1 ########################
IDs in batch 1: tensor([3235, 2726, 1501, 2934,  324, 3072, 3105, 3692,  963, 3410,  683, 1418,
        1840, 1823, 1084, 1083])
Epoch: 883, Training Loss: 0.09, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 884 - Batch 1 ########################
IDs in batch 1: tensor([1168,  132, 1923, 3081, 3486, 2743, 1063, 2810,  701, 3971, 1032, 3421,
        1326, 2257, 3253,  550])
Epoch: 884, Training Loss: 0.33, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 885 - Batch 1 ########################
IDs in batch 1: tensor([1711, 3475, 3908,  926, 1993, 3599,  514, 1524, 2523, 2510, 2751, 1283,
        3349,  476, 4253, 1569])
Epoch: 885, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.77
######################## Epoch 886 - Batch 1 ########################
IDs in batch 1: tensor([2412, 1773, 1493, 1420,  909, 3071, 1257, 3822, 2632, 3473,  395, 2035,
        1482, 2947, 1370,  870])
Epoch: 886, Training Loss: 0.21, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 887 - Batch 1 ########################
IDs in batch 1: tensor([1914, 1236, 2235, 3843, 2983, 2161, 3235,  106, 2151,  269, 1822, 2237,
         340, 1663,  993, 2189])
Epoch: 887, Training Loss: 0.27, Validation Loss: 0.49, accuracy = 0.77
######################## Epoch 888 - Batch 1 ########################
IDs in batch 1: tensor([2013, 3585, 1266, 3312, 3115,  886, 3675, 2261, 2891,  729, 2467, 3287,
         295, 3271, 1636,  101])
Epoch: 888, Training Loss: 0.16, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 889 - Batch 1 ########################
IDs in batch 1: tensor([ 417,  258, 1003, 3926, 3469, 3009,  923, 2711, 3516,  382, 2295, 4264,
         177, 3455,  582,  968])
Epoch: 889, Training Loss: 0.11, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 890 - Batch 1 ########################
IDs in batch 1: tensor([ 893, 4165, 2683, 1458, 2406, 4030, 1803, 2367, 1054,  376,   95, 1900,
        2953, 2741, 3589,  187])
Epoch: 890, Training Loss: 0.29, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 891 - Batch 1 ########################
IDs in batch 1: tensor([1336, 2099, 2902, 3715,  126,  766, 2377, 1641, 3713, 2132, 3429, 2680,
         465, 3005, 1546,  544])
Epoch: 891, Training Loss: 0.23, Validation Loss: 0.48, accuracy = 0.78
######################## Epoch 892 - Batch 1 ########################
IDs in batch 1: tensor([4012, 2936,  145, 2663, 2873,  544, 3379, 1923, 3055, 4195, 4033, 3478,
        2901, 1951, 3983, 2102])
Epoch: 892, Training Loss: 0.55, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 893 - Batch 1 ########################
IDs in batch 1: tensor([1488, 1405, 3388, 2003,  687, 2364, 2917, 4249, 4181, 1345, 1291, 3637,
        3975, 2609, 3470, 4076])
Epoch: 893, Training Loss: 0.10, Validation Loss: 0.47, accuracy = 0.78
######################## Epoch 894 - Batch 1 ########################
IDs in batch 1: tensor([1379, 1128, 1476, 2437, 2908, 3711, 2009, 3810, 1229, 1086, 2064, 1809,
          62, 2400,  368, 3608])
Epoch: 894, Training Loss: 0.12, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 895 - Batch 1 ########################
IDs in batch 1: tensor([2940, 4015, 3481,  994, 1766, 1008,  496, 3744,   25, 1600, 1638, 1770,
        1312, 3460, 3240, 3251])
Epoch: 895, Training Loss: 0.23, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 896 - Batch 1 ########################
IDs in batch 1: tensor([1802, 2614, 3206, 3385, 3568, 3377, 1949, 2137, 2538, 2832, 3398, 1728,
        1830, 1710, 2568, 4100])
Epoch: 896, Training Loss: 0.60, Validation Loss: 0.47, accuracy = 0.79
######################## Epoch 897 - Batch 1 ########################
IDs in batch 1: tensor([3366,  888,  368, 3185, 4124,  684, 2014, 3261,  354, 3982, 3426, 2159,
        1060,  751, 2924, 3098])
Epoch: 897, Training Loss: 0.12, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 898 - Batch 1 ########################
IDs in batch 1: tensor([2108,  874, 3336,  496, 1256, 4235,  969,  507, 1305, 2475,   46, 2143,
        1658, 2080, 3235, 1670])
Epoch: 898, Training Loss: 0.42, Validation Loss: 0.48, accuracy = 0.79
######################## Epoch 899 - Batch 1 ########################
IDs in batch 1: tensor([2185, 1396, 1955,  683,  402,  337,  405, 1834, 3311, 3688, 1855,  391,
           4,  591,  963, 1084])
Epoch: 899, Training Loss: 0.45, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 900 - Batch 1 ########################
IDs in batch 1: tensor([2901, 1894, 1779, 4234,  630, 2469, 1868, 2760,  372,  653, 2584, 3582,
         181,  923, 3656,  344])
Epoch: 900, Training Loss: 0.09, Validation Loss: 0.49, accuracy = 0.78
######################## Epoch 901 - Batch 1 ########################
IDs in batch 1: tensor([4018, 3304, 1141, 2143, 4012, 3614, 1093, 4062, 3991, 1085,  477,  438,
         807,  971,  749, 2024])
Epoch: 901, Training Loss: 0.32, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 902 - Batch 1 ########################
IDs in batch 1: tensor([1626, 2050, 2649, 4072, 1361, 1649, 1916, 3333,  245,  870, 2198,   28,
        1182,  983, 3526,  373])
Epoch: 902, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 903 - Batch 1 ########################
IDs in batch 1: tensor([2178, 1679,  873, 1415, 2329, 1645, 3465, 2428, 2998, 2631, 4242,  391,
        1458, 2257, 1573, 1985])
Epoch: 903, Training Loss: 0.12, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 904 - Batch 1 ########################
IDs in batch 1: tensor([ 306,  139, 3339, 2963, 1794, 2065, 3303, 1031, 1809, 3856,  805, 4124,
        2232, 2937,  891,   26])
Epoch: 904, Training Loss: 0.14, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 905 - Batch 1 ########################
IDs in batch 1: tensor([2993, 1434, 1623, 1406, 3777, 1626,  138, 2224, 2260, 1181, 3572, 2435,
        4154,  196,  694, 1097])
Epoch: 905, Training Loss: 0.44, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 906 - Batch 1 ########################
IDs in batch 1: tensor([3425,  601, 2120, 2765, 3630, 3369, 1173, 3734, 1031,  591, 2225,  397,
        1911, 1285, 3114, 2681])
Epoch: 906, Training Loss: 0.25, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 907 - Batch 1 ########################
IDs in batch 1: tensor([1841, 3204,  741, 1982, 2884,  199, 3642, 1020, 3642, 2177, 1658, 2782,
        3587, 2461, 3808, 4048])
Epoch: 907, Training Loss: 0.26, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 908 - Batch 1 ########################
IDs in batch 1: tensor([1641, 1351,  830, 1161,  110, 2109,  687, 2478, 2044, 1710, 2277,  796,
        1349,  878, 4253, 1845])
Epoch: 908, Training Loss: 0.31, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 909 - Batch 1 ########################
IDs in batch 1: tensor([ 642, 1578,  160, 3245, 4226, 3139, 2711, 3010, 1232, 2600, 2838, 2712,
        2428, 1496, 1223, 2110])
Epoch: 909, Training Loss: 0.10, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 910 - Batch 1 ########################
IDs in batch 1: tensor([1555,  892, 3503, 2324, 2113,  752,  229, 1524, 3434, 3920, 4184, 3265,
        1530, 2592, 2278,  928])
Epoch: 910, Training Loss: 0.14, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 911 - Batch 1 ########################
IDs in batch 1: tensor([3841, 2358, 2226,  275, 1233, 3489, 1124, 1143, 2148, 3493, 1177, 2094,
        1310, 2812,  430, 2305])
Epoch: 911, Training Loss: 0.10, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 912 - Batch 1 ########################
IDs in batch 1: tensor([ 170, 1051, 3144, 3051, 2134, 2272, 1933,  411, 1334, 2455, 4229,  201,
        2838, 4228,  482, 3822])
Epoch: 912, Training Loss: 0.10, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 913 - Batch 1 ########################
IDs in batch 1: tensor([1640, 3123, 3265, 4049, 1478, 3178, 4078, 2917, 2003,  732, 3492, 2837,
        2449, 2179, 2176, 4012])
Epoch: 913, Training Loss: 0.37, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 914 - Batch 1 ########################
IDs in batch 1: tensor([1996,  361, 3721, 2407, 1395, 1163,  779,  122,  949, 3878, 3382, 1974,
         788, 2343, 2847, 3423])
Epoch: 914, Training Loss: 0.11, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 915 - Batch 1 ########################
IDs in batch 1: tensor([1146,  947,  536, 1408, 1526,  348,  203, 1488, 2760, 3044, 1318, 1216,
         593, 2539,   74, 2629])
Epoch: 915, Training Loss: 0.62, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 916 - Batch 1 ########################
IDs in batch 1: tensor([ 109, 2764, 2134,  613, 2632, 3328, 4246,  607, 1181, 2167,  612, 3082,
        1473,  300, 2561, 2800])
Epoch: 916, Training Loss: 0.24, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 917 - Batch 1 ########################
IDs in batch 1: tensor([2493, 1055,  530, 1955, 3925,  612, 1206, 3178, 3372, 2443, 2844, 1216,
         613, 3989, 2291, 2116])
Epoch: 917, Training Loss: 0.09, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 918 - Batch 1 ########################
IDs in batch 1: tensor([ 844,  987, 1796, 4068,  229, 2312, 3452, 3912,  981, 2312, 3933, 2562,
        2710, 1597,  805,  625])
Epoch: 918, Training Loss: 0.36, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 919 - Batch 1 ########################
IDs in batch 1: tensor([2752,  683, 3259, 2141, 1255,   38, 4058, 3275, 1716, 3668,  907, 2770,
        2095,  890, 4049, 2703])
Epoch: 919, Training Loss: 0.36, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 920 - Batch 1 ########################
IDs in batch 1: tensor([3337, 2931, 2810, 4107, 4100, 2794, 1442, 1030, 2203, 3600, 1732,  660,
        1828, 2734, 3925, 3184])
Epoch: 920, Training Loss: 0.64, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 921 - Batch 1 ########################
IDs in batch 1: tensor([2725, 1093, 3812, 1083, 3698, 2587, 4161, 1375,  524, 1141, 2334, 2177,
        3179, 1821, 3214,  971])
Epoch: 921, Training Loss: 0.18, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 922 - Batch 1 ########################
IDs in batch 1: tensor([ 809, 3925, 2234, 1553, 1247, 3632,  575,  816, 3196,  775, 2050, 1008,
         960, 3742, 3410, 3392])
Epoch: 922, Training Loss: 0.08, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 923 - Batch 1 ########################
IDs in batch 1: tensor([ 547,  839, 1668, 2542, 4121, 3374, 3381, 4197, 2253, 2925, 1060, 3845,
        1384, 4217,  315, 4143])
Epoch: 923, Training Loss: 0.44, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 924 - Batch 1 ########################
IDs in batch 1: tensor([1185, 1432, 1248, 2693, 1660,   51, 1107, 2375,  825, 1459, 4261, 4139,
        3075, 1835, 3943, 3250])
Epoch: 924, Training Loss: 0.12, Validation Loss: 0.52, accuracy = 0.79
######################## Epoch 925 - Batch 1 ########################
IDs in batch 1: tensor([2538,  910,  321,  369,  920, 2968, 1567,  320, 1937, 3863, 2080,  569,
         205, 2672, 4226,  322])
Epoch: 925, Training Loss: 0.26, Validation Loss: 0.52, accuracy = 0.79
######################## Epoch 926 - Batch 1 ########################
IDs in batch 1: tensor([3040, 1007, 2688, 4037, 3908,  882, 4011, 4007, 3286,  747, 2292, 3950,
        2019, 4018, 2226, 3500])
Epoch: 926, Training Loss: 0.54, Validation Loss: 0.52, accuracy = 0.79
######################## Epoch 927 - Batch 1 ########################
IDs in batch 1: tensor([1177, 2772, 4072, 1312, 1646, 2664,  275, 2618, 1962,   14, 3126, 1155,
        1158, 3353, 1583, 3006])
Epoch: 927, Training Loss: 0.12, Validation Loss: 0.52, accuracy = 0.79
######################## Epoch 928 - Batch 1 ########################
IDs in batch 1: tensor([ 269, 2410, 3911,  893, 2953, 2195, 2074, 3027, 1883, 4246, 2173, 2122,
        1562, 1588,  507, 3284])
Epoch: 928, Training Loss: 0.37, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 929 - Batch 1 ########################
IDs in batch 1: tensor([ 278, 1808,   13, 2390, 1132, 3049, 1732, 1684, 2804, 1039, 1077, 4166,
        1570, 2324, 2565, 2589])
Epoch: 929, Training Loss: 0.16, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 930 - Batch 1 ########################
IDs in batch 1: tensor([2886, 3762, 1555, 3309, 3345, 2782,  467,  863, 1756, 3845, 1020, 4044,
         206, 1685, 1899,  961])
Epoch: 930, Training Loss: 0.66, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 931 - Batch 1 ########################
IDs in batch 1: tensor([ 151, 1597,  756, 2601, 3601, 3022, 1826, 1482, 2245,  314, 2982,  238,
         775,  651, 4050, 3283])
Epoch: 931, Training Loss: 0.56, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 932 - Batch 1 ########################
IDs in batch 1: tensor([ 245, 4107, 1575, 3447,  515, 3573, 1038, 2378, 3108,   61, 2038,  797,
        3672, 3258, 1976,  970])
Epoch: 932, Training Loss: 0.30, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 933 - Batch 1 ########################
IDs in batch 1: tensor([3432, 2347, 1684, 3102, 1638,  459, 2854, 3394, 2365,  316, 2695, 1357,
        1789, 1826, 3156,  137])
Epoch: 933, Training Loss: 0.30, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 934 - Batch 1 ########################
IDs in batch 1: tensor([3039,  974, 1158, 1302,  130,   11, 3480,  956, 2285, 1681, 1140, 3108,
        3459, 2379, 2892, 2548])
Epoch: 934, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 935 - Batch 1 ########################
IDs in batch 1: tensor([2519, 3217, 2540, 3470,  487, 1640, 1251, 1099, 2996,  494, 3356, 3390,
        2802,  623, 2472, 1524])
Epoch: 935, Training Loss: 0.21, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 936 - Batch 1 ########################
IDs in batch 1: tensor([ 418,  743, 3486, 2342,   56,  232, 1161, 2017, 3745,   98,  379,  522,
        3912, 1536,  300, 1008])
Epoch: 936, Training Loss: 0.53, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 937 - Batch 1 ########################
IDs in batch 1: tensor([1954, 2180, 2632, 3516, 2465,  878,   99,  462,  127, 3557,  823, 3339,
        2998, 2561, 1278,  375])
Epoch: 937, Training Loss: 0.17, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 938 - Batch 1 ########################
IDs in batch 1: tensor([2279, 4014, 2402,  612,  343,  886, 3680, 2218, 2799, 1899, 1156, 3243,
        1706, 3856, 1286, 2436])
Epoch: 938, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 939 - Batch 1 ########################
IDs in batch 1: tensor([ 788, 3147, 3712, 3407, 2435,   70, 1167,  892,   88,  899, 1438, 2548,
        2469, 3998, 3832,   31])
Epoch: 939, Training Loss: 0.06, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 940 - Batch 1 ########################
IDs in batch 1: tensor([3366, 3498,  701, 2365, 3443, 2978, 1634, 1497,  753,  917,  871, 2815,
        2990,  977, 3469, 4194])
Epoch: 940, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 941 - Batch 1 ########################
IDs in batch 1: tensor([ 520, 1925, 1574,  376, 2621, 1765, 2627,  721,  276, 2897, 3501,   51,
         180,  261, 1038,  959])
Epoch: 941, Training Loss: 0.56, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 942 - Batch 1 ########################
IDs in batch 1: tensor([3603, 4180, 2292, 3533, 4084,  505, 2399, 3907,   93,  494, 2871, 3863,
        1200,  991, 1244, 1463])
Epoch: 942, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 943 - Batch 1 ########################
IDs in batch 1: tensor([1568,  978, 2860, 2416, 1956, 3704,  961, 1975,  797, 2895, 2252, 2754,
        3314, 2649, 3980, 3728])
Epoch: 943, Training Loss: 0.48, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 944 - Batch 1 ########################
IDs in batch 1: tensor([1677, 3088, 1279, 1469, 2581, 2908, 3150, 2463,   73,  477, 1841, 1841,
        3259, 3865, 2826, 1511])
Epoch: 944, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 945 - Batch 1 ########################
IDs in batch 1: tensor([1961, 3038, 2741,   61,  395, 3751,  427, 1022,  656, 2730,  815,  660,
        4038, 2466,  663, 1344])
Epoch: 945, Training Loss: 0.30, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 946 - Batch 1 ########################
IDs in batch 1: tensor([1830,   92, 4189, 2365, 2800, 2765, 3392, 4159, 2416, 3418,  730, 2473,
        3921,  967, 2113, 2180])
Epoch: 946, Training Loss: 0.42, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 947 - Batch 1 ########################
IDs in batch 1: tensor([ 738, 3888, 2961, 4105,  657,  463, 3392, 2373, 2788,  672,  683, 2433,
        1625, 2224,  986, 4170])
Epoch: 947, Training Loss: 0.33, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 948 - Batch 1 ########################
IDs in batch 1: tensor([ 212,  470, 3975, 3709, 3143,  351,  195, 1395, 1678, 3065,  642, 4261,
          84,  887,  767, 1794])
Epoch: 948, Training Loss: 0.41, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 949 - Batch 1 ########################
IDs in batch 1: tensor([3053, 3023, 1972, 1778, 2520, 1740, 3484,  439,  601, 1927, 3373, 1273,
        2262, 3607, 3400, 3950])
Epoch: 949, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 950 - Batch 1 ########################
IDs in batch 1: tensor([1698,  874,  377, 1620, 3573, 2993,  508, 2524, 2791, 2965, 2815, 1642,
        4009, 1271, 2260, 3329])
Epoch: 950, Training Loss: 0.10, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 951 - Batch 1 ########################
IDs in batch 1: tensor([2879, 2123,  152, 3168,  279, 1812,  305, 2951, 1746, 1097, 1732,  469,
        3862, 3912, 3133, 3219])
Epoch: 951, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 952 - Batch 1 ########################
IDs in batch 1: tensor([ 863,   35, 4053, 3306, 1028, 3494, 2324,  827, 1984,  974, 2561, 2912,
        1093, 1720, 3704, 4039])
Epoch: 952, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 953 - Batch 1 ########################
IDs in batch 1: tensor([3607,  290, 1054, 1733, 1501, 1937, 1103, 2050,  823, 1388, 1482, 2435,
        3669, 3630, 3630, 3532])
Epoch: 953, Training Loss: 0.12, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 954 - Batch 1 ########################
IDs in batch 1: tensor([ 387, 1650, 4057, 3082, 1231, 1143,  143, 1633, 1167, 1162, 2066, 3958,
         937,  755,  933, 1485])
Epoch: 954, Training Loss: 0.72, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 955 - Batch 1 ########################
IDs in batch 1: tensor([3375,   26, 4078,  626,  628, 3073, 2399, 3960, 1569, 2360, 1868,  607,
        4134, 1181, 1332, 1655])
Epoch: 955, Training Loss: 0.24, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 956 - Batch 1 ########################
IDs in batch 1: tensor([3532,  572,  849, 3988, 2523,  717, 2719, 3255, 1877, 1708,  755,  789,
        2568, 3369, 2235, 4185])
Epoch: 956, Training Loss: 0.25, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 957 - Batch 1 ########################
IDs in batch 1: tensor([  95, 2953, 1634,  117, 3590, 3410,  544,  533, 3472, 2806,  194,  950,
          14, 4176, 3879, 4187])
Epoch: 957, Training Loss: 0.24, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 958 - Batch 1 ########################
IDs in batch 1: tensor([1638,  340, 3148, 4067,  354, 1881, 4253, 1644, 2108,  256, 2595,  405,
        3271, 3988, 3051, 1463])
Epoch: 958, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 959 - Batch 1 ########################
IDs in batch 1: tensor([3739, 1599, 4120, 1335,  893,  358, 3272, 1087, 3900, 3503, 3749,  427,
        4101, 3259, 2447, 1775])
Epoch: 959, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 960 - Batch 1 ########################
IDs in batch 1: tensor([1377, 1595, 1478, 3065, 1753, 3478, 2520, 3604, 3878,  276, 3969,  384,
        3152, 4174, 2370, 4078])
Epoch: 960, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 961 - Batch 1 ########################
IDs in batch 1: tensor([1196, 3905, 3289, 1618, 1511, 2135, 1328, 1678, 4032, 2072,  112,  878,
         292, 1287, 3206, 1423])
Epoch: 961, Training Loss: 0.28, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 962 - Batch 1 ########################
IDs in batch 1: tensor([1894, 4268, 2855, 2110, 3029, 3907, 2949, 1396, 3573, 1003, 3484, 1257,
          10, 3859, 2558,  389])
Epoch: 962, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 963 - Batch 1 ########################
IDs in batch 1: tensor([1034, 3204,  110, 4175, 2050,  207, 3323, 4087, 3921, 2771, 2005, 3023,
        3487, 3530,  862, 2094])
Epoch: 963, Training Loss: 0.24, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 964 - Batch 1 ########################
IDs in batch 1: tensor([ 594,  966,  437,  775, 3475, 4154, 2347, 1822,  926, 3856,  226,  505,
        2195, 2969,  995,  535])
Epoch: 964, Training Loss: 0.42, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 965 - Batch 1 ########################
IDs in batch 1: tensor([1458, 3540, 2873, 2540,   24, 3373, 2085,   43, 4226, 1830,  649, 2017,
        2996, 2170,   42, 3275])
Epoch: 965, Training Loss: 0.16, Validation Loss: 0.60, accuracy = 0.74
######################## Epoch 966 - Batch 1 ########################
IDs in batch 1: tensor([3023, 4217, 3642, 1351, 4256, 2863, 3528, 3418, 2419, 3667, 2908, 3738,
        4089, 2650, 1201, 4038])
Epoch: 966, Training Loss: 0.71, Validation Loss: 0.61, accuracy = 0.74
######################## Epoch 967 - Batch 1 ########################
IDs in batch 1: tensor([1328, 3695, 1257, 2450, 1673, 1651, 1913, 3792, 2272, 2468,  546, 3214,
        1600, 3702, 1017, 2494])
Epoch: 967, Training Loss: 0.17, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 968 - Batch 1 ########################
IDs in batch 1: tensor([2858, 1178, 2540, 1480, 3958, 2650, 1570, 3401, 1131, 2672, 3110, 1502,
        2338,  586, 2132, 1732])
Epoch: 968, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 969 - Batch 1 ########################
IDs in batch 1: tensor([  46, 1832, 1803, 2022, 2796,  823, 3812,  627, 1396,  874, 2652, 2827,
        3542, 3869, 3490, 4157])
Epoch: 969, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 970 - Batch 1 ########################
IDs in batch 1: tensor([3438, 2159,  489, 1384, 2320, 3505, 1396, 3248, 3875,  425,  930,  680,
        4000,  701, 1285, 2449])
Epoch: 970, Training Loss: 0.15, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 971 - Batch 1 ########################
IDs in batch 1: tensor([3433, 2866, 2842, 1180,  824, 2661, 3511,  376, 1379, 3120, 3771, 1480,
         143, 1990,  982, 3131])
Epoch: 971, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 972 - Batch 1 ########################
IDs in batch 1: tensor([1283,  264, 1204, 3199, 2382, 2990, 1746, 2812, 4166, 1660,  930, 2143,
        2157, 2655, 3256, 1678])
Epoch: 972, Training Loss: 0.19, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 973 - Batch 1 ########################
IDs in batch 1: tensor([2442, 1821, 1799, 2874,  435, 1592, 3114, 2070,  295, 1092, 3073, 4263,
        2010,   61,  575,  194])
Epoch: 973, Training Loss: 0.27, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 974 - Batch 1 ########################
IDs in batch 1: tensor([3689,   35, 2775, 2518, 4097,  264, 3601,  256, 3268, 1170, 3321, 1146,
        1673,  771, 3813, 3084])
Epoch: 974, Training Loss: 0.20, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 975 - Batch 1 ########################
IDs in batch 1: tensor([2550, 3888, 1723, 2026,  739, 2282,  393,   62, 1286, 3366, 1200, 3815,
         444, 2942, 1617,  950])
Epoch: 975, Training Loss: 0.32, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 976 - Batch 1 ########################
IDs in batch 1: tensor([ 203, 1762,  529, 1624, 1255, 3875, 3110, 1196,  232, 2276, 3585,   73,
        2309, 3039, 2649, 4070])
Epoch: 976, Training Loss: 0.14, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 977 - Batch 1 ########################
IDs in batch 1: tensor([1779,  281, 4257,  103, 3461, 3790, 3051, 3099,  862, 2969, 2203, 3698,
         829, 3760, 1733,  183])
Epoch: 977, Training Loss: 0.20, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 978 - Batch 1 ########################
IDs in batch 1: tensor([2795, 2511, 2095, 3143, 1373, 3782, 3475, 2442, 2629, 2482,  200,  682,
        2723, 2539, 1530, 2229])
Epoch: 978, Training Loss: 0.14, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 979 - Batch 1 ########################
IDs in batch 1: tensor([2085, 3897,  376, 1499, 1471, 1927, 2067, 1651, 3591, 3655, 1804,  941,
        1552,   88,  963,  558])
Epoch: 979, Training Loss: 0.34, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 980 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 3009,  225, 2964,  970, 3334,  150, 2191, 1101, 2509, 2681, 1980,
        1910, 1045, 1160, 3207])
Epoch: 980, Training Loss: 0.23, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 981 - Batch 1 ########################
IDs in batch 1: tensor([1324, 3621,  833, 1032, 2867, 3672, 4096, 2739, 3216, 3850, 2848,  822,
        1567, 3743, 1384, 1897])
Epoch: 981, Training Loss: 0.26, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 982 - Batch 1 ########################
IDs in batch 1: tensor([  95, 2521, 3994,  892, 4016,  919, 3016, 2081,  815, 2369,  471, 4031,
        1386, 3806, 2866,   46])
Epoch: 982, Training Loss: 0.10, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 983 - Batch 1 ########################
IDs in batch 1: tensor([ 527,  743, 1121,  915,  582, 1354, 2781, 2732, 2775, 2362, 1810, 3190,
        2470, 3102, 1186, 3542])
Epoch: 983, Training Loss: 0.15, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 984 - Batch 1 ########################
IDs in batch 1: tensor([ 663, 1054, 2085, 2086, 3265, 2401, 2831, 2344, 1600, 3975, 3130,  220,
         402, 3567, 2015, 3265])
Epoch: 984, Training Loss: 0.11, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 985 - Batch 1 ########################
IDs in batch 1: tensor([2099, 4075, 1787, 2369, 3913,  879, 3829, 1344, 2848,  752, 2603, 1144,
        1732, 4165, 1117, 2937])
Epoch: 985, Training Loss: 0.15, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 986 - Batch 1 ########################
IDs in batch 1: tensor([2371, 1897, 3693,    5, 1070, 1087,  709, 3982,  936, 4084, 4012, 1276,
         252, 3982, 3608,  515])
Epoch: 986, Training Loss: 0.16, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 987 - Batch 1 ########################
IDs in batch 1: tensor([ 884, 1920, 2031, 2461,  956, 2066, 2133,  613, 4036, 2653, 1723, 1085,
         538,  250, 1478,  442])
Epoch: 987, Training Loss: 0.28, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 988 - Batch 1 ########################
IDs in batch 1: tensor([3544, 1275, 3399, 3698, 1871, 3545,  899, 2497, 4234, 1274, 3069, 2947,
        2809, 4156, 4175,  627])
Epoch: 988, Training Loss: 0.17, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 989 - Batch 1 ########################
IDs in batch 1: tensor([2252, 2207, 2067, 1222, 2121, 1681, 2418, 1456, 1824, 1986, 2189, 2365,
        3718, 3214, 1979, 1984])
Epoch: 989, Training Loss: 0.27, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 990 - Batch 1 ########################
IDs in batch 1: tensor([2868, 2674, 1455, 2234, 4180,  910, 3658, 3898, 1453, 1065, 2035, 4138,
        1920, 1980,  839, 4214])
Epoch: 990, Training Loss: 0.36, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 991 - Batch 1 ########################
IDs in batch 1: tensor([1630, 3661,  487,  656,  280, 2282, 2203, 4031,  997,   56, 2420,  382,
          74, 3444,  704, 1325])
Epoch: 991, Training Loss: 0.51, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 992 - Batch 1 ########################
IDs in batch 1: tensor([3025, 1313, 3330, 1923,  779, 4139, 2256,  351, 1959, 1634,  921, 4087,
        1034, 1281,   99, 2791])
Epoch: 992, Training Loss: 0.10, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 993 - Batch 1 ########################
IDs in batch 1: tensor([2465, 4084, 3168, 2304,   20,  181,  100, 2386,  344,  369, 1050, 3994,
        1186, 1877, 2456, 2492])
Epoch: 993, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 994 - Batch 1 ########################
IDs in batch 1: tensor([4212, 2492, 3927, 2124, 1177,  195, 3058, 1006,  959, 2015, 3590, 1222,
        3787, 3478, 3746,  855])
Epoch: 994, Training Loss: 0.14, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 995 - Batch 1 ########################
IDs in batch 1: tensor([2953, 1395, 3327, 3161, 3488, 3251, 4032, 3373, 2858, 2346, 3760, 1264,
        4217, 1075, 3798,  418])
Epoch: 995, Training Loss: 0.32, Validation Loss: 0.57, accuracy = 0.74
######################## Epoch 996 - Batch 1 ########################
IDs in batch 1: tensor([  96,  225, 3535, 3862, 2462, 3838, 1504,  100, 3668, 4152, 3278, 1897,
        2752, 2108, 2141, 4113])
Epoch: 996, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.74
######################## Epoch 997 - Batch 1 ########################
IDs in batch 1: tensor([2587, 3366, 1132, 1588, 3812, 3894,  771, 1352,   97, 2252,  213, 3525,
         625,  147, 3203,  790])
Epoch: 997, Training Loss: 0.19, Validation Loss: 0.57, accuracy = 0.74
######################## Epoch 998 - Batch 1 ########################
IDs in batch 1: tensor([ 652, 3379, 1225,  584,  523, 1512,  238, 2949, 3536,  756, 2443, 4022,
         632,  809, 3618, 2280])
Epoch: 998, Training Loss: 0.48, Validation Loss: 0.57, accuracy = 0.74
######################## Epoch 999 - Batch 1 ########################
IDs in batch 1: tensor([2968,   34, 2316,  956, 2327, 3943, 1570,  547, 1088, 1500,  357,  928,
        3726, 2697, 4025,  679])
Epoch: 999, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.74
######################## Epoch 1000 - Batch 1 ########################
IDs in batch 1: tensor([2954, 3719, 2432, 3781, 2831,  292, 3378, 4127, 3478, 1623,  926, 1173,
        3304,  344, 1859,  334])
Epoch: 1000, Training Loss: 0.06, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1001 - Batch 1 ########################
IDs in batch 1: tensor([1108, 3152, 2603, 2508,  223, 4187, 3728, 1485, 1859,  577,  427, 1281,
        2605,  337, 3956, 2995])
Epoch: 1001, Training Loss: 0.16, Validation Loss: 0.56, accuracy = 0.74
######################## Epoch 1002 - Batch 1 ########################
IDs in batch 1: tensor([2473, 1443,  185,  188, 3398, 2013, 2853, 2655, 2700, 2555, 3731,  196,
        2550, 2075, 2681, 2167])
Epoch: 1002, Training Loss: 0.31, Validation Loss: 0.55, accuracy = 0.74
######################## Epoch 1003 - Batch 1 ########################
IDs in batch 1: tensor([2821, 1361,  819,  338,  869, 1808, 2366, 2977,  750, 1921, 1911, 2023,
        1571, 4166, 1249, 1570])
Epoch: 1003, Training Loss: 0.14, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1004 - Batch 1 ########################
IDs in batch 1: tensor([2828,  870, 1524, 4253,  514, 3852, 1065, 3823, 1050, 2463, 3493, 2261,
        2989, 2898, 1168, 4242])
Epoch: 1004, Training Loss: 0.13, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 1005 - Batch 1 ########################
IDs in batch 1: tensor([2245, 1951, 2480, 2996, 1453, 1051, 2643, 1154,  384, 1426, 3353, 1119,
        2653,  732, 1850,  838])
Epoch: 1005, Training Loss: 0.17, Validation Loss: 0.51, accuracy = 0.76
######################## Epoch 1006 - Batch 1 ########################
IDs in batch 1: tensor([1464,   70, 2298,  161, 3883, 4165, 3381, 3035, 2855, 1309, 2053,  896,
        2207, 3821, 1354, 3632])
Epoch: 1006, Training Loss: 0.16, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 1007 - Batch 1 ########################
IDs in batch 1: tensor([3115,  140, 4257, 2497, 3996,  281, 3091, 2982, 1861, 4015,  573,  172,
          51, 3549, 2667, 1181])
Epoch: 1007, Training Loss: 0.10, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 1008 - Batch 1 ########################
IDs in batch 1: tensor([ 678, 4268, 3870, 2752, 2360, 3914, 1984, 4197,  213, 3511, 3732, 3394,
        1937, 1391, 3564, 1330])
Epoch: 1008, Training Loss: 0.19, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 1009 - Batch 1 ########################
IDs in batch 1: tensor([1617, 3876, 3291, 3369, 4156, 1124, 3674, 1751, 2784, 3223, 1880, 1363,
        3448,  794, 3533, 1039])
Epoch: 1009, Training Loss: 0.13, Validation Loss: 0.51, accuracy = 0.77
######################## Epoch 1010 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 1270, 1221, 3733, 1765,  968, 2439, 1367,  839, 3846, 4003,  989,
         280, 1999,  982, 3185])
Epoch: 1010, Training Loss: 0.46, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 1011 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 2892, 2524, 4068,  302, 2899, 3952,  858, 3357, 2659, 3518, 2849,
        2894, 2466, 1552, 1132])
Epoch: 1011, Training Loss: 0.23, Validation Loss: 0.50, accuracy = 0.76
######################## Epoch 1012 - Batch 1 ########################
IDs in batch 1: tensor([3475, 1006,  432, 3379, 3079,  211, 3816, 1108, 3211, 4051, 2563, 2829,
         476, 1198, 1059, 3475])
Epoch: 1012, Training Loss: 0.35, Validation Loss: 0.50, accuracy = 0.77
######################## Epoch 1013 - Batch 1 ########################
IDs in batch 1: tensor([ 373,  320, 3706, 3590,  533, 4053, 1387,  787, 4075, 4127, 1255, 2777,
         642,  676, 1885, 2689])
Epoch: 1013, Training Loss: 0.16, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 1014 - Batch 1 ########################
IDs in batch 1: tensor([1958, 4076, 3427, 3537, 1559, 1110, 3894,  968, 3489,  471, 3922, 3022,
        1502, 2324, 1263, 3243])
Epoch: 1014, Training Loss: 0.14, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 1015 - Batch 1 ########################
IDs in batch 1: tensor([3354, 1014, 3368,  649,  893, 4055, 1763, 2276, 2548,  813, 3838, 2462,
        2262,  779, 1417,  544])
Epoch: 1015, Training Loss: 0.18, Validation Loss: 0.50, accuracy = 0.79
######################## Epoch 1016 - Batch 1 ########################
IDs in batch 1: tensor([4158,  412, 2426,  516, 3426, 1144, 3832, 3654,  544, 2051, 4234, 3435,
        2282, 2505, 2913, 4101])
Epoch: 1016, Training Loss: 0.23, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 1017 - Batch 1 ########################
IDs in batch 1: tensor([  63, 3851, 1982, 3866, 2950, 3338,  207, 1200, 4115, 3871, 3309, 3528,
        4061, 2546,  325, 4146])
Epoch: 1017, Training Loss: 0.17, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 1018 - Batch 1 ########################
IDs in batch 1: tensor([3771, 1199, 1647, 3632,  812, 2777, 2828, 1209, 3239, 2213, 1817,   72,
         583, 1128, 1699, 2350])
Epoch: 1018, Training Loss: 0.14, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 1019 - Batch 1 ########################
IDs in batch 1: tensor([3120, 1289, 1566, 1167, 3833, 2040, 2950, 1991, 3705, 1426,  623, 1935,
         684, 2117, 1732, 2415])
Epoch: 1019, Training Loss: 0.16, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 1020 - Batch 1 ########################
IDs in batch 1: tensor([ 555, 2789, 3757, 1383,  295, 2887, 2067,  926, 4077,  523,  527, 4119,
         371,  138, 3816, 1027])
Epoch: 1020, Training Loss: 0.30, Validation Loss: 0.51, accuracy = 0.79
######################## Epoch 1021 - Batch 1 ########################
IDs in batch 1: tensor([2876, 2949, 3047, 1369, 2281, 1962, 1799, 1963, 2871, 1027,  713, 4099,
        3674, 3488, 1773, 2669])
Epoch: 1021, Training Loss: 0.42, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 1022 - Batch 1 ########################
IDs in batch 1: tensor([ 472, 2966, 1480, 3647, 2629, 3498, 2004, 1388,  531, 3577, 4015,  128,
         463, 4257,  721, 3972])
Epoch: 1022, Training Loss: 0.87, Validation Loss: 0.50, accuracy = 0.78
######################## Epoch 1023 - Batch 1 ########################
IDs in batch 1: tensor([2315,  102, 3126, 1232, 3581, 3077, 3440,  375, 1563, 2394,  590, 3663,
        3197, 1897, 2899, 2015])
Epoch: 1023, Training Loss: 0.14, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 1024 - Batch 1 ########################
IDs in batch 1: tensor([3120, 3728,  995, 1648,  132, 3745,  726, 3193, 1708, 2687, 3698, 3913,
        1063, 4065, 3621, 1921])
Epoch: 1024, Training Loss: 0.18, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 1025 - Batch 1 ########################
IDs in batch 1: tensor([1049, 2743, 3178, 3399, 2189, 2078, 3278, 3128, 3948,  615, 4060, 1415,
        3342, 1370, 1140, 3475])
Epoch: 1025, Training Loss: 0.21, Validation Loss: 0.49, accuracy = 0.79
######################## Epoch 1026 - Batch 1 ########################
IDs in batch 1: tensor([2196,  774, 3765, 3069, 3216,  456,  211, 2894, 2791, 1371, 1612, 4266,
        2172, 3878, 2839,  875])
Epoch: 1026, Training Loss: 0.13, Validation Loss: 0.50, accuracy = 0.79
######################## Epoch 1027 - Batch 1 ########################
IDs in batch 1: tensor([1336, 2099,  555, 3208, 2482, 3564, 1808, 1432, 2391, 3523,  470, 2342,
         966, 2853, 2315, 1418])
Epoch: 1027, Training Loss: 0.08, Validation Loss: 0.50, accuracy = 0.79
######################## Epoch 1028 - Batch 1 ########################
IDs in batch 1: tensor([2802,  923, 3367, 2192, 2003, 3309, 2086, 1473,  558, 1084,   78, 4217,
         533,  243,  300, 1752])
Epoch: 1028, Training Loss: 0.16, Validation Loss: 0.50, accuracy = 0.79
######################## Epoch 1029 - Batch 1 ########################
IDs in batch 1: tensor([2414, 4203, 3083, 1041,  388, 3535, 1762, 1763, 2377, 2053, 3252, 1971,
         261, 1419, 3044, 2238])
Epoch: 1029, Training Loss: 0.16, Validation Loss: 0.51, accuracy = 0.78
######################## Epoch 1030 - Batch 1 ########################
IDs in batch 1: tensor([2986, 2598, 2344, 3518, 3340, 1675, 2863, 1034, 1748, 3452, 2051, 2854,
        3036, 3516,  978, 3072])
Epoch: 1030, Training Loss: 0.14, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 1031 - Batch 1 ########################
IDs in batch 1: tensor([1613,  594,  128, 2655, 1357, 2236, 3354, 2582,  128, 1826,   31,   57,
         317, 1328, 2521,  281])
Epoch: 1031, Training Loss: 0.53, Validation Loss: 0.52, accuracy = 0.78
######################## Epoch 1032 - Batch 1 ########################
IDs in batch 1: tensor([1851, 2281,   62, 1299, 1233, 1880, 1599, 3073, 2431, 3609,  709, 2934,
         104, 2466, 3433,  895])
Epoch: 1032, Training Loss: 0.28, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1033 - Batch 1 ########################
IDs in batch 1: tensor([2256,  303, 3027, 2235, 2504, 2546,  923,  813, 1162, 1656, 1521, 3698,
        1330, 3087, 1763, 4103])
Epoch: 1033, Training Loss: 0.16, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1034 - Batch 1 ########################
IDs in batch 1: tensor([3860,  910, 2475, 1376,  438,  991, 3389, 4176, 3182,  959, 4251, 1004,
        3894, 3927, 2784, 2546])
Epoch: 1034, Training Loss: 0.09, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1035 - Batch 1 ########################
IDs in batch 1: tensor([1618, 2457, 3704, 4148,  674, 1405, 4254, 1849, 4172, 3143,  757, 1676,
        3945, 3962,  691, 2348])
Epoch: 1035, Training Loss: 0.35, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1036 - Batch 1 ########################
IDs in batch 1: tensor([1367, 1136, 1693, 2406,  796, 3109, 3181,  173, 1305, 3087, 4257, 1152,
        2094, 3370, 2365, 2467])
Epoch: 1036, Training Loss: 0.24, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1037 - Batch 1 ########################
IDs in batch 1: tensor([2050, 3343, 1951, 1004, 2123, 3433, 1546, 3142,  982,  678,  550, 3523,
        2488, 3044,  688,  713])
Epoch: 1037, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1038 - Batch 1 ########################
IDs in batch 1: tensor([1657, 3772, 1955,  769, 1171, 2482, 3268, 1159, 2817, 1232, 2964, 1279,
        2025, 3112, 2764,  516])
Epoch: 1038, Training Loss: 0.35, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1039 - Batch 1 ########################
IDs in batch 1: tensor([2176, 1034,  412, 3895, 2090, 2482,  263, 1234, 1633,  554, 1250,  129,
        4069, 3494, 1017, 3671])
Epoch: 1039, Training Loss: 0.24, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1040 - Batch 1 ########################
IDs in batch 1: tensor([3188, 1408,  863,  587, 1765, 3940, 3298, 2577, 2056, 2452, 2847, 1102,
        3257, 3570, 1256, 1563])
Epoch: 1040, Training Loss: 0.45, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1041 - Batch 1 ########################
IDs in batch 1: tensor([3392, 1497, 3475, 3527, 3312, 1072, 1491, 2564, 2257, 2977, 2717, 1706,
        1418, 1272, 1251, 3314])
Epoch: 1041, Training Loss: 0.08, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1042 - Batch 1 ########################
IDs in batch 1: tensor([3378, 4138, 3447, 1855, 1934, 1504,  316,  517,  544, 3873, 3518,  747,
        1861, 3821, 1553, 1039])
Epoch: 1042, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1043 - Batch 1 ########################
IDs in batch 1: tensor([3438, 1147, 1061, 1277, 3223, 3204, 1292,  990, 3524, 4140, 3654, 3010,
        3428, 1356,  352, 4166])
Epoch: 1043, Training Loss: 0.31, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1044 - Batch 1 ########################
IDs in batch 1: tensor([2890, 3783, 1960, 3467, 3513, 2718, 3381, 1546, 3518, 3355, 2153, 3984,
        3841, 3846, 4124, 3930])
Epoch: 1044, Training Loss: 0.59, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1045 - Batch 1 ########################
IDs in batch 1: tensor([2462,  308, 3891, 1658,   52, 4039,  729, 1811, 4037, 3903,  758,  804,
        2334, 2465, 1228, 1376])
Epoch: 1045, Training Loss: 0.22, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1046 - Batch 1 ########################
IDs in batch 1: tensor([1730, 4007,  812, 3593, 1487, 2963, 3534, 1032, 2615, 3345, 3381, 1452,
        3458,   10, 1276,  359])
Epoch: 1046, Training Loss: 0.12, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1047 - Batch 1 ########################
IDs in batch 1: tensor([4086, 3143, 4089, 2564, 2449, 3276,  133, 3591, 1910, 3120,  459, 3765,
        1099, 2125, 3898,  547])
Epoch: 1047, Training Loss: 0.33, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1048 - Batch 1 ########################
IDs in batch 1: tensor([2703, 1163,  604, 2882,  970, 3734, 3077, 3591, 4212, 3850, 3216, 1491,
        1408, 4200, 3328, 4141])
Epoch: 1048, Training Loss: 0.35, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1049 - Batch 1 ########################
IDs in batch 1: tensor([3110,  787, 2431,  400, 3640, 4240, 2711, 1655,  448, 2897, 2284, 2482,
        3049,  594, 1352, 1258])
Epoch: 1049, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1050 - Batch 1 ########################
IDs in batch 1: tensor([  70,  942, 3415, 2347, 3798, 3823, 1963, 2885, 1047, 3715, 2275, 2301,
          82, 4235, 2775, 1569])
Epoch: 1050, Training Loss: 0.23, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1051 - Batch 1 ########################
IDs in batch 1: tensor([3552, 2880, 3389, 1711,  875, 2510,  109, 1057,  620, 3935, 3532, 3094,
        2112, 3252, 3545, 3982])
Epoch: 1051, Training Loss: 0.25, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1052 - Batch 1 ########################
IDs in batch 1: tensor([ 981,  401, 3094, 1722, 1628,  555, 1284, 2921,  781, 1480, 2154, 2943,
        2419, 2783, 1334, 3245])
Epoch: 1052, Training Loss: 0.31, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 1053 - Batch 1 ########################
IDs in batch 1: tensor([2836, 3018, 3637, 2284, 3255, 1001, 3765,  372, 1651, 3182, 2229,  991,
        3119, 4100, 1318, 1086])
Epoch: 1053, Training Loss: 0.07, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 1054 - Batch 1 ########################
IDs in batch 1: tensor([4096, 1948, 2169,  607, 3495,  450, 2687, 1102, 2954, 3065, 1944, 2517,
        2773, 3713,  644,  327])
Epoch: 1054, Training Loss: 0.13, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 1055 - Batch 1 ########################
IDs in batch 1: tensor([2053,  674,  133, 1573, 2364, 1802, 2086, 3492,  653, 3581,  537, 2024,
        3121, 4179, 2544,  986])
Epoch: 1055, Training Loss: 0.13, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 1056 - Batch 1 ########################
IDs in batch 1: tensor([1453, 2587, 1782, 1122, 3707, 3729, 1959, 1030, 2995, 3364,  300, 3306,
        1111, 3414, 3567, 2599])
Epoch: 1056, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1057 - Batch 1 ########################
IDs in batch 1: tensor([1526, 2874, 2524, 2312,  658, 3745, 2170, 1035, 3569,  953, 1092, 3440,
        3728, 1296, 4032, 3404])
Epoch: 1057, Training Loss: 0.28, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1058 - Batch 1 ########################
IDs in batch 1: tensor([ 283,  685, 2489, 3436, 1537, 2122, 2367,  818, 3590, 2810, 1951, 2322,
        2953, 1999,  855, 4002])
Epoch: 1058, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1059 - Batch 1 ########################
IDs in batch 1: tensor([1884,  678, 1645,  623, 3300, 1097, 4225, 1139, 1762,   70, 1596, 1408,
        3621,  342, 3771, 2119])
Epoch: 1059, Training Loss: 0.32, Validation Loss: 0.52, accuracy = 0.77
######################## Epoch 1060 - Batch 1 ########################
IDs in batch 1: tensor([1155, 2966, 1267, 2915, 3407, 1937, 1369, 3516, 4265, 1083, 2509, 1495,
        3536, 2629, 2562, 3256])
Epoch: 1060, Training Loss: 0.16, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1061 - Batch 1 ########################
IDs in batch 1: tensor([2959, 2805,  565,  869,   26,  520, 3451,  409, 2545, 1395,  344, 2749,
        1511, 3291, 3143, 2245])
Epoch: 1061, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1062 - Batch 1 ########################
IDs in batch 1: tensor([2902,  725, 3757, 3400, 2210,  368, 1026,  766, 1421, 1410, 1264, 2615,
         915, 2070, 1017, 1488])
Epoch: 1062, Training Loss: 0.40, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1063 - Batch 1 ########################
IDs in batch 1: tensor([1811, 3650, 2485, 4138, 4240,  594, 2468,   42, 1620, 1317, 1855, 3712,
        4238,  807,  186, 1840])
Epoch: 1063, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1064 - Batch 1 ########################
IDs in batch 1: tensor([2648, 3767, 4133, 3136,  510, 3392, 2019,  710, 3700,  131,  161,  463,
        4051, 3006, 1239, 3680])
Epoch: 1064, Training Loss: 0.08, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1065 - Batch 1 ########################
IDs in batch 1: tensor([ 237, 2166, 2983, 2777,  740, 1795, 3060, 3503, 3581, 2980,  113, 3417,
        1920, 2377,  933, 1147])
Epoch: 1065, Training Loss: 0.25, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1066 - Batch 1 ########################
IDs in batch 1: tensor([2672, 2845, 1623, 4050, 3994, 3409,  855,  683, 2041, 3144, 3804, 3826,
        2551,  284,  109,  676])
Epoch: 1066, Training Loss: 0.36, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1067 - Batch 1 ########################
IDs in batch 1: tensor([1585,  966, 1583, 1133, 3440, 1536,  753, 1404, 3075, 2782, 3792,  913,
        3688,  350, 3697,  924])
Epoch: 1067, Training Loss: 0.41, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1068 - Batch 1 ########################
IDs in batch 1: tensor([3141, 2550, 3938,  830, 2341,  455,  459,  398, 1144, 2131, 3704, 2355,
        2897, 4039, 2365, 1986])
Epoch: 1068, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1069 - Batch 1 ########################
IDs in batch 1: tensor([1591, 2406, 3176, 3599, 1638, 3668, 4107, 1965, 3081, 3710, 2866, 2817,
        3084, 1778, 3903, 2788])
Epoch: 1069, Training Loss: 0.27, Validation Loss: 0.57, accuracy = 0.74
######################## Epoch 1070 - Batch 1 ########################
IDs in batch 1: tensor([1171,  902, 4180, 2848,  180, 1093, 3764,  623, 3993, 3528,  824, 3245,
         892, 1209, 2745, 2453])
Epoch: 1070, Training Loss: 0.24, Validation Loss: 0.56, accuracy = 0.74
######################## Epoch 1071 - Batch 1 ########################
IDs in batch 1: tensor([3410, 1143,  838,  841, 3568, 2553,  739, 3300, 3217, 3904, 1731, 2051,
        1452, 2080, 3223, 2348])
Epoch: 1071, Training Loss: 0.14, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1072 - Batch 1 ########################
IDs in batch 1: tensor([3367,  243, 2078,  165, 2171, 2478, 1199, 4148, 1671, 3850, 1957, 1370,
        3782, 2822, 1108, 1733])
Epoch: 1072, Training Loss: 0.11, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1073 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 1185, 1367, 3836, 3426, 2342, 1360,  100, 1858, 1162, 3306, 1222,
        3930, 2300, 1872, 3185])
Epoch: 1073, Training Loss: 0.15, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 1074 - Batch 1 ########################
IDs in batch 1: tensor([3369, 1373, 2287, 3222, 2545, 4251, 3950, 1234,   14, 3244, 2356, 2682,
        1381, 3921,  552, 1452])
Epoch: 1074, Training Loss: 0.15, Validation Loss: 0.54, accuracy = 0.74
######################## Epoch 1075 - Batch 1 ########################
IDs in batch 1: tensor([ 220, 1559, 4011, 3713, 1727, 2542, 1167, 1630,  555,  284, 2247,  401,
        2382, 4245, 2967, 2960])
Epoch: 1075, Training Loss: 0.42, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 1076 - Batch 1 ########################
IDs in batch 1: tensor([2617, 2892, 3492, 2108,   60, 1452,  613, 4149, 1291,  659, 3407, 3808,
        3846, 3133, 2949, 2627])
Epoch: 1076, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 1077 - Batch 1 ########################
IDs in batch 1: tensor([1011, 1852,  316, 1638,  753,  826, 4126, 4258, 2177,  875,  936, 2829,
        3161, 1156,  904,  967])
Epoch: 1077, Training Loss: 0.32, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 1078 - Batch 1 ########################
IDs in batch 1: tensor([2743,  261, 3358, 1819, 3582, 3597,  393, 1974, 1195,  631, 1835, 2190,
        2485, 4128,  514, 1650])
Epoch: 1078, Training Loss: 0.37, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 1079 - Batch 1 ########################
IDs in batch 1: tensor([2355,   61, 4061, 3470, 3470,  821, 2730, 1375,  850, 3222,  455, 2126,
         354,  391, 3219,  875])
Epoch: 1079, Training Loss: 0.14, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1080 - Batch 1 ########################
IDs in batch 1: tensor([3497,  396, 3379, 1645, 2400, 3913, 1841, 3674,   82, 2322,  182,  170,
         625,  557,  376,   35])
Epoch: 1080, Training Loss: 0.56, Validation Loss: 0.53, accuracy = 0.75
######################## Epoch 1081 - Batch 1 ########################
IDs in batch 1: tensor([2791, 1953,  315,  317, 1495, 1317, 2526, 1684, 2489, 1495, 2159, 1789,
        1979, 3075, 1760, 1081])
Epoch: 1081, Training Loss: 0.23, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 1082 - Batch 1 ########################
IDs in batch 1: tensor([ 767, 4061, 2070, 3016, 3441,  588,  289, 1386, 1143, 2884, 3036, 4035,
        4245, 3447, 2663, 1175])
Epoch: 1082, Training Loss: 0.18, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1083 - Batch 1 ########################
IDs in batch 1: tensor([4249, 2193, 3815, 1594,  243,  412,  947,   63,  424, 1611,  779,  365,
        2019, 3745, 2494,   42])
Epoch: 1083, Training Loss: 0.46, Validation Loss: 0.52, accuracy = 0.76
######################## Epoch 1084 - Batch 1 ########################
IDs in batch 1: tensor([3871, 1700, 3658,  341, 3904, 2655, 3795, 2638, 3330, 3647,  915, 1039,
        2998, 1344, 3197, 2495])
Epoch: 1084, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 1085 - Batch 1 ########################
IDs in batch 1: tensor([2013, 1944, 2956, 1803, 2537, 3885, 2137, 3378,  411, 3674, 3913, 2373,
        3948, 3256, 3052, 2322])
Epoch: 1085, Training Loss: 0.65, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1086 - Batch 1 ########################
IDs in batch 1: tensor([2645, 3827, 3349,  724, 2379, 1008, 1041, 1855, 3927, 3112, 3366,  566,
        1665, 3637, 4048, 3364])
Epoch: 1086, Training Loss: 0.12, Validation Loss: 0.58, accuracy = 0.74
######################## Epoch 1087 - Batch 1 ########################
IDs in batch 1: tensor([1718,  399, 4117, 2066, 3982, 2715, 3336, 1644, 1088, 3954, 3317, 3270,
        3029, 2545, 3577, 2619])
Epoch: 1087, Training Loss: 0.22, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 1088 - Batch 1 ########################
IDs in batch 1: tensor([1700, 2822, 2195,  425, 1639, 3549, 4076, 3821, 4126, 1723,  186, 1596,
        2145, 2379, 1863, 1402])
Epoch: 1088, Training Loss: 0.12, Validation Loss: 0.59, accuracy = 0.73
######################## Epoch 1089 - Batch 1 ########################
IDs in batch 1: tensor([ 566, 2049,   49, 3714, 1988, 2691, 3610,  475, 2824, 4078, 3563, 3808,
        2495, 2642,  482, 3524])
Epoch: 1089, Training Loss: 0.30, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 1090 - Batch 1 ########################
IDs in batch 1: tensor([ 691,  129, 2951, 4188, 3286,  995, 1177, 2234, 2844, 3150, 3604, 3894,
        3057, 1299, 2883, 1039])
Epoch: 1090, Training Loss: 0.15, Validation Loss: 0.59, accuracy = 0.73
######################## Epoch 1091 - Batch 1 ########################
IDs in batch 1: tensor([ 160, 3648, 1840, 3813, 3658,  308, 4084, 2603, 1897, 3969,  605,   43,
        2087, 1437, 1932, 1216])
Epoch: 1091, Training Loss: 0.30, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 1092 - Batch 1 ########################
IDs in batch 1: tensor([1804, 1684, 3698, 1720,  391,  256, 3583, 1031, 1377,  910, 3765, 1354,
        3777, 1633, 1793, 3243])
Epoch: 1092, Training Loss: 0.15, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1093 - Batch 1 ########################
IDs in batch 1: tensor([3262, 3022,  848, 3638, 1576, 2159, 1073,  137, 1388, 3919, 1015, 2192,
        2499,  617, 1870,  676])
Epoch: 1093, Training Loss: 0.34, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1094 - Batch 1 ########################
IDs in batch 1: tensor([2011, 2199, 1189,  766,  815, 1605, 1190, 1146, 2763,  408,  758, 3166,
         729, 3888,  735,  884])
Epoch: 1094, Training Loss: 0.45, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1095 - Batch 1 ########################
IDs in batch 1: tensor([1090, 3981, 4035, 2341, 1351,  967, 2040,  245, 3531, 3446, 2927,  866,
        3993, 1999, 3429, 2386])
Epoch: 1095, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1096 - Batch 1 ########################
IDs in batch 1: tensor([4080, 3108,  953, 1420, 2844, 2339, 2145, 1686,  878, 2099,  180, 3228,
         699,  378, 1349, 2600])
Epoch: 1096, Training Loss: 0.32, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1097 - Batch 1 ########################
IDs in batch 1: tensor([2291, 3525,  789, 3240, 1731, 1296, 1923, 2828, 1429, 2169, 1642, 3710,
        3243, 1185, 3371, 2857])
Epoch: 1097, Training Loss: 0.15, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1098 - Batch 1 ########################
IDs in batch 1: tensor([1443, 2099, 1057,  724, 1921, 3035, 2204, 2131, 3879,  335,  704, 2365,
        4107, 2146, 1023, 1559])
Epoch: 1098, Training Loss: 0.31, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1099 - Batch 1 ########################
IDs in batch 1: tensor([3151,  534, 2697, 2365,  586, 2873, 2901, 1062,  462,  758, 2423,  539,
        1144, 2638, 2134, 1902])
Epoch: 1099, Training Loss: 0.18, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1100 - Batch 1 ########################
IDs in batch 1: tensor([2783, 3903, 3020, 3326,  848, 2423, 1511, 3168,  819, 2661, 3836,  194,
        2498,  102, 3980,  217])
Epoch: 1100, Training Loss: 0.08, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1101 - Batch 1 ########################
IDs in batch 1: tensor([3029, 4249,  529, 2538, 1120, 2776, 3258, 3617, 1155,  965, 2193, 2349,
         373,  214, 3932, 2217])
Epoch: 1101, Training Loss: 0.30, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1102 - Batch 1 ########################
IDs in batch 1: tensor([1675, 4181, 1070, 2467, 2225, 3035, 4212, 1010,  974, 4024,  524, 1117,
        4257, 1281, 2419, 1379])
Epoch: 1102, Training Loss: 0.30, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1103 - Batch 1 ########################
IDs in batch 1: tensor([1672, 2901,  944,  350, 1962, 1850, 2059, 1241, 2003, 4103, 2524, 2869,
        2504, 1089, 1438, 3831])
Epoch: 1103, Training Loss: 0.33, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1104 - Batch 1 ########################
IDs in batch 1: tensor([2092, 1367, 2297, 3968, 4044, 2600, 2730, 1824, 1663, 2363,  463, 3989,
        3111, 1126, 3044,  811])
Epoch: 1104, Training Loss: 0.30, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1105 - Batch 1 ########################
IDs in batch 1: tensor([3518, 4254, 2879,  194, 1337, 4235,  250, 4249,  701,  816, 1931, 2656,
        1638, 3624, 2937, 2316])
Epoch: 1105, Training Loss: 0.08, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1106 - Batch 1 ########################
IDs in batch 1: tensor([ 751, 1720, 1209, 3452, 1559,  743, 1858, 3705, 3942,  350,  610, 3709,
        4078, 4253,  126, 2821])
Epoch: 1106, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1107 - Batch 1 ########################
IDs in batch 1: tensor([3308, 2015,   59, 4220, 3667, 1274, 2081, 3082, 4080, 2393, 3727, 2290,
        1802, 2178, 2960, 2459])
Epoch: 1107, Training Loss: 0.63, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1108 - Batch 1 ########################
IDs in batch 1: tensor([3643,   74,  880, 2350, 1355,  662,  752, 3382,  137,  412, 3647, 2386,
        1444, 4255, 2902, 3980])
Epoch: 1108, Training Loss: 0.33, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1109 - Batch 1 ########################
IDs in batch 1: tensor([ 963, 1443, 2523, 1781, 1707, 1376, 3460, 3964, 3329, 3782, 3031, 2442,
        2323,  108, 4116, 2452])
Epoch: 1109, Training Loss: 0.17, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1110 - Batch 1 ########################
IDs in batch 1: tensor([ 344, 2292, 1418,  377, 3806, 1417, 2482, 1289,  794, 2798, 2332,  193,
        2873, 2886, 2359,  926])
Epoch: 1110, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1111 - Batch 1 ########################
IDs in batch 1: tensor([  68, 2954, 3947, 1281, 1501, 2590, 2650, 1756,  790,  733, 2827, 1026,
        3311,   71,  595, 3109])
Epoch: 1111, Training Loss: 0.28, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1112 - Batch 1 ########################
IDs in batch 1: tensor([3518, 1663,   56, 1883, 3227,  820, 2740, 2406, 2849, 2170, 1092,  971,
         963, 2669,  735,  424])
Epoch: 1112, Training Loss: 0.09, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1113 - Batch 1 ########################
IDs in batch 1: tensor([1628, 4116, 2649, 3525, 3014,  947, 4084, 1588, 2483, 3468, 2717,  355,
        2166, 1518, 2432, 1196])
Epoch: 1113, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1114 - Batch 1 ########################
IDs in batch 1: tensor([ 375, 4105, 4261, 3769, 1678, 3803, 1432, 3088, 1595, 2601, 1599,  610,
        1845, 1226, 2993,  753])
Epoch: 1114, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1115 - Batch 1 ########################
IDs in batch 1: tensor([3797, 1782, 2179, 2150,  933,  883,  243, 3821, 1128,  757,  219, 2692,
        3908, 2479, 2153, 1156])
Epoch: 1115, Training Loss: 0.42, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1116 - Batch 1 ########################
IDs in batch 1: tensor([2393,  704,  792,  470, 2382,  517, 3382, 2190,  818, 2179, 2689,  534,
        2784, 3435, 1311, 2117])
Epoch: 1116, Training Loss: 0.10, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1117 - Batch 1 ########################
IDs in batch 1: tensor([1107,  281, 1357, 2661, 1004, 4095, 3654, 3869, 2095,  986,  312, 3261,
         375, 3487, 1425, 1571])
Epoch: 1117, Training Loss: 0.27, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1118 - Batch 1 ########################
IDs in batch 1: tensor([3141, 2044, 3025, 1186, 4156, 1256,  928, 1347,  380,  243, 2356, 4223,
        2880,  439,   73, 2305])
Epoch: 1118, Training Loss: 0.12, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1119 - Batch 1 ########################
IDs in batch 1: tensor([  31, 1948, 2691, 3010,  636,  320, 1439, 1158, 2387, 2696, 1794, 1319,
        1308, 1630, 3211, 3115])
Epoch: 1119, Training Loss: 0.33, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1120 - Batch 1 ########################
IDs in batch 1: tensor([2154, 1219, 3166, 2419,  440, 1388,  497, 3996,  485, 1123, 1579, 3497,
        3543, 3813, 2196, 2950])
Epoch: 1120, Training Loss: 0.50, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1121 - Batch 1 ########################
IDs in batch 1: tensor([ 292, 3244, 3588, 2155,  646, 1310,  928,  150, 1775,  544, 3723, 3885,
        2763, 3705, 3754, 3078])
Epoch: 1121, Training Loss: 0.40, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1122 - Batch 1 ########################
IDs in batch 1: tensor([ 536, 1369,  625, 2592,  623, 1640,    7, 2700, 1740,  196, 4228, 3621,
         277, 3842, 2431, 3883])
Epoch: 1122, Training Loss: 0.34, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1123 - Batch 1 ########################
IDs in batch 1: tensor([2099, 3098,  812,  314, 1726, 3448,  652, 1034, 1239, 2348,  826, 4013,
        1540, 3782,  308, 2687])
Epoch: 1123, Training Loss: 0.22, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1124 - Batch 1 ########################
IDs in batch 1: tensor([3388, 3236, 1982,  718, 1938,  546, 3437, 3988, 2133, 2652, 4146, 1722,
        2758, 3474,  815,  333])
Epoch: 1124, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1125 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2937,  658,  438, 1974, 1625, 2291, 2280, 2891, 2167, 1152, 3306,
        1817, 2780, 3547, 1042])
Epoch: 1125, Training Loss: 0.22, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1126 - Batch 1 ########################
IDs in batch 1: tensor([ 816, 4168, 1951, 2205,  882, 3591,  356,  963, 1179, 4067,  183, 2479,
        2466, 3108,  933, 3975])
Epoch: 1126, Training Loss: 0.07, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1127 - Batch 1 ########################
IDs in batch 1: tensor([3370, 1991, 2449, 2551, 3111,  864,   71, 2934, 3311, 1948, 2619, 1945,
        1878, 1186, 1306,  459])
Epoch: 1127, Training Loss: 0.27, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1128 - Batch 1 ########################
IDs in batch 1: tensor([3378, 3911, 3312,  137, 1485,  415, 2126, 2375, 2116, 3495, 1632, 1042,
        2905, 3812, 2171, 2574])
Epoch: 1128, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1129 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 1306, 1122, 2603, 1506, 1051,   99, 3812, 2919, 4044, 2670, 1344,
        4103,  455,  565, 1866])
Epoch: 1129, Training Loss: 0.08, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1130 - Batch 1 ########################
IDs in batch 1: tensor([4073,  970, 3253, 1286,  527, 3251, 1374, 2697, 1798, 2400, 3245, 1092,
        3874, 3634,   74,  401])
Epoch: 1130, Training Loss: 0.12, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1131 - Batch 1 ########################
IDs in batch 1: tensor([ 159, 3786,  181, 1052, 1517, 1082, 2428, 1775,  140,  451,  180, 2354,
         639,  751, 1981, 2837])
Epoch: 1131, Training Loss: 0.35, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1132 - Batch 1 ########################
IDs in batch 1: tensor([ 963, 3846,  190,  496, 3739, 3747, 2261, 1536, 3465,  687, 2298,  988,
        2697,  440,  554, 1559])
Epoch: 1132, Training Loss: 0.20, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1133 - Batch 1 ########################
IDs in batch 1: tensor([3954, 1326, 3518,  661, 2476, 1302,  262, 3935, 2494,  396, 2003, 1489,
         516, 1851, 4122, 2831])
Epoch: 1133, Training Loss: 0.28, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1134 - Batch 1 ########################
IDs in batch 1: tensor([2337, 2624, 3733, 2286, 2636,  729,  909, 1305, 1070,  545, 3674, 2945,
        2060, 2070, 1120, 1702])
Epoch: 1134, Training Loss: 0.15, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1135 - Batch 1 ########################
IDs in batch 1: tensor([1406, 2499, 4070, 1970, 3124, 1826, 3375, 3136,  900, 1119, 1220, 1224,
        3038, 2710,  915, 2550])
Epoch: 1135, Training Loss: 0.29, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1136 - Batch 1 ########################
IDs in batch 1: tensor([1241,  969,  658, 2917, 2541, 3483, 2010, 3282, 2833, 3500, 3787, 3338,
        1308, 4084, 1009,  277])
Epoch: 1136, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1137 - Batch 1 ########################
IDs in batch 1: tensor([4055, 3016, 1737, 2148, 1299,  583, 1543,  306, 3659, 2783, 1233,  646,
          28, 2459,  936, 3183])
Epoch: 1137, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1138 - Batch 1 ########################
IDs in batch 1: tensor([2659,  198, 1804,   15, 1772, 4101,  522, 1083, 4050, 1117, 2700, 1596,
        1877, 3133, 4101, 4146])
Epoch: 1138, Training Loss: 0.15, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1139 - Batch 1 ########################
IDs in batch 1: tensor([1336,  928, 2631, 4217,  811, 2182, 4086, 2671, 3493, 1312,  894, 3354,
        3680, 2094, 3259, 2416])
Epoch: 1139, Training Loss: 0.33, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1140 - Batch 1 ########################
IDs in batch 1: tensor([1317, 1900,  213,  434, 3081, 2791,  437, 2466, 1673, 4268,  949, 1686,
        4039,   14,  826, 2316])
Epoch: 1140, Training Loss: 0.27, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1141 - Batch 1 ########################
IDs in batch 1: tensor([3936,  735, 2120,  822, 1641, 3016, 3930, 3081, 4254, 3939, 3833, 3751,
        1437, 1420, 2821, 2209])
Epoch: 1141, Training Loss: 0.28, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1142 - Batch 1 ########################
IDs in batch 1: tensor([4108, 1381,  419, 4235, 1760, 3729, 1269, 2690, 4035, 3845, 1877, 3717,
        4036, 1633, 1965, 2150])
Epoch: 1142, Training Loss: 0.50, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1143 - Batch 1 ########################
IDs in batch 1: tensor([ 135,  960,   82,  306, 1955,  538, 1693, 1311,  862, 1113, 1573, 3375,
        3424, 2072, 2848, 1635])
Epoch: 1143, Training Loss: 0.49, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1144 - Batch 1 ########################
IDs in batch 1: tensor([3810, 1892, 4225, 1892,  244, 3465, 2276,  572, 3467, 1405, 2137, 3115,
        1367, 4144, 1624, 4076])
Epoch: 1144, Training Loss: 0.15, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1145 - Batch 1 ########################
IDs in batch 1: tensor([3434, 2947, 1276,  326, 2667, 1185, 3428,  365, 3731, 1519, 1258, 3053,
         217,  816, 2860, 3074])
Epoch: 1145, Training Loss: 0.09, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 1146 - Batch 1 ########################
IDs in batch 1: tensor([1925, 3815,  337, 3022,  135, 3299, 1124, 2072,  657,   18,  538,  182,
         449,  954, 2398, 3661])
Epoch: 1146, Training Loss: 0.15, Validation Loss: 0.54, accuracy = 0.75
######################## Epoch 1147 - Batch 1 ########################
IDs in batch 1: tensor([2231, 2159, 1604, 2031, 1891,  950, 1247,   35,  224,  530, 1524, 1334,
        4026, 2453, 2777, 1025])
Epoch: 1147, Training Loss: 0.28, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1148 - Batch 1 ########################
IDs in batch 1: tensor([2257, 2179,  335, 3829, 2386, 4195, 3271, 2849, 2618, 2591,  684,  259,
        2777, 2671, 2110, 4176])
Epoch: 1148, Training Loss: 0.19, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1149 - Batch 1 ########################
IDs in batch 1: tensor([1633, 3554, 2535, 2676,  863, 3675, 3289, 3779,  785, 1239, 1185,  523,
        3435,  167,  724, 3938])
Epoch: 1149, Training Loss: 0.44, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1150 - Batch 1 ########################
IDs in batch 1: tensor([3388, 2883, 3975, 2144, 2690, 1808,  770, 1284, 1189, 3136,  887, 4227,
        3123,  535, 2574, 2284])
Epoch: 1150, Training Loss: 0.28, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1151 - Batch 1 ########################
IDs in batch 1: tensor([3951, 4024, 1809, 4078,  517, 3953, 1977, 1686, 1360, 2224, 2253,  342,
        2736,  188, 3395, 3259])
Epoch: 1151, Training Loss: 0.46, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1152 - Batch 1 ########################
IDs in batch 1: tensor([3370, 3023, 2394, 2767,  729, 2938, 2343,  441, 2446,  303, 3583,  796,
        1830,   41, 1143, 2997])
Epoch: 1152, Training Loss: 0.14, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1153 - Batch 1 ########################
IDs in batch 1: tensor([3551, 2645,  357, 3838, 2413, 3689, 3395,  265, 3143, 2841, 3388,  595,
        3532, 3055, 2050,  971])
Epoch: 1153, Training Loss: 0.42, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1154 - Batch 1 ########################
IDs in batch 1: tensor([1133, 1532, 2272, 1185,  767, 3075, 2028, 2027, 2496, 3886, 1947,  787,
        3352, 3168, 2709, 2205])
Epoch: 1154, Training Loss: 0.27, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1155 - Batch 1 ########################
IDs in batch 1: tensor([ 501, 1690, 2591, 1745, 1116, 3279, 3610, 2154, 2126, 3343, 2108, 1116,
        4032, 4107, 2738,  645])
Epoch: 1155, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1156 - Batch 1 ########################
IDs in batch 1: tensor([1024,  182, 4176, 3525,  399,  378, 4017,  277, 1984, 1163, 3516, 3728,
        1039, 3314,  237,  448])
Epoch: 1156, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1157 - Batch 1 ########################
IDs in batch 1: tensor([ 874, 1923, 2938, 3912, 2721, 1440, 3139,  714, 1344, 4030, 2544,   22,
        2670, 3276,  812,  120])
Epoch: 1157, Training Loss: 0.18, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1158 - Batch 1 ########################
IDs in batch 1: tensor([ 103, 2997, 3483,  640, 2107,  137, 2642,  622, 3387, 1952,  833, 2849,
         553, 3440,  389, 3124])
Epoch: 1158, Training Loss: 0.17, Validation Loss: 0.53, accuracy = 0.76
######################## Epoch 1159 - Batch 1 ########################
IDs in batch 1: tensor([2866, 1948, 2254, 1375, 1558, 3525, 2562, 1099, 2355, 2063, 4116, 3860,
        3415, 3077, 1156,   51])
Epoch: 1159, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1160 - Batch 1 ########################
IDs in batch 1: tensor([4073, 1369, 1672, 2276, 1330, 3545, 2760, 2745, 3298, 3974,  408,  469,
         964, 2203, 1357, 3851])
Epoch: 1160, Training Loss: 0.19, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1161 - Batch 1 ########################
IDs in batch 1: tensor([1101, 3637, 2742, 3499, 2067, 4005, 4075,  841,  828, 3351, 1580, 1646,
        2523,  117,  487, 4097])
Epoch: 1161, Training Loss: 0.40, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1162 - Batch 1 ########################
IDs in batch 1: tensor([3235, 1152, 3808, 1911,  340, 2860, 4030,  396, 1498, 2926,  684, 2492,
        1747, 1332, 3591, 3975])
Epoch: 1162, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1163 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 3031, 4230, 2872,  786,  109, 2680, 2368, 3637, 4158, 2078,  303,
        2038, 2849, 3233, 1367])
Epoch: 1163, Training Loss: 0.11, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1164 - Batch 1 ########################
IDs in batch 1: tensor([2182, 1920,  933, 2363, 2120, 3823, 2967,  568, 3831, 3120,  531,  968,
        3711, 4026,  639, 3150])
Epoch: 1164, Training Loss: 0.16, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1165 - Batch 1 ########################
IDs in batch 1: tensor([3379, 3521, 1891, 1891,  833, 4158, 2141, 1170, 3401, 2069, 4199, 2495,
        2964, 2837,  258,  496])
Epoch: 1165, Training Loss: 0.27, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1166 - Batch 1 ########################
IDs in batch 1: tensor([ 949,  483, 3583, 3098, 3299, 1351, 1748,  532, 1132, 2629, 1766, 1834,
        4138,  522,  334, 1224])
Epoch: 1166, Training Loss: 0.16, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1167 - Batch 1 ########################
IDs in batch 1: tensor([2719, 1762, 1073, 1305, 3151,  569, 1933, 3636,  640, 3283, 2760,  997,
        2897, 3879, 1294, 2173])
Epoch: 1167, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1168 - Batch 1 ########################
IDs in batch 1: tensor([1286, 3513, 1171, 4268, 2655,  977, 3389, 3779, 1171, 1794, 1596, 1712,
        1878, 2692, 2027, 2284])
Epoch: 1168, Training Loss: 0.16, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1169 - Batch 1 ########################
IDs in batch 1: tensor([4251,  684,  674, 3826, 1971, 1171, 1562, 1399,  974, 2841, 2879, 2700,
         934, 3838, 4163, 3539])
Epoch: 1169, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1170 - Batch 1 ########################
IDs in batch 1: tensor([3953, 1852, 3651,  822, 1196, 2354, 2069, 1866, 1193,  825, 3399, 1718,
        3765, 3354, 1518, 2727])
Epoch: 1170, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1171 - Batch 1 ########################
IDs in batch 1: tensor([ 342, 2265, 2412,  982, 2752, 2731, 2178,  368, 1918, 3291, 2439,  368,
        3802, 2418, 3963,  852])
Epoch: 1171, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1172 - Batch 1 ########################
IDs in batch 1: tensor([ 282, 2161, 3610, 3618, 2247, 4148, 3394,  891, 2541,  882, 3373, 4022,
        2599, 4227, 2562, 3964])
Epoch: 1172, Training Loss: 0.25, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1173 - Batch 1 ########################
IDs in batch 1: tensor([3528, 1728, 3110, 2180, 1484, 1209,  739, 3250, 1702, 1384, 1053, 3304,
        3356, 1657, 1592, 1213])
Epoch: 1173, Training Loss: 0.41, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1174 - Batch 1 ########################
IDs in batch 1: tensor([3914, 4200, 3436, 1224, 2180, 2498, 2176, 1594, 1825, 4002, 2349, 3542,
         471, 4195, 3031, 1010])
Epoch: 1174, Training Loss: 0.37, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1175 - Batch 1 ########################
IDs in batch 1: tensor([3474,  918, 1355,  961,  194, 1656, 2050, 1772,  113, 2969, 1795, 2256,
        3920,   71,  789, 3644])
Epoch: 1175, Training Loss: 0.26, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1176 - Batch 1 ########################
IDs in batch 1: tensor([3927,  825,  477,  128, 1388, 3376, 2887, 3535, 1963, 2402, 1361, 4149,
        2718, 2402,  566,  941])
Epoch: 1176, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1177 - Batch 1 ########################
IDs in batch 1: tensor([1124, 2066,   72, 3659, 3463, 1012,  201, 2520, 4223, 3252, 1131, 4166,
         198,  290, 4161, 2856])
Epoch: 1177, Training Loss: 0.30, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1178 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 2489,  442, 4005, 2508, 2997, 1979, 1794,  109, 3449, 2225, 2931,
         747,   72, 2863, 4026])
Epoch: 1178, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1179 - Batch 1 ########################
IDs in batch 1: tensor([1569, 2926, 3698,  876, 1591,  736, 1381, 2568, 3862, 3471, 1866, 2059,
          44,   43, 2989, 3483])
Epoch: 1179, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1180 - Batch 1 ########################
IDs in batch 1: tensor([ 483,  834,   38, 3827, 1030,  866, 2931, 3607, 3032,  362, 1116,  491,
        3699, 3753, 1804, 4078])
Epoch: 1180, Training Loss: 0.37, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1181 - Batch 1 ########################
IDs in batch 1: tensor([ 316, 1620, 2783,  837, 1611, 2188, 1336, 3527, 3304, 2382,  526,  763,
        3917, 4051, 2326, 3697])
Epoch: 1181, Training Loss: 0.35, Validation Loss: 0.55, accuracy = 0.75
######################## Epoch 1182 - Batch 1 ########################
IDs in batch 1: tensor([1706,  555, 2298, 3400, 3831, 2838, 4159, 2897,  837, 3098, 2764,  902,
         636,  872, 2964, 2046])
Epoch: 1182, Training Loss: 0.38, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1183 - Batch 1 ########################
IDs in batch 1: tensor([2541, 4031, 2599, 2661, 1459, 3298,  593, 1857, 4257, 1355, 1237, 1569,
        2678, 2238, 2154, 1536])
Epoch: 1183, Training Loss: 0.43, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1184 - Batch 1 ########################
IDs in batch 1: tensor([3509, 2840,  532, 2346, 2739, 3521, 1658, 3190, 1672, 1276, 3423, 3900,
        4014, 1285, 3081, 2805])
Epoch: 1184, Training Loss: 0.08, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1185 - Batch 1 ########################
IDs in batch 1: tensor([3903, 2249, 1568,  372, 4240, 2703, 3258, 4224, 3160, 1123, 2429,  949,
         524, 2693, 3497,  869])
Epoch: 1185, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1186 - Batch 1 ########################
IDs in batch 1: tensor([3024, 2562, 3147, 1670, 3439, 3377,  450, 3317, 1289, 3621, 3831,  182,
        1571, 1248, 2520, 2112])
Epoch: 1186, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1187 - Batch 1 ########################
IDs in batch 1: tensor([3671, 1895, 4190, 2936, 2805,  995, 1088,  139, 4065, 4003, 3689, 1467,
        1183, 2451,  888, 3328])
Epoch: 1187, Training Loss: 0.10, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1188 - Batch 1 ########################
IDs in batch 1: tensor([3650, 1676,  663, 4004, 4194,  514, 3180, 3845, 1661,  514, 3975, 1080,
        1858, 2652,   72, 3476])
Epoch: 1188, Training Loss: 0.21, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1189 - Batch 1 ########################
IDs in batch 1: tensor([3656,  826, 2316, 3286, 1170,  471, 2943, 2977, 2681,   47, 1380, 1414,
         511, 3360, 3226, 1658])
Epoch: 1189, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1190 - Batch 1 ########################
IDs in batch 1: tensor([ 980,  350,  160, 3797, 4082, 3537, 3533, 3309, 2334, 2295, 3276, 3667,
        3343,  382,  247, 3614])
Epoch: 1190, Training Loss: 0.21, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1191 - Batch 1 ########################
IDs in batch 1: tensor([1762, 1426, 3276, 2708, 4249, 2738,  873, 1660,  281, 2265, 1632, 3846,
         858, 2837, 1949, 2362])
Epoch: 1191, Training Loss: 0.20, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1192 - Batch 1 ########################
IDs in batch 1: tensor([1225, 1218, 4136, 3328, 2783, 1585, 2300, 1186,  730, 3728,  327,  895,
         232,  928, 3744, 3765])
Epoch: 1192, Training Loss: 0.48, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1193 - Batch 1 ########################
IDs in batch 1: tensor([  93, 3027, 4235,  466, 2524, 1850, 1156, 1882,  995, 3114, 3083, 2680,
         445, 3248, 3715,   28])
Epoch: 1193, Training Loss: 0.13, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1194 - Batch 1 ########################
IDs in batch 1: tensor([2298, 1221, 2248, 4227, 3014, 1312, 1386,  265, 3792, 1183, 1961, 3108,
         661, 3114, 1545, 1602])
Epoch: 1194, Training Loss: 0.18, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1195 - Batch 1 ########################
IDs in batch 1: tensor([1524,  435, 3362,  961, 3518, 3367, 3557,  198, 3698, 4110, 3326,  830,
        3705, 3785,  302,  653])
Epoch: 1195, Training Loss: 0.26, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1196 - Batch 1 ########################
IDs in batch 1: tensor([2195, 4077, 2479, 3845,  202,  941, 3270, 1633, 1420, 3303,  494, 2565,
        2316, 3913,  956, 3385])
Epoch: 1196, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1197 - Batch 1 ########################
IDs in batch 1: tensor([ 342, 2085, 3734,  775,  729, 1678, 3407,  842,  842,  538, 3738, 3860,
         553, 3452,  957, 2837])
Epoch: 1197, Training Loss: 0.61, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1198 - Batch 1 ########################
IDs in batch 1: tensor([1377, 3980,  128, 3151, 3047, 2898,  914, 3980, 2672, 1508, 3436, 2412,
        2745, 1947, 2019,    5])
Epoch: 1198, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1199 - Batch 1 ########################
IDs in batch 1: tensor([2429, 2772, 1818,  640, 2500,  191, 2605, 1016, 2998, 3082, 2598, 2487,
        2050,  300, 2355, 2683])
Epoch: 1199, Training Loss: 0.28, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1200 - Batch 1 ########################
IDs in batch 1: tensor([2483, 1982, 3409, 3536, 3836, 3647,  656, 3168,  899, 4065, 1530,  340,
        2224,  778,  572,  234])
Epoch: 1200, Training Loss: 0.22, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1201 - Batch 1 ########################
IDs in batch 1: tensor([3601, 2963, 3876, 1278,  658, 1585, 2312, 3030,  228,  282, 3808, 3859,
        3850, 4002,  266, 2436])
Epoch: 1201, Training Loss: 0.19, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1202 - Batch 1 ########################
IDs in batch 1: tensor([1090,  952,  625, 2383, 1722,  763, 2571, 4105,  308,   74, 1087,  454,
        3369, 2133, 3452,  882])
Epoch: 1202, Training Loss: 0.22, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1203 - Batch 1 ########################
IDs in batch 1: tensor([1057, 4051, 1658, 3746, 2364, 3907, 1774,   81, 1094, 4195, 3119,  735,
         685, 2653, 1315,  259])
Epoch: 1203, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1204 - Batch 1 ########################
IDs in batch 1: tensor([1869,  776, 3769,  656, 3242,  753, 3038,  130, 2416,   39, 3548,  709,
        1897,  603, 3246, 3415])
Epoch: 1204, Training Loss: 0.24, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1205 - Batch 1 ########################
IDs in batch 1: tensor([3618, 2366, 1763, 1374,  300, 2559, 3069, 1473, 1023, 1762,  399, 2495,
         914, 4175, 2472, 2394])
Epoch: 1205, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1206 - Batch 1 ########################
IDs in batch 1: tensor([2379, 2914,  375,  223, 2475, 3047,  983,  730, 4094, 2901, 1567, 1224,
        1380, 2362, 3339, 1787])
Epoch: 1206, Training Loss: 0.15, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1207 - Batch 1 ########################
IDs in batch 1: tensor([2921, 3289, 3692, 1318, 1220, 2237, 3389, 2113, 4026, 1242, 1640,  471,
        3826, 1761, 2646, 2950])
Epoch: 1207, Training Loss: 0.08, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1208 - Batch 1 ########################
IDs in batch 1: tensor([3253, 2250, 1221, 1909, 2874, 1911,  987, 1463, 2230, 3783, 1693,  553,
         883, 1292,  824, 4228])
Epoch: 1208, Training Loss: 0.26, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1209 - Batch 1 ########################
IDs in batch 1: tensor([3642, 3421,  991, 3837, 2459, 3891, 1166,   56, 3567, 1506, 1517,  602,
        2847,   35, 1822, 3719])
Epoch: 1209, Training Loss: 0.07, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1210 - Batch 1 ########################
IDs in batch 1: tensor([3723,  147, 3337,  751, 3547, 3308,  368, 3036, 1916, 3564,  398, 3830,
        1335, 1881, 1344, 3841])
Epoch: 1210, Training Loss: 0.08, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1211 - Batch 1 ########################
IDs in batch 1: tensor([4069, 3866, 2274, 2075,  811,  945, 3648,  450, 2087, 2462, 2277, 1498,
        4008, 3399, 1708, 3829])
Epoch: 1211, Training Loss: 0.10, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1212 - Batch 1 ########################
IDs in batch 1: tensor([1614,  876, 3252,   14,  402,  602,  644, 2849, 2173, 1136, 1425, 2052,
        1039, 1537, 3314,  735])
Epoch: 1212, Training Loss: 0.42, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1213 - Batch 1 ########################
IDs in batch 1: tensor([1420, 2286, 4125, 3354, 3389, 1506, 1510, 1947, 3239, 2479, 1673, 1020,
        3367, 1846, 1678, 3544])
Epoch: 1213, Training Loss: 0.30, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1214 - Batch 1 ########################
IDs in batch 1: tensor([2880, 3826, 1451, 2736, 3200, 2847, 2927, 4215, 2763,  183, 3109, 1404,
        3863, 2220, 4061, 1670])
Epoch: 1214, Training Loss: 0.22, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1215 - Batch 1 ########################
IDs in batch 1: tensor([2650, 1099, 4007, 3119, 3439,  324, 2449, 2709, 3438, 3460,  807, 2320,
         661, 2986, 2108, 3654])
Epoch: 1215, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1216 - Batch 1 ########################
IDs in batch 1: tensor([4168, 2656, 1780, 1986,  244, 2253,  862, 3897,  657, 1521, 3110, 3244,
        3693, 1517,    7, 1506])
Epoch: 1216, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1217 - Batch 1 ########################
IDs in batch 1: tensor([3624, 2459, 2179,  282, 3634, 4082, 3532, 3018, 3963, 3017,  245, 2377,
        3927, 2736, 1861, 1140])
Epoch: 1217, Training Loss: 0.30, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1218 - Batch 1 ########################
IDs in batch 1: tensor([ 405, 2660, 1904,  824,  955, 2338,  733, 2284,   95, 2315, 2505, 1853,
         340, 3500, 1589, 1937])
Epoch: 1218, Training Loss: 0.28, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1219 - Batch 1 ########################
IDs in batch 1: tensor([4072, 2511,  673, 1485, 3409, 1354,   10, 3733,  359, 1970,   63, 3004,
        1736, 3529, 3507, 3780])
Epoch: 1219, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1220 - Batch 1 ########################
IDs in batch 1: tensor([3228, 3250, 1727, 1221, 1458,  658, 2730, 3354, 3036,  733,  263, 1487,
         615,  316, 3644, 1042])
Epoch: 1220, Training Loss: 0.17, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1221 - Batch 1 ########################
IDs in batch 1: tensor([1214, 2784, 1024, 2589,   49, 4236,  483, 1017,  261, 2379, 1138, 1096,
        2472, 3850, 3919, 1731])
Epoch: 1221, Training Loss: 0.35, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1222 - Batch 1 ########################
IDs in batch 1: tensor([ 910,  821, 3526, 3886, 1170, 1274, 4002, 1003, 3092, 3738, 1552, 1760,
        1426, 4097, 2860, 2986])
Epoch: 1222, Training Loss: 0.12, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1223 - Batch 1 ########################
IDs in batch 1: tensor([3311, 3179, 3511, 2352, 4141, 2810,  866, 1673, 2023, 1273, 1509, 3554,
        1174, 3599, 2476,  355])
Epoch: 1223, Training Loss: 0.15, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1224 - Batch 1 ########################
IDs in batch 1: tensor([3394, 3079, 3437, 2879, 1562, 4127, 4141, 1092, 2734,    4, 1445, 1222,
        2908, 2334, 1548, 1745])
Epoch: 1224, Training Loss: 0.33, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1225 - Batch 1 ########################
IDs in batch 1: tensor([1676, 2867,  351, 2980, 4067, 1760, 3529, 2913, 2924, 2002, 1374, 3590,
        1031,  729,  568, 2212])
Epoch: 1225, Training Loss: 0.06, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1226 - Batch 1 ########################
IDs in batch 1: tensor([1009, 3818,  771,  881, 1455, 2081, 3985, 1471, 2494, 2913, 2403, 2926,
        1913, 3489,   93, 3282])
Epoch: 1226, Training Loss: 0.24, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1227 - Batch 1 ########################
IDs in batch 1: tensor([1365, 2717, 3789, 1236, 2868, 3536,  317, 4087,  893, 2393, 2942, 4060,
        4197, 1294,  919, 2376])
Epoch: 1227, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1228 - Batch 1 ########################
IDs in batch 1: tensor([4166,  466, 3876, 2572, 1796,   78,  444, 4008, 1360, 3563, 4101, 1623,
        3706, 1349, 1067, 3756])
Epoch: 1228, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1229 - Batch 1 ########################
IDs in batch 1: tensor([  15, 1588,  402, 3461, 1852,  103,  419,  864, 2879, 3355, 4242,  623,
         448,  449, 3028, 2620])
Epoch: 1229, Training Loss: 0.16, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1230 - Batch 1 ########################
IDs in batch 1: tensor([2398, 3283,  955, 3433, 2791, 1235, 1054, 3927, 2261, 3583,  211,  988,
        4008, 1279, 2109, 1665])
Epoch: 1230, Training Loss: 0.15, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1231 - Batch 1 ########################
IDs in batch 1: tensor([1297,  837, 2871, 1119,  259, 1828,  699, 2771, 3526,  399, 1488, 2730,
         129, 2682, 4156, 1387])
Epoch: 1231, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1232 - Batch 1 ########################
IDs in batch 1: tensor([3081, 2745, 3139, 1942, 2723, 1794, 3897,   14, 2567,  321, 3458, 2642,
        2431, 3311, 4166,  121])
Epoch: 1232, Training Loss: 0.20, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1233 - Batch 1 ########################
IDs in batch 1: tensor([2099, 2291, 2408, 3697, 2523,  826, 3821, 4156, 1885, 3417, 1349, 4026,
        3417, 3265, 1932,  438])
Epoch: 1233, Training Loss: 0.21, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1234 - Batch 1 ########################
IDs in batch 1: tensor([2367, 4235, 1910, 1038, 3700, 3564, 1953, 2225, 4082, 1993,  990, 3746,
        3197, 1809,  936, 2349])
Epoch: 1234, Training Loss: 0.29, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1235 - Batch 1 ########################
IDs in batch 1: tensor([1885, 2760,  995, 1509, 2844, 3290,  427,  679, 1833, 3329, 3443, 2415,
        2879, 1198, 1110,  762])
Epoch: 1235, Training Loss: 0.26, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1236 - Batch 1 ########################
IDs in batch 1: tensor([3518, 1168,  356,  672, 2572, 3797, 1346,  471, 2419, 2938, 1649,  126,
        3035, 2883, 2770, 2235])
Epoch: 1236, Training Loss: 0.06, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1237 - Batch 1 ########################
IDs in batch 1: tensor([ 739, 2558, 3778, 3897,  590, 3981, 4082,  602, 2050, 3414, 2250, 2469,
        1157,  137,  781, 1954])
Epoch: 1237, Training Loss: 0.10, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1238 - Batch 1 ########################
IDs in batch 1: tensor([3511,  674,   38, 2049,  400, 3610, 2541, 3275,  565, 2908,  887,  822,
        2874, 1216, 1949, 2286])
Epoch: 1238, Training Loss: 0.22, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1239 - Batch 1 ########################
IDs in batch 1: tensor([2921, 3157, 2301,  530, 4198,  212, 3404, 1634, 1921, 3003,  752, 3465,
        1183, 1186,  132,  557])
Epoch: 1239, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1240 - Batch 1 ########################
IDs in batch 1: tensor([ 138,  773, 1297, 3859,  104, 2059,  808, 4114, 2485,  170, 1491, 2682,
          62,  878, 2246, 4230])
Epoch: 1240, Training Loss: 0.22, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1241 - Batch 1 ########################
IDs in batch 1: tensor([2715, 2882,  606, 3022,  505,  539, 1189,    5, 3483,  422,  635, 2899,
         326,  613, 3529, 1954])
Epoch: 1241, Training Loss: 0.17, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1242 - Batch 1 ########################
IDs in batch 1: tensor([2606,  469, 4002,  882, 1812, 3525, 2540, 2292, 3483, 2489, 3407, 3381,
        2510, 1579, 3453, 2740])
Epoch: 1242, Training Loss: 0.24, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1243 - Batch 1 ########################
IDs in batch 1: tensor([2828, 3168, 4249, 3047,  140, 2498, 3769, 3919,  917, 1275, 3549,   32,
        2741, 3866, 2265, 2770])
Epoch: 1243, Training Loss: 0.11, Validation Loss: 0.53, accuracy = 0.79
######################## Epoch 1244 - Batch 1 ########################
IDs in batch 1: tensor([3246, 1103,  729, 2721, 1863, 3279, 2127, 2457, 2456, 1913, 2287,  770,
        1773, 4085, 2863, 2969])
Epoch: 1244, Training Loss: 0.13, Validation Loss: 0.53, accuracy = 0.79
######################## Epoch 1245 - Batch 1 ########################
IDs in batch 1: tensor([1429, 1793, 2682, 3865, 1644, 4213, 3014, 2870, 1082, 1032, 4008, 3343,
        1592, 2485, 3900, 1376])
Epoch: 1245, Training Loss: 0.17, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1246 - Batch 1 ########################
IDs in batch 1: tensor([1241, 2749, 1294, 1086,  749, 1884, 2663, 3905, 2563, 3329, 3749, 1485,
         763, 3842,  987, 3484])
Epoch: 1246, Training Loss: 0.22, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1247 - Batch 1 ########################
IDs in batch 1: tensor([3628, 4065, 3723, 2536, 2824, 3963,  352, 2963, 3673, 2655,  470,  247,
        3888, 2205,  300, 1370])
Epoch: 1247, Training Loss: 0.08, Validation Loss: 0.53, accuracy = 0.78
######################## Epoch 1248 - Batch 1 ########################
IDs in batch 1: tensor([ 419, 3239, 3313, 1275, 1011, 2726, 2739, 2429, 4168, 3391, 3787, 4180,
        3938, 1840, 3648, 2069])
Epoch: 1248, Training Loss: 0.33, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1249 - Batch 1 ########################
IDs in batch 1: tensor([2075, 2516,  160,  947,  676, 2146, 3398, 3202, 1147, 2951, 1602, 4127,
        1333, 3363, 2052, 2022])
Epoch: 1249, Training Loss: 0.08, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1250 - Batch 1 ########################
IDs in batch 1: tensor([3769, 3207, 3136,   27, 4097,  373, 4114, 1321, 1228, 2998,   93, 1088,
        4258, 4073, 1041, 2429])
Epoch: 1250, Training Loss: 0.09, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1251 - Batch 1 ########################
IDs in batch 1: tensor([1101, 1673, 1023, 1990, 2663, 2407, 2296, 4122,  440, 1060, 2926, 3317,
        1731, 3053, 2919,  409])
Epoch: 1251, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1252 - Batch 1 ########################
IDs in batch 1: tensor([3829, 4085, 1499, 3289, 1223, 2346, 1264, 3504, 3253, 1794, 1305, 3498,
         933, 2828, 2399, 1204])
Epoch: 1252, Training Loss: 0.14, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1253 - Batch 1 ########################
IDs in batch 1: tensor([ 924, 2063, 1107, 3506, 4251, 4117, 1121, 3183, 1878, 3446,  763, 3044,
        2726, 3492, 2418,  687])
Epoch: 1253, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1254 - Batch 1 ########################
IDs in batch 1: tensor([3866,  326, 3306, 3334, 2217, 3826, 3885, 3217,  434,  526, 1880, 1902,
        3366,  820,  384, 3308])
Epoch: 1254, Training Loss: 0.20, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1255 - Batch 1 ########################
IDs in batch 1: tensor([2719, 1733, 2373,  879,  803, 1444, 1808, 3677, 2856, 2535, 3795, 3217,
        3376,  661,  188, 2153])
Epoch: 1255, Training Loss: 0.11, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1256 - Batch 1 ########################
IDs in batch 1: tensor([2832, 2103, 2518, 1508,  701,  264,  941, 2087, 2687, 3544, 4100, 1878,
         149,  944,  577, 1020])
Epoch: 1256, Training Loss: 0.25, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1257 - Batch 1 ########################
IDs in batch 1: tensor([ 816,   37,   72, 1108, 2924, 1711, 3781, 3084, 2940,  232,  327, 2260,
         990,  863, 3270,  812])
Epoch: 1257, Training Loss: 0.38, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1258 - Batch 1 ########################
IDs in batch 1: tensor([2524, 2453, 3334, 1955, 1718, 2821, 3058, 1181, 1821, 2609, 3449, 3871,
         106, 1295, 1395, 3663])
Epoch: 1258, Training Loss: 0.18, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1259 - Batch 1 ########################
IDs in batch 1: tensor([3798, 2003, 1480, 1185, 1289,  102, 3973, 1982, 1900, 3078, 2065,  609,
        3587, 1294,  470,  505])
Epoch: 1259, Training Loss: 0.19, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1260 - Batch 1 ########################
IDs in batch 1: tensor([4025, 1569,   18, 3388, 3368, 4122, 3652, 1559, 3218,  389, 2444, 3356,
         236, 3836, 4154, 2804])
Epoch: 1260, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1261 - Batch 1 ########################
IDs in batch 1: tensor([3499, 1349, 2710, 2518, 3214, 3151, 2717, 3585,  961, 4261, 1754,  130,
        2826,   25,  771,  606])
Epoch: 1261, Training Loss: 0.07, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1262 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 3235,  426,  365, 3850, 1819, 2256, 3764, 3467,  657, 3790,  165,
         201, 3518,  851, 1886])
Epoch: 1262, Training Loss: 0.27, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1263 - Batch 1 ########################
IDs in batch 1: tensor([2347, 1580, 2517, 4125, 3588, 3804, 2144, 2671, 2298,  439, 2365, 2990,
        1958, 3133, 1226,  501])
Epoch: 1263, Training Loss: 0.19, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1264 - Batch 1 ########################
IDs in batch 1: tensor([1824, 3410,  955, 2205, 3217, 2555, 2804, 2453, 3640, 1834,  257,  846,
        1034, 1602,  899, 3793])
Epoch: 1264, Training Loss: 0.12, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1265 - Batch 1 ########################
IDs in batch 1: tensor([1132, 3699, 3367, 1755, 1469, 3659,  426, 2258, 3972, 2517, 1852,  474,
        2202,  873, 3124, 3002])
Epoch: 1265, Training Loss: 0.30, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1266 - Batch 1 ########################
IDs in batch 1: tensor([ 752, 3118,  382,  997,  537, 3376, 3600, 2840, 4166,  976,  417, 3333,
        1306, 1734, 3917, 1932])
Epoch: 1266, Training Loss: 0.25, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1267 - Batch 1 ########################
IDs in batch 1: tensor([1540, 3908,  752, 2789, 1812, 1089, 2983, 3193,   18, 3709, 3696,  792,
        2453, 2023, 3051, 3418])
Epoch: 1267, Training Loss: 0.08, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1268 - Batch 1 ########################
IDs in batch 1: tensor([ 164,  910, 2711, 1393, 1724, 1517, 1139, 3200, 3077, 2009, 3455, 4166,
        3245, 2035, 1143, 1708])
Epoch: 1268, Training Loss: 0.20, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1269 - Batch 1 ########################
IDs in batch 1: tensor([3123, 3081, 1665, 2968, 1811, 2457, 3926,  595, 4265,  837, 3526, 3896,
        1299,  334,  186, 3222])
Epoch: 1269, Training Loss: 0.17, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1270 - Batch 1 ########################
IDs in batch 1: tensor([3099,  712,  601,  470,  928, 1782,  102, 4095, 2733, 4236, 3352, 3969,
        3846, 2257,  306, 2919])
Epoch: 1270, Training Loss: 0.12, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1271 - Batch 1 ########################
IDs in batch 1: tensor([2898,  511, 1087,  454, 2305,  451, 2448, 1295, 3460, 1236, 2810, 2506,
        1775, 3706, 1844, 2286])
Epoch: 1271, Training Loss: 0.22, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1272 - Batch 1 ########################
IDs in batch 1: tensor([2848, 3352, 4048, 3676,  391, 1648, 3557, 3352, 2767,  657, 2855, 2574,
        3424,  342, 4051, 2151])
Epoch: 1272, Training Loss: 0.17, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1273 - Batch 1 ########################
IDs in batch 1: tensor([ 651, 1670, 1648,  131,  477,  150, 2334, 3551, 1491, 2967, 1011, 3594,
        4246, 2831, 1302,  278])
Epoch: 1273, Training Loss: 0.34, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1274 - Batch 1 ########################
IDs in batch 1: tensor([3438, 4095, 2046, 1552, 1222, 2002, 1257, 2869, 3573, 3200,  403, 3227,
         896,  811, 1026, 3177])
Epoch: 1274, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1275 - Batch 1 ########################
IDs in batch 1: tensor([1334,  541, 1672, 3976, 2621, 3704, 2802, 3902, 3360,  996, 1970,  306,
         399, 3015, 2146, 1189])
Epoch: 1275, Training Loss: 0.34, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1276 - Batch 1 ########################
IDs in batch 1: tensor([4122, 2260, 1633,  316, 3804, 1174,  873, 1248, 1311,  544,  683, 3152,
        3370, 2119, 3927, 2980])
Epoch: 1276, Training Loss: 0.16, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 1277 - Batch 1 ########################
IDs in batch 1: tensor([3486,   85,  194, 2344, 1222, 3498, 1672, 2261,  356, 1845, 3435, 2809,
         484, 2765, 1812, 1087])
Epoch: 1277, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.74
######################## Epoch 1278 - Batch 1 ########################
IDs in batch 1: tensor([3257,  351, 3920, 1063, 1819, 1138,  323, 3818,  785,  558, 1256, 3337,
        1376, 1371,  838, 2246])
Epoch: 1278, Training Loss: 0.30, Validation Loss: 0.58, accuracy = 0.74
######################## Epoch 1279 - Batch 1 ########################
IDs in batch 1: tensor([1061,  807, 2442, 3385, 3277, 2437,  535, 1948,  663, 1779, 3717, 1825,
        2589, 1746,  607, 1001])
Epoch: 1279, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.74
######################## Epoch 1280 - Batch 1 ########################
IDs in batch 1: tensor([3537, 2225, 1356,  127, 1266, 2741, 2521, 2056, 1010, 3535, 3951, 1961,
        2355, 3394, 1038,  136])
Epoch: 1280, Training Loss: 0.12, Validation Loss: 0.58, accuracy = 0.74
######################## Epoch 1281 - Batch 1 ########################
IDs in batch 1: tensor([2159, 2298, 1931, 1935, 2600, 1426, 1369, 1294, 2326,  138, 1850, 3818,
         726, 3894, 1204, 1612])
Epoch: 1281, Training Loss: 0.13, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1282 - Batch 1 ########################
IDs in batch 1: tensor([2373,   52, 1661, 2782, 2858, 1511, 2712, 2465, 2924,    5,  432, 2949,
        1824, 1374,  550, 2671])
Epoch: 1282, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1283 - Batch 1 ########################
IDs in batch 1: tensor([1986, 2993, 3583, 2872, 4218, 1345, 3022,  563, 3483, 2420,  663, 3956,
        3404,  639, 3983, 4035])
Epoch: 1283, Training Loss: 0.43, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1284 - Batch 1 ########################
IDs in batch 1: tensor([1056, 1247,  171,  422, 2356, 2322, 3718,  335, 2086,  855, 3395, 1551,
        2465, 2810, 2618, 2357])
Epoch: 1284, Training Loss: 0.08, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1285 - Batch 1 ########################
IDs in batch 1: tensor([1634, 3859, 4068,  943, 3511, 1331, 1320, 1193, 1775, 3102, 1045, 1871,
        2453, 2172, 3318, 2894])
Epoch: 1285, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1286 - Batch 1 ########################
IDs in batch 1: tensor([ 456, 1496,   27, 2212, 3190, 3747, 1904,  101, 1639,  110, 3381, 2188,
         361, 1540, 1038, 3769])
Epoch: 1286, Training Loss: 0.21, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1287 - Batch 1 ########################
IDs in batch 1: tensor([2943, 3270, 1108,  218, 2950, 3644, 2997, 2604, 3424, 1789, 4057, 3958,
        1819,  830,  881, 3132])
Epoch: 1287, Training Loss: 0.23, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1288 - Batch 1 ########################
IDs in batch 1: tensor([3244, 3985, 1909, 2653, 2902, 2238, 2615, 2348,  258, 3993, 1855, 3926,
        3997, 2465, 3518,  956])
Epoch: 1288, Training Loss: 0.34, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1289 - Batch 1 ########################
IDs in batch 1: tensor([3409, 2470, 2242, 4093,  344,  888, 1417,  795, 1950,  368, 2951, 2868,
        2787, 2228, 1996, 4141])
Epoch: 1289, Training Loss: 0.10, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1290 - Batch 1 ########################
IDs in batch 1: tensor([1960,  775, 3648, 2868, 2290, 3469, 4187, 3533, 3881, 2838,  981, 3838,
        3852, 3226, 1921, 3652])
Epoch: 1290, Training Loss: 0.63, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1291 - Batch 1 ########################
IDs in batch 1: tensor([ 226, 3807,  924, 4181, 3333, 2052, 2385, 2793,  425, 2156, 2133, 1379,
        2991, 2262, 1016, 2262])
Epoch: 1291, Training Loss: 0.48, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1292 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 3021, 2915, 1909,   86, 1670, 3995,  701, 2256, 2204, 1294, 2078,
        3259, 3074, 2559, 3692])
Epoch: 1292, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1293 - Batch 1 ########################
IDs in batch 1: tensor([3453,  316, 1611, 3003, 1224,  387, 1328, 2372, 1181,  122, 3203,  679,
        3211,  489, 3218, 1580])
Epoch: 1293, Training Loss: 0.25, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1294 - Batch 1 ########################
IDs in batch 1: tensor([3234, 2581,  545, 1252,  882, 2574, 3846, 3700,  134,  407, 2026, 2924,
        1216, 2342, 3553, 1844])
Epoch: 1294, Training Loss: 0.23, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1295 - Batch 1 ########################
IDs in batch 1: tensor([1658,  376,  858,  472, 1089, 2989, 2146, 1628, 4255, 2066,  937, 2119,
        1618, 1754, 4157, 1370])
Epoch: 1295, Training Loss: 0.35, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1296 - Batch 1 ########################
IDs in batch 1: tensor([1361, 1060,  883,  435, 3886,  917, 3659, 2358, 2118, 1902,    4,  541,
        4256, 2144, 1052, 2894])
Epoch: 1296, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1297 - Batch 1 ########################
IDs in batch 1: tensor([ 372, 1597, 3002, 1702, 1345, 2826, 2807, 1614, 1417, 2936, 3290,   32,
        4232, 1663, 3375,  330])
Epoch: 1297, Training Loss: 0.27, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1298 - Batch 1 ########################
IDs in batch 1: tensor([ 186, 1563, 2090, 2719, 1488,  954,  170,  787,  862, 1755, 2193, 2748,
        2523,  435, 2092, 3981])
Epoch: 1298, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1299 - Batch 1 ########################
IDs in batch 1: tensor([2027, 2831, 2179, 3688, 1375, 3701, 4099,  487, 3387, 2891, 2670, 3108,
         442, 3262,  369,  371])
Epoch: 1299, Training Loss: 0.25, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1300 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 1276, 2132,  732, 2558, 2493, 1073, 3049, 3616, 3920,  152, 3443,
         834, 1706, 1181,  505])
Epoch: 1300, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1301 - Batch 1 ########################
IDs in batch 1: tensor([3058,  244,  418,  584, 1317, 3374, 2968, 2126, 3257, 2232, 3289,  247,
         679, 2220, 1093, 2902])
Epoch: 1301, Training Loss: 0.07, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1302 - Batch 1 ########################
IDs in batch 1: tensor([ 981, 4050, 1508,  983, 1763, 3440, 1925, 1971, 2069, 1960, 2312,  237,
        2859, 2997,  578, 3111])
Epoch: 1302, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1303 - Batch 1 ########################
IDs in batch 1: tensor([3065,  635, 1049, 1885,  684, 3476, 3160,  968,  466, 3259, 2771, 2324,
         226, 2591, 3455, 2550])
Epoch: 1303, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1304 - Batch 1 ########################
IDs in batch 1: tensor([ 350, 2858, 2189, 1201,   99, 3233, 2236, 1563,  150, 1239,  846, 1183,
        1947, 3391,  630, 3025])
Epoch: 1304, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1305 - Batch 1 ########################
IDs in batch 1: tensor([4002, 3188, 3287, 1751, 2780, 2358, 4251, 4067,  890, 2198, 2509,  902,
         508, 1982, 3142, 2526])
Epoch: 1305, Training Loss: 0.20, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1306 - Batch 1 ########################
IDs in batch 1: tensor([2583, 2847,  623, 1971, 4069, 2428, 2754,   41, 3414, 2715, 3638,  605,
         412, 2738, 3474, 1868])
Epoch: 1306, Training Loss: 0.33, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1307 - Batch 1 ########################
IDs in batch 1: tensor([ 371, 1272, 2008, 3455, 2320,  757, 3833, 3567, 3834,  167, 1125, 4264,
        2019,   99, 4234, 2555])
Epoch: 1307, Training Loss: 0.47, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1308 - Batch 1 ########################
IDs in batch 1: tensor([1777,  732, 2282, 3672, 1911, 1817, 1428, 4156, 3190, 2265, 2103, 2500,
        3704,  976, 3804,  517])
Epoch: 1308, Training Loss: 0.14, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1309 - Batch 1 ########################
IDs in batch 1: tensor([1885, 1617,  848, 3712, 3713, 3614,  250, 1189,  824, 2804, 2990,  824,
        3317, 3823, 1968, 1846])
Epoch: 1309, Training Loss: 0.22, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1310 - Batch 1 ########################
IDs in batch 1: tensor([ 892, 1804, 1053, 3886,  106, 2137, 1044,  530, 1234,  363, 1457, 3486,
        1156, 3443, 2265, 1464])
Epoch: 1310, Training Loss: 0.44, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1311 - Batch 1 ########################
IDs in batch 1: tensor([2767, 2771, 3912, 3781,   15, 1077,  556,  465, 1216, 3244, 3607, 2564,
        3389, 3083,   57, 4134])
Epoch: 1311, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1312 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 3439, 2151, 3543, 2957,  164, 3223,  833, 3470,  389, 2963, 2824,
        1218, 1708, 2967, 2103])
Epoch: 1312, Training Loss: 0.06, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1313 - Batch 1 ########################
IDs in batch 1: tensor([3444, 2246, 1107, 3599, 3039, 3760,  691, 1287, 1027, 3268,  334, 1682,
        3455, 2912, 2181, 3256])
Epoch: 1313, Training Loss: 0.06, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1314 - Batch 1 ########################
IDs in batch 1: tensor([1767, 4157, 2135, 1635,  673, 2499, 1970, 1322, 2051, 3027, 3663, 1920,
        4185, 1030, 2437, 3995])
Epoch: 1314, Training Loss: 0.25, Validation Loss: 0.56, accuracy = 0.75
######################## Epoch 1315 - Batch 1 ########################
IDs in batch 1: tensor([2204,  918, 4148, 1102,  943, 1309, 2737,  997,  150, 2670, 2278, 1495,
        3154, 1638, 4249, 3692])
Epoch: 1315, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1316 - Batch 1 ########################
IDs in batch 1: tensor([1571, 3366, 3900,  814,  812, 2610,  527, 1072,  505, 3504, 2290, 1457,
        3465, 1229, 1101, 2511])
Epoch: 1316, Training Loss: 0.10, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1317 - Batch 1 ########################
IDs in batch 1: tensor([2494, 3804,  531, 2246,  732, 4187, 3652, 3016, 1842, 2420, 3990, 3549,
        3141, 3939,  858, 4056])
Epoch: 1317, Training Loss: 0.33, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1318 - Batch 1 ########################
IDs in batch 1: tensor([4089,  741, 3437, 1657, 3843, 2984, 2401, 1958, 3940, 2937,  139, 2346,
         596, 3829, 2917, 2363])
Epoch: 1318, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.75
######################## Epoch 1319 - Batch 1 ########################
IDs in batch 1: tensor([1022, 2643,  440, 3452, 1770, 2780, 1647, 2226, 1249, 2366,  484, 1510,
        1144,  265, 2448,  340])
Epoch: 1319, Training Loss: 0.29, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1320 - Batch 1 ########################
IDs in batch 1: tensor([1228, 3326, 3627,  282, 3964, 2284, 1365,  632, 1491, 1931, 1808, 3655,
        2559, 2377, 3860, 4010])
Epoch: 1320, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1321 - Batch 1 ########################
IDs in batch 1: tensor([ 556, 4212, 3271, 1491,  887,  583,  919, 4212, 3485, 1456,   63, 4017,
        3495,  256, 3513, 1005])
Epoch: 1321, Training Loss: 0.20, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1322 - Batch 1 ########################
IDs in batch 1: tensor([4128,  758,  816,  266, 2027, 3044,  803, 1098,  262, 2189, 2793, 3732,
        1618, 4103, 2876, 2982])
Epoch: 1322, Training Loss: 0.09, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1323 - Batch 1 ########################
IDs in batch 1: tensor([ 287, 4199, 2291, 3506, 4072, 3257, 2412,  656, 3228, 2782,  369, 1765,
         656, 1803,  652, 3668])
Epoch: 1323, Training Loss: 0.19, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1324 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1576, 2156, 4008, 1385, 1618, 2196, 1737, 1782, 4039, 2731, 1982,
        2238, 3470, 1870, 2584])
Epoch: 1324, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1325 - Batch 1 ########################
IDs in batch 1: tensor([2868,  756, 1233, 3028, 1592,  417, 3289, 1511, 2235, 3769,  769,  135,
        3267, 3554,  520, 2126])
Epoch: 1325, Training Loss: 0.37, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1326 - Batch 1 ########################
IDs in batch 1: tensor([3065, 3286, 1274, 3803, 4236,  305, 2508,  771, 3514, 2479, 1537,  455,
        3873, 3187, 3436, 1062])
Epoch: 1326, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1327 - Batch 1 ########################
IDs in batch 1: tensor([3617, 3031, 2123, 1451,   46, 2693,  680, 1498, 1015, 3551, 3938,  752,
        2132,  526, 1640, 1894])
Epoch: 1327, Training Loss: 0.25, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1328 - Batch 1 ########################
IDs in batch 1: tensor([1052, 1443, 3290,  515, 1318, 1056, 3701,  371, 2278, 1993, 1787, 3399,
        2004, 3236, 1039, 2690])
Epoch: 1328, Training Loss: 0.24, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1329 - Batch 1 ########################
IDs in batch 1: tensor([3843, 1094, 2562, 2591, 3701, 1618, 2249, 1319, 1988, 1897, 3876, 2727,
         646,  781, 3717,  481])
Epoch: 1329, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1330 - Batch 1 ########################
IDs in batch 1: tensor([3031, 2448, 1299,  167, 1851, 2450, 1417, 2488,  663, 2873, 1925, 4189,
        1824, 2131,  131, 3102])
Epoch: 1330, Training Loss: 0.06, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1331 - Batch 1 ########################
IDs in batch 1: tensor([1318, 2067,  452, 2003, 1006, 1671, 2428, 2645, 3943, 3710, 3182,  519,
         438, 3248,   77,  893])
Epoch: 1331, Training Loss: 0.18, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1332 - Batch 1 ########################
IDs in batch 1: tensor([3072, 1321, 1096, 4143, 1589,  355, 3514, 3208, 2343, 3268, 3371, 2738,
        3988,  245, 3779,  804])
Epoch: 1332, Training Loss: 0.34, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1333 - Batch 1 ########################
IDs in batch 1: tensor([2640, 3353, 2173, 1810,  615, 2141, 1552, 4024, 3211, 2529,  388, 3832,
        3261, 2207, 2917,   72])
Epoch: 1333, Training Loss: 0.20, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1334 - Batch 1 ########################
IDs in batch 1: tensor([2646, 3397, 2103,  434, 1322, 1317, 2015, 3327, 2857, 3049, 2695,  895,
        2776, 3780, 3999, 3886])
Epoch: 1334, Training Loss: 0.30, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1335 - Batch 1 ########################
IDs in batch 1: tensor([3588, 2428, 3204, 1059, 2234, 1049, 1183, 3542, 2606,  566, 2966, 4140,
        1880, 3912,  170,  846])
Epoch: 1335, Training Loss: 0.15, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1336 - Batch 1 ########################
IDs in batch 1: tensor([3471, 2867, 3196, 1278, 2505, 3936, 3020, 4143, 3600,  449, 1084, 3250,
        4157, 2887, 1098, 3084])
Epoch: 1336, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1337 - Batch 1 ########################
IDs in batch 1: tensor([1828, 3481, 2539, 3845,  736, 3109, 3932, 2950, 3763, 1511, 3540,  593,
        2480, 1159,  130, 2810])
Epoch: 1337, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1338 - Batch 1 ########################
IDs in batch 1: tensor([ 659, 2050, 2516,  694, 2466, 3188, 3494, 1925, 2727,  219, 2387,  766,
         100, 1770, 1657,  407])
Epoch: 1338, Training Loss: 0.17, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1339 - Batch 1 ########################
IDs in batch 1: tensor([3852,  106,   28, 2306, 1161, 3128,  402, 1331,  725, 3409, 3126, 3020,
        2956, 2617, 3956, 2842])
Epoch: 1339, Training Loss: 0.11, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1340 - Batch 1 ########################
IDs in batch 1: tensor([2193, 3953, 2835, 2914, 3695, 1828, 3813, 3813, 3202, 3108, 1153,  324,
        2956, 1624, 1195, 1069])
Epoch: 1340, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1341 - Batch 1 ########################
IDs in batch 1: tensor([1388,  816, 3702, 2094, 2655, 1546, 3638, 1213, 3638,  678, 3954,  891,
          60, 2723, 1326, 1833])
Epoch: 1341, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1342 - Batch 1 ########################
IDs in batch 1: tensor([1181, 2469,  987, 4175, 1818, 2927, 3466,  557, 1233, 1289, 1223, 3962,
        3826, 2832, 1063, 1313])
Epoch: 1342, Training Loss: 0.35, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1343 - Batch 1 ########################
IDs in batch 1: tensor([1787, 1921, 2375, 3608, 3563, 2797, 2701, 2572,  612,  841,  978, 2378,
        4070, 3378, 3182, 2443])
Epoch: 1343, Training Loss: 0.24, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1344 - Batch 1 ########################
IDs in batch 1: tensor([ 767, 3541, 3119, 4086,  333,  317, 4174, 1113,  393,  777,  961, 4195,
         305,  183, 2276,  632])
Epoch: 1344, Training Loss: 0.38, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1345 - Batch 1 ########################
IDs in batch 1: tensor([3501, 2760, 3746,  160, 2385,  871, 3859, 1949, 3022, 2829, 1780, 1193,
        3816, 3603, 2855, 3710])
Epoch: 1345, Training Loss: 0.17, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1346 - Batch 1 ########################
IDs in batch 1: tensor([2914,   60, 1489, 3398,  622, 3975, 3617, 1133,  413,  662, 3338, 2772,
        1467, 2565, 4118, 1779])
Epoch: 1346, Training Loss: 0.20, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1347 - Batch 1 ########################
IDs in batch 1: tensor([2776, 1328,  749, 2978,  796, 3688, 2394, 3423, 3627, 2553, 1878,  701,
        1500, 3972,  967, 1745])
Epoch: 1347, Training Loss: 0.35, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1348 - Batch 1 ########################
IDs in batch 1: tensor([ 279, 3601,  813, 3980, 1286, 1524, 3010, 2278, 2419, 3732, 4101, 1594,
        2793, 2223,  387, 1536])
Epoch: 1348, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1349 - Batch 1 ########################
IDs in batch 1: tensor([1900, 4105,  497,  196,  377, 2610, 1612,  507, 4131,  674,  966, 3617,
         492, 2937, 1290, 3015])
Epoch: 1349, Training Loss: 0.27, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1350 - Batch 1 ########################
IDs in batch 1: tensor([3421, 2301,  133,  488,  531, 1556, 2924, 3333, 3418, 1167, 2023,  247,
         739, 2285, 3532, 1001])
Epoch: 1350, Training Loss: 0.10, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1351 - Batch 1 ########################
IDs in batch 1: tensor([3907,  408, 3615,  517, 1055, 3616,  266, 3553, 3719, 1179, 2440, 1120,
         183, 2126,  217, 2780])
Epoch: 1351, Training Loss: 0.20, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1352 - Batch 1 ########################
IDs in batch 1: tensor([ 217, 1237, 1985, 3894,  108, 1244, 2806,  541, 2036, 1062,  829, 2090,
        2700, 3547, 4124, 2072])
Epoch: 1352, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1353 - Batch 1 ########################
IDs in batch 1: tensor([ 469,  786, 4235,  822, 2925,  389, 2402, 3640, 2748, 3275,  276, 2111,
        4136, 3529, 1457, 1343])
Epoch: 1353, Training Loss: 0.06, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1354 - Batch 1 ########################
IDs in batch 1: tensor([3581, 4238, 4255, 1982, 2405, 3440,  593, 2362, 3538, 3866,  587, 2146,
        3952, 3373,  320, 4039])
Epoch: 1354, Training Loss: 0.52, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1355 - Batch 1 ########################
IDs in batch 1: tensor([3538, 3268, 1470, 4038, 3530, 3875, 2711, 3326,  575, 2439, 1269,  126,
        3241, 1062, 2065, 2202])
Epoch: 1355, Training Loss: 0.09, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1356 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 4007, 1310,  424, 3447,  408, 4110, 1496, 1258, 2537, 3542, 4189,
        2978,  497, 3505, 1804])
Epoch: 1356, Training Loss: 0.10, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1357 - Batch 1 ########################
IDs in batch 1: tensor([2517, 1775, 2256, 1493, 3481, 4163, 2372,  776, 1511, 1693, 2915, 2276,
        2205, 1685, 2296,  194])
Epoch: 1357, Training Loss: 0.06, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1358 - Batch 1 ########################
IDs in batch 1: tensor([ 469, 3278, 3222,  388,  755, 1767, 1153, 2589, 2224, 2320, 4119, 3942,
        1761, 4195, 3221, 4099])
Epoch: 1358, Training Loss: 0.04, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1359 - Batch 1 ########################
IDs in batch 1: tensor([2873, 3509,  980,   92, 1596, 1923,  949, 4203, 3143, 3597, 2799,  236,
        3428, 3490,  875,  825])
Epoch: 1359, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1360 - Batch 1 ########################
IDs in batch 1: tensor([1157, 4158,  893,   57,  277, 2110, 1414, 2049, 1325,   30, 2188, 2583,
        1862, 1235,  171, 4075])
Epoch: 1360, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1361 - Batch 1 ########################
IDs in batch 1: tensor([4030, 3664, 3689, 3996,  956, 1143, 1950, 3834, 3976, 2312, 1387,  804,
        2244, 2522,  407, 3501])
Epoch: 1361, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1362 - Batch 1 ########################
IDs in batch 1: tensor([ 323,  980, 3590, 2363, 3527, 1543, 3478, 1509,   51, 3123, 3856,  441,
        4008,  790,  792, 3718])
Epoch: 1362, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1363 - Batch 1 ########################
IDs in batch 1: tensor([3590,   25,  448, 4086, 3472, 1895,   42,  518, 4099, 2015, 3781, 1236,
        3456,  102,  863, 3866])
Epoch: 1363, Training Loss: 0.07, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1364 - Batch 1 ########################
IDs in batch 1: tensor([3245, 3537,  394, 3408, 2391,  280,  190,  826, 1009, 1877, 2895, 1061,
        1469, 1499, 1690, 2695])
Epoch: 1364, Training Loss: 0.14, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1365 - Batch 1 ########################
IDs in batch 1: tensor([1824,  426, 2887, 1383, 2287, 2472, 1748,   85, 1640, 1821,  401, 2710,
         635,  691, 1502, 3031])
Epoch: 1365, Training Loss: 0.17, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1366 - Batch 1 ########################
IDs in batch 1: tensor([2328, 2917,  330, 3184,  200,  390, 3996, 2236, 1480,  871, 1853, 3372,
         751, 1355, 3783, 2885])
Epoch: 1366, Training Loss: 0.08, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1367 - Batch 1 ########################
IDs in batch 1: tensor([1391, 1177, 1803, 1977, 1708,  899, 3078, 3757, 1779, 1128,  770, 3821,
        4196, 4022,  986, 1066])
Epoch: 1367, Training Loss: 0.23, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1368 - Batch 1 ########################
IDs in batch 1: tensor([ 556, 2463, 2188, 1938, 1470, 3677, 3951, 3453, 3827, 1354, 3282, 1283,
        4166, 3894, 3284, 3031])
Epoch: 1368, Training Loss: 0.31, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1369 - Batch 1 ########################
IDs in batch 1: tensor([1899,    7, 1124,  498, 1510, 2689, 2003,  357, 1037, 2827,  438,  164,
         111, 1901, 3545, 1484])
Epoch: 1369, Training Loss: 0.30, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1370 - Batch 1 ########################
IDs in batch 1: tensor([ 893,  376,  827, 3973, 1972, 3426,  537, 2842, 1950, 3879, 3035, 1221,
         384,  400,  602, 2248])
Epoch: 1370, Training Loss: 0.09, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1371 - Batch 1 ########################
IDs in batch 1: tensor([1016, 2708, 3363, 3418, 2439, 2552, 4195, 2749,  674, 2905, 3092,  444,
        2802, 3972, 4134, 2978])
Epoch: 1371, Training Loss: 0.38, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1372 - Batch 1 ########################
IDs in batch 1: tensor([3475, 2228, 3827, 3739, 2943,  159, 2648, 2764, 2109, 3386, 2780, 3139,
        1340, 1658, 3397, 1901])
Epoch: 1372, Training Loss: 0.54, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1373 - Batch 1 ########################
IDs in batch 1: tensor([3928, 4121, 1082, 2458,  139, 1880, 3179, 4121, 2410, 3506, 2375,  989,
         850, 1640, 3660,  595])
Epoch: 1373, Training Loss: 0.21, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1374 - Batch 1 ########################
IDs in batch 1: tensor([3487, 2406, 1677, 3697, 2230, 2632, 4093, 1774, 1062, 3110, 2809, 3290,
        3587, 3647, 1880, 1087])
Epoch: 1374, Training Loss: 0.17, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1375 - Batch 1 ########################
IDs in batch 1: tensor([3536,   51,  880,  841, 3435, 1559, 3718, 1824, 2098, 2097, 1650,   82,
        1684, 1676,  717, 3689])
Epoch: 1375, Training Loss: 0.33, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1376 - Batch 1 ########################
IDs in batch 1: tensor([ 180, 1334, 3016, 3699,  980,  186, 4065, 1588, 1510, 1519, 1574,  830,
        3243, 3484, 2984,  102])
Epoch: 1376, Training Loss: 0.38, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1377 - Batch 1 ########################
IDs in batch 1: tensor([2787, 1786, 2851, 2179, 1909, 3220, 2650,  503, 1306, 2784, 1886, 2782,
        3689, 2467, 1540, 3655])
Epoch: 1377, Training Loss: 0.13, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1378 - Batch 1 ########################
IDs in batch 1: tensor([2353, 2432,  863, 3486, 3974, 3451, 2468, 3321,   15, 3190,   77,  137,
        3206, 1710, 3803, 3057])
Epoch: 1378, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1379 - Batch 1 ########################
IDs in batch 1: tensor([3803, 1684, 3865, 3945,  721, 2882, 1490,   42, 1602, 2724, 4159,  699,
        4061, 2258, 3016, 3832])
Epoch: 1379, Training Loss: 0.12, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1380 - Batch 1 ########################
IDs in batch 1: tensor([1954,  510,  809,  993, 1680, 4073, 1006,   60, 2606,  839,  839, 2940,
        1935, 1976, 2499,  930])
Epoch: 1380, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1381 - Batch 1 ########################
IDs in batch 1: tensor([1651,  201,  837,   41, 1285, 1971, 1274, 2322, 2663, 3746, 1432, 4051,
        3193, 2590, 1860, 3812])
Epoch: 1381, Training Loss: 0.05, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1382 - Batch 1 ########################
IDs in batch 1: tensor([ 733, 2617, 2483, 3246, 1872, 3000, 1918, 1328, 3624, 1509, 2111,  317,
         811, 2884, 1457, 2860])
Epoch: 1382, Training Loss: 0.26, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1383 - Batch 1 ########################
IDs in batch 1: tensor([ 171, 3964, 3289, 1357, 3874,  120,  501, 3699, 2451, 2419,  773, 3123,
         642,  602, 1604, 2587])
Epoch: 1383, Training Loss: 0.20, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1384 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 1990, 3998, 2295, 3614, 3537, 2856,   15,  412, 1406, 1573, 1072,
        1177, 3830, 2551, 1726])
Epoch: 1384, Training Loss: 0.18, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1385 - Batch 1 ########################
IDs in batch 1: tensor([1154, 3190, 3353, 1842, 4268, 3494,  586, 2231, 2587, 1232,  988, 3363,
         904,  507, 4002,  469])
Epoch: 1385, Training Loss: 0.06, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1386 - Batch 1 ########################
IDs in batch 1: tensor([3337, 2005, 3338, 1102,  527, 2508, 1436, 1001, 2931, 2780,  403, 2996,
        2518, 1722,  407,   46])
Epoch: 1386, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1387 - Batch 1 ########################
IDs in batch 1: tensor([1383, 4187, 1718, 3367, 1277, 1676, 3528, 2571,  730, 3919,  466, 3424,
        1174,  883, 2689, 3663])
Epoch: 1387, Training Loss: 0.18, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1388 - Batch 1 ########################
IDs in batch 1: tensor([1443,  387, 3394, 2393, 2027, 3603, 4131, 3377, 2868, 1595, 2242, 3870,
        3936, 4170,  766, 2959])
Epoch: 1388, Training Loss: 0.18, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1389 - Batch 1 ########################
IDs in batch 1: tensor([3609,   51,  409, 2984, 1454, 3074, 1099,   46, 2902, 4117,  756, 1402,
         573, 1153, 3157, 1567])
Epoch: 1389, Training Loss: 0.33, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1390 - Batch 1 ########################
IDs in batch 1: tensor([3277, 1670, 1559, 2927, 2388, 3244,  117, 2262,  413, 1452, 1678,  490,
        1463,  537, 3668, 2461])
Epoch: 1390, Training Loss: 0.36, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1391 - Batch 1 ########################
IDs in batch 1: tensor([3634, 3763, 1559, 1166, 3156, 1933, 2976, 1111, 1706, 1214, 2879, 2691,
        1567, 1870, 3738, 4188])
Epoch: 1391, Training Loss: 0.05, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1392 - Batch 1 ########################
IDs in batch 1: tensor([3253, 1084, 1099, 4242, 2109, 4138, 2449, 1426, 3712, 2692, 2932, 2859,
        1360,  781, 3094, 3342])
Epoch: 1392, Training Loss: 0.10, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1393 - Batch 1 ########################
IDs in batch 1: tensor([ 183, 2272, 1490, 1328, 3497, 1840, 2036, 3883,  389, 2161, 2669, 1006,
         183, 2067,  243,   32])
Epoch: 1393, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.76
######################## Epoch 1394 - Batch 1 ########################
IDs in batch 1: tensor([2203, 2648, 3291, 1996, 2631, 1143, 1436, 1982, 1476,  895, 1242, 1052,
         577, 2110, 3468, 1670])
Epoch: 1394, Training Loss: 0.15, Validation Loss: 0.53, accuracy = 0.77
######################## Epoch 1395 - Batch 1 ########################
IDs in batch 1: tensor([3632, 3363, 3879, 2448, 3060, 4214, 3150, 1237, 1471, 2745, 2655, 1947,
        1485, 3815, 4133, 4159])
Epoch: 1395, Training Loss: 0.37, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1396 - Batch 1 ########################
IDs in batch 1: tensor([1784, 3257, 2356, 1003, 1693, 3433, 2853, 2234, 2782, 1175, 2578,  131,
        1706, 2848, 1372,  563])
Epoch: 1396, Training Loss: 0.15, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1397 - Batch 1 ########################
IDs in batch 1: tensor([4195, 3942, 2034, 3151, 2026, 1794,  873, 2868, 2526, 2120,  362, 1252,
        2224, 1990, 3769,  492])
Epoch: 1397, Training Loss: 0.13, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1398 - Batch 1 ########################
IDs in batch 1: tensor([3429, 3218, 1162, 2051, 3317,  626, 3896, 3528, 3118, 4135, 1971, 3793,
        2610,  550, 1772, 1066])
Epoch: 1398, Training Loss: 0.17, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1399 - Batch 1 ########################
IDs in batch 1: tensor([2356, 3363,  750, 1896, 3400, 1748, 1381, 1266, 2035, 1075,  915,  969,
        2210,  709,  743, 2464])
Epoch: 1399, Training Loss: 0.43, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1400 - Batch 1 ########################
IDs in batch 1: tensor([3469,  426, 2806, 2327, 2524, 4076,  902, 1152, 3157, 2331,  944, 1704,
        1101,  970, 2038, 2224])
Epoch: 1400, Training Loss: 0.14, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1401 - Batch 1 ########################
IDs in batch 1: tensor([2046, 2838, 3621, 1156, 2483, 4163, 1760,  276, 1168, 3661,  357, 1093,
        2552, 1526,  259, 1656])
Epoch: 1401, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1402 - Batch 1 ########################
IDs in batch 1: tensor([3264,  415,  930, 3481, 2797, 3401, 2723,  533, 1605, 2204, 3239,  739,
        2546, 2440,  965,  955])
Epoch: 1402, Training Loss: 0.06, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1403 - Batch 1 ########################
IDs in batch 1: tensor([ 988, 1269,   44,  921,   56, 3963,  546, 3973, 2642, 1402, 1357, 4200,
        3717,  904, 3614, 1500])
Epoch: 1403, Training Loss: 0.12, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1404 - Batch 1 ########################
IDs in batch 1: tensor([ 220, 3853,  470,  965,  455, 2742, 3036, 3227, 3394, 1266,  104,   31,
         804, 2011, 1793, 3386])
Epoch: 1404, Training Loss: 0.16, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1405 - Batch 1 ########################
IDs in batch 1: tensor([1745, 3831, 1428,   26, 3975, 1763, 1833, 1633, 3900, 1910, 3911,  380,
        4152, 4040, 2251,  441])
Epoch: 1405, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1406 - Batch 1 ########################
IDs in batch 1: tensor([3202,  594, 2795,  536, 1076, 4136, 2646, 2224, 2299, 2998, 1258, 2234,
        2746, 3448, 3323, 1152])
Epoch: 1406, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1407 - Batch 1 ########################
IDs in batch 1: tensor([1415, 3495, 2664, 1308, 1374, 1860, 3154,  827, 3847,   18, 4152, 1306,
        3521,  412, 1200, 1822])
Epoch: 1407, Training Loss: 0.18, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1408 - Batch 1 ########################
IDs in batch 1: tensor([3813, 3827, 3112, 3689, 1853, 1651,  228, 3917,  928, 2123, 1879, 1287,
        2131,  520,  863, 3693])
Epoch: 1408, Training Loss: 0.22, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1409 - Batch 1 ########################
IDs in batch 1: tensor([4010, 1495, 1900, 2199,   20,  422,  681,  953, 3757,  101, 2287, 3771,
        1038, 1332, 2053, 2520])
Epoch: 1409, Training Loss: 0.19, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1410 - Batch 1 ########################
IDs in batch 1: tensor([  43, 4119, 1970, 1232, 2829, 2973, 3371, 1579, 1232, 3471, 2092,  351,
        1317,  953,  351, 3742])
Epoch: 1410, Training Loss: 0.09, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1411 - Batch 1 ########################
IDs in batch 1: tensor([  50, 3542, 2209, 4265, 3644, 1761, 1673, 3465,  467,    7, 1347, 2835,
         657, 3668, 1177,  967])
Epoch: 1411, Training Loss: 0.30, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1412 - Batch 1 ########################
IDs in batch 1: tensor([1137,  516, 2134, 3756,  516, 2763, 1057, 3235, 1690, 3856, 4073, 3511,
        1383, 1372,  129, 3111])
Epoch: 1412, Training Loss: 0.08, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1413 - Batch 1 ########################
IDs in batch 1: tensor([1144,  858, 4116, 1279, 1082, 3982,   88, 2247, 4025,   70, 2056, 1007,
        1379,  198, 1108, 3270])
Epoch: 1413, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1414 - Batch 1 ########################
IDs in batch 1: tensor([3803, 2299, 3859, 1728, 1937, 2178, 4126, 3130, 1081,  191, 1553,  214,
        1745, 1828, 3570, 1087])
Epoch: 1414, Training Loss: 0.05, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1415 - Batch 1 ########################
IDs in batch 1: tensor([3228,  131,  526, 4114,  981, 2642, 2745,  994, 2741, 2064, 1971, 3607,
        2856, 3182, 4077, 2041])
Epoch: 1415, Training Loss: 0.20, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1416 - Batch 1 ########################
IDs in batch 1: tensor([3220, 2019, 3126,  915,  987, 3032, 2725, 3284, 2166, 2131, 3255,  187,
        3262, 2871, 2447, 1880])
Epoch: 1416, Training Loss: 0.53, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1417 - Batch 1 ########################
IDs in batch 1: tensor([3037, 2828, 4046, 1551,  236, 2150, 3932, 2638, 1012, 1349, 3706, 2535,
         544, 1181, 2725,   72])
Epoch: 1417, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1418 - Batch 1 ########################
IDs in batch 1: tensor([ 789, 1810, 1197, 2099, 2192, 2446, 2913, 1955, 1271, 3713, 2104, 1675,
        4039, 3330, 3077, 2296])
Epoch: 1418, Training Loss: 0.39, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1419 - Batch 1 ########################
IDs in batch 1: tensor([3429, 4242, 4223, 4048,  752, 1017, 3783, 2291, 3306, 4181, 2487, 3610,
        1037, 3042, 1787, 2876])
Epoch: 1419, Training Loss: 0.26, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1420 - Batch 1 ########################
IDs in batch 1: tensor([2749, 4082,   32, 3634, 3258, 2715,  848,  438, 2659,  918, 1271,  498,
         789, 2770, 2372, 1934])
Epoch: 1420, Training Loss: 0.04, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1421 - Batch 1 ########################
IDs in batch 1: tensor([1216,  332, 2610, 3487, 2312, 1931, 2708, 1476, 3920, 3381,  211, 2552,
        2408, 1734, 1782, 3244])
Epoch: 1421, Training Loss: 0.08, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1422 - Batch 1 ########################
IDs in batch 1: tensor([ 858, 2807, 1369, 2926,  933, 4156, 1530, 3428,  305, 3081,   52, 2342,
        2990,  587,  126, 2592])
Epoch: 1422, Training Loss: 0.11, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1423 - Batch 1 ########################
IDs in batch 1: tensor([ 220, 2327, 3342, 1121, 1442, 2689, 2956, 2646, 1786, 1841, 1834, 4226,
        1835, 3493, 1017, 3672])
Epoch: 1423, Training Loss: 0.26, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1424 - Batch 1 ########################
IDs in batch 1: tensor([ 968, 2627, 1900, 3726,  140, 1326, 1161, 4100, 1525, 4220, 1548, 2748,
        3557, 4179, 3568, 4072])
Epoch: 1424, Training Loss: 0.27, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1425 - Batch 1 ########################
IDs in batch 1: tensor([  50, 2285,   59, 1808,  282, 2344, 3141, 1508, 3188, 2385,  875, 2953,
        1851,  639, 2189,  822])
Epoch: 1425, Training Loss: 0.03, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1426 - Batch 1 ########################
IDs in batch 1: tensor([3891, 3862, 2855, 3671, 1309, 3404, 1974, 3452, 1772, 4141, 3135, 3838,
        2204, 3465, 2112,  106])
Epoch: 1426, Training Loss: 0.51, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1427 - Batch 1 ########################
IDs in batch 1: tensor([2059,  613, 2125, 1279, 3985, 1266, 3874, 3192, 2444,   77, 1575, 1090,
        2113,  841, 2049, 1484])
Epoch: 1427, Training Loss: 0.07, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1428 - Batch 1 ########################
IDs in batch 1: tensor([1419,  736, 4215, 4141, 2104, 2363,  691, 1312, 4005, 1088, 2586, 2584,
        2827,  966, 3099, 1870])
Epoch: 1428, Training Loss: 0.13, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1429 - Batch 1 ########################
IDs in batch 1: tensor([ 680, 3914, 2841, 2908, 1558, 3781, 1571, 3333, 2205, 2326, 2959, 2961,
        3177, 1234, 3467,  345])
Epoch: 1429, Training Loss: 0.17, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1430 - Batch 1 ########################
IDs in batch 1: tensor([ 558,   41, 3275, 3363, 3563, 3836, 2013, 1861, 2871, 2841, 3908, 1712,
        3704, 3597, 4204,  969])
Epoch: 1430, Training Loss: 0.33, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1431 - Batch 1 ########################
IDs in batch 1: tensor([ 212, 1671, 3102, 4213, 3484, 2401, 1558, 1239, 2245, 2529, 1981, 1012,
        2252, 2676,   25, 1381])
Epoch: 1431, Training Loss: 0.04, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1432 - Batch 1 ########################
IDs in batch 1: tensor([1273,  778, 3344,  332,  755, 3938,   15, 1041, 2961,  449, 1775, 3015,
         121, 3862, 1415, 2495])
Epoch: 1432, Training Loss: 0.38, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1433 - Batch 1 ########################
IDs in batch 1: tensor([2369, 4018, 3541, 2691,  781, 2378,  415,  834, 1224, 4025, 2959, 3207,
        1235, 2618, 2661, 4038])
Epoch: 1433, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1434 - Batch 1 ########################
IDs in batch 1: tensor([ 469, 3541, 2776,  485, 3128, 2886, 3094, 1832,  224, 1502, 4136,  830,
         365,  962,  851, 1504])
Epoch: 1434, Training Loss: 0.24, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1435 - Batch 1 ########################
IDs in batch 1: tensor([3409, 1949,  439,  228, 2344, 1747, 2207, 2398, 2984, 3845, 3369, 3637,
        3875,  876, 3917, 3455])
Epoch: 1435, Training Loss: 0.26, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1436 - Batch 1 ########################
IDs in batch 1: tensor([2690, 2329,  587,  413, 3496, 2069, 2282,  501,  637, 1708,  639, 1860,
        2180, 3518, 1811, 2947])
Epoch: 1436, Training Loss: 0.12, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1437 - Batch 1 ########################
IDs in batch 1: tensor([3601, 1763, 3003,  312, 1752,  822, 3430, 3886, 2924, 2745,  933, 3552,
        1003,  917, 1559, 1022])
Epoch: 1437, Training Loss: 0.29, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1438 - Batch 1 ########################
IDs in batch 1: tensor([2659, 1328, 1895,  377, 3142, 3953, 1675,  794, 2787, 1442, 1591,   21,
        3856, 3369, 4257, 4224])
Epoch: 1438, Training Loss: 0.16, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1439 - Batch 1 ########################
IDs in batch 1: tensor([ 323, 1279,  365, 1633, 3715, 2415, 2127,  354, 1471, 2451, 2312,  944,
        1077, 1947, 2177,  770])
Epoch: 1439, Training Loss: 0.07, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1440 - Batch 1 ########################
IDs in batch 1: tensor([3525, 1355, 1395, 1153, 1437,  490, 3425,  977, 3995,  954, 1878, 2098,
        3358, 3677, 3183, 3780])
Epoch: 1440, Training Loss: 0.08, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1441 - Batch 1 ########################
IDs in batch 1: tensor([ 741, 2571,  120, 1774, 3866, 3940, 1167, 1971, 2464, 1747, 3757, 3771,
        3845, 3078, 1042, 2458])
Epoch: 1441, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1442 - Batch 1 ########################
IDs in batch 1: tensor([4033, 1250, 1891, 2706, 4048,  917, 3015,  221, 3671, 2343,  852, 1490,
         969,  302, 4070,  727])
Epoch: 1442, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1443 - Batch 1 ########################
IDs in batch 1: tensor([ 595, 1745, 2449, 4223, 3749,  510, 4080,  465, 3065, 3075,  343, 3699,
        3935, 3787,  819, 1526])
Epoch: 1443, Training Loss: 0.19, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1444 - Batch 1 ########################
IDs in batch 1: tensor([1419, 3647, 1945, 1196, 1482, 1502, 2372, 2219, 2364, 2053, 2117,  830,
         154, 1009, 1737, 2902])
Epoch: 1444, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1445 - Batch 1 ########################
IDs in batch 1: tensor([  73, 1576, 3481, 3287,  893, 3111, 1384,    4, 3032, 2712, 2257, 2416,
        3858, 4056,  575, 1844])
Epoch: 1445, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1446 - Batch 1 ########################
IDs in batch 1: tensor([3256,  758, 4101, 4004, 1157,  244,  198, 1396, 1512, 3745, 3927, 1612,
         558,   18, 1456, 1041])
Epoch: 1446, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1447 - Batch 1 ########################
IDs in batch 1: tensor([4049, 2444, 1580,  354, 3222, 2517, 2064, 3157,  172, 1373,  316, 3016,
        1984, 3166, 1130,  881])
Epoch: 1447, Training Loss: 0.12, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1448 - Batch 1 ########################
IDs in batch 1: tensor([ 269, 3465, 4166, 4027, 3732, 1501, 3476, 2322, 4181,  317, 1845, 2314,
        1101, 1271, 3216, 3713])
Epoch: 1448, Training Loss: 0.07, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1449 - Batch 1 ########################
IDs in batch 1: tensor([2370, 1473, 2519, 4124, 2390,  442, 3721, 3236,  193, 3607, 3000, 3399,
        2899, 2034,   72, 2326])
Epoch: 1449, Training Loss: 0.24, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1450 - Batch 1 ########################
IDs in batch 1: tensor([ 121, 3474, 4003, 3190, 1344,  512, 2167,  320, 2860,  484, 2002, 1042,
        2034,   10, 2356, 2468])
Epoch: 1450, Training Loss: 0.12, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1451 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2696, 2049, 4007, 3376, 3135, 2691,  753, 1051, 2056, 1832,  279,
        1727, 3948, 1055, 2036])
Epoch: 1451, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1452 - Batch 1 ########################
IDs in batch 1: tensor([1686, 2965, 1571, 2797, 2523, 2441, 2924,  941,  517, 4115,  952,  803,
        2116, 1282, 3452, 1408])
Epoch: 1452, Training Loss: 0.16, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1453 - Batch 1 ########################
IDs in batch 1: tensor([2738, 1954, 3900, 2013, 3894, 3092,  828, 3261, 2859, 3434, 2410,   68,
         119, 1519, 1570, 2913])
Epoch: 1453, Training Loss: 0.06, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1454 - Batch 1 ########################
IDs in batch 1: tensor([4134,  202,  422, 2447, 2456, 3407,  639, 1563, 3357, 2442, 1795,  346,
        2050, 1970, 3644, 1599])
Epoch: 1454, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1455 - Batch 1 ########################
IDs in batch 1: tensor([  71, 2024, 3479, 2568,  147,  888, 3429,   82,  891,  670, 2009, 1344,
        4254,  956, 3668, 1613])
Epoch: 1455, Training Loss: 0.21, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1456 - Batch 1 ########################
IDs in batch 1: tensor([3673, 4215, 2231, 4205, 2235,  718, 3905, 1957, 3713, 1463,   10, 2447,
        2587, 3812,  924, 2414])
Epoch: 1456, Training Loss: 0.30, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1457 - Batch 1 ########################
IDs in batch 1: tensor([1083,  735, 3084,  263, 1476, 1866, 3856, 3917, 1512, 3439, 2195, 2866,
        1118, 2500,   60, 3146])
Epoch: 1457, Training Loss: 0.18, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1458 - Batch 1 ########################
IDs in batch 1: tensor([2146, 2003,  470,  827, 3558, 2719, 2332, 4249, 3406, 3428, 3832, 1113,
        3907,  308, 3118, 1569])
Epoch: 1458, Training Loss: 0.10, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1459 - Batch 1 ########################
IDs in batch 1: tensor([1901, 1480, 2225, 2945,  962, 3082,  368,  895, 3437,  908,   22, 1352,
        1255, 3000, 2919, 3643])
Epoch: 1459, Training Loss: 0.24, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1460 - Batch 1 ########################
IDs in batch 1: tensor([3632, 1455, 3870,  425, 1102, 2235, 2242, 2890, 3740,  640, 2323,  930,
        3830,  849, 3939, 1277])
Epoch: 1460, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1461 - Batch 1 ########################
IDs in batch 1: tensor([3529, 3526, 3469, 3298,    5, 1034, 1804, 2272, 1270, 1755,  522, 3037,
        1977, 2212, 1602,  450])
Epoch: 1461, Training Loss: 0.08, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1462 - Batch 1 ########################
IDs in batch 1: tensor([1008, 1144,  165, 3387,  442, 1949, 3711, 3777, 3713, 2810, 1076, 2885,
        1256, 2871,  644, 3492])
Epoch: 1462, Training Loss: 0.22, Validation Loss: 0.55, accuracy = 0.79
######################## Epoch 1463 - Batch 1 ########################
IDs in batch 1: tensor([3147, 1163, 2809, 1552, 2280,  757, 1279, 2748, 2349, 1698, 2094, 3020,
        3239, 2912, 2754, 3481])
Epoch: 1463, Training Loss: 0.19, Validation Loss: 0.55, accuracy = 0.79
######################## Epoch 1464 - Batch 1 ########################
IDs in batch 1: tensor([4163, 2106, 3372, 3755, 2229, 2414,   62, 3039, 2400, 2761, 3135, 1501,
        1836, 1232,  190, 1229])
Epoch: 1464, Training Loss: 0.09, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1465 - Batch 1 ########################
IDs in batch 1: tensor([3131,  642, 2761, 2156, 3349, 2157, 2925, 1010,  343, 2581,   68, 2993,
        1081, 3677, 2278, 2983])
Epoch: 1465, Training Loss: 0.07, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1466 - Batch 1 ########################
IDs in batch 1: tensor([3604, 1180, 2562, 2372, 2378, 1218, 4078, 3779, 2204, 1444, 3908, 2700,
        4061, 3822, 2296, 1458])
Epoch: 1466, Training Loss: 0.14, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1467 - Batch 1 ########################
IDs in batch 1: tensor([1031, 4190,  330, 2526, 3637,   73, 1161, 1305, 1612, 1493, 1454, 3199,
         583, 1880,  965, 2579])
Epoch: 1467, Training Loss: 0.21, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1468 - Batch 1 ########################
IDs in batch 1: tensor([1760, 2387, 1159, 3507,  430, 1708, 1363,  595, 2331, 2970,  640, 3006,
         639, 1166, 1942, 1364])
Epoch: 1468, Training Loss: 0.29, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1469 - Batch 1 ########################
IDs in batch 1: tensor([  18, 3040, 2003, 1233, 2080, 2960, 2680, 3975,  788, 2295, 2420, 1439,
        2446,  524, 1857, 2857])
Epoch: 1469, Training Loss: 0.10, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1470 - Batch 1 ########################
IDs in batch 1: tensor([ 949, 3102, 4073, 2810, 4199, 1302, 3672, 2034, 1530, 4222,  220, 2990,
        3845, 3587,  454, 4065])
Epoch: 1470, Training Loss: 0.11, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1471 - Batch 1 ########################
IDs in batch 1: tensor([ 333, 1950, 3270, 1947, 2209, 3702,  670, 1190, 4110, 3184, 2261, 1635,
        2090,  792, 2793, 4246])
Epoch: 1471, Training Loss: 0.34, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1472 - Batch 1 ########################
IDs in batch 1: tensor([3554, 3719,  942, 3428, 2653, 1409, 2435, 3451, 2737,  569,  985, 3650,
        3879, 1487, 2387, 3949])
Epoch: 1472, Training Loss: 0.15, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1473 - Batch 1 ########################
IDs in batch 1: tensor([1951, 3793,  809, 1452, 2052,  229,  408, 2614, 3994, 3845, 4149, 3753,
        2468, 4039, 1043,  321])
Epoch: 1473, Training Loss: 0.13, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1474 - Batch 1 ########################
IDs in batch 1: tensor([3268,  505,  864, 1080,  526, 1270, 2706, 2272,  376, 3780,  687, 2229,
         658, 2506,  605,  377])
Epoch: 1474, Training Loss: 0.21, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1475 - Batch 1 ########################
IDs in batch 1: tensor([2099,  819,  755,  302, 2559, 4141, 2603, 3190, 2977, 2524, 3256, 1096,
        2205, 2973, 1032, 3395])
Epoch: 1475, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1476 - Batch 1 ########################
IDs in batch 1: tensor([ 785, 2097, 2155,  278, 2956, 1266,  811,  578,  258,  100,  450, 2874,
          78, 3321, 3563, 3390])
Epoch: 1476, Training Loss: 0.10, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1477 - Batch 1 ########################
IDs in batch 1: tensor([ 886, 2578, 3984, 3879, 1478, 1340, 3371, 2809, 1143,  776, 3729,  127,
        3463, 3812, 3200,  362])
Epoch: 1477, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1478 - Batch 1 ########################
IDs in batch 1: tensor([3660, 2548, 1765, 3827,  323, 4227, 3590, 2731, 1970, 2369,  497, 1530,
        2124, 2645, 3904, 3640])
Epoch: 1478, Training Loss: 0.17, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1479 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 1260, 2286, 3617,  974, 1365, 4254, 1909, 3337, 4036,  769, 1125,
        3417, 3627,  821,  913])
Epoch: 1479, Training Loss: 0.48, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1480 - Batch 1 ########################
IDs in batch 1: tensor([ 182,  871, 2999, 1408, 3535, 4003, 3883, 3339, 1634, 3228, 3384, 1981,
        3252,  843, 2517,  982])
Epoch: 1480, Training Loss: 0.05, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1481 - Batch 1 ########################
IDs in batch 1: tensor([1428,  613, 1167, 1251, 1070, 2718, 3055,  850,  881, 1635, 1504,  516,
        1507,  896,  950, 1063])
Epoch: 1481, Training Loss: 1.13, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1482 - Batch 1 ########################
IDs in batch 1: tensor([3529,  775,  747,  586, 4180,  400, 2050, 2226,  159, 1377, 3881, 4226,
         786, 1655, 2739, 1271])
Epoch: 1482, Training Loss: 0.18, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1483 - Batch 1 ########################
IDs in batch 1: tensor([ 854,   92,  841,  807, 1034, 4096, 3608,  812, 2360, 2157, 2746, 3746,
        3727, 4249, 2371, 1635])
Epoch: 1483, Training Loss: 0.29, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1484 - Batch 1 ########################
IDs in batch 1: tensor([ 971, 2476, 2405,  820, 1305, 1559, 1620, 3552,  880, 2087,  712, 3831,
        1504, 4003, 1345,  127])
Epoch: 1484, Training Loss: 0.23, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1485 - Batch 1 ########################
IDs in batch 1: tensor([3284, 1772, 3885, 2589,  538,  136, 4229, 2499, 3385, 3803,  837, 1236,
         839,  129,  843,  184])
Epoch: 1485, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1486 - Batch 1 ########################
IDs in batch 1: tensor([ 691, 3718, 3495, 2999, 1579, 3278,  947,   30, 2919, 3060,  796, 2363,
        2159, 1642, 1575, 3597])
Epoch: 1486, Training Loss: 0.04, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1487 - Batch 1 ########################
IDs in batch 1: tensor([2879, 3816,  820, 2833,  104, 3845,  875, 1857, 1974, 2494, 2358, 1482,
        2734, 1712, 3312, 3127])
Epoch: 1487, Training Loss: 0.19, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1488 - Batch 1 ########################
IDs in batch 1: tensor([2109, 3489, 1226, 3300, 3343, 3933,  777, 3238, 1061, 2819, 1061, 2183,
        3150, 2817, 1198, 3308])
Epoch: 1488, Training Loss: 0.45, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1489 - Batch 1 ########################
IDs in batch 1: tensor([ 345, 1200,  424, 4226, 1641, 3973,  612,  982, 4099, 3763, 2857,   70,
        2791,   72, 2907, 3181])
Epoch: 1489, Training Loss: 0.09, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1490 - Batch 1 ########################
IDs in batch 1: tensor([1204, 3614, 1292,   28, 2653,  512, 3590,  327, 3628, 1644, 2446, 1177,
        4048, 3218, 1920, 3816])
Epoch: 1490, Training Loss: 0.19, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1491 - Batch 1 ########################
IDs in batch 1: tensor([2666, 1225, 2400, 2234, 3400, 3790, 3437,  326,  953, 2894, 1443, 2441,
        3769, 3092, 2304,  448])
Epoch: 1491, Training Loss: 0.05, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1492 - Batch 1 ########################
IDs in batch 1: tensor([ 672, 1264, 1162,  405, 2118, 4056,  554, 1086,  606, 2107, 3962, 2700,
        1626, 2451, 1266, 3648])
Epoch: 1492, Training Loss: 0.22, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1493 - Batch 1 ########################
IDs in batch 1: tensor([1119,  918, 4255, 2614, 1563,   30,  465, 2695,  694, 4158, 2469, 1745,
        3701, 2436, 1962, 2261])
Epoch: 1493, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1494 - Batch 1 ########################
IDs in batch 1: tensor([  26, 3003, 4032, 2022, 4024, 3308, 3176, 2751, 1070, 1537, 3790, 3375,
         660, 2853, 2459,  159])
Epoch: 1494, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1495 - Batch 1 ########################
IDs in batch 1: tensor([3147, 2367, 2599, 1346, 3471, 4175, 2014, 3326, 3852, 1439, 2511,  617,
         738,  646,  604, 2179])
Epoch: 1495, Training Loss: 0.15, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1496 - Batch 1 ########################
IDs in batch 1: tensor([ 729,  978, 3664, 3330,  360, 1121,  920, 3407,  164, 3656, 3858, 3157,
        2736, 2959, 2416, 3379])
Epoch: 1496, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1497 - Batch 1 ########################
IDs in batch 1: tensor([1548, 3371, 1732,  886,  219,   14, 1578,  933, 2005, 1379, 1566, 2858,
         822, 1326, 3452, 3458])
Epoch: 1497, Training Loss: 0.33, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1498 - Batch 1 ########################
IDs in batch 1: tensor([3452, 3279, 3940, 2926, 2578,  340, 3544, 2552, 3314, 2116, 1934, 3472,
        3211, 2014,  733, 3668])
Epoch: 1498, Training Loss: 0.41, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1499 - Batch 1 ########################
IDs in batch 1: tensor([1222,  752,   96, 2141,  477,  832, 1062, 2352, 2905, 3942, 2414, 1733,
          32,   11, 1372, 2680])
Epoch: 1499, Training Loss: 0.50, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1500 - Batch 1 ########################
IDs in batch 1: tensor([3765, 3905, 3474, 2320,  472,   63,  876, 3397, 2860, 1526, 2583, 3940,
        2643, 2461, 1990,  375])
Epoch: 1500, Training Loss: 0.19, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1501 - Batch 1 ########################
IDs in batch 1: tensor([3962, 1389,  167, 2631,  342, 1569, 2518, 3507, 2859, 3630, 3139, 2839,
        1088, 1057, 1784,  130])
Epoch: 1501, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1502 - Batch 1 ########################
IDs in batch 1: tensor([ 183,  976, 1442, 3539, 3640, 1356, 2262, 3672,  266, 2217,  445, 4242,
        1804,  955, 1914, 2640])
Epoch: 1502, Training Loss: 0.09, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1503 - Batch 1 ########################
IDs in batch 1: tensor([ 586, 1935, 2170, 1233,  815,  251,  957, 1159, 3818, 1488, 4031, 3569,
        2348,  531, 3531, 1352])
Epoch: 1503, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1504 - Batch 1 ########################
IDs in batch 1: tensor([2204, 3654, 2840, 2281, 1080,  465, 4107, 3142, 1467,  876, 3826, 3005,
          43, 1977, 3362, 1376])
Epoch: 1504, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1505 - Batch 1 ########################
IDs in batch 1: tensor([ 870, 1176, 2660, 1859, 3236, 1308, 1481, 3440, 1121, 3994, 2751, 2018,
         864, 2244, 3009,  773])
Epoch: 1505, Training Loss: 0.19, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1506 - Batch 1 ########################
IDs in batch 1: tensor([2517, 3956,   32, 1075,  143, 2890, 3270,  518, 2469, 3192,  130,  956,
         344, 1686, 3526, 1885])
Epoch: 1506, Training Loss: 0.26, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1507 - Batch 1 ########################
IDs in batch 1: tensor([3207,  225, 4016, 4225, 1274, 3176, 3313, 1328, 3895, 1077, 2882, 3912,
        3314, 2827, 2483,  513])
Epoch: 1507, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1508 - Batch 1 ########################
IDs in batch 1: tensor([3873,  811, 1585, 3360, 4135, 1057, 1069, 3154, 2002, 4073, 1065, 1832,
         573, 1442, 4255, 3636])
Epoch: 1508, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1509 - Batch 1 ########################
IDs in batch 1: tensor([4101, 1260, 2258,  961, 2085,  839, 4172, 2121, 3488, 1291,  376, 3913,
        1583, 3628, 3913, 1958])
Epoch: 1509, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1510 - Batch 1 ########################
IDs in batch 1: tensor([ 369, 2517, 3675, 3807, 2956, 3051, 1506,  487, 1264,  546,  812,  196,
         430,  334, 1643, 1775])
Epoch: 1510, Training Loss: 0.34, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1511 - Batch 1 ########################
IDs in batch 1: tensor([3178, 2085, 1955, 2254, 2649, 2453, 2299, 4261,  919, 1193, 4018, 1645,
        1877, 3663, 3397, 3831])
Epoch: 1511, Training Loss: 0.22, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1512 - Batch 1 ########################
IDs in batch 1: tensor([3268, 1891, 3161, 2598, 1643, 2506, 2080, 2609, 2605,  138, 2276, 2645,
        4117, 4017,   41, 1332])
Epoch: 1512, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1513 - Batch 1 ########################
IDs in batch 1: tensor([2352,  218, 3218,  625, 3446,  714, 2446, 1877, 3362,  796, 4107, 1842,
          42, 2927, 4133,  202])
Epoch: 1513, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1514 - Batch 1 ########################
IDs in batch 1: tensor([1611, 1778, 2494, 2040, 2764,  673, 1962,  757, 1546, 3022, 2420,  190,
         470, 2746,  196, 3928])
Epoch: 1514, Training Loss: 0.10, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1515 - Batch 1 ########################
IDs in batch 1: tensor([3523, 2366, 1467, 2548,  844, 3777, 3236, 2304, 1467, 3709, 1450, 2847,
         682, 3988, 4018, 2416])
Epoch: 1515, Training Loss: 0.26, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1516 - Batch 1 ########################
IDs in batch 1: tensor([ 430, 1439, 1116, 3489, 1951, 3410, 1663,   85, 1154, 1360, 1325, 3444,
        1045, 3109, 1681, 3088])
Epoch: 1516, Training Loss: 0.19, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1517 - Batch 1 ########################
IDs in batch 1: tensor([1808,  908, 2347, 1734, 3180, 3121,  467, 3091, 1295, 2577, 4016, 2895,
        3975, 2926, 2758, 2123])
Epoch: 1517, Training Loss: 0.26, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1518 - Batch 1 ########################
IDs in batch 1: tensor([ 684, 3015, 2541, 4135, 2676, 2407,  928, 3732, 2748,  786, 4179, 1931,
        2798,   20,  363,  477])
Epoch: 1518, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1519 - Batch 1 ########################
IDs in batch 1: tensor([4121, 1532, 1450, 4159, 2329, 4199,  194,  886, 4254, 3991, 1672,  533,
        3211, 3439, 1076, 2605])
Epoch: 1519, Training Loss: 0.05, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1520 - Batch 1 ########################
IDs in batch 1: tensor([1104, 3532, 1119, 3989, 1722, 1065, 4050, 2621, 1198, 2383, 3739, 1886,
        2544, 3409,  380, 2113])
Epoch: 1520, Training Loss: 0.13, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1521 - Batch 1 ########################
IDs in batch 1: tensor([ 878,  143, 3746, 2341, 4057, 3789, 2592,   13,   46, 2022, 3436, 1777,
        3762, 2072, 1312,  550])
Epoch: 1521, Training Loss: 0.05, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1522 - Batch 1 ########################
IDs in batch 1: tensor([ 988, 2640, 2659, 3953, 4030,  617, 2995, 1485, 3972, 1122, 4068, 2314,
        2787, 2805, 3418,  201])
Epoch: 1522, Training Loss: 0.06, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1523 - Batch 1 ########################
IDs in batch 1: tensor([1316, 1858, 1255, 3949, 3644, 1072, 1537, 2442, 1274, 3436, 2859,  134,
        4218, 1223, 1179,  758])
Epoch: 1523, Training Loss: 0.13, Validation Loss: 0.55, accuracy = 0.76
######################## Epoch 1524 - Batch 1 ########################
IDs in batch 1: tensor([2219, 3588,  936, 4057, 1355,   27, 4234,  128,  317,  717, 2963,   21,
        3310,  833, 1081, 1069])
Epoch: 1524, Training Loss: 0.24, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1525 - Batch 1 ########################
IDs in batch 1: tensor([4108, 2179,  741, 3016, 1388, 2379, 3495, 4025, 1305,  653, 1335, 3349,
        3958,  489, 1415, 4050])
Epoch: 1525, Training Loss: 0.05, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1526 - Batch 1 ########################
IDs in batch 1: tensor([1600,   71, 1387, 2482, 1473, 2770, 1850, 2793, 2264, 1116, 1331, 1597,
         805, 2730, 2723,  894])
Epoch: 1526, Training Loss: 0.21, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1527 - Batch 1 ########################
IDs in batch 1: tensor([2666, 3222, 1110, 2223,  804, 4131, 3859, 1077,  223, 3865, 1226, 1377,
        1832, 2322, 3042, 2653])
Epoch: 1527, Training Loss: 0.11, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1528 - Batch 1 ########################
IDs in batch 1: tensor([2959,  872, 4161,  274, 2281, 4077,  492, 1239, 1015, 3417, 2131,  200,
        1022, 3360,  682, 2120])
Epoch: 1528, Training Loss: 0.18, Validation Loss: 0.54, accuracy = 0.77
######################## Epoch 1529 - Batch 1 ########################
IDs in batch 1: tensor([ 419,  200, 3718, 1443, 3115, 3652, 2035, 2112, 3749, 2192, 1685, 2405,
         326, 3963, 3728, 3421])
Epoch: 1529, Training Loss: 0.16, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1530 - Batch 1 ########################
IDs in batch 1: tensor([1489, 3162, 1482, 3711, 3648, 3384, 1511, 2578,  626, 1182, 1356, 3524,
        3079,  900, 1244, 3496])
Epoch: 1530, Training Loss: 0.19, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1531 - Batch 1 ########################
IDs in batch 1: tensor([3221, 3055,  790, 4223,  665, 1237, 1090, 2218,  250, 1356,  459, 3528,
        1257, 3637,  250, 2009])
Epoch: 1531, Training Loss: 0.07, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1532 - Batch 1 ########################
IDs in batch 1: tensor([2296,  327,  363, 2207, 1062, 3634, 2144,   35, 1343, 1176, 1599, 3006,
        3553,  833, 1812,   32])
Epoch: 1532, Training Loss: 0.11, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1533 - Batch 1 ########################
IDs in batch 1: tensor([2453,  730, 1138, 3553, 3885, 3221, 3366, 1784,  804,  424, 2700, 3845,
         942, 2773, 1540, 1286])
Epoch: 1533, Training Loss: 0.12, Validation Loss: 0.54, accuracy = 0.79
######################## Epoch 1534 - Batch 1 ########################
IDs in batch 1: tensor([1379, 1592, 3804,  770, 3217, 2301, 2440, 2094, 1285,  982, 3548, 2326,
        4195, 1948,  226, 3105])
Epoch: 1534, Training Loss: 0.05, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1535 - Batch 1 ########################
IDs in batch 1: tensor([ 961, 3058, 1724,  187,  544, 2986, 1167,  787, 2761, 3888, 1252,  574,
        1153, 1601, 1798, 4124])
Epoch: 1535, Training Loss: 0.37, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1536 - Batch 1 ########################
IDs in batch 1: tensor([4008, 1795, 1635,  582, 2964, 3845, 3713, 2462, 3821, 2791, 2670,  751,
        2391, 2869, 3188, 4093])
Epoch: 1536, Training Loss: 0.28, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1537 - Batch 1 ########################
IDs in batch 1: tensor([3268,  604, 1034, 2758, 2993,  605, 4049, 1179, 2980, 3261, 2727,  977,
        2360, 1834, 2356,  735])
Epoch: 1537, Training Loss: 0.06, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1538 - Batch 1 ########################
IDs in batch 1: tensor([3084,  530,  622, 1602, 1085, 1920,  224, 3945,  635, 3360, 1498,  613,
          11,  425, 1641, 1959])
Epoch: 1538, Training Loss: 0.34, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1539 - Batch 1 ########################
IDs in batch 1: tensor([3551,  926, 2329, 2822, 2237, 1751, 2943, 1803, 3245, 1481, 1032,  494,
         503, 1476, 4037,  485])
Epoch: 1539, Training Loss: 0.22, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1540 - Batch 1 ########################
IDs in batch 1: tensor([ 558,  826, 3015, 2180, 2738,   13, 2645, 3928, 3127, 4010,   98, 3157,
         442, 2858, 1804, 4168])
Epoch: 1540, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1541 - Batch 1 ########################
IDs in batch 1: tensor([1566, 2540, 2550, 3279,  795, 2748, 3275, 1627, 1239,   99, 1620, 2063,
        3542, 2066, 1506, 1294])
Epoch: 1541, Training Loss: 0.07, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1542 - Batch 1 ########################
IDs in batch 1: tensor([2855,   35,  391, 3501, 2606, 3549, 3376, 3430, 3557, 2209, 3999, 3647,
        2253,  427,  136, 3585])
Epoch: 1542, Training Loss: 0.56, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1543 - Batch 1 ########################
IDs in batch 1: tensor([3852, 4126, 2794, 4015,  623,  494, 3609,  419, 3398,   82, 3366, 3837,
         792, 2591, 1367,  630])
Epoch: 1543, Training Loss: 0.04, Validation Loss: 0.55, accuracy = 0.77
######################## Epoch 1544 - Batch 1 ########################
IDs in batch 1: tensor([1766, 1786, 2599, 3672, 2051,  732, 1083, 1248, 2122,  259,  990,  526,
        3339, 1588, 2737,  262])
Epoch: 1544, Training Loss: 0.16, Validation Loss: 0.54, accuracy = 0.78
######################## Epoch 1545 - Batch 1 ########################
IDs in batch 1: tensor([3526, 2141, 3180, 2405, 3569, 2141, 1825, 3896, 1317,  957,  534, 2989,
        2349, 3939, 2088, 3688])
Epoch: 1545, Training Loss: 0.38, Validation Loss: 0.55, accuracy = 0.78
######################## Epoch 1546 - Batch 1 ########################
IDs in batch 1: tensor([3536, 3527, 2541, 3905, 1053, 3696, 1292, 3823, 3030, 1155, 4238,  770,
        2331, 4076, 2015, 2924])
Epoch: 1546, Training Loss: 0.36, Validation Loss: 0.57, accuracy = 0.76
######################## Epoch 1547 - Batch 1 ########################
IDs in batch 1: tensor([4119, 1133,  326, 1942, 2039, 1899, 1501, 2313, 1031, 2274, 2883, 3837,
         680,  413,  321, 3697])
Epoch: 1547, Training Loss: 0.09, Validation Loss: 0.56, accuracy = 0.76
######################## Epoch 1548 - Batch 1 ########################
IDs in batch 1: tensor([3142,  375, 3609, 1197,  373, 2364, 2261, 1878,   63, 2494, 1365, 3492,
        1072, 2232, 1124, 2970])
Epoch: 1548, Training Loss: 0.17, Validation Loss: 0.56, accuracy = 0.77
######################## Epoch 1549 - Batch 1 ########################
IDs in batch 1: tensor([3792, 4265, 4227, 1975, 3387,  930,  569, 3732,  322, 1731, 1035, 2558,
        2895, 3483, 3028, 1007])
Epoch: 1549, Training Loss: 0.16, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1550 - Batch 1 ########################
IDs in batch 1: tensor([4175, 1999, 1125, 2837, 1870, 3071, 4194, 1470, 2275, 3812,  869,  430,
         501, 4173, 1824, 2970])
Epoch: 1550, Training Loss: 0.11, Validation Loss: 0.58, accuracy = 0.75
######################## Epoch 1551 - Batch 1 ########################
IDs in batch 1: tensor([1084, 3926, 3083, 4039, 1236, 2693, 2584, 3939,  896, 4158, 4166, 2520,
        2309,  150, 3500,   47])
Epoch: 1551, Training Loss: 0.06, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1552 - Batch 1 ########################
IDs in batch 1: tensor([3536,  976, 1332,  287, 2586, 3148, 1511,  994,  382, 2067, 4044,  360,
        3058, 3532,  471,  926])
Epoch: 1552, Training Loss: 0.09, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1553 - Batch 1 ########################
IDs in batch 1: tensor([3783, 2475,   20, 3256, 2358, 3533, 3617, 3079, 3746, 1571, 2408,  767,
        2751, 2072, 3506, 2459])
Epoch: 1553, Training Loss: 0.19, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1554 - Batch 1 ########################
IDs in batch 1: tensor([2950, 4056, 2968, 3563, 2632,  280, 1723,  816, 1784, 4055, 3150, 3111,
        2751, 4089, 2437,  992])
Epoch: 1554, Training Loss: 0.15, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1555 - Batch 1 ########################
IDs in batch 1: tensor([1308, 2256,  359,  631,  111,  729,  110, 2690, 4131,  876,  710, 2867,
        3430,  652, 1278, 2220])
Epoch: 1555, Training Loss: 0.18, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1556 - Batch 1 ########################
IDs in batch 1: tensor([3003, 2641, 2643,  566, 3548,  520, 2721,  954, 2584, 1471, 2065, 1484,
         709, 1568, 3507, 1677])
Epoch: 1556, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1557 - Batch 1 ########################
IDs in batch 1: tensor([1134, 3969, 1361, 2004,  180, 1795, 3399,  512, 3018, 2724, 1882, 2854,
         596, 1600, 1568,  342])
Epoch: 1557, Training Loss: 0.16, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1558 - Batch 1 ########################
IDs in batch 1: tensor([ 289, 1084,  257, 1589,  656, 1599, 3398,  661, 2426, 2659, 4086,  295,
        3372, 4227, 2949, 3543])
Epoch: 1558, Training Loss: 0.14, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1559 - Batch 1 ########################
IDs in batch 1: tensor([ 535,  193,   21,   32, 1092, 2517, 3897, 2357, 3342, 1283, 2746,  109,
        1885, 4135,  501, 2031])
Epoch: 1559, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1560 - Batch 1 ########################
IDs in batch 1: tensor([3060, 2868, 3395, 4154, 3083, 2652, 2292, 1346,  933, 3713,   46, 1780,
        3544, 1590, 2880, 2060])
Epoch: 1560, Training Loss: 0.18, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1561 - Batch 1 ########################
IDs in batch 1: tensor([4121, 1343, 3621, 3333, 1310,  593,  626, 2482, 2835, 4159, 3252, 1726,
        3355, 2452,  884,  343])
Epoch: 1561, Training Loss: 0.09, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1562 - Batch 1 ########################
IDs in batch 1: tensor([3168, 1638, 3472,  970, 3154, 2863,  343, 3303, 2826, 2161, 3871, 3144,
        3368, 1119,  533,  418])
Epoch: 1562, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1563 - Batch 1 ########################
IDs in batch 1: tensor([2562, 3060, 3610, 2025, 2260,  170,  121, 4008, 1367,  327, 1244, 3698,
        3366, 4213,  352, 1977])
Epoch: 1563, Training Loss: 0.25, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1564 - Batch 1 ########################
IDs in batch 1: tensor([1123, 3987, 2254,  522, 3878,  318, 1573, 2567,  130, 3727, 3259, 1532,
        3351,  303,  130, 2372])
Epoch: 1564, Training Loss: 0.36, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1565 - Batch 1 ########################
IDs in batch 1: tensor([ 526, 2060,  967,  651, 3948,  440, 4009, 3193, 3570, 1415, 1712, 2927,
        4003, 2721, 2183,  109])
Epoch: 1565, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1566 - Batch 1 ########################
IDs in batch 1: tensor([1519, 1171, 1786,  996, 4184, 3676, 1976, 3283, 2226, 2081, 4240, 2999,
         489, 1223, 1553, 2271])
Epoch: 1566, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1567 - Batch 1 ########################
IDs in batch 1: tensor([2442,   46, 2198,  934, 1546,  368, 2075,  662,  952,  220, 1706, 1842,
        1028, 4026, 1448,  830])
Epoch: 1567, Training Loss: 0.72, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1568 - Batch 1 ########################
IDs in batch 1: tensor([1220, 3912, 1761, 2558, 4044,  469, 1883, 3778, 2840, 4235,  944, 3651,
        2262, 3624, 1182, 1066])
Epoch: 1568, Training Loss: 0.09, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1569 - Batch 1 ########################
IDs in batch 1: tensor([2172, 3363, 2787, 3035, 1973, 2359, 2217, 4099,  644, 3554, 1625,  900,
        3028, 4227, 1824, 1295])
Epoch: 1569, Training Loss: 0.18, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1570 - Batch 1 ########################
IDs in batch 1: tensor([3513, 2357, 1686,  300, 1296, 1846, 3726, 2039, 3719, 2815,  418, 2810,
         104, 1459,  866,  397])
Epoch: 1570, Training Loss: 0.11, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1571 - Batch 1 ########################
IDs in batch 1: tensor([3282, 2399, 1274,  946, 4174, 2872, 2589, 2476, 3729, 3437, 2112, 3221,
         915,  194, 2213, 1351])
Epoch: 1571, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1572 - Batch 1 ########################
IDs in batch 1: tensor([1373, 3471, 1502, 3587, 3589,  532, 3509, 4099, 2660, 1702, 2505, 3180,
        1275, 3336, 3289, 2942])
Epoch: 1572, Training Loss: 0.06, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1573 - Batch 1 ########################
IDs in batch 1: tensor([2059, 1597,   73, 1183,  303, 3261, 1901, 3497,   28, 1878,   51, 3886,
        2787, 1490, 3985,  672])
Epoch: 1573, Training Loss: 0.08, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1574 - Batch 1 ########################
IDs in batch 1: tensor([3241, 2586, 1425,  318, 2802, 1257, 3490, 2173, 1257, 1794, 1840, 4230,
        3712, 2004,  263, 2749])
Epoch: 1574, Training Loss: 0.10, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1575 - Batch 1 ########################
IDs in batch 1: tensor([1895, 1443, 3749,  413, 3404,  881, 1842, 3567, 3850, 3970,  355, 3390,
         491, 4108,  219, 3961])
Epoch: 1575, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1576 - Batch 1 ########################
IDs in batch 1: tensor([3370, 2643, 1212, 2942, 1334, 2670,  377,  523, 2701, 2181,  826, 3914,
        1487, 1360, 4175, 3108])
Epoch: 1576, Training Loss: 0.08, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1577 - Batch 1 ########################
IDs in batch 1: tensor([1183, 1232, 2587, 1255,  139, 3804, 4038, 1457, 1024,  481, 1136, 1611,
        3544, 1601, 4173, 1755])
Epoch: 1577, Training Loss: 0.38, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1578 - Batch 1 ########################
IDs in batch 1: tensor([1525, 2366, 3144, 3650,  582, 4146, 2315, 1909,   84,  510, 3922, 1269,
        2957, 1794, 3935, 2465])
Epoch: 1578, Training Loss: 0.21, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1579 - Batch 1 ########################
IDs in batch 1: tensor([1039, 3196, 1436, 1031, 1292, 1218, 2966,  503, 2892, 1559, 2539,  149,
        1545,  358, 3111,  683])
Epoch: 1579, Training Loss: 0.37, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1580 - Batch 1 ########################
IDs in batch 1: tensor([2672, 2447,  348, 1781, 1710,  934, 2691, 1506, 2176, 2751,  393,  990,
         419, 1497, 2423, 3654])
Epoch: 1580, Training Loss: 0.33, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1581 - Batch 1 ########################
IDs in batch 1: tensor([2676, 2559, 2112, 1223, 1160, 1363, 1632,  712, 2358, 3239,  950, 2407,
        2999, 3022,  864, 3747])
Epoch: 1581, Training Loss: 0.15, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1582 - Batch 1 ########################
IDs in batch 1: tensor([  50, 2866, 3640, 2721,   72, 2567, 2373,  193, 3152, 2104,  164,  572,
        1710, 1423, 4051, 1682])
Epoch: 1582, Training Loss: 0.05, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1583 - Batch 1 ########################
IDs in batch 1: tensor([3300, 2290,  278, 4040,  205,  183, 4108, 2721, 2997, 1097, 3900,  394,
        1159, 1991, 3762, 3570])
Epoch: 1583, Training Loss: 0.11, Validation Loss: 0.58, accuracy = 0.76
######################## Epoch 1584 - Batch 1 ########################
IDs in batch 1: tensor([2739,  846, 2885, 2014, 1204, 1311, 4140, 3074, 2947, 3069,  955, 1335,
        2736, 3368, 2912, 2019])
Epoch: 1584, Training Loss: 0.11, Validation Loss: 0.59, accuracy = 0.76
######################## Epoch 1585 - Batch 1 ########################
IDs in batch 1: tensor([  27, 4053, 4000, 2858, 3375, 3964, 2965,  949,  980, 3902, 1499, 1849,
        3055, 1432, 3148, 1330])
Epoch: 1585, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1586 - Batch 1 ########################
IDs in batch 1: tensor([ 167, 3241,  805, 2342, 1884, 3553, 1518, 2943, 2751, 4107, 1408, 1957,
        3400,  131, 3243,  663])
Epoch: 1586, Training Loss: 0.11, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1587 - Batch 1 ########################
IDs in batch 1: tensor([3658, 2689,  130, 3489, 2983, 3782, 3533,   52, 1356,  337, 2157, 2954,
         159, 3456,  352, 3668])
Epoch: 1587, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1588 - Batch 1 ########################
IDs in batch 1: tensor([2954,  725,  959,  512, 2947, 1594, 3963,  743,   49, 1670, 3234, 3254,
        3006, 3404, 1166,  985])
Epoch: 1588, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.75
######################## Epoch 1589 - Batch 1 ########################
IDs in batch 1: tensor([3044, 2606, 2347, 3099, 2495, 3636,  924,  282, 3092, 2931, 3984, 3114,
        3369, 2564, 1099,  517])
Epoch: 1589, Training Loss: 0.16, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1590 - Batch 1 ########################
IDs in batch 1: tensor([1909, 1355, 1723, 1236, 3020, 2448, 1640, 3455, 2990, 2807, 2880, 2280,
        4056, 1344, 3257, 1540])
Epoch: 1590, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1591 - Batch 1 ########################
IDs in batch 1: tensor([ 662, 2620,   64, 2265, 2926, 1808,  854, 2709, 2416, 2193, 2390,   47,
        3721, 3524, 3030, 2652])
Epoch: 1591, Training Loss: 0.23, Validation Loss: 0.61, accuracy = 0.74
######################## Epoch 1592 - Batch 1 ########################
IDs in batch 1: tensor([ 904, 2254, 1834,  804,  284, 2817, 3358, 4224, 2689, 3998, 4161, 1231,
        4217, 1330, 2339, 3528])
Epoch: 1592, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.74
######################## Epoch 1593 - Batch 1 ########################
IDs in batch 1: tensor([  57,  980, 1154,  103, 1789,  131, 1143,  145,  739, 2873, 3355,  887,
        3636, 1956, 4069, 1506])
Epoch: 1593, Training Loss: 0.40, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1594 - Batch 1 ########################
IDs in batch 1: tensor([  42, 3283, 1822,  397, 1274, 3079, 3077, 1292, 1152, 1511,  980, 2091,
        3952, 2232, 3417,  306])
Epoch: 1594, Training Loss: 0.14, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1595 - Batch 1 ########################
IDs in batch 1: tensor([2749,  367, 3592,  195, 4255, 2230,  334, 4044, 3723,  523, 2065, 1678,
        1409,  324, 1162, 3489])
Epoch: 1595, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1596 - Batch 1 ########################
IDs in batch 1: tensor([1161, 2961,  498, 2761,  136, 2226, 2494, 1369,  603, 1710, 1504, 2088,
         689, 3865,  554, 3079])
Epoch: 1596, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1597 - Batch 1 ########################
IDs in batch 1: tensor([1444, 4187,  796, 1051, 1627, 4158, 2306, 3521,  656, 4176,  659,  462,
        3056, 2849, 1252, 1960])
Epoch: 1597, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1598 - Batch 1 ########################
IDs in batch 1: tensor([ 933,  152, 1027, 2224, 1438, 2148,  920, 3193, 1501, 3124,  631,  190,
        1548, 1174, 3782,  159])
Epoch: 1598, Training Loss: 0.35, Validation Loss: 0.60, accuracy = 0.74
######################## Epoch 1599 - Batch 1 ########################
IDs in batch 1: tensor([1716, 3448, 2664, 2522,  151, 1242,  689,  147, 1626, 3470, 2587, 3729,
        1963, 2494, 3287, 1249])
Epoch: 1599, Training Loss: 0.22, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1600 - Batch 1 ########################
IDs in batch 1: tensor([3920,  171, 1432,  694, 3760, 2956, 2736, 1037, 2692, 3277, 2304, 1319,
          15, 1496,  882, 2413])
Epoch: 1600, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1601 - Batch 1 ########################
IDs in batch 1: tensor([2449,  503, 1945, 1489, 1349,  444, 3674, 1153,  491, 3607, 1799, 1526,
        2449, 3636, 3634, 2440])
Epoch: 1601, Training Loss: 0.16, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1602 - Batch 1 ########################
IDs in batch 1: tensor([1320, 4096, 1189, 3688, 3727, 1562, 3399, 4251,  424,  723, 3105,  813,
        2199, 2968, 3594, 2519])
Epoch: 1602, Training Loss: 0.15, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1603 - Batch 1 ########################
IDs in batch 1: tensor([1600, 1099, 3816, 3790,  968,   59, 2121, 3069,  465, 2090, 1063,  441,
        2230,  577,  514, 3917])
Epoch: 1603, Training Loss: 0.20, Validation Loss: 0.61, accuracy = 0.75
######################## Epoch 1604 - Batch 1 ########################
IDs in batch 1: tensor([4152, 3495, 4073,  949, 2936, 3092, 3738, 2535, 3991, 1636,  206,  578,
        1472, 1417,  442, 3698])
Epoch: 1604, Training Loss: 0.26, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1605 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 2272, 3702, 1346, 1996,  574, 1911, 3251,  980, 3926, 1591, 1804,
        1511, 4008, 4036, 1665])
Epoch: 1605, Training Loss: 0.30, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1606 - Batch 1 ########################
IDs in batch 1: tensor([  57, 3843, 1443, 3948, 3465, 1306, 1410, 1186, 3441,  112, 3308, 2219,
        1208, 1313, 3389, 3010])
Epoch: 1606, Training Loss: 0.25, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1607 - Batch 1 ########################
IDs in batch 1: tensor([2789, 2591, 2610, 1434,  976,  244, 3587, 1159, 2156, 3896, 1935, 3719,
         155, 1183, 1886, 2087])
Epoch: 1607, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1608 - Batch 1 ########################
IDs in batch 1: tensor([2544,  430, 3813, 1051, 3615,  113, 1167,  683, 3029, 1285,  161,  140,
        3032, 3190, 3549, 3792])
Epoch: 1608, Training Loss: 0.26, Validation Loss: 0.57, accuracy = 0.77
######################## Epoch 1609 - Batch 1 ########################
IDs in batch 1: tensor([2026,  133,  306, 3702,  327, 2833, 1944, 2059,  265, 1093, 2897, 3146,
        2568,  957, 2795, 2499])
Epoch: 1609, Training Loss: 0.04, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1610 - Batch 1 ########################
IDs in batch 1: tensor([1796, 1962, 2645, 3154, 1103, 2953,  788, 4225, 4014, 1634,  996, 2127,
        3727, 2689, 1657, 3275])
Epoch: 1610, Training Loss: 0.23, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1611 - Batch 1 ########################
IDs in batch 1: tensor([1413, 1434, 2358,  245, 2202,  729, 1086, 3866, 2676,   72, 3452,  558,
        3467, 3932, 1772,  891])
Epoch: 1611, Training Loss: 0.13, Validation Loss: 0.56, accuracy = 0.79
######################## Epoch 1612 - Batch 1 ########################
IDs in batch 1: tensor([2064, 3608,  980,  338,  670,  921, 3208, 1372, 1686, 1144, 3336, 3220,
        2730,  547, 3489, 1944])
Epoch: 1612, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1613 - Batch 1 ########################
IDs in batch 1: tensor([1132, 3459, 1887, 1251, 1748, 2921, 1178, 3782, 1932,   51, 1656, 3829,
         128, 1954, 3499, 3252])
Epoch: 1613, Training Loss: 0.21, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1614 - Batch 1 ########################
IDs in batch 1: tensor([1772,  444,  824,   61, 1845, 1927,  440, 1786, 3963, 4032, 2440, 2195,
        1047, 3779, 1296, 2872])
Epoch: 1614, Training Loss: 0.14, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1615 - Batch 1 ########################
IDs in batch 1: tensor([3661, 3869,  408, 2132, 3115,  837, 1933, 2563,  437, 2135, 3858, 4200,
        1354,  316,  689, 2401])
Epoch: 1615, Training Loss: 0.24, Validation Loss: 0.56, accuracy = 0.78
######################## Epoch 1616 - Batch 1 ########################
IDs in batch 1: tensor([2231,  738, 4077, 3471, 2070, 1526, 3159, 2496, 3928, 2516, 1556, 2821,
        2605, 2812, 2408, 1733])
Epoch: 1616, Training Loss: 0.27, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1617 - Batch 1 ########################
IDs in batch 1: tensor([ 607, 3600, 3637, 1774, 2857, 1767,  591, 1532, 2271, 3822, 1155, 2996,
        3983, 2417, 3112, 3815])
Epoch: 1617, Training Loss: 0.10, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1618 - Batch 1 ########################
IDs in batch 1: tensor([ 797, 2863, 4245, 1111,  758,  478, 3934, 3523, 2420,  930, 1563, 2031,
        1147,  363, 1988, 1027])
Epoch: 1618, Training Loss: 0.21, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 1619 - Batch 1 ########################
IDs in batch 1: tensor([1132,   93, 2291, 1921, 2578, 2219,  330,  612, 1003, 4158, 2415, 2291,
        1884,  844, 3954, 2403])
Epoch: 1619, Training Loss: 0.08, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1620 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 3851, 3948, 2205, 4084,  615, 1432, 3239, 2354, 3985, 4068, 1762,
        3235, 1183,  872,  234])
Epoch: 1620, Training Loss: 0.26, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1621 - Batch 1 ########################
IDs in batch 1: tensor([2143, 4261, 1716, 4095, 1404, 3710, 1234, 3291, 3572, 1781, 3437, 1471,
        1147, 2934, 2298, 1540])
Epoch: 1621, Training Loss: 0.11, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1622 - Batch 1 ########################
IDs in batch 1: tensor([3765, 1752, 2248, 4134, 3408,  478, 2386, 2708, 2640, 2551, 2581, 1627,
        3863, 3715, 2050, 3833])
Epoch: 1622, Training Loss: 0.43, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1623 - Batch 1 ########################
IDs in batch 1: tensor([3588, 2734, 2807, 3521, 4024, 3265,  200, 1345, 3993, 3738, 3162, 2067,
        2212, 4078, 1733, 1470])
Epoch: 1623, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1624 - Batch 1 ########################
IDs in batch 1: tensor([1101, 2719,  134, 3598, 1490, 2393, 4099, 1450,  510, 2858,  258, 3843,
        1057, 2157, 2376, 1448])
Epoch: 1624, Training Loss: 0.25, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1625 - Batch 1 ########################
IDs in batch 1: tensor([2332, 2604,  771, 1471,  974, 2161, 1011, 2485, 3879, 3424, 3818,  344,
        2088, 2833,  573,  615])
Epoch: 1625, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1626 - Batch 1 ########################
IDs in batch 1: tensor([ 281,  287, 3504, 3886,  556, 3318, 2154, 2993,  430, 3572,  992, 3952,
        2284, 2883, 2224, 4085])
Epoch: 1626, Training Loss: 0.24, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1627 - Batch 1 ########################
IDs in batch 1: tensor([3792, 2829,   63, 2965,  930,  261, 3176, 2506,  141, 3027, 1526,  544,
        2223, 2590, 4061,  172])
Epoch: 1627, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1628 - Batch 1 ########################
IDs in batch 1: tensor([2565, 3822, 2514, 2343, 3925, 3283, 3858,  445, 1846, 3534, 1894,  732,
        2545, 4180, 1960,   27])
Epoch: 1628, Training Loss: 0.32, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1629 - Batch 1 ########################
IDs in batch 1: tensor([2825,  474, 2206, 3896, 2085,  351,  140,  352, 2260, 2968, 3883, 1171,
        3487, 2223, 1894,   11])
Epoch: 1629, Training Loss: 0.14, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1630 - Batch 1 ########################
IDs in batch 1: tensor([3897,  658, 2598, 2248, 1952, 4078, 2118, 3907, 1489,  143, 2401, 2575,
         790,  492, 2798, 4000])
Epoch: 1630, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1631 - Batch 1 ########################
IDs in batch 1: tensor([2413, 1119, 1866,  402, 2408,  879, 3630, 3286, 1795, 3927,  823, 1980,
        3707, 2581, 3526, 3490])
Epoch: 1631, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1632 - Batch 1 ########################
IDs in batch 1: tensor([2225, 3028, 3958,  450,  148,  317, 2088, 4068, 2765,  191, 2313,  835,
         130, 2687,  902, 3513])
Epoch: 1632, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1633 - Batch 1 ########################
IDs in batch 1: tensor([2733, 4013, 2015, 4072,  997,  113, 2238, 2851, 2926, 3585, 1336, 3813,
        2516, 2212,  575, 4158])
Epoch: 1633, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1634 - Batch 1 ########################
IDs in batch 1: tensor([1103, 3705, 4036, 3980, 2649,  879, 1035, 2462, 3168, 2703,  947, 2040,
        3192, 1681, 2241, 1706])
Epoch: 1634, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1635 - Batch 1 ########################
IDs in batch 1: tensor([2479,  484, 1444, 3709, 4016,  147, 3897, 3872,  102,  177, 2274,  888,
        2483, 2949,  335, 3734])
Epoch: 1635, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1636 - Batch 1 ########################
IDs in batch 1: tensor([ 636, 3783, 1625, 1405, 3984, 3357, 3568, 1953,  190, 3244, 1103, 2064,
         895, 3395, 1841,  699])
Epoch: 1636, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1637 - Batch 1 ########################
IDs in batch 1: tensor([ 369,  515,  357, 3366, 1731, 3222, 1224, 2264, 1938, 1232, 3078, 1977,
        3514, 2703,  834, 2667])
Epoch: 1637, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1638 - Batch 1 ########################
IDs in batch 1: tensor([3439,  679, 1097,  173, 3308, 3718, 1754,   61,  575, 3458, 2257,  135,
         823, 3994, 2067, 1784])
Epoch: 1638, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1639 - Batch 1 ########################
IDs in batch 1: tensor([2937, 1935, 2891, 3438,  879, 1470, 3754,  306, 2034, 3732,  152, 2109,
        3499, 3314, 4107, 3815])
Epoch: 1639, Training Loss: 0.24, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1640 - Batch 1 ########################
IDs in batch 1: tensor([2701, 3632, 2198, 3385, 3702,  139,   49, 1325, 1799, 3336, 3187, 2044,
         587,  682, 2166, 1322])
Epoch: 1640, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1641 - Batch 1 ########################
IDs in batch 1: tensor([1777,  369, 4217,  627, 1077, 3495, 3583, 1780, 3719, 2203,  752, 2976,
        2551, 1051, 3499, 2509])
Epoch: 1641, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1642 - Batch 1 ########################
IDs in batch 1: tensor([ 228, 3087,  407, 3118,   24, 3919,  656,  111, 3590, 1126, 1244,  135,
        4261, 2470, 3384,  657])
Epoch: 1642, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1643 - Batch 1 ########################
IDs in batch 1: tensor([4055, 3872, 4086, 2119, 3963, 3009,  945, 3858, 2726, 2387,  483,  661,
        1065,  838, 3995, 4003])
Epoch: 1643, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1644 - Batch 1 ########################
IDs in batch 1: tensor([1399, 2663,  263, 1229,  462, 2642, 3530, 1935, 2652, 3705, 3557, 3056,
        3669,  572, 3194, 3754])
Epoch: 1644, Training Loss: 0.25, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1645 - Batch 1 ########################
IDs in batch 1: tensor([3640, 3118, 2973,  727,  303,  870, 3226, 2701, 2672, 2300, 1613, 1070,
         874, 3362, 3900, 2309])
Epoch: 1645, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1646 - Batch 1 ########################
IDs in batch 1: tensor([3744, 2081, 4026, 3183, 4008, 4010, 2758, 2841, 2015, 1576, 3543, 2555,
        1972, 3972, 1649,  200])
Epoch: 1646, Training Loss: 0.24, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1647 - Batch 1 ########################
IDs in batch 1: tensor([1958, 3015, 1344,  591,  963, 1862, 3075, 2362, 4229, 4038, 2391, 3585,
         501, 2836, 2642,  539])
Epoch: 1647, Training Loss: 0.09, Validation Loss: 0.60, accuracy = 0.79
######################## Epoch 1648 - Batch 1 ########################
IDs in batch 1: tensor([3837,  823, 1055, 3217, 2855,  880, 1057, 2950, 2776,  511, 2441,  717,
          63, 3499,  221, 3895])
Epoch: 1648, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1649 - Batch 1 ########################
IDs in batch 1: tensor([2425, 4230, 2209,  325, 2514, 1675, 1015, 3088, 3448,  870, 1285, 2921,
        1802, 3470, 1080,  282])
Epoch: 1649, Training Loss: 0.11, Validation Loss: 0.60, accuracy = 0.79
######################## Epoch 1650 - Batch 1 ########################
IDs in batch 1: tensor([1233, 1197, 1070,  732,  587, 2030,  645, 2870, 3453, 2631,  596, 3197,
        3397, 2616, 2137, 1370])
Epoch: 1650, Training Loss: 0.20, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1651 - Batch 1 ########################
IDs in batch 1: tensor([  61, 3753, 2196, 3870, 3349, 3881,  104, 2517, 2892, 2919, 1458, 2193,
        3382, 2406, 1456, 2913])
Epoch: 1651, Training Loss: 0.17, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1652 - Batch 1 ########################
IDs in batch 1: tensor([3968,  980,  541, 3971,  971,  164, 1679, 1491, 2309, 1965, 2487,  132,
        2963, 3846, 1495, 2989])
Epoch: 1652, Training Loss: 0.38, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1653 - Batch 1 ########################
IDs in batch 1: tensor([2743, 1562, 4095, 1276, 1179,  485,  573, 1690, 4120, 2286, 1331,  880,
        1751, 1008, 1651, 3098])
Epoch: 1653, Training Loss: 0.31, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1654 - Batch 1 ########################
IDs in batch 1: tensor([1038, 1519, 1470, 1153, 1381, 3127, 3098, 3499, 2188, 1994,  295,  277,
         774, 2869, 1063, 3921])
Epoch: 1654, Training Loss: 0.21, Validation Loss: 0.59, accuracy = 0.79
######################## Epoch 1655 - Batch 1 ########################
IDs in batch 1: tensor([1157, 3323, 2978, 1070,  625, 1266, 1973, 4249, 4006, 2912, 2733, 2712,
        1175,  518, 4165, 4245])
Epoch: 1655, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.79
######################## Epoch 1656 - Batch 1 ########################
IDs in batch 1: tensor([1573, 3818, 1308,  430, 3362, 3495,  287,  170, 1022, 1313, 1001, 3282,
         185,  456, 1789, 1600])
Epoch: 1656, Training Loss: 0.47, Validation Loss: 0.57, accuracy = 0.80
Save best Model_1 @ epoch 1656 acc: 0.7971864009378663
Email sent!
######################## Epoch 1657 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 1558, 3656, 3831, 4070, 3284, 4018, 2586,  445, 2945, 3621, 2537,
        2793, 4016, 3765,  338])
Epoch: 1657, Training Loss: 0.21, Validation Loss: 0.57, accuracy = 0.79
######################## Epoch 1658 - Batch 1 ########################
IDs in batch 1: tensor([ 773, 3905,  471, 1159,  106, 3921, 1102, 2668, 1335, 2480, 3388, 3141,
        3397, 3398, 1158, 3664])
Epoch: 1658, Training Loss: 0.05, Validation Loss: 0.57, accuracy = 0.79
######################## Epoch 1659 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 1855, 3539, 4196, 3543,  829, 2133, 3440,   52, 2476,  735,  371,
           5,   22, 2230, 1818])
Epoch: 1659, Training Loss: 0.16, Validation Loss: 0.57, accuracy = 0.79
######################## Epoch 1660 - Batch 1 ########################
IDs in batch 1: tensor([1054,  679, 1132,  393, 2437, 2767,  620, 3898,  239, 1094,  401, 4238,
         778, 3476,  322, 3585])
Epoch: 1660, Training Loss: 0.41, Validation Loss: 0.57, accuracy = 0.79
######################## Epoch 1661 - Batch 1 ########################
IDs in batch 1: tensor([4017, 4136, 2357, 2375, 3408, 2978, 1626,  751,  201, 2312, 1290, 2324,
        2954,  896,  651, 3262])
Epoch: 1661, Training Loss: 0.03, Validation Loss: 0.57, accuracy = 0.78
######################## Epoch 1662 - Batch 1 ########################
IDs in batch 1: tensor([3256, 4108, 3154, 1657, 2969, 3326, 1496,  736, 2261,  483, 2473, 3806,
        3436,  217, 2899, 4120])
Epoch: 1662, Training Loss: 0.09, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1663 - Batch 1 ########################
IDs in batch 1: tensor([1346, 1740, 3656,   10, 2131, 4095, 1822, 1706,  691, 1811, 2564, 1626,
        4217, 2015, 1096, 1646])
Epoch: 1663, Training Loss: 0.18, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 1664 - Batch 1 ########################
IDs in batch 1: tensor([1206,  154, 4007, 2574, 3898, 3621, 2641,  306, 3853, 1668, 1201, 1519,
        1794,  183, 1005, 3406])
Epoch: 1664, Training Loss: 0.09, Validation Loss: 0.57, accuracy = 0.79
######################## Epoch 1665 - Batch 1 ########################
IDs in batch 1: tensor([3607, 3964, 3178, 1982, 3241,  936, 3261, 2341, 1374, 2426, 3161, 2242,
        3585, 3557, 4116, 3196])
Epoch: 1665, Training Loss: 0.56, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1666 - Batch 1 ########################
IDs in batch 1: tensor([ 323, 1956, 1147, 3091, 1640, 3159,  534, 4105,  202, 4205,  127, 2122,
        3270, 4175, 4069,  511])
Epoch: 1666, Training Loss: 0.04, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1667 - Batch 1 ########################
IDs in batch 1: tensor([ 756, 3693, 2738, 2516,  105, 3538, 3029,   95, 3707, 2334,  430, 2260,
         524, 3674, 4116, 2771])
Epoch: 1667, Training Loss: 0.26, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1668 - Batch 1 ########################
IDs in batch 1: tensor([1760,  318, 1174, 3475, 3637, 1249, 2552, 3434, 2559, 3017, 2872, 2776,
          24, 1891, 2413, 3869])
Epoch: 1668, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1669 - Batch 1 ########################
IDs in batch 1: tensor([3530, 1072, 3723,  292, 3245,  191, 2008,  890, 1097, 2060,  102, 3603,
        2885, 3553, 1386, 1321])
Epoch: 1669, Training Loss: 0.32, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1670 - Batch 1 ########################
IDs in batch 1: tensor([3221, 3671, 3505,  568, 2428, 3139, 1904, 2051, 3148, 1762, 3235, 3607,
         652, 2583, 2122, 2555])
Epoch: 1670, Training Loss: 0.21, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1671 - Batch 1 ########################
IDs in batch 1: tensor([ 538,  755,  736, 1904, 1752, 1850, 1168, 1748, 2112, 3309, 2261, 1868,
        3897,  524, 1809, 2536])
Epoch: 1671, Training Loss: 0.20, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1672 - Batch 1 ########################
IDs in batch 1: tensor([2258, 2505,  851, 4067, 1370, 3591, 2199, 1270,  928, 2123,  105, 1459,
         679, 2584,  909,  750])
Epoch: 1672, Training Loss: 0.21, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1673 - Batch 1 ########################
IDs in batch 1: tensor([1986, 1925, 2655, 2074, 3108, 1882, 3642, 4175, 3025, 1567,  714, 3900,
        2976,  787, 3035, 2403])
Epoch: 1673, Training Loss: 0.28, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1674 - Batch 1 ########################
IDs in batch 1: tensor([ 378, 1812, 3127, 2067, 3352, 1032, 3795, 4031, 3443, 4114,  871,  265,
        1752,  723,  282,  890])
Epoch: 1674, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1675 - Batch 1 ########################
IDs in batch 1: tensor([1121, 2504,  228,  553,  214, 4196,  844, 3993,  257, 1830, 2621, 1216,
        1821, 3947, 2718,  351])
Epoch: 1675, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1676 - Batch 1 ########################
IDs in batch 1: tensor([1124, 2678, 1826,  894, 2567, 3468, 3227, 2225,  424, 3663,  456, 2853,
        1911, 1343, 1651, 1710])
Epoch: 1676, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1677 - Batch 1 ########################
IDs in batch 1: tensor([3363, 1923, 1614, 1965, 3437,  828,  110,   49, 3514,  306, 1956, 2260,
        3963,  604, 3448,  665])
Epoch: 1677, Training Loss: 0.18, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1678 - Batch 1 ########################
IDs in batch 1: tensor([3558, 1224, 1337, 1023,  785, 2926, 3938,  642, 3426, 1088, 3099, 2567,
        3218, 1066,  408, 1675])
Epoch: 1678, Training Loss: 0.30, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1679 - Batch 1 ########################
IDs in batch 1: tensor([1612, 3101, 3672,  739, 1426, 1591,  820, 1069, 4197, 2280, 2558, 1794,
        2873, 3337,  334, 2656])
Epoch: 1679, Training Loss: 0.13, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1680 - Batch 1 ########################
IDs in batch 1: tensor([ 909, 2942, 4078, 2810, 1318, 3435,  814, 2455, 2420,  717, 3166, 1518,
        1639, 4057, 3110,  325])
Epoch: 1680, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1681 - Batch 1 ########################
IDs in batch 1: tensor([ 266, 3204, 2583,   35, 3429, 1562, 2989,  432, 3738, 2618, 1588,  555,
         843,  574, 2957, 1963])
Epoch: 1681, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1682 - Batch 1 ########################
IDs in batch 1: tensor([2636,  435, 4101,  778, 2229, 1679, 2742, 1299, 2754, 2229, 4198, 3031,
        2394,  841, 3432, 3504])
Epoch: 1682, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1683 - Batch 1 ########################
IDs in batch 1: tensor([3528, 2228,  494, 2926, 1718, 3009, 4204, 2190,  974, 1228, 3016, 3362,
        3650,  975,  466, 2680])
Epoch: 1683, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1684 - Batch 1 ########################
IDs in batch 1: tensor([1208, 3757, 1156,  149, 3914,  102, 2908, 1252, 4046, 1472,  400, 2385,
         617, 2242, 2828, 4255])
Epoch: 1684, Training Loss: 0.22, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1685 - Batch 1 ########################
IDs in batch 1: tensor([2771,  662, 1552, 2290,  133, 1463, 1962,  332, 2385,  516, 1003, 3731,
        3148, 4000, 2552,  234])
Epoch: 1685, Training Loss: 0.22, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1686 - Batch 1 ########################
IDs in batch 1: tensor([1232, 2484, 2775, 4197, 3648, 3082, 3636,  950, 1841, 2761, 2493, 2508,
        1065, 1627, 4212,  683])
Epoch: 1686, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1687 - Batch 1 ########################
IDs in batch 1: tensor([1104, 1470, 1568, 1098, 1811, 1472, 3852, 1222, 2108,  444, 2787, 3552,
         666, 3976, 3143, 1676])
Epoch: 1687, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1688 - Batch 1 ########################
IDs in batch 1: tensor([ 340, 1488, 4212, 3902,  995, 3197, 2334,  555, 3091, 4232,  812,  914,
         323, 2887, 2109,  462])
Epoch: 1688, Training Loss: 0.09, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1689 - Batch 1 ########################
IDs in batch 1: tensor([4013, 2661, 3911, 3304, 1625, 2618,  942,  159, 3044,   28,  909, 2133,
        3327, 3994, 4187,  909])
Epoch: 1689, Training Loss: 0.11, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1690 - Batch 1 ########################
IDs in batch 1: tensor([4100,  519, 3938,  269, 3057, 3640, 4114, 3032,  980, 3591, 3467, 1313,
        1655,  815, 2185,  971])
Epoch: 1690, Training Loss: 0.17, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1691 - Batch 1 ########################
IDs in batch 1: tensor([ 552,  913,  449, 2095,  717,  388, 2518, 1373,  183, 2256, 2523,  369,
        2440, 3485, 2584, 2146])
Epoch: 1691, Training Loss: 0.31, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1692 - Batch 1 ########################
IDs in batch 1: tensor([2770,  221, 3838, 2056,  396, 1846, 1600, 2286, 3843, 2831, 2731, 2249,
        3382, 3451, 4096, 3676])
Epoch: 1692, Training Loss: 0.20, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1693 - Batch 1 ########################
IDs in batch 1: tensor([1690, 1610, 1485, 1445, 3823, 3228,  536, 1836,  786, 2949, 3894, 4146,
        2469,  280,  110,  601])
Epoch: 1693, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1694 - Batch 1 ########################
IDs in batch 1: tensor([ 971, 2614, 2636, 2331, 1141,  842, 1775, 3150,  266, 1710, 3406, 3543,
        2111, 2116, 1233,  251])
Epoch: 1694, Training Loss: 0.14, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1695 - Batch 1 ########################
IDs in batch 1: tensor([1634, 1956, 2614, 4080, 1963,  321, 4077, 3514, 3659,   18, 3135,  757,
         712, 3956, 2247, 2667])
Epoch: 1695, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1696 - Batch 1 ########################
IDs in batch 1: tensor([3945, 1633, 2555, 1340, 3989, 1472, 1716,   52, 3717,  986, 1747, 3057,
        1958, 4220, 4141, 1639])
Epoch: 1696, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1697 - Batch 1 ########################
IDs in batch 1: tensor([3182, 3372, 4140,  572,  120, 1196,  449, 3624, 4010,  750, 3290, 2245,
        1014, 3447, 3220, 2400])
Epoch: 1697, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1698 - Batch 1 ########################
IDs in batch 1: tensor([3072,  546, 3833, 3161, 3714,  251, 2212, 1138, 3058, 1325, 2244, 2087,
         338, 3136, 1381, 1655])
Epoch: 1698, Training Loss: 0.20, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1699 - Batch 1 ########################
IDs in batch 1: tensor([1501, 3590,  269, 1617, 2542, 3123, 3444,  739, 3696,  128, 3999, 1765,
        3689, 2964,  539, 1354])
Epoch: 1699, Training Loss: 0.17, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1700 - Batch 1 ########################
IDs in batch 1: tensor([2731, 3960,  986,  625,  956, 1733, 4015, 3529, 1233, 2559, 1367,  653,
        3222, 3839, 3660,  544])
Epoch: 1700, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1701 - Batch 1 ########################
IDs in batch 1: tensor([3712, 1376, 2949, 1179, 2195, 2603,   56, 2765,  635, 1473, 2038, 2954,
        2961,   70, 2192,  194])
Epoch: 1701, Training Loss: 0.21, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1702 - Batch 1 ########################
IDs in batch 1: tensor([4070, 1770, 2835, 1971, 2390, 2371,  530, 1306,  531, 3644, 1958, 3786,
        2559,  531, 3197, 3608])
Epoch: 1702, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1703 - Batch 1 ########################
IDs in batch 1: tensor([3382, 3874, 2827, 4076, 4094, 1434, 2924, 4256, 3769, 4205,  141, 1752,
        3483, 2285,  881, 2104])
Epoch: 1703, Training Loss: 0.24, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1704 - Batch 1 ########################
IDs in batch 1: tensor([ 303,  625,  910, 2206, 1828, 3618, 2010, 2886, 4156, 3663, 2748, 4018,
        3950,  239, 1346, 3082])
Epoch: 1704, Training Loss: 0.27, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1705 - Batch 1 ########################
IDs in batch 1: tensor([2621, 2250, 2631,  796, 1088, 2479, 3490, 1242,  430,  807, 3494, 2337,
        2456, 3468,  449,  338])
Epoch: 1705, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1706 - Batch 1 ########################
IDs in batch 1: tensor([2855,   72, 2631, 3159, 4044, 1391, 3698, 3113, 1700, 2253, 1379, 1410,
        1712, 2912, 2286, 3337])
Epoch: 1706, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1707 - Batch 1 ########################
IDs in batch 1: tensor([2755, 3938, 1421, 3871, 2644,  645,  327, 1076, 2014, 3590, 4085, 1467,
        2645, 3905, 3323, 2463])
Epoch: 1707, Training Loss: 0.09, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1708 - Batch 1 ########################
IDs in batch 1: tensor([2314, 1153,   46, 2542, 2439, 3661, 2235, 2968,  656, 3300, 1134, 1162,
        1962, 3588,  195, 1213])
Epoch: 1708, Training Loss: 0.07, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1709 - Batch 1 ########################
IDs in batch 1: tensor([ 854,   88, 3075, 3731, 3372, 1347, 2775,  520, 1956,  122, 3509, 2943,
        1341, 4186, 2126,  824])
Epoch: 1709, Training Loss: 0.14, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1710 - Batch 1 ########################
IDs in batch 1: tensor([1290, 2942,  111, 3664, 2354, 3705, 4232, 1645, 1308, 1817, 1297, 3176,
         767, 3079, 1406, 3162])
Epoch: 1710, Training Loss: 0.13, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1711 - Batch 1 ########################
IDs in batch 1: tensor([3192, 2347, 2482, 2976, 2123, 3291,  131,  441, 1628,  252, 2464, 3876,
         206, 2348,  456,  369])
Epoch: 1711, Training Loss: 0.12, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1712 - Batch 1 ########################
IDs in batch 1: tensor([3202, 1663,  651,   13, 4060, 2940, 3271,  152, 3468, 3144, 2408, 3268,
        1387, 1954,  219,  450])
Epoch: 1712, Training Loss: 0.03, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1713 - Batch 1 ########################
IDs in batch 1: tensor([ 112, 1383, 1899, 2664, 3058,  224, 3261,  264, 3996, 2701, 4175,  665,
        3753, 3458,  569,  816])
Epoch: 1713, Training Loss: 0.22, Validation Loss: 0.60, accuracy = 0.79
######################## Epoch 1714 - Batch 1 ########################
IDs in batch 1: tensor([1084, 1219, 2376, 2166, 4012, 2111, 2286, 2429, 1212, 2347, 3455, 3009,
        2536, 1576, 3463, 3542])
Epoch: 1714, Training Loss: 0.18, Validation Loss: 0.60, accuracy = 0.79
######################## Epoch 1715 - Batch 1 ########################
IDs in batch 1: tensor([ 844, 1291, 2312, 3157, 2597,  217,  653, 2974,   93, 3851,  991, 1004,
        1974, 2382, 1083,    4])
Epoch: 1715, Training Loss: 0.14, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1716 - Batch 1 ########################
IDs in batch 1: tensor([ 104,  380, 1799, 2097, 1562,  623, 1559, 2234, 3098, 2831,  498, 3832,
        2780, 1830,  740,  186])
Epoch: 1716, Training Loss: 0.09, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1717 - Batch 1 ########################
IDs in batch 1: tensor([3228, 3004, 1364, 3789, 1120, 2296, 1271, 1918, 1035, 2969,  740, 2046,
          73, 4159, 3756, 1518])
Epoch: 1717, Training Loss: 0.38, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1718 - Batch 1 ########################
IDs in batch 1: tensor([1067, 1436, 3676,  387,  976,  526,  379,  452, 3208, 1732,  350, 3624,
         871, 3651, 3624,  718])
Epoch: 1718, Training Loss: 0.29, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1719 - Batch 1 ########################
IDs in batch 1: tensor([2261,  816,   47, 2510, 3399, 3032,  524, 2094, 2869, 3993, 3257,  936,
        1274, 1657, 3311, 1337])
Epoch: 1719, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 1720 - Batch 1 ########################
IDs in batch 1: tensor([4006,  656,  396, 1204, 3379, 1722,  137, 3644, 3501, 1748,  394, 3706,
        3421, 2708,  792, 1498])
Epoch: 1720, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1721 - Batch 1 ########################
IDs in batch 1: tensor([1897,  954, 3699, 3338, 3374, 1134, 2736, 2019, 2279, 2377, 2485, 1060,
        1646, 1532, 1973, 4263])
Epoch: 1721, Training Loss: 0.27, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1722 - Batch 1 ########################
IDs in batch 1: tensor([2729, 2276, 3504, 2980, 2653,  263, 2508, 1228,  981,  220, 1484, 2220,
         494, 3203,  419,  262])
Epoch: 1722, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1723 - Batch 1 ########################
IDs in batch 1: tensor([1685, 2230, 2280,  206,  194,  679, 2697,  490, 1117, 2183, 1222, 3151,
        1474, 1282, 2334, 3109])
Epoch: 1723, Training Loss: 0.21, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1724 - Batch 1 ########################
IDs in batch 1: tensor([3022, 2056, 3473, 4113, 2228,  489, 1393,  651, 3211, 1469, 3573, 2638,
        2736, 1001, 2115, 3812])
Epoch: 1724, Training Loss: 0.38, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 1725 - Batch 1 ########################
IDs in batch 1: tensor([  43, 1510, 1812,   30,  946, 2559,  338,  657, 2915, 3052, 3447, 1331,
        4222, 2428, 1022, 2450])
Epoch: 1725, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1726 - Batch 1 ########################
IDs in batch 1: tensor([1092, 1224, 4238, 1828,  488, 1092,  987,  130, 3243, 1589, 1212, 3943,
         413,  769, 2379, 3968])
Epoch: 1726, Training Loss: 0.45, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1727 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 3745, 3075, 3996, 2363, 1224,  890, 3318, 3404,  902, 2390, 3934,
        3356, 3933, 2316, 1082])
Epoch: 1727, Training Loss: 0.38, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1728 - Batch 1 ########################
IDs in batch 1: tensor([1357,  438,  466, 2858,  741, 2455, 1322, 1496,  762, 2031, 3847, 2578,
        4181, 2899, 1066, 2142])
Epoch: 1728, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1729 - Batch 1 ########################
IDs in batch 1: tensor([1011, 1789,  596, 1506, 3185, 1765, 1219, 2738,  184,   85,  814, 3953,
        3391, 3490, 3995, 3594])
Epoch: 1729, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1730 - Batch 1 ########################
IDs in batch 1: tensor([ 685, 2997, 1222, 1519, 3970,  275, 3206, 2087, 4251, 3850,  384, 3127,
        1316, 2523, 3538,  269])
Epoch: 1730, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1731 - Batch 1 ########################
IDs in batch 1: tensor([1775,  943, 1081, 2868, 2440, 3876, 1540,  891, 3952, 2185, 1731, 1690,
        3632, 2141, 2066, 3187])
Epoch: 1731, Training Loss: 0.13, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1732 - Batch 1 ########################
IDs in batch 1: tensor([3147, 1321,  657, 3461, 1600, 1556,  908,  261,  522, 3243, 1088, 3268,
        3920,  188, 2275, 2520])
Epoch: 1732, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1733 - Batch 1 ########################
IDs in batch 1: tensor([1390, 3945, 2150, 2983, 1551, 3970, 2574, 2218, 2196, 2439, 1136, 3364,
        2986, 2416, 4197,  283])
Epoch: 1733, Training Loss: 0.16, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1734 - Batch 1 ########################
IDs in batch 1: tensor([3037,  776,  713,  988, 3783, 2796, 3514,   47, 1334, 3654,  730, 2258,
        3251,  666, 2095,  351])
Epoch: 1734, Training Loss: 0.13, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1735 - Batch 1 ########################
IDs in batch 1: tensor([2511,  478, 4018, 2844,  718, 2153, 3159, 1493, 3827, 1387,  825,  302,
        2327, 4242,  667, 3338])
Epoch: 1735, Training Loss: 0.04, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1736 - Batch 1 ########################
IDs in batch 1: tensor([2014, 2449, 1177, 2435, 3777,  866, 1762, 1438, 1832, 3627, 2419, 3732,
        3783, 1014, 1124, 2065])
Epoch: 1736, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1737 - Batch 1 ########################
IDs in batch 1: tensor([2884, 4168, 2328, 1556, 3485, 4179, 1393, 3207, 1438,  874, 2723, 2344,
        2242, 1096, 1131, 3299])
Epoch: 1737, Training Loss: 0.04, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1738 - Batch 1 ########################
IDs in batch 1: tensor([1440, 2464, 1229, 1174, 2504, 3870, 1432,  133, 1022,  161,  459, 1467,
        2856, 1591, 2730, 3110])
Epoch: 1738, Training Loss: 0.25, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 1739 - Batch 1 ########################
IDs in batch 1: tensor([2391,  796, 3674, 3669, 3592,  340, 3582, 1665, 1346,  269, 2198,  322,
        1545, 3363, 1655, 2999])
Epoch: 1739, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1740 - Batch 1 ########################
IDs in batch 1: tensor([2614, 3545, 1147, 1834, 3083, 3448, 2616, 4143, 2366, 1094, 3506, 2417,
        3823, 1723, 4240, 1899])
Epoch: 1740, Training Loss: 0.36, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1741 - Batch 1 ########################
IDs in batch 1: tensor([3760,  527,   62, 3568, 2051, 2789, 1641, 1727,  425, 3540, 1419, 2600,
         709,  593, 2697, 1451])
Epoch: 1741, Training Loss: 0.14, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1742 - Batch 1 ########################
IDs in batch 1: tensor([1415, 2256,  160,  456, 2693, 1102, 1219, 1123, 1817, 2479, 4058, 1949,
        2732,  957, 1425, 4135])
Epoch: 1742, Training Loss: 0.45, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1743 - Batch 1 ########################
IDs in batch 1: tensor([3105,  869, 1042,  203,  363, 1177, 3220, 1084,  245,   18, 4038,  926,
        2123,  106,  489, 1656])
Epoch: 1743, Training Loss: 0.29, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1744 - Batch 1 ########################
IDs in batch 1: tensor([2274, 3781,  237, 2505, 3181,  704, 1775,  670,   47,  135,   10,  232,
        2472, 3444, 1041, 1760])
Epoch: 1744, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1745 - Batch 1 ########################
IDs in batch 1: tensor([3114, 1802, 1163, 3432, 3441, 4049, 2964, 2772, 1972, 1193,  674, 1641,
        3207,  195,  678,  557])
Epoch: 1745, Training Loss: 0.09, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1746 - Batch 1 ########################
IDs in batch 1: tensor([1004,  459, 1176, 3369, 3176, 1041,  684, 2583, 1110,  915, 1731,  751,
        2837,  656, 3705,  538])
Epoch: 1746, Training Loss: 0.33, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1747 - Batch 1 ########################
IDs in batch 1: tensor([3651, 3415, 1452,  676,  201, 3077, 2489, 3330, 2063, 3601, 2925, 2674,
        1894, 1569, 4006,  735])
Epoch: 1747, Training Loss: 0.18, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1748 - Batch 1 ########################
IDs in batch 1: tensor([1977, 1010, 1123, 3489,  949, 2749, 2517, 2991, 1891, 1914, 1882, 1452,
         284, 3349, 2600, 2296])
Epoch: 1748, Training Loss: 0.09, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 1749 - Batch 1 ########################
IDs in batch 1: tensor([ 942,  413, 3677, 3032, 3953,  827, 3044,  520, 3115, 1251, 4267, 2867,
        2063, 3778, 1308,  430])
Epoch: 1749, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.75
######################## Epoch 1750 - Batch 1 ########################
IDs in batch 1: tensor([2441, 2019, 2678, 1034, 2995,  437, 2124, 1842, 2262, 3384,  632,  680,
        3597, 2237, 2671,  907])
Epoch: 1750, Training Loss: 0.25, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1751 - Batch 1 ########################
IDs in batch 1: tensor([2709, 3021, 2393, 3852,  578, 1925, 1762, 1684, 1419, 3131, 2449, 3286,
         129, 1927,  474,  102])
Epoch: 1751, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1752 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 1748, 4088, 1718, 3883, 3408, 3223, 3027, 3882, 3344,  636, 2030,
        3594, 3714, 3949, 3014])
Epoch: 1752, Training Loss: 0.17, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1753 - Batch 1 ########################
IDs in batch 1: tensor([ 644, 3652,   81, 3227, 1671, 3505, 2537, 4121, 3337,  971, 3786, 2489,
         482, 1994, 4016, 1480])
Epoch: 1753, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 1754 - Batch 1 ########################
IDs in batch 1: tensor([ 955,  934, 1221,  946, 1537, 3102, 1660,  993,  941, 3875, 1206, 1575,
         733, 3438,  773, 2710])
Epoch: 1754, Training Loss: 0.43, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1755 - Batch 1 ########################
IDs in batch 1: tensor([ 762,  712, 1832, 3139, 3656, 1830, 1028, 3527, 2854, 2832, 1011,  365,
         274, 3439, 2489, 1113])
Epoch: 1755, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1756 - Batch 1 ########################
IDs in batch 1: tensor([2218, 4108, 1904, 1693, 3423, 1178, 2281,  510, 3115, 2073, 2051, 1480,
        2492, 3935,  335, 1942])
Epoch: 1756, Training Loss: 0.16, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1757 - Batch 1 ########################
IDs in batch 1: tensor([1097, 3197, 4157, 3272,  586, 2090, 2880, 1039,   52,  255, 3518, 4016,
         393, 2749, 3836, 3203])
Epoch: 1757, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1758 - Batch 1 ########################
IDs in batch 1: tensor([2631, 1576, 4089, 1491, 2688, 3797, 1464, 2959, 2365,  946,   15, 3714,
        3997, 1525, 1478, 3255])
Epoch: 1758, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1759 - Batch 1 ########################
IDs in batch 1: tensor([1270,  541, 4181,  518, 1639, 1279,  172, 3945, 1934, 1711,  628, 3713,
        1968, 1042, 1045, 3985])
Epoch: 1759, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1760 - Batch 1 ########################
IDs in batch 1: tensor([4105,  644,  122, 1576, 2159, 1277, 1916, 1945,    4, 3823, 3391, 1162,
         539, 3467, 2013, 2764])
Epoch: 1760, Training Loss: 0.22, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1761 - Batch 1 ########################
IDs in batch 1: tensor([4217,  519, 4161,  154, 2357, 4039, 2966,  968, 1613,  755, 1670, 3925,
        1241, 2799, 3317, 3279])
Epoch: 1761, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1762 - Batch 1 ########################
IDs in batch 1: tensor([2121,  797, 1178,  946, 2418, 3539,  959, 3023, 2144, 2695, 1425, 3340,
        1825, 1249,  127, 3961])
Epoch: 1762, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1763 - Batch 1 ########################
IDs in batch 1: tensor([ 826, 2758, 1545, 4036, 2567, 1972, 1136, 1784, 1774, 1035, 2732, 2087,
        2571, 3493, 2879, 4070])
Epoch: 1763, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1764 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 3816, 2022, 2375,  262, 1365, 3879, 2382,  670,  995, 4072, 4082,
        1061, 4161, 4061, 2636])
Epoch: 1764, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1765 - Batch 1 ########################
IDs in batch 1: tensor([3951, 2578,  207, 3352,  786, 1141, 2695, 2447, 2932, 3753, 3124, 4072,
        3304, 1869, 3250, 1016])
Epoch: 1765, Training Loss: 0.35, Validation Loss: 0.64, accuracy = 0.74
######################## Epoch 1766 - Batch 1 ########################
IDs in batch 1: tensor([3661, 3330, 3032, 2650, 2388, 4121, 1374, 1518, 3128,  919,  346, 1444,
         488, 3984,  119,   52])
Epoch: 1766, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1767 - Batch 1 ########################
IDs in batch 1: tensor([1947, 3272,  839, 2894, 2378, 1222,  957, 3287, 2703, 2324, 3808, 1976,
        3739, 4163, 3248, 3267])
Epoch: 1767, Training Loss: 0.46, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1768 - Batch 1 ########################
IDs in batch 1: tensor([2897, 1568, 1011, 3958, 3238, 3216, 2627, 1933, 2456, 3505, 3368, 2857,
        2470, 1137, 2439, 1753])
Epoch: 1768, Training Loss: 0.33, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1769 - Batch 1 ########################
IDs in batch 1: tensor([ 522, 2967, 1235, 3564, 1024, 4037,  897, 1866,  928, 1935, 4067, 3860,
        2217, 3369,  112, 2275])
Epoch: 1769, Training Loss: 0.32, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1770 - Batch 1 ########################
IDs in batch 1: tensor([3638, 2883, 4234,  342, 2275,  481, 2578, 1844, 1016,    7, 3202, 1991,
        3514, 3235, 3314,  135])
Epoch: 1770, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1771 - Batch 1 ########################
IDs in batch 1: tensor([2632, 3102, 2706, 1326, 1110, 3101, 2688,  699, 2337, 3354, 1107,  180,
        1944, 1823, 2258, 3704])
Epoch: 1771, Training Loss: 0.17, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1772 - Batch 1 ########################
IDs in batch 1: tensor([2867, 2659, 1832, 1186, 4095, 1267, 3911, 2648, 2539, 3434, 1355, 1521,
        1802, 1269, 2526, 2180])
Epoch: 1772, Training Loss: 0.24, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1773 - Batch 1 ########################
IDs in batch 1: tensor([2444,  117, 3438, 2829, 2413, 3372, 3388, 3837, 1512, 2908, 1090, 2153,
        1500, 4194, 1214, 1704])
Epoch: 1773, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1774 - Batch 1 ########################
IDs in batch 1: tensor([2871,  637, 2879, 3451, 2964, 3921,  503, 1360,  992, 1927, 4170, 2017,
        3387, 1201, 1754, 1219])
Epoch: 1774, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1775 - Batch 1 ########################
IDs in batch 1: tensor([3569, 1808,  218, 1588,  995, 2529, 3271, 1628, 3912, 2552,  130, 1134,
        1823, 1059, 1066,  132])
Epoch: 1775, Training Loss: 0.20, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1776 - Batch 1 ########################
IDs in batch 1: tensor([1808,  269, 1051, 1574, 3853, 3988,  217, 3434,  591, 2450, 1567,  262,
        2589, 4044, 4229,  553])
Epoch: 1776, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1777 - Batch 1 ########################
IDs in batch 1: tensor([3547,  620, 1877, 1748, 3935, 4024, 3507, 3485, 1706, 1171, 2575, 2146,
        2117,  305, 2582, 3767])
Epoch: 1777, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1778 - Batch 1 ########################
IDs in batch 1: tensor([1242,  667, 1340,  102, 1601, 3397, 4175, 3052, 1371, 3680, 1849, 2649,
        1496, 2312, 2468, 2558])
Epoch: 1778, Training Loss: 0.03, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1779 - Batch 1 ########################
IDs in batch 1: tensor([3452, 1495, 4008, 3484,  532, 3807, 2851, 3460, 1588, 1279, 3991, 4235,
        3256, 1574, 3286,  269])
Epoch: 1779, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1780 - Batch 1 ########################
IDs in batch 1: tensor([3729,    4,  305, 1623,  673, 2223, 1778, 3524, 3834, 1826,  474, 3016,
        1953,  258, 2520, 1491])
Epoch: 1780, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1781 - Batch 1 ########################
IDs in batch 1: tensor([1032, 3388,  520,  909, 1945, 4179, 1146,   39, 3196, 2591,  824, 2723,
        4181, 3535, 2964, 2499])
Epoch: 1781, Training Loss: 0.03, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 1782 - Batch 1 ########################
IDs in batch 1: tensor([1144, 1418,  789, 2997, 1948, 1425, 3141, 1819, 3935, 2106, 1260, 1355,
        3573, 1374, 2098, 3353])
Epoch: 1782, Training Loss: 0.21, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1783 - Batch 1 ########################
IDs in batch 1: tensor([1473,  872,  658, 3024, 2359, 1325, 4105, 2668,  344, 2764, 3183, 3634,
        1509, 2099, 2519, 3177])
Epoch: 1783, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1784 - Batch 1 ########################
IDs in batch 1: tensor([ 605, 2097,  774, 2601, 3570, 2124, 2719, 3418, 2776, 3282, 3463, 1810,
        3392, 2966, 1216, 3021])
Epoch: 1784, Training Loss: 0.24, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1785 - Batch 1 ########################
IDs in batch 1: tensor([1937, 2924, 1972, 3257, 2567, 2248, 1082, 4144, 2182, 2745, 3262, 1716,
        4075,  662, 4141, 3702])
Epoch: 1785, Training Loss: 0.17, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1786 - Batch 1 ########################
IDs in batch 1: tensor([2719, 2996,  758,  518, 3490, 1022, 3749, 1229, 2484,  594, 1263,  572,
        2739, 1317, 3983, 2193])
Epoch: 1786, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1787 - Batch 1 ########################
IDs in batch 1: tensor([4154, 1132,  518, 3911, 3460,  928, 2086, 2584, 4253,  825, 2772, 2277,
        2439, 2942, 1595,  679])
Epoch: 1787, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1788 - Batch 1 ########################
IDs in batch 1: tensor([ 593, 1708,  941, 2198,  774,  649, 3743, 3154, 2137, 2448, 2487, 1981,
        2863, 3236, 1731, 1840])
Epoch: 1788, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1789 - Batch 1 ########################
IDs in batch 1: tensor([ 573,  534, 1380, 2758, 1716,  375, 2337, 1699,  263, 3242, 4258, 2277,
         980, 1234,  758, 3455])
Epoch: 1789, Training Loss: 0.22, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1790 - Batch 1 ########################
IDs in batch 1: tensor([3238, 3836,  426,  412, 2466, 2353, 2484, 1844,  890, 1380,  699, 2563,
          77, 1793, 2621, 1585])
Epoch: 1790, Training Loss: 0.06, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1791 - Batch 1 ########################
IDs in batch 1: tensor([ 930, 3830, 3543, 1543, 4022, 2617, 1171,  277, 2739, 3945,  371, 2372,
        1680, 3111, 2789,  148])
Epoch: 1791, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1792 - Batch 1 ########################
IDs in batch 1: tensor([3807, 2126, 2781, 3500,  805, 1640, 3980,  991, 1644,  140, 1690, 1781,
        1463, 3016, 1731, 1611])
Epoch: 1792, Training Loss: 0.28, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1793 - Batch 1 ########################
IDs in batch 1: tensor([1556,  639, 1657, 2887, 2797, 3495, 1221, 1042, 1272, 1436, 2198, 3437,
         323, 1782,  909, 3150])
Epoch: 1793, Training Loss: 0.24, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 1794 - Batch 1 ########################
IDs in batch 1: tensor([1568, 1588, 3190, 3640,  333, 2188, 4114, 2508, 2443, 4242, 3056, 1959,
         930, 3336, 1408, 3337])
Epoch: 1794, Training Loss: 0.10, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1795 - Batch 1 ########################
IDs in batch 1: tensor([3182, 2680, 1984,  739, 1266, 3235, 1334, 1552, 3248, 2915, 3268, 4038,
         833, 4175,  926, 2823])
Epoch: 1795, Training Loss: 0.02, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1796 - Batch 1 ########################
IDs in batch 1: tensor([ 160,  934,   71, 3934, 1160, 3027,  721, 3016, 2257, 1860, 2773, 3456,
         713, 3497,  601, 1084])
Epoch: 1796, Training Loss: 0.13, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1797 - Batch 1 ########################
IDs in batch 1: tensor([3953,  554,  605, 1055,  395, 1734, 2746, 2457,  466, 3471, 2458, 3475,
        2506, 3500, 1179,  824])
Epoch: 1797, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1798 - Batch 1 ########################
IDs in batch 1: tensor([1426, 1347, 2741, 3976, 3395, 3178, 3661,  976, 3830, 2205, 2031,  609,
        1387, 3079,  373, 2797])
Epoch: 1798, Training Loss: 0.10, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1799 - Batch 1 ########################
IDs in batch 1: tensor([ 334, 2008, 4128, 2754, 2504,  975, 1037, 1931, 1038,  887, 2669,  442,
         172, 1772, 1017, 2842])
Epoch: 1799, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1800 - Batch 1 ########################
IDs in batch 1: tensor([ 644, 2974,  109, 3866, 1878, 1146, 2264, 1345, 2688, 3802, 2473, 3219,
        2627,  553, 3339, 3180])
Epoch: 1800, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1801 - Batch 1 ########################
IDs in batch 1: tensor([ 205, 3894, 1923, 1428, 1395, 2804,  275, 2420, 3528,  729,  691, 1480,
        1802, 3204, 3386, 2182])
Epoch: 1801, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1802 - Batch 1 ########################
IDs in batch 1: tensor([2151,   41,   25, 1624, 1600, 2687, 1942, 3481, 2812,  809, 4264, 3858,
         533, 2041, 2701, 2711])
Epoch: 1802, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1803 - Batch 1 ########################
IDs in batch 1: tensor([4062, 1959, 1386, 1626,  726, 3428, 2833, 1387, 1886, 1120, 1093,   11,
        3826, 2548, 2107,  121])
Epoch: 1803, Training Loss: 0.32, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 1804 - Batch 1 ########################
IDs in batch 1: tensor([1409, 3767,  914, 1822, 1428, 3427, 1141, 3314, 2777,  771, 3238, 3469,
          25, 1286,   19,  811])
Epoch: 1804, Training Loss: 0.16, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1805 - Batch 1 ########################
IDs in batch 1: tensor([3418, 3404,  357,  302, 3384, 3329,  823,  718, 1459, 1464, 1097, 1850,
        1322,  184, 1025,  679])
Epoch: 1805, Training Loss: 0.27, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 1806 - Batch 1 ########################
IDs in batch 1: tensor([3182, 2787, 2258, 3581, 2150, 3786, 1573, 1576, 2382, 4073, 1786,  785,
        1457, 2180, 1495,  688])
Epoch: 1806, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1807 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 3277,  181,  395, 1167, 4115,  327, 2541, 2751, 1780, 2942,  750,
        2172, 1981, 1842, 1023])
Epoch: 1807, Training Loss: 0.18, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1808 - Batch 1 ########################
IDs in batch 1: tensor([2697, 1110,  962, 2344, 1866, 2183, 1702, 3092,  141,  476, 4089, 1559,
         199, 2562,  807, 2284])
Epoch: 1808, Training Loss: 0.25, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1809 - Batch 1 ########################
IDs in batch 1: tensor([1218, 4188, 4118,  919, 2255, 3265, 1009, 2090, 1213, 1218, 3971, 3109,
        3552, 1250,  955, 3031])
Epoch: 1809, Training Loss: 0.13, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1810 - Batch 1 ########################
IDs in batch 1: tensor([1156, 4263, 2458, 4089, 2687, 3689, 2715, 3084,  814, 4146, 3234,  534,
         767, 4251, 1728, 3996])
Epoch: 1810, Training Loss: 0.25, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1811 - Batch 1 ########################
IDs in batch 1: tensor([1670, 2126,  758, 1039, 1399,  330, 3711,  522, 3455,  726, 1413, 3713,
        1902,  350, 3391, 1620])
Epoch: 1811, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1812 - Batch 1 ########################
IDs in batch 1: tensor([3290, 2784,  372, 1826, 3238,  864,  218, 1546, 3049, 3669, 4149, 3207,
        3723, 3159, 1999,  786])
Epoch: 1812, Training Loss: 0.07, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1813 - Batch 1 ########################
IDs in batch 1: tensor([2013,  152, 2280,  718, 2469,  102, 2355,  805, 2648,  190, 2541, 1507,
        1716,  584, 1597, 3567])
Epoch: 1813, Training Loss: 0.33, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1814 - Batch 1 ########################
IDs in batch 1: tensor([1103, 3711, 1140, 1355,   56,  950, 3218, 3942, 2304,  425, 3337, 2156,
        3969,    7,  893, 3021])
Epoch: 1814, Training Loss: 0.13, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1815 - Batch 1 ########################
IDs in batch 1: tensor([2600, 3981, 2354, 2245, 4264, 2282,  923, 2449, 2069, 2123, 1673, 3489,
        1934, 2601, 3337,  721])
Epoch: 1815, Training Loss: 0.33, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1816 - Batch 1 ########################
IDs in batch 1: tensor([1098,  417,  322, 3987, 2953, 3879, 3953, 2027, 3572, 3667,  515, 1043,
        2467, 1294, 3367, 2615])
Epoch: 1816, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1817 - Batch 1 ########################
IDs in batch 1: tensor([1698, 3763,  844, 3184,  750, 3391, 1252,  338, 3109,  824, 3387, 3369,
        3883, 2825, 3895, 4013])
Epoch: 1817, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1818 - Batch 1 ########################
IDs in batch 1: tensor([3223, 2783, 3778, 3525, 1911, 2758, 2402, 3621,  330, 2598,  871, 2359,
         141, 3888, 1525, 2112])
Epoch: 1818, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1819 - Batch 1 ########################
IDs in batch 1: tensor([3356, 2272, 1092, 1429,  553, 1957, 2812, 2305, 1641, 3765,  361, 3150,
         258,  449, 3876, 3387])
Epoch: 1819, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1820 - Batch 1 ########################
IDs in batch 1: tensor([2825, 4067, 2950, 3995, 1933,  343,  171, 1937, 1642, 1250,  134,  679,
        1171, 4143, 2156, 3211])
Epoch: 1820, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1821 - Batch 1 ########################
IDs in batch 1: tensor([2591, 4133, 2642, 3135, 1773, 3415, 1332,  858, 3077, 1022, 1035, 2743,
        3836, 3548, 1372, 2452])
Epoch: 1821, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1822 - Batch 1 ########################
IDs in batch 1: tensor([ 308,  899,  959, 1010, 4119, 2599, 3101, 4093, 3876,  409, 2567,  718,
        1414,  122,  954, 4174])
Epoch: 1822, Training Loss: 0.17, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1823 - Batch 1 ########################
IDs in batch 1: tensor([3342, 2258, 1386,  135, 2687,  753, 2019,  522, 2213, 3475, 3256, 2671,
        2234,  586, 3696,  781])
Epoch: 1823, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1824 - Batch 1 ########################
IDs in batch 1: tensor([1778,  278,  278, 2835, 3932, 2223,  968,  199, 1369, 1745, 3020,   41,
         375, 1798, 2558, 3827])
Epoch: 1824, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1825 - Batch 1 ########################
IDs in batch 1: tensor([2925,  726, 1728, 3150, 1490, 1360, 3289, 3702, 2829, 3862, 2876,  904,
        2353,  155, 4227,  344])
Epoch: 1825, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1826 - Batch 1 ########################
IDs in batch 1: tensor([1651, 3982,  187,  689, 4223,  733, 1611,  613, 2670, 2847,  812, 3601,
         879, 4267,   68, 2223])
Epoch: 1826, Training Loss: 0.12, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1827 - Batch 1 ########################
IDs in batch 1: tensor([2738, 2926, 3699,  858,  426, 2181, 3951,  232, 1463,  306,  365, 1168,
        2703,   46, 3494, 3876])
Epoch: 1827, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1828 - Batch 1 ########################
IDs in batch 1: tensor([2620, 3905, 3353,  172, 3630, 2842,   85, 3183,  736, 1166, 3511, 1825,
         317, 2095, 2179, 4035])
Epoch: 1828, Training Loss: 0.12, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1829 - Batch 1 ########################
IDs in batch 1: tensor([2301, 1263, 1949, 1543, 1016, 1182, 1055,  789, 2161, 3250,   44, 3983,
        2521, 3042, 3492,  995])
Epoch: 1829, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1830 - Batch 1 ########################
IDs in batch 1: tensor([3594, 2838,   64, 2295,  689, 3540, 2949, 1459, 2331, 2229, 3486, 3618,
        1286, 2620,  337, 3000])
Epoch: 1830, Training Loss: 0.21, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1831 - Batch 1 ########################
IDs in batch 1: tensor([ 986, 1763, 1054, 1144, 3837, 3239, 3688, 2218,  850, 2444,  755, 1625,
         985, 4089, 3808, 3592])
Epoch: 1831, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1832 - Batch 1 ########################
IDs in batch 1: tensor([ 335, 2963, 3009, 2996, 1375,  891, 1053, 2063, 2473, 1309, 1737, 4126,
        4002,   13, 1174, 2346])
Epoch: 1832, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 1833 - Batch 1 ########################
IDs in batch 1: tensor([2991, 1122, 3005, 2509, 1454, 2690, 2868,  823, 3648, 1299, 2134, 2092,
        2298, 3118, 1712, 1974])
Epoch: 1833, Training Loss: 0.08, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1834 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 3505, 1413, 3757,  450, 2382, 3618, 1751, 4253, 1051,  342,  438,
        3115,  743, 3327, 1032])
Epoch: 1834, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 1835 - Batch 1 ########################
IDs in batch 1: tensor([3159, 4124, 3098, 1404, 3343, 3702, 3503, 2373, 1028, 3243,  975,  316,
         477, 2443, 2046, 1296])
Epoch: 1835, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1836 - Batch 1 ########################
IDs in batch 1: tensor([2133, 3925, 3304,  666, 2924, 2780, 3354, 2721, 3364,  282, 2520, 2298,
        3858, 3021, 2220, 3904])
Epoch: 1836, Training Loss: 0.57, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1837 - Batch 1 ########################
IDs in batch 1: tensor([2982, 3544, 3146, 3528, 1642, 1706, 1828, 2244, 1434, 2327, 3027, 1315,
        2660,  770, 4184, 2725])
Epoch: 1837, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1838 - Batch 1 ########################
IDs in batch 1: tensor([1574, 2207, 3558, 1558, 3078, 2217, 3683, 1491,  752, 1933, 2456,  508,
         838, 1128, 4148, 3084])
Epoch: 1838, Training Loss: 0.10, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1839 - Batch 1 ########################
IDs in batch 1: tensor([3832, 1355, 1380,  786, 1409, 2225, 1390, 1634, 3360, 4184, 2712, 2927,
        2804, 2632, 1480,  279])
Epoch: 1839, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1840 - Batch 1 ########################
IDs in batch 1: tensor([2262, 2806,  803,  804, 3438, 2133, 2157, 3367,   99, 2300, 3360, 2940,
         969, 3161, 1948, 1393])
Epoch: 1840, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1841 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 3017,  338, 1464,  477,  918, 2183, 1850, 1942, 3216,  994, 3778,
        1385, 2986, 1039,  803])
Epoch: 1841, Training Loss: 0.28, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1842 - Batch 1 ########################
IDs in batch 1: tensor([2953,  255, 1685, 4115,  511, 2419,  828, 2067, 3982, 2863, 2296, 4238,
         582,  279, 3637, 1880])
Epoch: 1842, Training Loss: 0.07, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1843 - Batch 1 ########################
IDs in batch 1: tensor([3615, 3841, 1858, 2255, 2483, 3146, 3118,  133,  243,  218, 3428, 2035,
        2281, 3795, 2925, 2073])
Epoch: 1843, Training Loss: 0.45, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1844 - Batch 1 ########################
IDs in batch 1: tensor([2142, 1450,  659,  138, 2691, 3203, 4154, 1295, 1233, 2022, 1676, 1464,
        3815, 2640, 2856, 1463])
Epoch: 1844, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1845 - Batch 1 ########################
IDs in batch 1: tensor([2855, 1530, 1798,  832, 3015,  886,  462,  340, 2117, 3489, 3453, 3478,
        4188, 1944, 1176, 3360])
Epoch: 1845, Training Loss: 0.26, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1846 - Batch 1 ########################
IDs in batch 1: tensor([2709, 2740, 3496, 3082, 3988, 3837, 3829, 1092, 1237, 3417,  139, 2572,
         899, 3461, 2378, 3047])
Epoch: 1846, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1847 - Batch 1 ########################
IDs in batch 1: tensor([ 670, 1055, 1536, 2342, 1613, 2740,   77, 4227, 1804, 1160, 2369, 1678,
        2478, 3797, 1098, 3983])
Epoch: 1847, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1848 - Batch 1 ########################
IDs in batch 1: tensor([4224, 2444,  966, 2403, 2797, 1332, 2391,  186, 3141, 3027, 2394, 2482,
        3160,  976, 1295,  104])
Epoch: 1848, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1849 - Batch 1 ########################
IDs in batch 1: tensor([ 819, 1596,  225, 2170, 3241, 3658, 3727,  315, 3862, 1006,  466, 3999,
        1471, 1241, 3208, 1299])
Epoch: 1849, Training Loss: 0.36, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1850 - Batch 1 ########################
IDs in batch 1: tensor([2890, 2710, 3313,  943, 1787, 3603, 4238, 3020, 2338,  657, 4225, 4138,
        1279, 2844, 3757, 2247])
Epoch: 1850, Training Loss: 0.38, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1851 - Batch 1 ########################
IDs in batch 1: tensor([1306,  843,  343, 1376,  389, 4031, 3681,  182, 2341, 2236, 3398, 3197,
        4004, 2299, 3896,  511])
Epoch: 1851, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1852 - Batch 1 ########################
IDs in batch 1: tensor([2579, 1255,   74, 3362, 3674, 3539,  390,  400,  302, 3851, 1834, 4124,
        2450, 1796,  850, 2659])
Epoch: 1852, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1853 - Batch 1 ########################
IDs in batch 1: tensor([3961,  651,  694, 3439, 3949, 1730, 3142, 2726, 3426, 3039, 2989, 1578,
        3533, 2656,    4, 3363])
Epoch: 1853, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1854 - Batch 1 ########################
IDs in batch 1: tensor([3878, 2721, 1764, 1286, 3664, 3531,  131, 3659,  723, 1255, 2148,  832,
        4039, 2642, 1836, 1599])
Epoch: 1854, Training Loss: 0.24, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1855 - Batch 1 ########################
IDs in batch 1: tensor([2441, 1248, 1162, 2884, 3351, 3577, 1986, 4108, 2710,  955, 2582, 3705,
        2218, 4121, 4086,  937])
Epoch: 1855, Training Loss: 0.30, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 1856 - Batch 1 ########################
IDs in batch 1: tensor([2148, 1292, 1498, 3358, 1122,  544,   81, 1923, 2154, 1284, 1057, 4082,
        3118, 1059,  603, 1266])
Epoch: 1856, Training Loss: 0.32, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1857 - Batch 1 ########################
IDs in batch 1: tensor([2353, 3404, 1331, 3601, 3858,  900, 1334, 2278,  769, 2363,   81, 2144,
         104, 1900, 2567, 1152])
Epoch: 1857, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1858 - Batch 1 ########################
IDs in batch 1: tensor([1676,  501, 4037, 1952, 2272, 3947, 3733, 2551, 3610, 1795, 4101, 1911,
        1661, 3254, 2945, 2350])
Epoch: 1858, Training Loss: 0.26, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1859 - Batch 1 ########################
IDs in batch 1: tensor([3958, 2235,  482, 2895, 3440, 4057, 3239, 2867, 3372, 3488, 4049, 2925,
        3334,  620, 3240, 3018])
Epoch: 1859, Training Loss: 0.59, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1860 - Batch 1 ########################
IDs in batch 1: tensor([ 964, 4118, 1408,  281,  919, 2537,  340, 2279, 1037, 4077,  377, 2450,
        4227,  229, 2371, 2275])
Epoch: 1860, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 1861 - Batch 1 ########################
IDs in batch 1: tensor([2672,  407, 3135, 3504, 3340, 2149, 2031, 2342, 2891, 1374, 1751, 1658,
         790, 3671, 1988, 3754])
Epoch: 1861, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1862 - Batch 1 ########################
IDs in batch 1: tensor([3479,  258, 2521, 2597,   99, 1027,  785, 3389, 3118,   68,  101, 2712,
        2009, 1690,  766,  773])
Epoch: 1862, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 1863 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 1760,  835, 2810,  287, 1962, 1511, 3262, 1279,  794,  516,  147,
        1330, 3475,  996, 1782])
Epoch: 1863, Training Loss: 0.52, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1864 - Batch 1 ########################
IDs in batch 1: tensor([2284,  439, 3018, 1811, 1325,  182, 3860, 3415, 2976, 2342, 2480, 2542,
        1199, 2711, 1173, 3143])
Epoch: 1864, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1865 - Batch 1 ########################
IDs in batch 1: tensor([1229, 4044,  766, 2301,  497,  739, 1229, 3862, 4159, 3547, 1009, 3342,
         667, 2416, 3049, 1073])
Epoch: 1865, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 1866 - Batch 1 ########################
IDs in batch 1: tensor([3177, 2110,  986, 3764, 1860, 1857,  555, 3992, 2365,  988,  448, 1914,
        1712,  819, 2244, 1747])
Epoch: 1866, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1867 - Batch 1 ########################
IDs in batch 1: tensor([2437, 1057, 3627,  449, 2712, 1195, 1521, 2250, 1132, 2736, 2812, 1030,
         582, 4168, 1756, 1543])
Epoch: 1867, Training Loss: 0.44, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1868 - Batch 1 ########################
IDs in batch 1: tensor([1237, 1704, 2402, 3345, 1070,  983,  104, 2386, 2378, 2690, 3865, 3377,
        3540, 2170,  181,   51])
Epoch: 1868, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1869 - Batch 1 ########################
IDs in batch 1: tensor([1006, 3500, 2418, 1291,  807, 2251, 2065, 2353, 4186, 1225, 2535, 2180,
         894, 1235, 2529, 3570])
Epoch: 1869, Training Loss: 0.30, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1870 - Batch 1 ########################
IDs in batch 1: tensor([4040, 2555, 2394, 1459, 1967, 3166,  488, 1200,  814, 1832, 4062, 2229,
        3298, 2265, 1108, 1030])
Epoch: 1870, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1871 - Batch 1 ########################
IDs in batch 1: tensor([2582, 2590, 3888, 2629, 1073, 2148, 3963, 1775, 1959,  469, 1321, 3453,
           5,  100, 1812, 3124])
Epoch: 1871, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1872 - Batch 1 ########################
IDs in batch 1: tensor([4158, 4196,  941, 2600, 3435, 3283, 3378, 3404, 2838, 1182,  205, 2008,
        1956, 2447, 2860, 2539])
Epoch: 1872, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1873 - Batch 1 ########################
IDs in batch 1: tensor([3467, 2069,  214, 2203, 2382, 3311,  477, 3363, 1157,  333, 2804, 3632,
        2324, 1354, 1982, 1681])
Epoch: 1873, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1874 - Batch 1 ########################
IDs in batch 1: tensor([1781,  481,  363, 3031,   68, 1716, 2049, 3394, 4107, 1869, 4134, 3430,
         755, 2368, 2672, 3002])
Epoch: 1874, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1875 - Batch 1 ########################
IDs in batch 1: tensor([1862, 3023, 1885,  797, 2453,  640,  667, 2078, 3440, 2275, 3283, 1900,
        4027, 1700, 1076,  377])
Epoch: 1875, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1876 - Batch 1 ########################
IDs in batch 1: tensor([ 223,  459, 2365, 2290, 1320,  725, 1143, 3029, 3992, 2326,  315, 1147,
        1774, 2156, 3386, 2959])
Epoch: 1876, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1877 - Batch 1 ########################
IDs in batch 1: tensor([ 727, 1704, 3088, 2118, 3497, 3094,  640, 1825, 3493, 1526, 3747, 4225,
         530,  727,  425,  503])
Epoch: 1877, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 1878 - Batch 1 ########################
IDs in batch 1: tensor([2535, 2908, 2899, 2951, 3769, 2133,  583,  837, 2113, 1685, 3667,  977,
        3689,  808, 1861, 1571])
Epoch: 1878, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1879 - Batch 1 ########################
IDs in batch 1: tensor([3258, 3423, 3131, 3321, 2851, 3807, 3664, 2343, 2017, 3342, 3921, 4159,
         280, 2088,  871, 2354])
Epoch: 1879, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1880 - Batch 1 ########################
IDs in batch 1: tensor([4265,  266, 1918, 2997, 1343,  670,  467, 2797, 1222,  981, 1512,   84,
        1990, 3583, 2496, 1859])
Epoch: 1880, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1881 - Batch 1 ########################
IDs in batch 1: tensor([4253, 2049, 4033, 1248, 3616, 3557,  312,  832, 1595, 2426, 4094, 1540,
        1852, 2127, 1387, 4234])
Epoch: 1881, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1882 - Batch 1 ########################
IDs in batch 1: tensor([1707, 1030, 2153, 2086,  292, 1476, 4140, 3368,  623, 2802, 3038,  119,
        3118, 2383, 3635, 1469])
Epoch: 1882, Training Loss: 0.67, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1883 - Batch 1 ########################
IDs in batch 1: tensor([2488, 4141, 2961, 3831,  134,  389, 1270,  694, 2701,  345, 1579, 1186,
        1410, 3712, 1612, 1161])
Epoch: 1883, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1884 - Batch 1 ########################
IDs in batch 1: tensor([ 259,  796,  245, 3692, 2092,  367, 3444, 1779, 2400, 1370, 3271, 3971,
        1316, 4085, 3200, 3927])
Epoch: 1884, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1885 - Batch 1 ########################
IDs in batch 1: tensor([3000, 2388, 2046, 3020, 2817, 3278,  743,   25, 1096, 1734, 2188, 1177,
        4179,  886, 3238,  165])
Epoch: 1885, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1886 - Batch 1 ########################
IDs in batch 1: tensor([ 377,  869, 1579, 1568,  566, 2277,  198,  545, 3973, 1360, 4089, 2369,
        3573,  251, 3630, 3374])
Epoch: 1886, Training Loss: 0.29, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1887 - Batch 1 ########################
IDs in batch 1: tensor([ 730, 1248, 2536, 2915,  373, 2352, 2771, 3705, 2245,  418, 3951, 3473,
        1263,  681, 3677, 1454])
Epoch: 1887, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.74
######################## Epoch 1888 - Batch 1 ########################
IDs in batch 1: tensor([2619,  365,  735, 2349, 3483, 2977, 2429, 1699, 1141, 2595, 2125,  718,
         369, 1038, 1316, 2483])
Epoch: 1888, Training Loss: 0.10, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1889 - Batch 1 ########################
IDs in batch 1: tensor([2638, 3194, 2309, 2754, 2299,  857,  892, 1712, 2567, 4265, 1234,   82,
        3115, 1824, 1706, 4060])
Epoch: 1889, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.74
######################## Epoch 1890 - Batch 1 ########################
IDs in batch 1: tensor([3661,  399, 4176,  797, 1858, 3235, 1162, 2010, 1369, 3084, 2666, 2463,
        3392, 2028, 3407, 3771])
Epoch: 1890, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1891 - Batch 1 ########################
IDs in batch 1: tensor([2371, 3871, 3110, 2798, 2842, 2229, 3710, 2146, 2192, 3503, 2963, 1798,
        3418, 1116, 1753,  376])
Epoch: 1891, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.74
######################## Epoch 1892 - Batch 1 ########################
IDs in batch 1: tensor([1108,  964, 3968, 2660, 3842, 1982,  371, 3987, 2035,   73,  183, 2362,
        2489,  839, 1627, 3497])
Epoch: 1892, Training Loss: 0.16, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1893 - Batch 1 ########################
IDs in batch 1: tensor([2357, 4131, 2540,  848,  956, 3895,  322, 4015, 1291,  546, 3932,  832,
        1113,  448, 2066, 1357])
Epoch: 1893, Training Loss: 0.33, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1894 - Batch 1 ########################
IDs in batch 1: tensor([1324, 4264, 1866, 1125,  380,  234,  950, 4025, 2172, 3500, 1282, 1049,
        3648, 1556,  243, 2541])
Epoch: 1894, Training Loss: 0.15, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1895 - Batch 1 ########################
IDs in batch 1: tensor([2070, 1663,  389, 2479,  550, 1491, 2508, 2081, 4016, 1945, 2379,  393,
        3423, 3394,  432, 2202])
Epoch: 1895, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1896 - Batch 1 ########################
IDs in batch 1: tensor([1309, 4099, 1746, 2828, 1711, 2645, 2494, 1892, 1648,  396,  224, 2255,
         763, 1567, 3183, 2287])
Epoch: 1896, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1897 - Batch 1 ########################
IDs in batch 1: tensor([2550, 3448, 2879, 3485, 2600, 1346, 2248,  699, 2934, 3157, 3850, 2844,
        4108, 1201, 3990, 4146])
Epoch: 1897, Training Loss: 0.37, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1898 - Batch 1 ########################
IDs in batch 1: tensor([3029,  131, 2407,  455,  651, 2391, 2287, 3035, 4088, 3202, 1678, 1429,
        3267, 3250, 2399, 2537])
Epoch: 1898, Training Loss: 0.11, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1899 - Batch 1 ########################
IDs in batch 1: tensor([3567, 3969, 1049,  415, 3449, 2984,  651, 3541, 3472,  413,  538,  214,
        2205, 1363, 3228,  466])
Epoch: 1899, Training Loss: 0.06, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1900 - Batch 1 ########################
IDs in batch 1: tensor([4124, 3010, 2851, 4135, 1384, 3704, 2517, 2188,   96, 1612, 3329,  188,
         964, 3036, 2649,  968])
Epoch: 1900, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1901 - Batch 1 ########################
IDs in batch 1: tensor([ 137,  223, 1464, 1116, 3016, 2743, 2401, 1275,  207, 1090, 2337,  284,
         141, 1640,  792, 2352])
Epoch: 1901, Training Loss: 0.15, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1902 - Batch 1 ########################
IDs in batch 1: tensor([3942, 1585, 2682,  689, 3151, 1451, 3534, 1453, 1512, 1778,  526, 4004,
        3552, 1178, 1173,  674])
Epoch: 1902, Training Loss: 0.24, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1903 - Batch 1 ########################
IDs in batch 1: tensor([ 225, 3886, 2178, 3470,  967, 3744, 2959,  263, 3731, 1452, 3821, 1121,
         527, 2919,  713,  104])
Epoch: 1903, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1904 - Batch 1 ########################
IDs in batch 1: tensor([1532, 3451, 2600, 3689,  900,  566, 1892, 2328, 1585, 2485,  384, 3221,
         556, 1088, 3540, 3128])
Epoch: 1904, Training Loss: 0.06, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1905 - Batch 1 ########################
IDs in batch 1: tensor([ 325, 1981,   10, 4055, 3493,  679, 4016, 1824, 2170,  950, 2924, 3960,
          77, 3698, 1236, 1028])
Epoch: 1905, Training Loss: 0.11, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1906 - Batch 1 ########################
IDs in batch 1: tensor([1444, 1597, 1497, 3833, 1895, 2963, 2559, 1066, 3226, 1624, 3039, 1968,
        1437, 3727, 1381, 3327])
Epoch: 1906, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1907 - Batch 1 ########################
IDs in batch 1: tensor([3797, 1647, 4107, 1454,  736, 3362, 1331, 4014, 1960, 3947, 1858, 2761,
         181, 3364, 1463, 1331])
Epoch: 1907, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1908 - Batch 1 ########################
IDs in batch 1: tensor([ 796, 4181, 3907, 1567, 1143, 3533, 3101, 2791, 3271, 1332, 3203, 3049,
        1693, 1199, 2377, 1920])
Epoch: 1908, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1909 - Batch 1 ########################
IDs in batch 1: tensor([4108, 2338, 4103, 3228, 2146,  781,   26, 3467,  266, 2619, 3989,   70,
        1896, 3717, 3356,  883])
Epoch: 1909, Training Loss: 0.08, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1910 - Batch 1 ########################
IDs in batch 1: tensor([2678, 2993, 3658,  282,  380, 2712, 3804, 1014, 3317, 1485, 1700, 1830,
         676,   34,  993,  259])
Epoch: 1910, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1911 - Batch 1 ########################
IDs in batch 1: tensor([3018, 2034, 2866, 1828, 2936,   95,  975, 2120, 2467,  704, 4051, 1008,
        4268, 2887, 2461, 1133])
Epoch: 1911, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1912 - Batch 1 ########################
IDs in batch 1: tensor([2644, 2342, 1160, 1457, 2476, 3634, 4115, 1476, 3643, 2379,  878, 3696,
        2342,  510,  151, 2236])
Epoch: 1912, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1913 - Batch 1 ########################
IDs in batch 1: tensor([1014,  587,  110, 2442, 1405, 2435, 1518,  160,    4, 2511, 1954, 3488,
        2690, 2624, 3410, 3439])
Epoch: 1913, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1914 - Batch 1 ########################
IDs in batch 1: tensor([3495, 3654, 1330, 1173,  501,   20, 1310, 1803,  593,  498, 4039,  872,
         417, 3052, 2305, 1216])
Epoch: 1914, Training Loss: 0.30, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1915 - Batch 1 ########################
IDs in batch 1: tensor([ 199, 1274, 2606,  333,  440, 1656, 1999, 2039, 1600, 1810, 3480, 2072,
        3425,  751, 2727, 2192])
Epoch: 1915, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1916 - Batch 1 ########################
IDs in batch 1: tensor([3425, 2196, 1111, 1354, 1320, 1990, 1986, 1753, 2408, 2770, 3468, 2749,
        3547, 3853, 2638, 1274])
Epoch: 1916, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1917 - Batch 1 ########################
IDs in batch 1: tensor([ 977,  449, 4122, 3468, 3199,  908,  247,  396,  864, 3358,  775,  520,
        2568, 4037, 2104, 2758])
Epoch: 1917, Training Loss: 0.19, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1918 - Batch 1 ########################
IDs in batch 1: tensor([ 533, 3355,  593, 2477, 1846, 2616,  640, 3693, 1020, 2810, 1974,  108,
        1031, 2540, 4067, 1496])
Epoch: 1918, Training Loss: 0.13, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1919 - Batch 1 ########################
IDs in batch 1: tensor([2742, 1774,  577,  183,  786, 1175, 2761, 2036, 4000, 2443, 3475,  361,
        2993, 1885, 4144, 3533])
Epoch: 1919, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1920 - Batch 1 ########################
IDs in batch 1: tensor([  15,  886, 2148, 4159, 3874, 2459, 4172, 2863, 1420, 2989,  563, 3547,
        3920,  843, 3501, 3545])
Epoch: 1920, Training Loss: 0.10, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1921 - Batch 1 ########################
IDs in batch 1: tensor([ 756, 2378, 2476, 1051, 2388, 1767, 3131,  481,  505,  661, 3871, 3466,
        1360,  605, 1092, 2745])
Epoch: 1921, Training Loss: 0.12, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1922 - Batch 1 ########################
IDs in batch 1: tensor([1320, 3460, 2242, 3832,  160,  136,  774, 1198, 3443,   37, 2583, 3035,
        1258, 2390,  763, 3743])
Epoch: 1922, Training Loss: 0.16, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1923 - Batch 1 ########################
IDs in batch 1: tensor([1257,  143,  623, 1718, 2264, 1139,  985, 3733, 1968, 2949,  662, 1232,
        2218, 3882, 1956, 4227])
Epoch: 1923, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 1924 - Batch 1 ########################
IDs in batch 1: tensor([2824, 2109, 2296, 2327,  134, 2715, 2348, 3610, 1182,  490,  880, 3100,
        3354, 3252, 2367,  218])
Epoch: 1924, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.78
######################## Epoch 1925 - Batch 1 ########################
IDs in batch 1: tensor([3006, 1963, 3652, 1357, 2188,  848,  712, 2290, 2932,  400, 1597, 1425,
        2806, 2417, 3992, 4128])
Epoch: 1925, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 1926 - Batch 1 ########################
IDs in batch 1: tensor([2299, 2206, 4187,  330,  330, 2522,  451, 2451, 2005,  553,  194, 3598,
        1502, 1508,  306, 4268])
Epoch: 1926, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.78
######################## Epoch 1927 - Batch 1 ########################
IDs in batch 1: tensor([3438, 1107,  151,  195, 3943,  553,  338, 1455,  615, 1506, 2758, 1551,
        3121,  615, 1524,  729])
Epoch: 1927, Training Loss: 0.62, Validation Loss: 0.65, accuracy = 0.78
######################## Epoch 1928 - Batch 1 ########################
IDs in batch 1: tensor([ 557, 3306, 2729,  203, 2113, 3279, 2553,  843, 1826, 2406, 3928, 2220,
        3243, 4198, 3882, 3521])
Epoch: 1928, Training Loss: 0.26, Validation Loss: 0.65, accuracy = 0.78
######################## Epoch 1929 - Batch 1 ########################
IDs in batch 1: tensor([2754, 3194, 3671,  295,  682, 2610, 2592,  841, 1324, 2179,  265,  852,
        2223, 1408,  573, 3671])
Epoch: 1929, Training Loss: 0.17, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1930 - Batch 1 ########################
IDs in batch 1: tensor([1656, 2370, 1377, 2796, 1170,  244, 1313,  269, 3514,  811,  344,   99,
         757, 4240, 2295, 3444])
Epoch: 1930, Training Loss: 0.17, Validation Loss: 0.65, accuracy = 0.78
######################## Epoch 1931 - Batch 1 ########################
IDs in batch 1: tensor([4049,   39, 1775, 1952,  565, 2477,  462, 1506, 3468, 1566,  813, 3677,
         713, 4173,  147, 4235])
Epoch: 1931, Training Loss: 0.10, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 1932 - Batch 1 ########################
IDs in batch 1: tensor([ 408, 4195, 3018, 3812, 3388, 3663,  194, 1558, 1336, 3976, 1828, 2730,
         300, 2572, 3373, 2423])
Epoch: 1932, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1933 - Batch 1 ########################
IDs in batch 1: tensor([4195, 1708,  639, 2155, 3711,  258, 3022,   30,  839, 2915, 2873, 3148,
        2030,  918, 4185, 3408])
Epoch: 1933, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1934 - Batch 1 ########################
IDs in batch 1: tensor([3581, 1420,  212, 3795, 2134, 1632, 3723, 3021,  476, 4057, 3146, 2236,
        1686, 3437, 3764, 1614])
Epoch: 1934, Training Loss: 0.06, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1935 - Batch 1 ########################
IDs in batch 1: tensor([3101, 1871,  721, 3900, 2880, 2078, 4046, 1881, 1835, 3813, 2437, 3287,
         182, 2236, 2127, 4005])
Epoch: 1935, Training Loss: 0.71, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 1936 - Batch 1 ########################
IDs in batch 1: tensor([2883, 2461, 3563, 2276, 1916, 3264, 3426, 3780, 2453, 1271,  470, 1617,
        3472, 2798,   60, 3621])
Epoch: 1936, Training Loss: 0.28, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1937 - Batch 1 ########################
IDs in batch 1: tensor([3787,  968,  399, 4188, 2403, 1901, 2441, 1796, 2538, 1099, 3465, 2936,
         937,  539,  771, 3308])
Epoch: 1937, Training Loss: 0.11, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1938 - Batch 1 ########################
IDs in batch 1: tensor([ 211,   82, 3188, 3681, 3267,  933,  917, 1938,  846,  488, 3658, 2375,
        2538, 2914, 2149, 1536])
Epoch: 1938, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 1939 - Batch 1 ########################
IDs in batch 1: tensor([1252, 3427, 2562, 3337,   18, 2656, 2879,  673, 3509, 3640, 3544, 1059,
        3783, 2364, 1756, 3039])
Epoch: 1939, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 1940 - Batch 1 ########################
IDs in batch 1: tensor([2996, 1718, 3771, 3492, 3842,  344, 2312, 3765, 3779, 2304, 3144, 2443,
        1179,  959, 1706, 1084])
Epoch: 1940, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 1941 - Batch 1 ########################
IDs in batch 1: tensor([1308, 2280, 2802, 1753,  557, 4127, 1766, 2629,  773, 1062, 2869, 2459,
        3661, 3661, 3101, 3535])
Epoch: 1941, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1942 - Batch 1 ########################
IDs in batch 1: tensor([ 550, 4254, 3345, 2745, 2863, 2798, 2056, 1932, 2629, 3472, 2669, 4055,
        2746, 3168, 1283,  536])
Epoch: 1942, Training Loss: 0.45, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1943 - Batch 1 ########################
IDs in batch 1: tensor([2546,  377, 1456,  505, 1237,  544, 2278, 2782,  295, 1676,  302,  952,
         790,  917, 2616,  103])
Epoch: 1943, Training Loss: 0.58, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 1944 - Batch 1 ########################
IDs in batch 1: tensor([ 583, 2143, 3907, 4186, 2840, 2306,  190, 3228, 3949, 1260, 1367, 1508,
         821,  882, 3843, 3709])
Epoch: 1944, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1945 - Batch 1 ########################
IDs in batch 1: tensor([1756, 4261,  884, 2148, 1229,  896, 2571, 1125, 3599,  584, 1134, 1451,
        4030,  679, 3558, 4094])
Epoch: 1945, Training Loss: 0.26, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 1946 - Batch 1 ########################
IDs in batch 1: tensor([ 644, 2802, 3500, 1832, 1455, 2868,  997,  183, 2581, 3255, 4251, 1728,
        1436, 1951,  275, 2873])
Epoch: 1946, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1947 - Batch 1 ########################
IDs in batch 1: tensor([1119, 3495, 2617, 1090, 1380, 1877, 1190, 4027, 2817, 4236, 4058, 2046,
        3121,  953,  752, 1397])
Epoch: 1947, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1948 - Batch 1 ########################
IDs in batch 1: tensor([2831, 3120, 2838, 2591,  556, 1641, 3208, 2091,  566, 2719, 2025,  330,
        2644, 2577, 2377,  211])
Epoch: 1948, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1949 - Batch 1 ########################
IDs in batch 1: tensor([1198, 1973, 1167, 3922, 1679, 2942, 1480,  206, 1158, 3822,  100, 1214,
         747,  693, 1809, 3203])
Epoch: 1949, Training Loss: 0.49, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1950 - Batch 1 ########################
IDs in batch 1: tensor([1119, 1861, 1968,  992, 2851, 3052, 1050, 2963, 1330, 2523, 2949,  202,
        2388, 4016, 3123, 4196])
Epoch: 1950, Training Loss: 0.10, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1951 - Batch 1 ########################
IDs in batch 1: tensor([ 887, 1942, 2506, 4048, 1417, 1543, 1065, 1977, 2153, 3476,  181, 1153,
        2627, 2800, 2044, 2661])
Epoch: 1951, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1952 - Batch 1 ########################
IDs in batch 1: tensor([3461, 2584, 1077,  623, 1934,  340, 4006,  289, 3275, 1073, 3471, 3156,
        3289, 3071, 2567, 2609])
Epoch: 1952, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1953 - Batch 1 ########################
IDs in batch 1: tensor([3971, 3415, 1032, 2882, 3110, 4073, 1450,  956, 2535, 2262, 2836, 3760,
         400,  763, 2555, 3208])
Epoch: 1953, Training Loss: 0.23, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1954 - Batch 1 ########################
IDs in batch 1: tensor([4017, 1643, 2382, 3767,  255,  238,  109, 3222, 1434, 1846, 3142, 1158,
        3353,  971, 3668, 2908])
Epoch: 1954, Training Loss: 0.17, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1955 - Batch 1 ########################
IDs in batch 1: tensor([2148, 1536, 3643, 3463,  119, 2824, 3036, 2476, 2791, 4035, 3536,  842,
        4245, 3871, 4085, 1832])
Epoch: 1955, Training Loss: 0.35, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1956 - Batch 1 ########################
IDs in batch 1: tensor([1732, 4084,  440, 3314, 1057,  724, 3717,  990, 3024, 3438, 3284, 2731,
        1009, 3124, 2378, 4096])
Epoch: 1956, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1957 - Batch 1 ########################
IDs in batch 1: tensor([2831, 2832, 4185, 2643,  321, 2375, 3904, 2582, 3504, 3109, 3544,  129,
        3991, 2868, 1224, 3668])
Epoch: 1957, Training Loss: 0.13, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1958 - Batch 1 ########################
IDs in batch 1: tensor([2524, 1305, 3227, 1121, 2433,  945,  512, 3846, 3216,  849, 4128, 2854,
        1463,  448, 3917,   38])
Epoch: 1958, Training Loss: 0.34, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1959 - Batch 1 ########################
IDs in batch 1: tensor([1325, 2618, 3257, 4097, 1156, 1318,  934, 3973, 1490, 3291, 1510,  886,
        2238, 1909, 2206, 2182])
Epoch: 1959, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1960 - Batch 1 ########################
IDs in batch 1: tensor([1361, 2473,  292,  302, 1959, 4232,  483, 4122, 2385, 2045, 1834, 3194,
        3769, 1491, 2385, 3435])
Epoch: 1960, Training Loss: 0.11, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1961 - Batch 1 ########################
IDs in batch 1: tensor([3871, 1602, 1934, 1871, 3652, 1170,  492, 3675,  343, 2018, 3114,  740,
        4044, 1264,  266,  315])
Epoch: 1961, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1962 - Batch 1 ########################
IDs in batch 1: tensor([ 575, 3472, 3734,  610, 3526, 2034, 4011, 4213, 1680, 2749, 2467, 3771,
         763, 2797, 3609, 1612])
Epoch: 1962, Training Loss: 0.28, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1963 - Batch 1 ########################
IDs in batch 1: tensor([ 384, 1087, 1878,  229, 2161, 2504, 2892,  198, 1277, 2784, 2403, 1585,
        1711, 1630, 2279, 4049])
Epoch: 1963, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1964 - Batch 1 ########################
IDs in batch 1: tensor([1373, 2451, 3637, 1242,  498, 1295, 4179, 1536, 2629, 2855, 4110,  171,
        3514,   82, 3392, 3143])
Epoch: 1964, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1965 - Batch 1 ########################
IDs in batch 1: tensor([ 672, 1042, 3838, 2663, 1012, 1285, 2991, 4051,  662,  103, 2166, 2730,
        1257, 1257,  832, 1982])
Epoch: 1965, Training Loss: 0.24, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 1966 - Batch 1 ########################
IDs in batch 1: tensor([ 794, 2306, 2183, 3516, 3425, 3760, 3486, 1885, 2315,  667,  332, 2356,
        3642, 1218, 2255, 2577])
Epoch: 1966, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1967 - Batch 1 ########################
IDs in batch 1: tensor([1899, 1498, 1176, 1251, 1250, 4135,  913, 3024, 3701, 3168, 3197, 3594,
        2739, 3564, 1555, 2141])
Epoch: 1967, Training Loss: 0.07, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1968 - Batch 1 ########################
IDs in batch 1: tensor([2383,  202, 1421, 1781, 2003, 2436, 1828, 1258, 2494, 1476, 1039,  173,
        2279, 2847, 1766,  732])
Epoch: 1968, Training Loss: 0.15, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1969 - Batch 1 ########################
IDs in batch 1: tensor([ 494,  344, 2524,  200,  583, 1101, 2562, 1248, 1146,  300, 2771, 3254,
        3009, 2377, 3920,  282])
Epoch: 1969, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1970 - Batch 1 ########################
IDs in batch 1: tensor([4186, 1270, 2851, 1377, 1121,  937,  712, 2169, 1290, 1881, 3874, 3006,
         121, 2669, 1646,  588])
Epoch: 1970, Training Loss: 0.13, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1971 - Batch 1 ########################
IDs in batch 1: tensor([1214, 3113, 3318,   19, 1948, 3651, 1047,  846, 3688,  487,  681, 3283,
        1010, 3744, 1226, 3744])
Epoch: 1971, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1972 - Batch 1 ########################
IDs in batch 1: tensor([2537, 1007, 1208, 2328, 3876,  755,   84, 2620, 3408, 3381, 3590, 2463,
         909, 1877,  689,  858])
Epoch: 1972, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1973 - Batch 1 ########################
IDs in batch 1: tensor([1166, 2202, 2860,  202, 1316,  177,  749, 1828, 1066,  121, 4255, 3727,
        1043, 4146, 3355, 2223])
Epoch: 1973, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1974 - Batch 1 ########################
IDs in batch 1: tensor([2287,  237, 2610, 1023,  523, 3539, 1668, 1570, 2282, 1309, 2562,  474,
         907, 1122, 2638,  534])
Epoch: 1974, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 1975 - Batch 1 ########################
IDs in batch 1: tensor([3882, 3511, 1635, 3638, 1860, 2998, 2098,  741,  673, 1947, 2921,  679,
         261, 3407, 3963, 3423])
Epoch: 1975, Training Loss: 0.25, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1976 - Batch 1 ########################
IDs in batch 1: tensor([3833,  819,  980, 1153, 2890, 1248, 1884, 3900, 2640, 2968, 1952,  944,
        2382, 4126,  470, 1942])
Epoch: 1976, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1977 - Batch 1 ########################
IDs in batch 1: tensor([ 923, 1578,  693, 3542, 1681, 2828, 2024, 2103,  792, 3154, 2851, 3698,
        2536, 4161, 4249, 1651])
Epoch: 1977, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1978 - Batch 1 ########################
IDs in batch 1: tensor([1117,  623, 1938, 2616,  275, 2659, 3417, 3908,   57, 2126, 3124, 1825,
        2060,  830,  620, 2883])
Epoch: 1978, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1979 - Batch 1 ########################
IDs in batch 1: tensor([ 100, 2921,  556, 3349, 1257, 2366, 1530, 2603, 1380, 3954, 4180,  665,
        1337, 4026,  290, 2348])
Epoch: 1979, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.75
######################## Epoch 1980 - Batch 1 ########################
IDs in batch 1: tensor([  18,  305,  601,  376, 3081, 1337, 1283, 1369, 1870,  908, 2789, 1507,
         477, 1798, 3981, 3547])
Epoch: 1980, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1981 - Batch 1 ########################
IDs in batch 1: tensor([ 237,  771, 3698, 1402, 1658, 3943,  492, 1595, 3827,  321,   70, 2656,
        2399,  512,   77,  524])
Epoch: 1981, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.75
######################## Epoch 1982 - Batch 1 ########################
IDs in batch 1: tensor([3934, 1285, 3228,  228, 2541, 3271, 3810,  398,  683, 2220, 3945, 3437,
        1763, 1432,  872, 1183])
Epoch: 1982, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1983 - Batch 1 ########################
IDs in batch 1: tensor([4120, 2182, 1860, 3363, 2519, 3038, 3866,  789, 3423, 1376, 3467, 1474,
         514, 3216, 2736,   73])
Epoch: 1983, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1984 - Batch 1 ########################
IDs in batch 1: tensor([3304,  280, 4067, 2723, 2617, 2104,   43,  177,  864,  316, 2618, 3035,
        3747,  512,  626, 3184])
Epoch: 1984, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1985 - Batch 1 ########################
IDs in batch 1: tensor([3983, 4236, 3228,  785,  533,  688, 2255, 3553,  756, 2741,  893, 3136,
        2831, 2940, 2681, 2312])
Epoch: 1985, Training Loss: 0.30, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 1986 - Batch 1 ########################
IDs in batch 1: tensor([3863, 3006, 2074, 1161, 1070, 1798,  830, 1849, 3461, 2869, 1760, 3478,
        2649, 3917, 1786, 3673])
Epoch: 1986, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 1987 - Batch 1 ########################
IDs in batch 1: tensor([3751, 3683, 2836, 2476, 2110, 3481, 1481,  736, 2500, 2736,  407, 2727,
        3532, 2348, 1471,  128])
Epoch: 1987, Training Loss: 0.23, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1988 - Batch 1 ########################
IDs in batch 1: tensor([3594,  921, 1959, 1599, 1573, 4255, 4048,  966,  320,  173,  712,  961,
        1798,  758, 2582, 4030])
Epoch: 1988, Training Loss: 0.18, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 1989 - Batch 1 ########################
IDs in batch 1: tensor([2719, 3016, 3483,  605, 2844, 3714,  961, 1324, 2597, 2418, 1650,  191,
         526, 1055,  346, 3913])
Epoch: 1989, Training Loss: 0.12, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1990 - Batch 1 ########################
IDs in batch 1: tensor([ 740, 1445, 4134, 3024, 2758, 1899,  816, 1199, 1736, 2284,  226, 2458,
          59,  490,  359, 1476])
Epoch: 1990, Training Loss: 0.24, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 1991 - Batch 1 ########################
IDs in batch 1: tensor([1248, 2085, 1634,  637, 4036, 3152, 2825, 4235, 3942,  316, 2064, 1548,
        3483, 2328,  874,  130])
Epoch: 1991, Training Loss: 0.14, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1992 - Batch 1 ########################
IDs in batch 1: tensor([1563,  844, 2085, 3961, 2204, 4100, 1459, 4055, 1498,  888, 1849, 3154,
        3253,  881,  138, 3366])
Epoch: 1992, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1993 - Batch 1 ########################
IDs in batch 1: tensor([ 172, 1863, 3798,  804, 3312,  456,  588, 4049, 2087, 3699, 1022, 2701,
        3743, 1023, 3981, 2497])
Epoch: 1993, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1994 - Batch 1 ########################
IDs in batch 1: tensor([1787,  750, 1913,  953, 3289, 2161, 1390,  773,  332, 3000, 2907, 2854,
         477, 1291, 3683, 3650])
Epoch: 1994, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1995 - Batch 1 ########################
IDs in batch 1: tensor([ 882, 2182, 2620, 3577, 2856,   93, 1084, 1179, 3374, 2022,  332,  395,
        3987,  769, 1325,  527])
Epoch: 1995, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1996 - Batch 1 ########################
IDs in batch 1: tensor([ 394, 3072, 3025, 3222, 2973, 3540,  350, 2599, 2999,  646, 1349,  538,
        3640, 2034, 3415, 2254])
Epoch: 1996, Training Loss: 0.26, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 1997 - Batch 1 ########################
IDs in batch 1: tensor([1081,  628, 1417, 2917,  839, 2509, 2305, 2327, 1276, 3367, 3309, 3303,
        1299, 3476, 4158, 2398])
Epoch: 1997, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1998 - Batch 1 ########################
IDs in batch 1: tensor([3139,  321, 3683, 2522, 1982, 2286, 2932, 2412, 1453, 3053, 1380, 1233,
        3047, 3992,    7, 1878])
Epoch: 1998, Training Loss: 0.09, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 1999 - Batch 1 ########################
IDs in batch 1: tensor([1754, 3790, 3105,  439,  103, 3535, 1730, 1979, 3202, 4039, 4086, 3476,
        3151, 2060, 2868,  171])
Epoch: 1999, Training Loss: 0.40, Validation Loss: 0.62, accuracy = 0.75
######################## Epoch 2000 - Batch 1 ########################
IDs in batch 1: tensor([3206, 1310,  492, 2740, 3100, 1415, 3928, 3241, 2758, 1200, 1699, 1250,
        3572,  841,   38, 3039])
Epoch: 2000, Training Loss: 0.12, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 2001 - Batch 1 ########################
IDs in batch 1: tensor([3345, 1665, 1611, 1214,  837, 3503,  498, 1828, 1973, 3821,  256, 3777,
        3131, 3478, 2193, 4025])
Epoch: 2001, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 2002 - Batch 1 ########################
IDs in batch 1: tensor([1088, 1179,   26,  218, 2755, 2688, 2947, 2905,  239, 1826,  467, 3178,
         717, 2332, 1004, 1589])
Epoch: 2002, Training Loss: 0.28, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2003 - Batch 1 ########################
IDs in batch 1: tensor([1996, 4003, 3113, 1066, 2494, 3188, 2320,  557,  343, 3494, 2155, 2025,
        3983, 3733, 3808, 1891])
Epoch: 2003, Training Loss: 0.41, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2004 - Batch 1 ########################
IDs in batch 1: tensor([ 851,  808, 2804, 3123,   96, 2663,  822, 2137, 1003, 2508,  899, 1133,
        4245, 4135, 3493, 2382])
Epoch: 2004, Training Loss: 0.17, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2005 - Batch 1 ########################
IDs in batch 1: tensor([ 478, 3005, 3271, 3397, 3846, 1604, 1379, 2518, 1014,  402, 2925, 4187,
         518, 1147,  477,  639])
Epoch: 2005, Training Loss: 0.21, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 2006 - Batch 1 ########################
IDs in batch 1: tensor([2217, 4166, 1879,  425, 1128,   10, 3506, 1024, 3121, 2819, 1257, 3362,
        1949, 3151, 4234, 3390])
Epoch: 2006, Training Loss: 0.26, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2007 - Batch 1 ########################
IDs in batch 1: tensor([ 263,  862,  740, 1318, 3111, 3582, 1760, 3808, 2132,  435, 2873, 3895,
        2603, 4014, 4121,  974])
Epoch: 2007, Training Loss: 0.05, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2008 - Batch 1 ########################
IDs in batch 1: tensor([3718,   96, 3878, 3797,  465, 2179, 1712, 2143,  202,   61, 1173, 2553,
        1630, 1101, 2915, 1399])
Epoch: 2008, Training Loss: 0.26, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2009 - Batch 1 ########################
IDs in batch 1: tensor([1255, 3423, 2974, 3364, 4107, 3676, 2220, 1766,  687, 3999, 2177, 2969,
        3336,  236,  556, 1166])
Epoch: 2009, Training Loss: 0.08, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2010 - Batch 1 ########################
IDs in batch 1: tensor([1178, 1281, 1264,  749, 1625,  813,  950, 1620, 3769, 3587, 3755, 2444,
        4133,  274, 2907, 2693])
Epoch: 2010, Training Loss: 0.17, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2011 - Batch 1 ########################
IDs in batch 1: tensor([ 993, 1108, 2360, 1034, 3740, 3366,   86, 1708, 2553, 2823,   70, 2297,
        3922,  978, 1485, 2435])
Epoch: 2011, Training Loss: 0.12, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 2012 - Batch 1 ########################
IDs in batch 1: tensor([2964,  488,  871, 3481, 3498,  937, 3934, 3921, 3279, 2583, 2487, 2297,
        2275, 2203, 3544, 2170])
Epoch: 2012, Training Loss: 0.35, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 2013 - Batch 1 ########################
IDs in batch 1: tensor([ 602,  792, 3614,  409,  199, 1952, 3610,  894, 3184, 3712,  687,  833,
         470, 1594, 3344, 3581])
Epoch: 2013, Training Loss: 0.14, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 2014 - Batch 1 ########################
IDs in batch 1: tensor([3415, 4253, 1972, 4189, 2455, 4044, 1050, 2565, 3256, 3721,  258, 3621,
        2290,  529, 3895, 2448])
Epoch: 2014, Training Loss: 0.35, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2015 - Batch 1 ########################
IDs in batch 1: tensor([ 526, 2180, 3663,  377, 2892, 1634, 2120,  779, 1306, 4175,  689,  605,
         300,  333, 1209, 1208])
Epoch: 2015, Training Loss: 0.22, Validation Loss: 0.59, accuracy = 0.77
######################## Epoch 2016 - Batch 1 ########################
IDs in batch 1: tensor([3443, 3747, 2144, 3570, 3756,  968, 1333, 3488, 1844, 2314,  756, 1076,
         266,  771, 1330, 1032])
Epoch: 2016, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 2017 - Batch 1 ########################
IDs in batch 1: tensor([2297, 1380,  989,  538,  749, 1295, 3025, 1677, 1273, 2649, 2978, 1536,
        3907, 2417, 3712, 1648])
Epoch: 2017, Training Loss: 0.09, Validation Loss: 0.58, accuracy = 0.77
######################## Epoch 2018 - Batch 1 ########################
IDs in batch 1: tensor([2052, 3018, 1443, 1909,  778, 3430, 3863, 3514, 1675,  257, 3427, 1156,
        1932, 3391, 1005, 2511])
Epoch: 2018, Training Loss: 0.06, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 2019 - Batch 1 ########################
IDs in batch 1: tensor([1860, 2660, 1866,  165, 3409, 1824, 2416, 2542, 3638, 2653,  315, 4149,
         252, 3572, 1199, 1185])
Epoch: 2019, Training Loss: 0.26, Validation Loss: 0.58, accuracy = 0.78
######################## Epoch 2020 - Batch 1 ########################
IDs in batch 1: tensor([2773, 2229, 1975,  815, 3270, 3771, 1420, 4022, 2244, 3031,  558,  394,
        1836, 1376, 4179, 2339])
Epoch: 2020, Training Loss: 0.24, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 2021 - Batch 1 ########################
IDs in batch 1: tensor([3480,  292, 3795, 3878,  833, 2285,  848, 1077, 2603, 3798, 1782, 2290,
        1295, 1016, 1128,  915])
Epoch: 2021, Training Loss: 0.08, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 2022 - Batch 1 ########################
IDs in batch 1: tensor([3962, 2666, 3968, 4174,  251, 4107, 1555, 4016, 3114, 4225, 3954, 1559,
        1960, 2466, 1812, 3771])
Epoch: 2022, Training Loss: 0.29, Validation Loss: 0.59, accuracy = 0.78
######################## Epoch 2023 - Batch 1 ########################
IDs in batch 1: tensor([1650,  422, 2459,  688,  372, 1722, 2092, 4222,  622,   32, 4039, 2356,
         838, 1498, 3853, 3647])
Epoch: 2023, Training Loss: 0.13, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2024 - Batch 1 ########################
IDs in batch 1: tensor([1133, 3037, 2210, 1393,  613, 3143, 2493,  899, 2521, 2859, 1751,  534,
        2362, 1364, 1567, 3132])
Epoch: 2024, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2025 - Batch 1 ########################
IDs in batch 1: tensor([1794,  265, 2809, 2796, 4263, 3723, 1894, 3127, 1548,   86,  981, 1589,
        2598, 4055,  466, 4254])
Epoch: 2025, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2026 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 3721, 2641, 3870, 3743, 1330, 3303, 1574, 2919,  358, 3208,  752,
        3738, 1042, 1953, 1858])
Epoch: 2026, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2027 - Batch 1 ########################
IDs in batch 1: tensor([1732, 2256, 2494, 3219,  519, 3528, 1857,  193, 3781, 1825, 3700, 2606,
        3337, 1082, 3836, 2700])
Epoch: 2027, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2028 - Batch 1 ########################
IDs in batch 1: tensor([1321, 2682, 1803,  541, 1014, 2086, 3896, 1263, 3660, 1056,  494, 3375,
        3255,  228, 3203, 2121])
Epoch: 2028, Training Loss: 0.15, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2029 - Batch 1 ########################
IDs in batch 1: tensor([ 968, 3139, 1955,  913, 2110, 3077,  274, 3038,  635, 2378,  127,  863,
        2777, 2536, 2063, 1948])
Epoch: 2029, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2030 - Batch 1 ########################
IDs in batch 1: tensor([1125, 1257, 1007, 3310,  133, 1455,  305, 3628,  640, 3516, 1035, 2085,
        3014,  966, 2886, 2191])
Epoch: 2030, Training Loss: 0.32, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2031 - Batch 1 ########################
IDs in batch 1: tensor([1728, 3585,  632, 4087, 1090,  196,  390, 3298, 1551, 2709, 3746,  881,
        2568, 3961,  397, 3652])
Epoch: 2031, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2032 - Batch 1 ########################
IDs in batch 1: tensor([1370,  736, 3932,  357,  512,  119, 2924, 3886, 2734, 1016, 1589, 4117,
         985, 1404, 1822,  128])
Epoch: 2032, Training Loss: 0.37, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2033 - Batch 1 ########################
IDs in batch 1: tensor([3098,  140, 2577, 3226, 3216, 4205, 4138, 2761, 3821,  251, 3342, 2578,
        1070, 1868, 3458,  949])
Epoch: 2033, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2034 - Batch 1 ########################
IDs in batch 1: tensor([3997, 2548,  425, 3557, 3643,  620, 2095, 3719, 2978, 2646, 1620, 3751,
        4187,  732, 3110, 3199])
Epoch: 2034, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2035 - Batch 1 ########################
IDs in batch 1: tensor([2770, 2406, 4006, 1397, 3473, 2562, 1909, 4189, 2669, 3637, 3568, 3674,
        3407, 3836, 3677, 2624])
Epoch: 2035, Training Loss: 0.62, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 2036 - Batch 1 ########################
IDs in batch 1: tensor([2844, 2711,  894, 3135, 3101, 2249, 2327, 3017, 3975,  888, 3932, 3283,
         368, 2375,  603,  409])
Epoch: 2036, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2037 - Batch 1 ########################
IDs in batch 1: tensor([2824,  546, 4165, 2659, 1493,  568, 1967,  467, 2157,  602, 4124, 3132,
        1216, 2538, 4251,  701])
Epoch: 2037, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2038 - Batch 1 ########################
IDs in batch 1: tensor([1178,  730,  954, 2700,  578, 2650,  228, 1365,   38, 3452, 2353, 2391,
           5, 2005, 3516,  710])
Epoch: 2038, Training Loss: 0.20, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2039 - Batch 1 ########################
IDs in batch 1: tensor([1397,  844,  822, 2969, 1218, 2863, 1595,  723,  565, 1428, 1022,  645,
        3914, 2375, 1208,  725])
Epoch: 2039, Training Loss: 0.54, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2040 - Batch 1 ########################
IDs in batch 1: tensor([ 826, 1728,  756, 3732, 2309, 4056, 2002, 3310,  546,  206, 1974,  437,
        3589,  223,  401, 2659])
Epoch: 2040, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2041 - Batch 1 ########################
IDs in batch 1: tensor([2176,  375,  290, 3495,  665,  150, 1166, 3709, 2360, 2940, 3557, 1209,
        3991, 2428, 4224, 1434])
Epoch: 2041, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2042 - Batch 1 ########################
IDs in batch 1: tensor([ 522, 2144,  632,  305,  682, 2480, 3997,  735, 2901,  122, 3935, 3083,
          35, 1032, 2579,  874])
Epoch: 2042, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2043 - Batch 1 ########################
IDs in batch 1: tensor([2504, 3732, 3185,  646,  441, 3312, 2950, 2706, 2348,  829,  237,  109,
        4099, 2199, 1858,  277])
Epoch: 2043, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2044 - Batch 1 ########################
IDs in batch 1: tensor([3778, 3831, 4080, 2819, 2326, 2099, 3583, 3667, 3956, 3888, 3671, 1891,
        1110, 2223, 3373, 1990])
Epoch: 2044, Training Loss: 0.82, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2045 - Batch 1 ########################
IDs in batch 1: tensor([2271, 1346, 3932, 1083, 4061, 2401, 2420,  976,   18, 1223, 1146, 2085,
        4101, 2563, 3637,  474])
Epoch: 2045, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2046 - Batch 1 ########################
IDs in batch 1: tensor([ 607,  258, 3387, 2572, 4058, 2011,  612, 1223, 4264, 2016, 3532, 3022,
        3537, 3763,  815,  247])
Epoch: 2046, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2047 - Batch 1 ########################
IDs in batch 1: tensor([1949,  109, 1159, 1335, 3581, 3030, 4070, 3933, 2775, 3907, 2659, 1037,
        2180, 2203, 2453, 2963])
Epoch: 2047, Training Loss: 0.15, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2048 - Batch 1 ########################
IDs in batch 1: tensor([2018, 3214, 2253, 3313,  282, 1045,  642, 3029, 2523, 2885, 3147, 3863,
        1710,  626, 3226, 1497])
Epoch: 2048, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2049 - Batch 1 ########################
IDs in batch 1: tensor([2252, 3572, 1131,  588, 4203, 2721, 2356,   49, 2065,  631, 1139, 2522,
        2729, 1128, 3184,  797])
Epoch: 2049, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2050 - Batch 1 ########################
IDs in batch 1: tensor([3990, 1354, 1235, 2936, 2493, 3083, 3669, 2040, 3318, 2583, 2882, 1960,
        2711, 2107, 3908,  914])
Epoch: 2050, Training Loss: 0.17, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2051 - Batch 1 ########################
IDs in batch 1: tensor([3109, 1846, 2339,  377,  343, 1116,  646, 3236, 3091, 2192,  679, 4218,
         308, 3719, 2467, 1337])
Epoch: 2051, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2052 - Batch 1 ########################
IDs in batch 1: tensor([3958, 4255,  337, 3161, 2697, 1045, 2676, 3311, 3216,  425, 2538, 1521,
        2364, 3863, 3947,  265])
Epoch: 2052, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2053 - Batch 1 ########################
IDs in batch 1: tensor([1817, 2562,  586, 3015, 3072,  212, 1832, 1789,  290,  430, 1675, 1056,
        1082, 2401, 1101, 1649])
Epoch: 2053, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2054 - Batch 1 ########################
IDs in batch 1: tensor([ 511, 2925, 2341, 3234, 4154, 2328, 3300, 2819, 3200, 1650, 2606, 3638,
        1826, 2931, 2638, 1808])
Epoch: 2054, Training Loss: 0.42, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2055 - Batch 1 ########################
IDs in batch 1: tensor([2695,  359, 2883, 1521,  466, 3429, 2579,  278,   31,  358, 1098, 2980,
        2964, 2123, 1213,   28])
Epoch: 2055, Training Loss: 0.28, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2056 - Batch 1 ########################
IDs in batch 1: tensor([3427, 1226,  809, 1041, 3468, 2650, 1276,  534,  413,  154, 3264,  758,
        4010,  563, 3342, 3339])
Epoch: 2056, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2057 - Batch 1 ########################
IDs in batch 1: tensor([1823, 1367, 4220, 4096,  180, 1223, 2113,  411, 2793, 1825, 1010, 4229,
         533,  994, 1526, 2272])
Epoch: 2057, Training Loss: 0.15, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2058 - Batch 1 ########################
IDs in batch 1: tensor([1731, 1272,  110, 2537, 3399,  317, 1773,  727, 1711, 3298,  946, 3969,
        3548, 2680, 2886, 2847])
Epoch: 2058, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2059 - Batch 1 ########################
IDs in batch 1: tensor([2681, 1279, 1452, 2356, 2282,  934,  833, 1993, 3593, 2825, 2692, 4179,
        1011, 1921, 1374,  855])
Epoch: 2059, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2060 - Batch 1 ########################
IDs in batch 1: tensor([2049,  193, 3938, 3914, 4263,  390, 1925, 2614, 2683,  729, 3447, 2285,
        1639, 2153, 3534, 3885])
Epoch: 2060, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2061 - Batch 1 ########################
IDs in batch 1: tensor([4027,  896, 3958, 3919, 2446, 2210, 2835, 1047, 1471, 2976,  515, 2522,
        2249, 3717, 2284, 1825])
Epoch: 2061, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2062 - Batch 1 ########################
IDs in batch 1: tensor([3541,  340, 2063,  602, 3465, 1429,  173,  713,  863,  295, 1297, 1573,
         188, 2746,  609, 1341])
Epoch: 2062, Training Loss: 0.39, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2063 - Batch 1 ########################
IDs in batch 1: tensor([ 137, 2555, 1647, 1745, 2495,  666, 2277, 3214, 1272, 4236, 2027, 2237,
         514, 2980,  701, 1186])
Epoch: 2063, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2064 - Batch 1 ########################
IDs in batch 1: tensor([3006,  941, 2462, 3483,  454, 3969, 1982, 1455,  990, 3017, 1178,  842,
         896,  924, 3318, 3391])
Epoch: 2064, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2065 - Batch 1 ########################
IDs in batch 1: tensor([3816, 1263, 3492, 2151, 3356,  306, 4253,  475, 1796, 4189, 1661, 3557,
         483,  613, 2447,  121])
Epoch: 2065, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2066 - Batch 1 ########################
IDs in batch 1: tensor([1881, 2359, 3731,  244,    5, 3926, 2306, 3976, 2022, 1249, 4024, 1383,
        2304, 2328, 4101, 4136])
Epoch: 2066, Training Loss: 0.23, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2067 - Batch 1 ########################
IDs in batch 1: tensor([3557, 3052, 3197, 3207, 3282,  596, 2212,  333, 3701, 2039, 3777, 3614,
        2035, 3204, 2169, 1859])
Epoch: 2067, Training Loss: 0.39, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2068 - Batch 1 ########################
IDs in batch 1: tensor([1731, 1118, 2244, 2444,  322, 3715, 2870,  724,  968, 2578, 2678, 4204,
        3927,  393, 3919, 3242])
Epoch: 2068, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2069 - Batch 1 ########################
IDs in batch 1: tensor([1525, 4125,  651, 3426, 3818, 4175, 3903, 2257,  689, 4170,   26, 2949,
        2854, 1421,  639, 1332])
Epoch: 2069, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2070 - Batch 1 ########################
IDs in batch 1: tensor([2517, 1519,  954,  895, 3060, 2710,  507,  864, 2074, 4062, 1039,  846,
        2980, 4035, 2672, 3643])
Epoch: 2070, Training Loss: 0.14, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2071 - Batch 1 ########################
IDs in batch 1: tensor([1302, 2517, 2462, 2519,  409, 3983, 3042,  846, 3698,   32, 2373, 2146,
         195,  773, 2241, 3345])
Epoch: 2071, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2072 - Batch 1 ########################
IDs in batch 1: tensor([2373, 1521, 2555, 1234, 2615, 3379, 1798, 1716, 2220, 2347, 3905,  844,
        2103, 2448, 3044, 1897])
Epoch: 2072, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2073 - Batch 1 ########################
IDs in batch 1: tensor([3036, 3428, 2357, 1975, 3753, 1451, 3109, 3609, 2103, 3603, 3772, 2577,
        2804, 1636, 2118, 3397])
Epoch: 2073, Training Loss: 0.44, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2074 - Batch 1 ########################
IDs in batch 1: tensor([1414, 2181, 3681, 1923,  251, 2086, 3351, 3220, 2428, 1229, 4249,  333,
        3300, 2123,  225,  225])
Epoch: 2074, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 2075 - Batch 1 ########################
IDs in batch 1: tensor([2417, 3020, 1747,  747, 3803, 2603, 2953, 2256, 2203, 3312, 1420, 1247,
         391,  640, 2829, 2052])
Epoch: 2075, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2076 - Batch 1 ########################
IDs in batch 1: tensor([3378, 3176, 1949, 4226, 2953, 2312, 3387, 3600, 3017, 4176,  688,  756,
        2088,  434, 2763, 3541])
Epoch: 2076, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2077 - Batch 1 ########################
IDs in batch 1: tensor([3334, 2049,  538, 1156,   61, 2650,  491,  133,   35, 3338, 1756, 1545,
        3996, 2571, 2510, 4212])
Epoch: 2077, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.74
######################## Epoch 2078 - Batch 1 ########################
IDs in batch 1: tensor([ 590, 2689, 3220, 1883, 2991,  131, 2853, 2836, 3516, 3239, 1459,  694,
        3530,  740, 3537, 1647])
Epoch: 2078, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 2079 - Batch 1 ########################
IDs in batch 1: tensor([ 990, 1067, 3390,  522, 4049, 3018,  485, 1325, 1869, 2344, 3351,  437,
        3936, 4230, 1319, 2895])
Epoch: 2079, Training Loss: 0.15, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 2080 - Batch 1 ########################
IDs in batch 1: tensor([2284, 1209, 3650, 4107, 1066, 2379, 1765, 3222, 1287, 1891, 2357, 2764,
        2125, 3790, 4115, 2379])
Epoch: 2080, Training Loss: 0.14, Validation Loss: 0.63, accuracy = 0.75
######################## Epoch 2081 - Batch 1 ########################
IDs in batch 1: tensor([3404, 1635, 2548, 2124, 2014, 4196, 2709, 3111, 1440,  148, 2915, 1183,
        2440, 2167, 1567,   39])
Epoch: 2081, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2082 - Batch 1 ########################
IDs in batch 1: tensor([2494, 4016, 2305, 2300, 1198, 4246, 4256, 3526, 2782, 1945, 3190, 2023,
        1660, 4238, 2437, 3235])
Epoch: 2082, Training Loss: 0.36, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2083 - Batch 1 ########################
IDs in batch 1: tensor([3109,  276, 3181, 3841,  843, 3742, 2574, 4149, 4086, 2455, 1833, 1195,
        3667, 1623, 2884, 1673])
Epoch: 2083, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2084 - Batch 1 ########################
IDs in batch 1: tensor([4224, 2579, 2241,   46, 1283,  758,  913,  106, 2073, 3314, 2056, 4057,
        3992,  574, 3545, 3408])
Epoch: 2084, Training Loss: 0.13, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2085 - Batch 1 ########################
IDs in batch 1: tensor([2717,  814,  490, 2296,   50,  126, 1171, 1766, 3511, 3557,  264,   35,
        2672, 1331, 3713, 1471])
Epoch: 2085, Training Loss: 0.13, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2086 - Batch 1 ########################
IDs in batch 1: tensor([2606, 3821,  546, 2748, 2692,  511, 1364, 2807, 2231, 1383, 4236, 1641,
        1952, 2309, 1361, 2542])
Epoch: 2086, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2087 - Batch 1 ########################
IDs in batch 1: tensor([2382, 2746, 1766, 1418, 1017,  217,  140,  563, 1175, 3636, 2950,   85,
         262, 3200, 1289, 2363])
Epoch: 2087, Training Loss: 0.13, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2088 - Batch 1 ########################
IDs in batch 1: tensor([2921,  954, 4048, 1712, 2563,   82,  809, 1014, 1972, 2018, 1546, 3399,
        1620,  252,  177,  913])
Epoch: 2088, Training Loss: 0.25, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2089 - Batch 1 ########################
IDs in batch 1: tensor([3637, 3444, 2248, 1045, 2936, 2097,  363, 4097, 2344,  417, 2375, 3912,
         602, 2691, 3177, 2516])
Epoch: 2089, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2090 - Batch 1 ########################
IDs in batch 1: tensor([3503, 1740, 2052, 2213, 1333, 2619, 3733, 3128, 1545, 3898,  961, 3139,
        3108, 3593,  921, 2185])
Epoch: 2090, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2091 - Batch 1 ########################
IDs in batch 1: tensor([3470, 1602, 2016, 2957,  550, 4057, 1443, 1569, 2334,  507, 2624, 1846,
         613, 2457, 2117,  926])
Epoch: 2091, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2092 - Batch 1 ########################
IDs in batch 1: tensor([2109, 2781,  776, 3504, 4105, 1337,  846, 4203, 2895, 3628,  182,  359,
        1020, 2249, 2597, 3010])
Epoch: 2092, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2093 - Batch 1 ########################
IDs in batch 1: tensor([ 394,  833, 2002,  517, 1536, 2188, 3200, 1365, 2431, 1318, 1341,  407,
         325, 2022, 3865, 1007])
Epoch: 2093, Training Loss: 0.27, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2094 - Batch 1 ########################
IDs in batch 1: tensor([ 982,  368,  887, 2115, 1670, 2968, 1599, 2149,  170, 3534,  530, 2763,
        3474, 3177, 1639, 3257])
Epoch: 2094, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2095 - Batch 1 ########################
IDs in batch 1: tensor([1665, 4251, 3421, 2218,  763,  181, 3747, 1682, 2999, 1370, 2605,  138,
         320, 1137,   77, 1716])
Epoch: 2095, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2096 - Batch 1 ########################
IDs in batch 1: tensor([2223,  651, 4253, 2480, 1507, 4126, 1795,  401, 3352,  393, 2026, 3159,
         809,   15,  312, 1125])
Epoch: 2096, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2097 - Batch 1 ########################
IDs in batch 1: tensor([2449, 1546, 2313,   74, 2838,  333, 1766,  738, 1536,   30, 3098, 2963,
        1176,  662,  214, 2253])
Epoch: 2097, Training Loss: 0.12, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2098 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 3254,  603, 1646, 1851, 1779,  432, 2382,  341,  478, 1526, 2453,
        3822, 1472, 2835, 1904])
Epoch: 2098, Training Loss: 0.16, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2099 - Batch 1 ########################
IDs in batch 1: tensor([ 455,  312,  534, 3983,  913, 1166,  287, 2066, 1506, 2886, 3962, 3156,
         891, 4176, 1613, 1251])
Epoch: 2099, Training Loss: 0.15, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2100 - Batch 1 ########################
IDs in batch 1: tensor([ 991, 4144, 3603,  373, 3075, 1545, 1030, 1252, 3902, 4256, 1249,  779,
        2017, 3971, 1914, 3538])
Epoch: 2100, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2101 - Batch 1 ########################
IDs in batch 1: tensor([1297, 1723, 3969, 2365, 2891, 2924, 4228, 3244, 1789, 2019,  673,  635,
         219, 1056, 1023, 3715])
Epoch: 2101, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2102 - Batch 1 ########################
IDs in batch 1: tensor([3746, 3077, 1274, 2951,  717, 1406, 3109, 2732, 2231, 2070, 2758, 1853,
        1927, 1945,  758,   37])
Epoch: 2102, Training Loss: 0.22, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2103 - Batch 1 ########################
IDs in batch 1: tensor([1668, 1923, 1673,   95, 2969,  771, 2854,  751,  154, 1317, 4257, 1812,
        3742,  365, 3256, 4051])
Epoch: 2103, Training Loss: 0.23, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2104 - Batch 1 ########################
IDs in batch 1: tensor([3466,  191, 2709, 1122, 2078, 1255, 1777, 4263, 2011, 3270, 1281,  334,
        2621, 4030, 2741, 1365])
Epoch: 2104, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2105 - Batch 1 ########################
IDs in batch 1: tensor([2018, 1774,   98,  278, 1385, 3934, 1101, 4085, 3160, 2586,   72, 2056,
        4185,  870, 3353, 1799])
Epoch: 2105, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2106 - Batch 1 ########################
IDs in batch 1: tensor([1248, 1518, 3614, 1365, 2366, 4232,  682, 2046, 2535, 1673, 3527,  412,
        3306,  797,  657, 2281])
Epoch: 2106, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2107 - Batch 1 ########################
IDs in batch 1: tensor([2183, 2019,  709, 3244, 2027, 2603, 3423, 2553,  389,  396, 3963, 3977,
        3503, 2582, 1349, 2447])
Epoch: 2107, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2108 - Batch 1 ########################
IDs in batch 1: tensor([2711, 4058,  582, 2514, 1555, 2315, 1636, 2970,   71, 1720, 4184, 4014,
         947,  919, 3985, 4251])
Epoch: 2108, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2109 - Batch 1 ########################
IDs in batch 1: tensor([3891, 2725,  173, 1817, 2890, 1162, 3954, 3234, 1279, 1636, 1425,  362,
         387, 1467, 3568, 2526])
Epoch: 2109, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2110 - Batch 1 ########################
IDs in batch 1: tensor([3369, 2331,  863, 3016, 1185, 1396,  335, 2499, 2446, 2064, 3345, 3656,
        3456, 3304, 2617, 2442])
Epoch: 2110, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2111 - Batch 1 ########################
IDs in batch 1: tensor([3131, 2119, 3354, 2674, 1244, 3101, 2772,  739, 3886, 3132, 2475, 1600,
        2751, 1032, 3818, 4265])
Epoch: 2111, Training Loss: 0.13, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2112 - Batch 1 ########################
IDs in batch 1: tensor([  62, 1290,  360, 2976, 3219, 3441, 1641, 2997, 3765,  128, 3836, 2780,
         583, 3632, 4022, 3975])
Epoch: 2112, Training Loss: 0.07, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2113 - Batch 1 ########################
IDs in batch 1: tensor([3233,  578, 1284, 4057, 1736, 3339, 4161,   81, 1596,  126, 3544,    4,
        3375, 3135, 1087, 2059])
Epoch: 2113, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2114 - Batch 1 ########################
IDs in batch 1: tensor([3233,  491, 2956, 2185, 3321, 2122, 2605, 2614, 2334, 1024, 2142, 3490,
        4099, 3485, 2537, 2414])
Epoch: 2114, Training Loss: 0.49, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2115 - Batch 1 ########################
IDs in batch 1: tensor([3973, 3183, 3568,  411, 2938, 1097,  825,  520, 4205, 1968, 3933, 1754,
        1510, 2207, 4078,  523])
Epoch: 2115, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2116 - Batch 1 ########################
IDs in batch 1: tensor([ 788, 1740, 3284,  456, 2299, 1242, 2301, 1279, 1417, 1178, 3554,  950,
        2010, 3277, 2798, 3017])
Epoch: 2116, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2117 - Batch 1 ########################
IDs in batch 1: tensor([2339,  330, 3970, 3010, 1197, 1772, 1636, 2198, 4190, 4003, 1634,    4,
        1276, 4122, 2237, 2475])
Epoch: 2117, Training Loss: 0.15, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2118 - Batch 1 ########################
IDs in batch 1: tensor([3895, 1778, 3499, 1155, 1426,  790, 1083, 4166, 3506, 4152,  841,  839,
        3731, 1067, 1511, 3815])
Epoch: 2118, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2119 - Batch 1 ########################
IDs in batch 1: tensor([2154, 3261, 1128, 2508, 3370, 2385, 1104, 2708, 3972, 2195, 1390,  796,
        1551, 1406,  659, 1296])
Epoch: 2119, Training Loss: 0.26, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2120 - Batch 1 ########################
IDs in batch 1: tensor([ 212, 1823,  596, 3998,  808, 3358, 1333,  101, 3108, 2562, 3933, 1081,
        2546, 2135, 3733, 4065])
Epoch: 2120, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2121 - Batch 1 ########################
IDs in batch 1: tensor([1140, 3002, 3355, 3029, 2915, 1855, 2013, 3568, 1883,   60, 2905, 2522,
        3244, 1328, 3779, 1624])
Epoch: 2121, Training Loss: 0.23, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2122 - Batch 1 ########################
IDs in batch 1: tensor([1833, 2726,  960, 4116, 2796, 3151,  120,  314, 2107,  821, 1060, 2417,
        3002, 2040,  609, 3286])
Epoch: 2122, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2123 - Batch 1 ########################
IDs in batch 1: tensor([1007, 1264, 2230, 1546, 2157, 3872, 2265,   28, 3133, 2036, 2040, 3807,
        2410,  417, 2823, 2066])
Epoch: 2123, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2124 - Batch 1 ########################
IDs in batch 1: tensor([ 936,  888, 1605,   84,  733, 1094,   21, 3573,  226, 3598, 4251, 1633,
        4152, 3374, 1841,  897])
Epoch: 2124, Training Loss: 0.49, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2125 - Batch 1 ########################
IDs in batch 1: tensor([ 988,  112, 4265, 1726, 2328, 3543,  636, 2899, 2839, 2950, 1896, 2108,
        1933,   84, 3036, 4159])
Epoch: 2125, Training Loss: 0.36, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2126 - Batch 1 ########################
IDs in batch 1: tensor([1793, 2341, 1158, 3977, 3838, 2346, 3466, 3496, 3395, 3084,  830, 1143,
        3818,  985,  749, 1911])
Epoch: 2126, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2127 - Batch 1 ########################
IDs in batch 1: tensor([1337,  852,  103, 2107, 2663, 2680,  497, 2853,  182,   38,   97, 3954,
        2141, 4035, 2390,  777])
Epoch: 2127, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2128 - Batch 1 ########################
IDs in batch 1: tensor([3525, 1596, 3471, 1982, 2090, 3262, 3342, 3216,  941, 4067, 2797, 1640,
        3987, 3660,  835, 3723])
Epoch: 2128, Training Loss: 0.39, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2129 - Batch 1 ########################
IDs in batch 1: tensor([3042, 2736,  143, 3827, 1228, 2745, 3371, 1772,  649, 2841, 3535,  602,
        3268, 1016,  649, 1918])
Epoch: 2129, Training Loss: 0.09, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2130 - Batch 1 ########################
IDs in batch 1: tensor([ 462, 2461, 2262, 3942, 1932,  239, 2477,  122, 3031, 1384, 3697,  411,
         351, 1779, 1267, 1113])
Epoch: 2130, Training Loss: 0.26, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2131 - Batch 1 ########################
IDs in batch 1: tensor([ 487, 3982, 3385, 1051, 2942, 1478, 3200, 2049, 3437, 1880,  841, 1981,
        1453, 3388, 1677, 1804])
Epoch: 2131, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2132 - Batch 1 ########################
IDs in batch 1: tensor([2204,  857, 4107, 4068, 2879, 2275, 2371, 4016, 1260, 1343,  949, 3024,
         531, 2207, 2615,  394])
Epoch: 2132, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2133 - Batch 1 ########################
IDs in batch 1: tensor([4093,  565, 1122, 2908,  767, 4078,   85, 3760,   62, 3432,  334, 4176,
        3220, 2035, 3438, 1309])
Epoch: 2133, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2134 - Batch 1 ########################
IDs in batch 1: tensor([3832, 2833, 3051,  968, 2696, 3394, 3075, 1163, 3539, 3128, 3272, 1133,
        3200, 1007, 2249, 2482])
Epoch: 2134, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2135 - Batch 1 ########################
IDs in batch 1: tensor([3710, 4069, 3098, 3934, 2278,  232,  223, 3675, 3505,  287, 2338,  736,
        1887,  751, 2135, 2483])
Epoch: 2135, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2136 - Batch 1 ########################
IDs in batch 1: tensor([2316, 3500,  827, 1927,  378, 2170, 2701,  394, 2360, 2729, 4007, 3897,
        2646,   63, 3223, 3120])
Epoch: 2136, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2137 - Batch 1 ########################
IDs in batch 1: tensor([1085, 1955, 2511, 3128, 1651, 2853,  505, 3185, 1766, 1949, 3427,  305,
        4107, 1263, 1920,  207])
Epoch: 2137, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2138 - Batch 1 ########################
IDs in batch 1: tensor([1762, 2780,  989,  498,  523,  444, 1124,  152, 3211, 4107, 1383, 2436,
         981, 2415, 1347, 2880])
Epoch: 2138, Training Loss: 0.27, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2139 - Batch 1 ########################
IDs in batch 1: tensor([1959,  593, 4075, 1372, 1113,  895, 3823, 2069, 3834, 1345, 4121, 3052,
        2584, 3765, 1158, 4234])
Epoch: 2139, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2140 - Batch 1 ########################
IDs in batch 1: tensor([3783, 2670,  371, 3676, 2386,  147, 2003,  652, 3975, 1374, 3981,  419,
        2953, 1233, 3119, 2166])
Epoch: 2140, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2141 - Batch 1 ########################
IDs in batch 1: tensor([ 687, 3985, 4015, 3471, 3816,  607,  220, 4093, 3117,   99, 3334, 1840,
        2355, 4213, 2741, 1239])
Epoch: 2141, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2142 - Batch 1 ########################
IDs in batch 1: tensor([1502, 1931, 1960,  758, 3883,  871, 3399, 2489, 3298,  623, 2748, 2708,
         830, 1774, 3363, 1216])
Epoch: 2142, Training Loss: 0.13, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2143 - Batch 1 ########################
IDs in batch 1: tensor([ 751, 1459,  332, 1183, 1020,  396, 2867,  779, 3126, 2678, 1579, 2110,
        2851, 2166, 2660, 3718])
Epoch: 2143, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2144 - Batch 1 ########################
IDs in batch 1: tensor([ 265,  640, 1365, 1141, 3642, 3456, 2879,  776, 3003,  202, 3117, 2069,
        3599,  312, 1693, 2841])
Epoch: 2144, Training Loss: 0.21, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2145 - Batch 1 ########################
IDs in batch 1: tensor([2257, 1050, 2104, 3998,  405, 2789, 3974, 2617, 1904,  396,  887, 4113,
         584, 2431,  949, 1037])
Epoch: 2145, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2146 - Batch 1 ########################
IDs in batch 1: tensor([2715, 1206, 1540, 1312, 1718, 1840, 1082,  786, 1290,  530,  141,  376,
        1612,  937, 3493, 3882])
Epoch: 2146, Training Loss: 0.56, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2147 - Batch 1 ########################
IDs in batch 1: tensor([3765, 1650,  949, 2649, 4264, 1886, 2353, 1266, 1726,  766, 3098, 2217,
        1774, 2732, 2860, 3004])
Epoch: 2147, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2148 - Batch 1 ########################
IDs in batch 1: tensor([2478, 2271,  990,  485, 3309, 1070, 3920, 3401, 3698,  445,  902, 4149,
        2369, 1485, 2415, 2999])
Epoch: 2148, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2149 - Batch 1 ########################
IDs in batch 1: tensor([  72,  202, 3785, 1198, 3746, 3157, 2856, 4127, 1377, 1371, 2108, 4189,
          72, 2477,  541, 1566])
Epoch: 2149, Training Loss: 0.09, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2150 - Batch 1 ########################
IDs in batch 1: tensor([1146, 1611, 1601, 3585, 4011,  327, 2466, 2572,  432, 3956, 1521, 3771,
        2192, 3714, 3248, 2540])
Epoch: 2150, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2151 - Batch 1 ########################
IDs in batch 1: tensor([1982,  265,  758, 1594, 1913, 2385, 2167,  206, 1420, 2872,  967, 4131,
        2056,  875, 3707, 1495])
Epoch: 2151, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2152 - Batch 1 ########################
IDs in batch 1: tensor([1555, 3743, 1454, 3598,  397, 3553, 1911, 3945, 3010, 3470, 1081, 2339,
         804, 4055, 2230, 2493])
Epoch: 2152, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2153 - Batch 1 ########################
IDs in batch 1: tensor([2272, 3767,  871,  292, 3162, 3340,  378, 3362, 2400, 1953, 3016, 2400,
         344, 1286, 3802, 3005])
Epoch: 2153, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2154 - Batch 1 ########################
IDs in batch 1: tensor([3841, 2807, 2544,   42, 3928, 2902,  260, 1810, 2617, 4175, 2645, 4049,
        2099,  907, 3216, 3176])
Epoch: 2154, Training Loss: 0.35, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2155 - Batch 1 ########################
IDs in batch 1: tensor([2444, 1626, 3112, 3441, 2632, 1319, 2185, 3523,  895, 1260, 1857, 3493,
        1641,  494, 2261, 2249])
Epoch: 2155, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2156 - Batch 1 ########################
IDs in batch 1: tensor([2241,  770,  452,  718, 2708,  656, 1349,  833, 3746, 2312, 2586, 2738,
        4240, 3150, 2320, 1232])
Epoch: 2156, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2157 - Batch 1 ########################
IDs in batch 1: tensor([3078,  245, 3460, 2167, 1599, 3256, 2688, 3742, 3342, 3047, 1050, 1087,
        2723, 1809,  639, 3988])
Epoch: 2157, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2158 - Batch 1 ########################
IDs in batch 1: tensor([3179,  578, 2287, 2823, 1080, 4181, 1933, 1285, 1041, 3042, 4053,  776,
        4173,  260, 3531, 3858])
Epoch: 2158, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2159 - Batch 1 ########################
IDs in batch 1: tensor([ 985, 4212,   10,  870, 1132,  126,  666,  283, 2418, 1204, 3003, 2169,
        4073,  584,  346, 1225])
Epoch: 2159, Training Loss: 0.54, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2160 - Batch 1 ########################
IDs in batch 1: tensor([1170, 4002, 2743, 3182, 3459, 1279,  122, 3144, 1993,  632, 2936,  327,
        1685, 2466,  757,  595])
Epoch: 2160, Training Loss: 0.17, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2161 - Batch 1 ########################
IDs in batch 1: tensor([1657, 2457,  275, 1111, 1644, 2905, 1957, 3624, 3925, 3569, 2552, 2358,
        3161, 4126, 1568, 3554])
Epoch: 2161, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2162 - Batch 1 ########################
IDs in batch 1: tensor([1524, 1590, 3933, 2863, 4197, 3797, 2872,  989, 2022,  850, 1097, 3856,
         631, 1153,  926, 3847])
Epoch: 2162, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2163 - Batch 1 ########################
IDs in batch 1: tensor([2149, 1473, 3326, 1844, 3430,  872,  683, 2771, 2257, 2183, 3838, 2526,
        3912,  891, 4077, 2086])
Epoch: 2163, Training Loss: 0.08, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2164 - Batch 1 ########################
IDs in batch 1: tensor([3044, 1111, 2437, 2356, 1613, 2841,  412, 4026,  518,  656, 3942, 2051,
        1501, 4181, 1357, 1195])
Epoch: 2164, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2165 - Batch 1 ########################
IDs in batch 1: tensor([ 895, 1213, 3711, 1413, 2060, 2393, 4148, 3674,  277, 2562, 1380, 3950,
        1007, 1473,  658,  788])
Epoch: 2165, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2166 - Batch 1 ########################
IDs in batch 1: tensor([1596, 2433, 2537, 1851, 2575, 2180, 4141,  909, 2899, 3386, 3950, 3511,
        2414, 3105, 2398, 1118])
Epoch: 2166, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2167 - Batch 1 ########################
IDs in batch 1: tensor([ 530, 1498, 3873, 1730, 3351, 3113, 2324, 2506, 2246, 2871,  969, 3179,
        3391, 1849, 2954, 4069])
Epoch: 2167, Training Loss: 0.16, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2168 - Batch 1 ########################
IDs in batch 1: tensor([1067,  517,  964, 2030, 2342, 3308,  408, 3370, 3244, 1818, 2400,  762,
         874, 1975, 2934,  507])
Epoch: 2168, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2169 - Batch 1 ########################
IDs in batch 1: tensor([3356,  449,  161,  326,  338, 1174, 3323, 3135, 3719, 1306, 2661, 2791,
        3827,  325, 2212, 3872])
Epoch: 2169, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2170 - Batch 1 ########################
IDs in batch 1: tensor([ 206, 2189, 1643, 3767, 2003, 2433, 3700, 1844, 2960, 3363, 3075,  849,
         139, 3953,  170, 1628])
Epoch: 2170, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2171 - Batch 1 ########################
IDs in batch 1: tensor([ 626,   97,  396,  167, 2383, 1373, 2378, 3513, 2246, 3533, 3424, 1580,
        2860, 1237, 2349, 2890])
Epoch: 2171, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2172 - Batch 1 ########################
IDs in batch 1: tensor([2954, 4143, 2476, 1620,  557, 1786, 3150, 1322, 2638, 4230, 3885, 3144,
        2287, 1241, 2278, 2682])
Epoch: 2172, Training Loss: 0.08, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2173 - Batch 1 ########################
IDs in batch 1: tensor([2448, 2807,  832, 4056, 1467, 3390, 2538, 3676, 3936, 4228, 2444, 3409,
        2328, 3176, 3891,  287])
Epoch: 2173, Training Loss: 0.34, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2174 - Batch 1 ########################
IDs in batch 1: tensor([ 723, 2583, 3608, 2405, 3091, 2286, 1496,  679, 4214,  738, 3391, 1049,
        2664,  812, 2480, 4057])
Epoch: 2174, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2175 - Batch 1 ########################
IDs in batch 1: tensor([3680,  987, 2857, 3025, 1098, 1299, 3264, 3025, 1956, 3621, 2575, 1600,
        1971, 1332, 2369, 3530])
Epoch: 2175, Training Loss: 0.21, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2176 - Batch 1 ########################
IDs in batch 1: tensor([ 893, 1484,  809, 2795, 2036,  455, 2065, 3470,  949, 3963, 2073, 3570,
        1737, 4099, 4030, 1745])
Epoch: 2176, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2177 - Batch 1 ########################
IDs in batch 1: tensor([2386, 2905,  770, 1921, 2854, 2252, 1909, 3287,  236, 1011,  213, 1518,
         988, 1055, 3859, 2228])
Epoch: 2177, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2178 - Batch 1 ########################
IDs in batch 1: tensor([1190, 3047, 1452, 2499, 2463, 4085,  644, 4036, 3328, 1469, 1617, 4078,
        1396, 1219, 2655, 3904])
Epoch: 2178, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2179 - Batch 1 ########################
IDs in batch 1: tensor([2113, 4133, 1319,  947, 1760, 3793, 2798, 1990, 1773, 2752, 1773, 1885,
         104, 4077, 1798, 1980])
Epoch: 2179, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2180 - Batch 1 ########################
IDs in batch 1: tensor([ 165,  652, 2618,   99,  303, 1878,  186, 3763, 3664, 1948, 1841, 1176,
        2544,  463, 3656,  681])
Epoch: 2180, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2181 - Batch 1 ########################
IDs in batch 1: tensor([2884, 3664, 2235,   49, 3228,  155, 1269,  245, 1526, 1047, 1034, 3390,
        3306, 1111, 4140,  610])
Epoch: 2181, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2182 - Batch 1 ########################
IDs in batch 1: tensor([3845, 3543, 2312, 3190, 3368, 4068, 2545, 1650, 3199, 3433, 1704, 3178,
         232, 1579,  503,  316])
Epoch: 2182, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2183 - Batch 1 ########################
IDs in batch 1: tensor([2461, 3092, 3564, 1736, 3136, 1171, 3373,  229, 3651, 1570,   72, 3398,
        2514, 3592, 1623, 2783])
Epoch: 2183, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2184 - Batch 1 ########################
IDs in batch 1: tensor([4200, 2505, 1543, 3833, 3727, 3719, 1918, 3875, 3354,  263, 1540, 2618,
        4212, 2961, 1918, 2115])
Epoch: 2184, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2185 - Batch 1 ########################
IDs in batch 1: tensor([ 755, 1673,  496, 1755, 3006, 4011,  439, 1425,  149, 1638, 2669, 2558,
         212,  875,  709, 2402])
Epoch: 2185, Training Loss: 0.48, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2186 - Batch 1 ########################
IDs in batch 1: tensor([3328, 2441, 2056, 2991, 4069,  670, 1841, 3051, 1849,  755,   68, 4215,
        1278, 1080,   10, 1985])
Epoch: 2186, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2187 - Batch 1 ########################
IDs in batch 1: tensor([1920,  520, 3990, 3836,   46,  788, 2519,   18, 1569, 1073, 3148,  264,
         816, 3977, 2118, 2540])
Epoch: 2187, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2188 - Batch 1 ########################
IDs in batch 1: tensor([4168, 3733, 1763, 2885, 3930, 2545, 1904, 3206,  394, 3476, 1711, 1482,
        3329, 2839, 3236, 1798])
Epoch: 2188, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2189 - Batch 1 ########################
IDs in batch 1: tensor([3475, 2605,  660,  199, 3268, 2995,    7,  626, 1020,  121, 3945, 2013,
        3168, 2550,  756, 3505])
Epoch: 2189, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2190 - Batch 1 ########################
IDs in batch 1: tensor([2326,   95, 2256, 3378, 1167, 2337, 1383, 3378, 2247,  863, 3852, 1345,
        2617, 1370, 1344,  553])
Epoch: 2190, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2191 - Batch 1 ########################
IDs in batch 1: tensor([ 148, 3313, 4188, 2394, 1752,  257, 1050, 1610, 3105,  785, 1886, 1414,
        2038,  966, 2219, 2833])
Epoch: 2191, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2192 - Batch 1 ########################
IDs in batch 1: tensor([ 738, 3964,  223,  945, 1275, 2185,  547, 3891, 1443, 3604, 2907,  989,
        3651, 3802, 1524, 2475])
Epoch: 2192, Training Loss: 0.16, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2193 - Batch 1 ########################
IDs in batch 1: tensor([1574,  188, 1623, 3829, 3077,  662, 1425, 3271, 4101, 4085, 3395, 3993,
         623, 2375, 4125, 2489])
Epoch: 2193, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2194 - Batch 1 ########################
IDs in batch 1: tensor([2106, 1459,   32, 3693, 4146, 3495, 3813, 2323, 1794, 3836, 1869, 3614,
        3936, 4173,   81,  880])
Epoch: 2194, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2195 - Batch 1 ########################
IDs in batch 1: tensor([1495, 1595, 3869, 3376, 1604,  550, 3039, 3364, 2056, 1779, 3904, 3706,
        4245, 1722,  575, 3988])
Epoch: 2195, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2196 - Batch 1 ########################
IDs in batch 1: tensor([2670, 1665, 1894, 1292, 1619, 3484, 3683,  322,  333, 1197,  274, 3009,
        2276, 2450, 2199, 2837])
Epoch: 2196, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2197 - Batch 1 ########################
IDs in batch 1: tensor([2743, 3755, 3650, 2118, 1671, 1642, 3071,  281, 1724,  947,  498, 1226,
        3853,  586, 1937, 3437])
Epoch: 2197, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2198 - Batch 1 ########################
IDs in batch 1: tensor([3381, 3355, 1137, 1410, 2238, 2435, 2386, 3998, 3286, 3142, 1817, 1518,
        2346,  679,  198, 2516])
Epoch: 2198, Training Loss: 0.03, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2199 - Batch 1 ########################
IDs in batch 1: tensor([3099, 1134, 3087, 4018, 3503, 2180, 3540, 2019, 4179,  259, 3954, 1075,
        1214, 3506, 2823, 4220])
Epoch: 2199, Training Loss: 0.27, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2200 - Batch 1 ########################
IDs in batch 1: tensor([ 397, 2748,  735, 3182, 3250, 3329, 1183,  200, 1699, 2912, 3951, 3953,
        4181, 3371, 2465, 2065])
Epoch: 2200, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2201 - Batch 1 ########################
IDs in batch 1: tensor([2718, 2892, 1418, 2436, 2616, 2866, 1850, 3441,  788,  184, 4232, 3672,
        2761,  256, 2870, 1953])
Epoch: 2201, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2202 - Batch 1 ########################
IDs in batch 1: tensor([3947,  333, 1222, 3570, 3236, 1566, 3340, 1530, 4055, 3927,  826, 3832,
        1140, 1605, 1117, 2479])
Epoch: 2202, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2203 - Batch 1 ########################
IDs in batch 1: tensor([2579, 1764,  243, 3256, 1832, 2458, 2010, 2016, 4195, 2296, 2954, 1295,
        2447,  678, 1154, 3693])
Epoch: 2203, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2204 - Batch 1 ########################
IDs in batch 1: tensor([1681, 1693, 2758, 3604, 2966, 4212,  481, 2118,  636,  988,  837, 2783,
        2746, 4204, 3196,  518])
Epoch: 2204, Training Loss: 0.14, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2205 - Batch 1 ########################
IDs in batch 1: tensor([3223, 1409, 4245,  881, 4245, 1153,  773,  173, 2050, 2564, 2091, 1979,
         219,   59,  994, 1332])
Epoch: 2205, Training Loss: 0.21, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2206 - Batch 1 ########################
IDs in batch 1: tensor([3279, 1380,  837,  635,  514, 1352, 1454,  923, 3547, 1242, 1039, 3358,
        3528, 2410,  988,  964])
Epoch: 2206, Training Loss: 0.40, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2207 - Batch 1 ########################
IDs in batch 1: tensor([ 132,  701, 1092,  985, 2277, 1438, 3988, 1104,   18, 1633, 2382, 2178,
        2772, 4075, 1592, 2937])
Epoch: 2207, Training Loss: 0.14, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2208 - Batch 1 ########################
IDs in batch 1: tensor([2868,  341, 1756, 1894,  312, 1067, 2697,  709, 2092, 3557, 1745, 3932,
        1232, 2999, 2470, 3110])
Epoch: 2208, Training Loss: 0.12, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2209 - Batch 1 ########################
IDs in batch 1: tensor([3029, 3745,  863, 2334, 3836, 2871,  250, 3898, 3352, 3423, 4038, 1384,
        2362, 3234, 1056, 3223])
Epoch: 2209, Training Loss: 0.13, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2210 - Batch 1 ########################
IDs in batch 1: tensor([3250, 4163, 2969,  993, 2053, 1415, 3110, 3803,  577,  546, 1481, 1904,
        2280, 1042, 2854,  130])
Epoch: 2210, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.78
######################## Epoch 2211 - Batch 1 ########################
IDs in batch 1: tensor([ 193, 3589, 3136, 3989, 2603, 2780, 2996,  649, 2538, 4116,  379, 1415,
        2690, 2040, 3022, 1402])
Epoch: 2211, Training Loss: 0.03, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2212 - Batch 1 ########################
IDs in batch 1: tensor([1222, 1720, 1753, 1124, 1070, 2680, 1248, 2274, 3369, 4174, 1117, 2059,
          35,  841, 3839, 1638])
Epoch: 2212, Training Loss: 0.20, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2213 - Batch 1 ########################
IDs in batch 1: tensor([1822, 3287,  578, 2406, 1836, 3547, 2390, 3262, 2028, 3105, 1365,  182,
        1274, 2632,  995, 2011])
Epoch: 2213, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2214 - Batch 1 ########################
IDs in batch 1: tensor([1308, 3949, 2244,  326,  613, 3406, 2118, 3632,  367, 2039, 2800, 4204,
         450, 3900, 3142, 3642])
Epoch: 2214, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2215 - Batch 1 ########################
IDs in batch 1: tensor([4031, 3700,  818,  185, 4113,  566, 3778, 2483, 1588, 1923, 4088,  177,
        4168,  821, 2524, 2202])
Epoch: 2215, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2216 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 3485, 2354,  455,  139, 1152, 1900, 3183, 3075, 1656, 1444, 1102,
        2212, 3071, 3051, 3127])
Epoch: 2216, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.79
######################## Epoch 2217 - Batch 1 ########################
IDs in batch 1: tensor([1185, 1328, 1474, 3806, 3838, 3055,  470, 2895,  139, 1651, 3878, 1583,
        3599,  170, 2370, 1716])
Epoch: 2217, Training Loss: 0.23, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2218 - Batch 1 ########################
IDs in batch 1: tensor([2741, 1287, 3219,  269, 1957, 3449, 3993, 2439, 1141, 1098, 3900, 1834,
         412, 1309, 1258,  455])
Epoch: 2218, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2219 - Batch 1 ########################
IDs in batch 1: tensor([1909, 1451, 3485,  949,  426, 3425, 3630, 4152, 1778,  185, 1746, 1707,
         751, 1957, 1716,  609])
Epoch: 2219, Training Loss: 0.20, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2220 - Batch 1 ########################
IDs in batch 1: tensor([3874, 2115, 2195, 1952, 1627, 3111, 2506, 2951, 2726, 2663,  219, 2188,
          50, 2433, 3618, 2614])
Epoch: 2220, Training Loss: 0.40, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2221 - Batch 1 ########################
IDs in batch 1: tensor([ 871, 1120,   46, 3094, 1988, 1950, 2961, 2348, 3004, 3573, 1665, 1104,
        2124, 3052, 3367, 2056])
Epoch: 2221, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.79
######################## Epoch 2222 - Batch 1 ########################
IDs in batch 1: tensor([2382, 4108, 3192,  324, 3386, 2690, 1005, 1643, 1559, 3196,  408,   63,
        2041, 2719, 2452, 2412])
Epoch: 2222, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2223 - Batch 1 ########################
IDs in batch 1: tensor([3353, 1178,  921, 3275,  362, 1478, 4139,  225, 1786, 3031, 3242, 1028,
         139, 1921, 2312, 2234])
Epoch: 2223, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.78
######################## Epoch 2224 - Batch 1 ########################
IDs in batch 1: tensor([3113,  234, 2895, 4214, 3911, 2124, 3176, 3115,  470, 1990, 3624, 2583,
        4190, 1698, 1034, 3005])
Epoch: 2224, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.79
######################## Epoch 2225 - Batch 1 ########################
IDs in batch 1: tensor([ 471, 2231, 1414, 3110, 2670, 3987,   46, 2056, 2524,  993, 1887,  345,
        2783, 2833, 3447, 2343])
Epoch: 2225, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2226 - Batch 1 ########################
IDs in batch 1: tensor([ 834, 2178,   73, 2998, 2907, 3714, 1438,  841, 2718, 3084, 1960, 1340,
         220, 3406, 2161, 2329])
Epoch: 2226, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.79
######################## Epoch 2227 - Batch 1 ########################
IDs in batch 1: tensor([2701,   32, 1484, 1419, 4060,  274, 1250, 2617,   26, 2426, 4215,  348,
        1405, 3098, 1094,  632])
Epoch: 2227, Training Loss: 0.24, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2228 - Batch 1 ########################
IDs in batch 1: tensor([2191, 3648, 3343,  565, 2196, 4198, 2695, 1273, 1076, 3492,   59, 3132,
        1722, 2682, 3846,  491])
Epoch: 2228, Training Loss: 0.03, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2229 - Batch 1 ########################
IDs in batch 1: tensor([1495,  776, 2435, 3973,   21,  281,  882, 3398, 1347,  825, 1884, 4077,
        1370, 3939, 1642, 2242])
Epoch: 2229, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2230 - Batch 1 ########################
IDs in batch 1: tensor([  99, 3509, 2993, 3349, 1596,  147,  426, 3265, 1072, 2738,  607, 4005,
        2250, 4141, 2343, 2295])
Epoch: 2230, Training Loss: 0.02, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2231 - Batch 1 ########################
IDs in batch 1: tensor([3969, 3754,  317, 4140,  110, 1825,  812, 2285, 2921, 3663, 1072, 1782,
        1478,  723, 4255, 3589])
Epoch: 2231, Training Loss: 0.14, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2232 - Batch 1 ########################
IDs in batch 1: tensor([ 809,  832, 2108, 2072,   13,  680, 2925, 3697, 3673, 3207, 2418, 2368,
         323,  603, 2682,  606])
Epoch: 2232, Training Loss: 0.12, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2233 - Batch 1 ########################
IDs in batch 1: tensor([ 639,  991, 3590, 2229, 1707,  413, 1011, 1387, 2854, 2198, 2255, 3256,
        2368, 4159, 1195,  544])
Epoch: 2233, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2234 - Batch 1 ########################
IDs in batch 1: tensor([3425, 4118, 1176, 2362, 3733, 1991, 2838, 1853,  921, 2457, 3878, 2670,
        1325, 1937,  882, 1351])
Epoch: 2234, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2235 - Batch 1 ########################
IDs in batch 1: tensor([1061, 3751, 2028, 4161, 2876, 3948, 3374, 2213, 1255, 3942, 2182, 2016,
         265, 1545, 3127, 3521])
Epoch: 2235, Training Loss: 0.18, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2236 - Batch 1 ########################
IDs in batch 1: tensor([ 120,  316, 2676, 3885,  550, 3057, 1093,  167, 4217, 1613, 2509, 4232,
          98, 3131,  275, 4078])
Epoch: 2236, Training Loss: 0.20, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2237 - Batch 1 ########################
IDs in batch 1: tensor([2014, 4005, 1844, 3537, 2407,   60,   86, 2455, 1781,  382, 2855, 1270,
         292, 4135,   14, 1174])
Epoch: 2237, Training Loss: 0.03, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2238 - Batch 1 ########################
IDs in batch 1: tensor([ 515, 1745, 4246, 3793, 3233,  857, 2465, 2874, 3697,  465, 1855,  407,
        3256, 1623,  544,  555])
Epoch: 2238, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2239 - Batch 1 ########################
IDs in batch 1: tensor([2151, 3360, 2599, 3423, 2749,  330,  104, 2458,  879, 3778, 1770, 3588,
        3373, 3326, 2025, 3143])
Epoch: 2239, Training Loss: 0.19, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2240 - Batch 1 ########################
IDs in batch 1: tensor([1950, 3433, 1568, 4035, 1651,  732,  918, 1384, 1772, 3038, 1887, 2857,
         184, 2775, 1740,  659])
Epoch: 2240, Training Loss: 0.17, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2241 - Batch 1 ########################
IDs in batch 1: tensor([3471,   61, 3661, 2469,  843, 1896, 2212, 2709, 3591,  207, 4215, 3371,
        2254, 1199,  262,   27])
Epoch: 2241, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2242 - Batch 1 ########################
IDs in batch 1: tensor([2863, 1872, 3127, 1897, 1004, 4013,  923, 2087,  756, 2521, 2586, 1918,
        3729, 2386, 1405, 1628])
Epoch: 2242, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2243 - Batch 1 ########################
IDs in batch 1: tensor([2838, 1589,  593, 2312,  830, 3798, 2872, 2213,  295, 2177, 3710, 3954,
        3821, 2870, 2413, 2761])
Epoch: 2243, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2244 - Batch 1 ########################
IDs in batch 1: tensor([1648, 2968, 2831, 2709, 1005,  823, 4062,  988, 3375, 1305, 3951, 3947,
        1428, 3349, 3152,  962])
Epoch: 2244, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2245 - Batch 1 ########################
IDs in batch 1: tensor([1039,   39, 3536,  203,  796,  918, 1944, 1134,  930, 3128, 2782,  214,
        3897, 2358, 3027, 1226])
Epoch: 2245, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2246 - Batch 1 ########################
IDs in batch 1: tensor([3471, 4038,  726, 4242, 1686, 1121, 3610, 3865, 3223, 3160, 3743,   61,
        1335,  384, 3253, 1113])
Epoch: 2246, Training Loss: 0.05, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2247 - Batch 1 ########################
IDs in batch 1: tensor([3488, 3808,  263, 1097, 3648, 1746, 1693, 2511, 3499, 4205, 2420, 1817,
        1413, 2998,  679,  659])
Epoch: 2247, Training Loss: 0.03, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2248 - Batch 1 ########################
IDs in batch 1: tensor([2072, 1573, 1614, 1204, 1804,  224, 1223, 3000, 4184, 1524, 1335, 1646,
        4242,  109, 4011, 3020])
Epoch: 2248, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2249 - Batch 1 ########################
IDs in batch 1: tensor([ 544, 2483, 2645, 2690, 1349, 1724, 3587,  323, 2942,  678,  606, 2182,
        3920,  781, 1597, 1869])
Epoch: 2249, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2250 - Batch 1 ########################
IDs in batch 1: tensor([ 102, 4199, 1752, 2586, 2545, 2156, 1242, 3114, 1968, 1784, 2400, 2984,
         432, 1089,  857, 2638])
Epoch: 2250, Training Loss: 0.18, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2251 - Batch 1 ########################
IDs in batch 1: tensor([1567, 2600, 2664, 2522,  923, 1985, 3427, 2462, 1693,  334, 2080, 3298,
        2146, 2124,  969,   20])
Epoch: 2251, Training Loss: 0.03, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2252 - Batch 1 ########################
IDs in batch 1: tensor([1795, 2010,  292, 4016, 1042, 1236, 2299, 1140, 1212,  256, 1369, 2522,
        2447, 2476,  688, 2727])
Epoch: 2252, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2253 - Batch 1 ########################
IDs in batch 1: tensor([1059,  247, 1134, 4103, 1016, 1682, 1062, 2844, 4186,  788,  134, 3308,
        1334, 2561,  689, 2405])
Epoch: 2253, Training Loss: 0.34, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2254 - Batch 1 ########################
IDs in batch 1: tensor([3876, 3466, 3087, 2631, 3960,  826, 2783, 3590, 2153, 3922, 1686, 1841,
        3954,  306,  620, 3351])
Epoch: 2254, Training Loss: 0.19, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2255 - Batch 1 ########################
IDs in batch 1: tensor([1636,  289,  357, 3762,  167, 1143, 1657, 2586, 2276, 1295, 4006,   44,
        1496, 2238, 2874, 1526])
Epoch: 2255, Training Loss: 0.11, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2256 - Batch 1 ########################
IDs in batch 1: tensor([ 651, 2736, 2115, 4088,    5, 2752, 1408, 3743,  721,  854, 3746, 2473,
         538, 2005, 1510,  556])
Epoch: 2256, Training Loss: 0.29, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2257 - Batch 1 ########################
IDs in batch 1: tensor([ 136, 2104, 3418, 2676, 3414, 3406, 4229, 1085, 2553,  213, 4076, 2603,
        1937,  603, 3934, 3882])
Epoch: 2257, Training Loss: 0.47, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2258 - Batch 1 ########################
IDs in batch 1: tensor([3318, 1670,  382, 3009, 2297, 2316,  239, 2859,  594, 3732,  893,  834,
        2734, 3388, 1379, 3187])
Epoch: 2258, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2259 - Batch 1 ########################
IDs in batch 1: tensor([3055, 1097, 3975,   50, 2500, 1264,  962, 3872, 2448, 1645, 4002, 2492,
        3898,  434, 3242,  394])
Epoch: 2259, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2260 - Batch 1 ########################
IDs in batch 1: tensor([3267, 4198, 3638, 2087,  512,  718, 1840, 2524, 2300, 2676, 2627,  733,
         678, 2967, 1685, 1658])
Epoch: 2260, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2261 - Batch 1 ########################
IDs in batch 1: tensor([1932,  788,  147, 1481,  607, 4214, 1589, 2945, 4242,  362, 3179, 2478,
         993, 3404,  699, 1042])
Epoch: 2261, Training Loss: 0.12, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2262 - Batch 1 ########################
IDs in batch 1: tensor([3391,  602, 3727, 2606, 3939, 3688, 1060,  239, 1124,  295, 3989, 2871,
        1044,  263,  170, 1306])
Epoch: 2262, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2263 - Batch 1 ########################
IDs in batch 1: tensor([2567, 3879,  451, 2681, 2265, 4163, 2936, 4099, 3047,  985, 1884,   64,
        1623, 3728, 1031, 2036])
Epoch: 2263, Training Loss: 0.26, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2264 - Batch 1 ########################
IDs in batch 1: tensor([1014, 1414, 2085, 1453, 1196, 2926, 1006, 4220, 2483, 4038, 2832,  915,
         117,  993, 2942, 1828])
Epoch: 2264, Training Loss: 0.23, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2265 - Batch 1 ########################
IDs in batch 1: tensor([3345, 1214,  449,   51, 2825, 1782, 2827, 1022, 3444, 3407,  474, 1360,
        3208, 1275, 2416,  161])
Epoch: 2265, Training Loss: 0.03, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2266 - Batch 1 ########################
IDs in batch 1: tensor([ 787,  401, 2999, 1042,  899, 2275,  642, 2452, 2298, 3194, 3942, 2610,
         833, 1316, 2412, 2855])
Epoch: 2266, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2267 - Batch 1 ########################
IDs in batch 1: tensor([2464, 1639, 3079, 2433, 4075, 1428, 2348, 3615,  513, 2974, 1954,  741,
        3509, 1331, 3542, 2725])
Epoch: 2267, Training Loss: 0.12, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2268 - Batch 1 ########################
IDs in batch 1: tensor([2052, 3429, 2038, 4096, 1948, 1200, 2731,  255, 2858,  718, 2642,  582,
        3715,  207,  255, 1859])
Epoch: 2268, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2269 - Batch 1 ########################
IDs in batch 1: tensor([3336, 2218, 3869, 2577,  717, 1111, 4144,  417, 4213, 3351, 1756, 4232,
        1015, 2851,  499, 4037])
Epoch: 2269, Training Loss: 0.45, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2270 - Batch 1 ########################
IDs in batch 1: tensor([2927, 3226, 2505, 1124, 2827, 3547, 2457, 1960, 3042, 3945,  152, 2552,
         815,  857,  369,  627])
Epoch: 2270, Training Loss: 0.08, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2271 - Batch 1 ########################
IDs in batch 1: tensor([1157, 1117, 1035, 3841, 3369,   60, 1965, 2552, 1708, 1137,  918, 2712,
        1204,  804, 2650, 1471])
Epoch: 2271, Training Loss: 0.27, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2272 - Batch 1 ########################
IDs in batch 1: tensor([2829, 3873, 1302, 1415, 2849,  632, 3148, 2719,   84, 1646, 2775, 1780,
        3912, 1491, 1373, 1402])
Epoch: 2272, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2273 - Batch 1 ########################
IDs in batch 1: tensor([2482, 3764, 1663, 1508, 3463, 3764, 2799, 1269, 3481, 1900, 2379, 3194,
        2117, 1647, 3152, 3808])
Epoch: 2273, Training Loss: 0.25, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2274 - Batch 1 ########################
IDs in batch 1: tensor([   5, 2514, 1047, 2066,  656,  342,  873, 2171,  475, 3651,  752, 3581,
        3991, 4131,  862,  870])
Epoch: 2274, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2275 - Batch 1 ########################
IDs in batch 1: tensor([2817, 4016, 2040, 1736, 1176,  440,  790, 1229, 1397, 2860, 1485,  492,
        3130,  821,   51, 1241])
Epoch: 2275, Training Loss: 0.28, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2276 - Batch 1 ########################
IDs in batch 1: tensor([1313, 2775, 3643, 2664,  936, 4225, 4062, 3628, 1408,  902, 1277,  220,
         982, 2965,  379, 2606])
Epoch: 2276, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2277 - Batch 1 ########################
IDs in batch 1: tensor([3513,  864, 1548, 3754, 3533,  315, 1052, 1558, 1155, 3534, 3162, 4040,
        2044,  645,  239, 2166])
Epoch: 2277, Training Loss: 0.45, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2278 - Batch 1 ########################
IDs in batch 1: tensor([2746, 4128,   34, 3002, 2604, 2851, 2746, 4213, 2770, 2350, 2650, 1972,
         147,  767,   11, 3547])
Epoch: 2278, Training Loss: 0.14, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2279 - Batch 1 ########################
IDs in batch 1: tensor([3615, 3667, 2521,  226,  743, 1432,   73, 1454,  588, 1213, 2882,  167,
         282, 1316, 3744, 2295])
Epoch: 2279, Training Loss: 0.51, Validation Loss: 0.62, accuracy = 0.78
######################## Epoch 2280 - Batch 1 ########################
IDs in batch 1: tensor([1131, 3962, 1923,  518, 2697,  195,  150,   43, 1526, 2690, 1886, 2572,
        3570, 3072, 1722, 3533])
Epoch: 2280, Training Loss: 0.02, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2281 - Batch 1 ########################
IDs in batch 1: tensor([2541, 3860,  466,  167, 1126, 3583,  515, 2170, 2419, 1374, 3114,  691,
        1886, 3731, 1334,  926])
Epoch: 2281, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2282 - Batch 1 ########################
IDs in batch 1: tensor([3289, 1690, 2220, 3582, 1275, 2661,  930, 1061, 1223, 1543, 4056,  652,
        3271, 2828, 3564, 1537])
Epoch: 2282, Training Loss: 0.04, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2283 - Batch 1 ########################
IDs in batch 1: tensor([3326, 3530,  143, 2927, 1241, 4044,  829, 3827, 1660, 1092, 2559, 1971,
        1190, 2458,  691,  714])
Epoch: 2283, Training Loss: 0.10, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2284 - Batch 1 ########################
IDs in batch 1: tensor([2102,  944, 1274, 1432, 2886, 3927, 2274,  740,  377, 2132, 4172, 1965,
         838, 1473, 3513, 1476])
Epoch: 2284, Training Loss: 0.14, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2285 - Batch 1 ########################
IDs in batch 1: tensor([2292, 1562, 2689, 2732, 2245, 3452, 3952, 2737,  741, 4033, 2545, 3860,
        2984, 1060, 3388, 2206])
Epoch: 2285, Training Loss: 0.46, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2286 - Batch 1 ########################
IDs in batch 1: tensor([ 229, 2209, 1395,  794,  752,  425,  398, 3872, 3461, 3740, 1443,  367,
        1322,   96, 3755,  191])
Epoch: 2286, Training Loss: 0.19, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2287 - Batch 1 ########################
IDs in batch 1: tensor([3669, 3392, 2957, 1177, 3911, 2470, 1467, 1880, 1644, 1282, 1811, 1938,
         968, 1052,  182,  442])
Epoch: 2287, Training Loss: 0.47, Validation Loss: 0.64, accuracy = 0.75
######################## Epoch 2288 - Batch 1 ########################
IDs in batch 1: tensor([1877,  361, 3486, 2119, 2555, 4060, 3339, 2901, 1567, 3049, 1267, 3838,
         786, 3366, 3762, 1345])
Epoch: 2288, Training Loss: 0.15, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2289 - Batch 1 ########################
IDs in batch 1: tensor([1092, 2839, 2978, 1656, 2179, 2028,  982,  102, 1887, 2251, 1711, 2772,
        1311, 3970,  726, 2458])
Epoch: 2289, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2290 - Batch 1 ########################
IDs in batch 1: tensor([3989, 1399, 3599, 3121, 3553, 3197, 3330, 1976, 2917,  360, 3603, 4161,
        3032, 1932,   74,  362])
Epoch: 2290, Training Loss: 0.15, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2291 - Batch 1 ########################
IDs in batch 1: tensor([  86, 3233, 2953, 1325, 2178, 3381, 2204,  884, 3932, 1391, 1770,   31,
        3323, 2281, 3701, 2760])
Epoch: 2291, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2292 - Batch 1 ########################
IDs in batch 1: tensor([4135, 3100,  466,  320, 2467,  941,  426, 1796, 1798, 2092, 3644, 1633,
        2157, 4184,  864, 3526])
Epoch: 2292, Training Loss: 0.16, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2293 - Batch 1 ########################
IDs in batch 1: tensor([ 639,  275, 2285,   78, 2964, 3709, 1173, 1559, 1193,  907, 1085, 2212,
        2217, 2898, 1921, 1555])
Epoch: 2293, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.78
######################## Epoch 2294 - Batch 1 ########################
IDs in batch 1: tensor([2176, 3872, 4086, 3387, 4051,  164, 1042, 1069, 1774, 2537, 1408,  625,
        2621,  137, 4204, 1030])
Epoch: 2294, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2295 - Batch 1 ########################
IDs in batch 1: tensor([3447,  606, 4189, 3326, 3144, 3826, 2891, 2797, 3870,  923, 3898, 1123,
        2429, 1904,  773, 1712])
Epoch: 2295, Training Loss: 0.22, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2296 - Batch 1 ########################
IDs in batch 1: tensor([ 308,   46,  474,  985, 4146, 3426, 1110, 3151, 4232, 2855, 1766, 1938,
         269, 3961, 3956, 3056])
Epoch: 2296, Training Loss: 0.06, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2297 - Batch 1 ########################
IDs in batch 1: tensor([3806, 2376, 3337, 2295, 4039, 1959, 2742, 1618, 4088,  514, 1575,   35,
         827, 1850, 2886, 1634])
Epoch: 2297, Training Loss: 0.14, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2298 - Batch 1 ########################
IDs in batch 1: tensor([1643,  919,  401, 3765, 3655,  379, 2246, 1030, 1007, 3038,   88, 4251,
        3223, 1612, 1663, 3121])
Epoch: 2298, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2299 - Batch 1 ########################
IDs in batch 1: tensor([2144,  354, 1910, 1775,  477, 3395,  278, 2448,  887,  974, 1923, 1120,
        3453, 4161,  277, 1244])
Epoch: 2299, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2300 - Batch 1 ########################
IDs in batch 1: tensor([2550, 1949, 3921, 1491, 3632, 2806, 1426, 1081,  326,  954, 4014, 3636,
        4082, 1310, 3333, 1312])
Epoch: 2300, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2301 - Batch 1 ########################
IDs in batch 1: tensor([1604, 2524,  119, 2891, 2562, 4122, 1242, 1285, 3277,  441, 2375,  653,
        1965, 1942, 3539, 2729])
Epoch: 2301, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2302 - Batch 1 ########################
IDs in batch 1: tensor([2620, 2848, 2855, 2003,  512, 2144, 3126, 3614, 2804, 3469, 1546,  203,
        3142, 3017, 3601, 3879])
Epoch: 2302, Training Loss: 0.17, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2303 - Batch 1 ########################
IDs in batch 1: tensor([2167, 3552, 2035, 3223, 3501,  405, 4107, 2376, 1891,  426, 3569, 3072,
        1442, 1459, 4121, 3531])
Epoch: 2303, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2304 - Batch 1 ########################
IDs in batch 1: tensor([1271, 2706,  152,  945,  872,  724, 4220, 1955, 3821, 4267, 1623,  923,
        4062, 4003, 3539, 3535])
Epoch: 2304, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2305 - Batch 1 ########################
IDs in batch 1: tensor([1712, 3751,  879, 1005, 3526, 4217, 1388, 2324, 4125, 2018,  727,  990,
         652, 3258,  980, 2797])
Epoch: 2305, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2306 - Batch 1 ########################
IDs in batch 1: tensor([3364,  813, 1809, 2931, 1569, 4040, 3180,  896, 2358, 1121, 1511, 3658,
        2937, 2470, 4261, 1737])
Epoch: 2306, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2307 - Batch 1 ########################
IDs in batch 1: tensor([1680, 1315, 1143,  855, 4190, 3701, 3886, 4037,  631, 1756, 2866, 1911,
        4263,   13, 1620, 3504])
Epoch: 2307, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2308 - Batch 1 ########################
IDs in batch 1: tensor([4175, 2337, 2645, 2907,  345, 2344, 1782, 3969, 1920,  538, 3974, 1901,
         986,   19,  974,  747])
Epoch: 2308, Training Loss: 0.10, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2309 - Batch 1 ########################
IDs in batch 1: tensor([2802,  732, 4050, 1747, 3521, 1182, 1090,  701, 3142, 3327, 2359, 1084,
        1754, 1455,  532, 2276])
Epoch: 2309, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2310 - Batch 1 ########################
IDs in batch 1: tensor([ 752,  818, 3467, 2348,   15, 2309, 2965, 1186,  575, 3248,  959, 3424,
         679, 3509, 3236,  813])
Epoch: 2310, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2311 - Batch 1 ########################
IDs in batch 1: tensor([3238, 1546, 3476,  609, 2546,   86,   68, 3732,  207,  926, 1647, 1153,
        2652, 3696, 3401, 1176])
Epoch: 2311, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2312 - Batch 1 ########################
IDs in batch 1: tensor([1160,  510, 4128, 3650, 3499, 1175, 2137, 2348, 2618, 3933,  651, 2771,
        1390, 2418,  955,   86])
Epoch: 2312, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2313 - Batch 1 ########################
IDs in batch 1: tensor([ 907, 3577, 2461,  399, 3394, 2967,  280, 4122, 3928, 3430,  987, 3598,
         234, 1798, 2362, 1799])
Epoch: 2313, Training Loss: 0.40, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2314 - Batch 1 ########################
IDs in batch 1: tensor([3279, 3271, 3262, 2943,  773, 2120, 2672,  499, 3652, 3928, 3291, 2605,
         191,  593, 2332, 1186])
Epoch: 2314, Training Loss: 0.14, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2315 - Batch 1 ########################
IDs in batch 1: tensor([3865, 1012,  237, 3074,  134, 1482, 1555, 2899,  750, 3936, 3985,  171,
        4257, 3451, 2715,  813])
Epoch: 2315, Training Loss: 0.36, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2316 - Batch 1 ########################
IDs in batch 1: tensor([1057,   97,  950, 2672,  663, 3777, 2437, 1988, 1104, 3674,  507, 1004,
        1214, 1648,  173,  496])
Epoch: 2316, Training Loss: 0.33, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2317 - Batch 1 ########################
IDs in batch 1: tensor([4149, 2102, 2821,  604, 1704, 4127, 1038,  282, 3591,  892,  872, 2947,
         894,   32, 4203, 3398])
Epoch: 2317, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2318 - Batch 1 ########################
IDs in batch 1: tensor([  42,  482, 3551, 1985, 2377, 3927, 4025, 1961, 1489, 3603, 2819, 1175,
        2327,   96,  572, 2013])
Epoch: 2318, Training Loss: 0.18, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2319 - Batch 1 ########################
IDs in batch 1: tensor([3932, 1994, 2423, 3829, 2517, 3146, 3921, 3870, 1163,  343,   15, 1305,
        1716, 1084, 1746, 2970])
Epoch: 2319, Training Loss: 0.05, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2320 - Batch 1 ########################
IDs in batch 1: tensor([3251,  110, 1287, 3333, 3843, 2458, 1886,   18, 1495, 3020, 3760, 3953,
        2552, 3913,  712,  397])
Epoch: 2320, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2321 - Batch 1 ########################
IDs in batch 1: tensor([ 200, 4097, 3713, 1734, 1047, 3337, 3404,  578, 3869, 3196, 3488, 3055,
         161, 3607,   38,  595])
Epoch: 2321, Training Loss: 0.07, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2322 - Batch 1 ########################
IDs in batch 1: tensor([2575,  665,  730,  171, 3961,  606, 1896, 3036, 2015, 3795, 1996,  476,
         846, 2721, 2863, 1337])
Epoch: 2322, Training Loss: 0.11, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2323 - Batch 1 ########################
IDs in batch 1: tensor([2851, 2591,  992, 2255, 2604, 2789,  646,  944, 2446,   96,  203,  213,
        2092, 1552, 2149, 3150])
Epoch: 2323, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2324 - Batch 1 ########################
IDs in batch 1: tensor([ 203, 4266, 2366, 1249, 2519, 1633,  659, 3783, 1571,  471, 1291, 2447,
         553, 4232, 2667, 2366])
Epoch: 2324, Training Loss: 0.14, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2325 - Batch 1 ########################
IDs in batch 1: tensor([1963, 3374, 1948,  919, 2780, 1927, 3513, 2751,  879, 3381, 2700,  289,
         555, 3187, 1219,  214])
Epoch: 2325, Training Loss: 0.02, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2326 - Batch 1 ########################
IDs in batch 1: tensor([1125, 2328, 1045, 2876, 1006,  531,  827, 2773, 3381,  140, 3871,  491,
        2565, 1143,  609,  819])
Epoch: 2326, Training Loss: 0.28, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2327 - Batch 1 ########################
IDs in batch 1: tensor([1440, 2402, 2255, 3044, 3938, 1599, 1204, 3829, 1844, 2377, 1379,  181,
        3337, 3267,  436,  960])
Epoch: 2327, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2328 - Batch 1 ########################
IDs in batch 1: tensor([2653, 3943, 4094, 1954, 2126,  263, 1321, 1220, 3683, 3176, 2212,  287,
         303, 3447, 1094,  575])
Epoch: 2328, Training Loss: 0.09, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2329 - Batch 1 ########################
IDs in batch 1: tensor([3421,  975, 1084, 2118, 1971, 3157, 2264,  990,  290, 3925, 3214, 1413,
         226, 2080,  257, 2117])
Epoch: 2329, Training Loss: 0.06, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2330 - Batch 1 ########################
IDs in batch 1: tensor([1405, 2339, 3446,  790, 2867, 4158, 3439, 3572, 4230, 2246,  952, 1521,
        1244,  606, 2529, 3284])
Epoch: 2330, Training Loss: 0.28, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2331 - Batch 1 ########################
IDs in batch 1: tensor([1537, 2764, 3354, 4140, 1051, 2817,  193, 1028, 2945, 3395, 1185,  324,
        4200, 1789, 1302, 1632])
Epoch: 2331, Training Loss: 0.10, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2332 - Batch 1 ########################
IDs in batch 1: tensor([3878,  743, 3803, 1123,  147,  613, 3160, 3354, 2170, 1859, 1872,  238,
        3397, 1360, 2232,  400])
Epoch: 2332, Training Loss: 0.02, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2333 - Batch 1 ########################
IDs in batch 1: tensor([3151, 1086, 2760,  605, 3832, 2506, 3035, 3022, 3673, 3573,  747, 2940,
         490,   14, 3203, 3328])
Epoch: 2333, Training Loss: 0.18, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2334 - Batch 1 ########################
IDs in batch 1: tensor([ 332, 1751, 2833, 3618, 3177, 1595, 2095,  985, 3127, 2390,  365,  171,
        2524, 3233, 3603, 3878])
Epoch: 2334, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2335 - Batch 1 ########################
IDs in batch 1: tensor([ 949, 1324, 1381,  492,  923, 1818, 2833, 2802,  914, 2435, 1351,  788,
        3027, 3023, 1062, 1408])
Epoch: 2335, Training Loss: 0.36, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2336 - Batch 1 ########################
IDs in batch 1: tensor([1480, 1302, 4148, 1334,  832, 3234, 1809,  607, 2195,  436, 1090, 3746,
        2236,  284, 4037, 3526])
Epoch: 2336, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2337 - Batch 1 ########################
IDs in batch 1: tensor([1569,  766,  360, 3786, 2106, 2497, 2106, 1540, 1361, 2763, 1406, 3507,
        1680, 1009, 1328, 1397])
Epoch: 2337, Training Loss: 0.11, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2338 - Batch 1 ########################
IDs in batch 1: tensor([2726, 4121, 1752, 2587, 2869, 1054,  789, 1316, 2439, 2206, 3742, 2181,
        2246,  467, 3739,  218])
Epoch: 2338, Training Loss: 0.03, Validation Loss: 0.61, accuracy = 0.78
######################## Epoch 2339 - Batch 1 ########################
IDs in batch 1: tensor([ 858, 4148, 2444, 1463, 2059, 4136, 2022,  435, 3572, 2674,  221, 3507,
        1777,  371,  752, 1634])
Epoch: 2339, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2340 - Batch 1 ########################
IDs in batch 1: tensor([2629,  730, 1704, 3980, 3528, 3642, 2789,  805, 4014,  919, 2284, 3032,
        2167,  928, 3886, 1480])
Epoch: 2340, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2341 - Batch 1 ########################
IDs in batch 1: tensor([1229,  966,  315,  212, 2433, 2520, 1331, 3834, 1294, 3810, 2202, 3479,
        3211, 2760,  857,  186])
Epoch: 2341, Training Loss: 0.11, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2342 - Batch 1 ########################
IDs in batch 1: tensor([1376, 4186, 3958,  685, 2973,   18,  830, 3388, 2592, 3567, 4257, 3004,
        3376, 2134, 3314, 1942])
Epoch: 2342, Training Loss: 0.52, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2343 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 1218, 3474, 1206, 2063, 2733,  622,  896,  445, 1081, 4117, 2246,
        2072, 3287, 3785, 3787])
Epoch: 2343, Training Loss: 0.12, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2344 - Batch 1 ########################
IDs in batch 1: tensor([ 422, 1819,  936, 1104, 1321, 3663, 1417, 3404,  536, 3060, 2135, 3553,
        2040, 3101,  532, 1493])
Epoch: 2344, Training Loss: 0.04, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2345 - Batch 1 ########################
IDs in batch 1: tensor([1445, 4196, 2045, 3497, 1990, 2853, 1326, 2627, 2550, 3279, 1319, 1417,
        4187, 4058, 1235, 3719])
Epoch: 2345, Training Loss: 0.16, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2346 - Batch 1 ########################
IDs in batch 1: tensor([3429, 2899,  588, 3369,  778,  187, 4069,  866, 1506,  274,  133,  773,
        1158,  536, 3567,  269])
Epoch: 2346, Training Loss: 0.39, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2347 - Batch 1 ########################
IDs in batch 1: tensor([3219, 2996, 3306,  110, 3110, 2451, 1346, 1525, 2172, 1684, 1364, 1704,
        4230, 3152, 2656, 2370])
Epoch: 2347, Training Loss: 0.08, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2348 - Batch 1 ########################
IDs in batch 1: tensor([3673, 2067, 2358, 1390,  891, 1491,  914, 1324, 1458, 1626, 2189, 1123,
        3233,  491,  752, 2188])
Epoch: 2348, Training Loss: 0.13, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2349 - Batch 1 ########################
IDs in batch 1: tensor([3131, 1061,  407,  814, 1754, 1028, 1131, 3211, 4218, 3568, 1747, 1305,
        2777, 3527, 1345,   72])
Epoch: 2349, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2350 - Batch 1 ########################
IDs in batch 1: tensor([1200, 2376,  181,  439, 1374, 1316, 3989, 2179, 1374, 1181, 1216, 1878,
        1934, 3747,   27, 1197])
Epoch: 2350, Training Loss: 0.29, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2351 - Batch 1 ########################
IDs in batch 1: tensor([ 384, 2371, 1668, 4176, 3342, 3672, 4200, 1684, 3570, 4088,  862, 3585,
        1032,  676, 1851, 3035])
Epoch: 2351, Training Loss: 0.21, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2352 - Batch 1 ########################
IDs in batch 1: tensor([3833, 1878, 3675, 1993, 2428, 2195,  658, 1950, 1454, 3547,  143, 3185,
        2159, 3277,  489, 4105])
Epoch: 2352, Training Loss: 0.23, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2353 - Batch 1 ########################
IDs in batch 1: tensor([1762,  670,  430, 2765, 2848,  196, 2024,  603, 1328, 1474, 2632, 3282,
        3005,  321, 1845, 1070])
Epoch: 2353, Training Loss: 0.09, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2354 - Batch 1 ########################
IDs in batch 1: tensor([  61, 2403, 4224, 2371, 1138, 2237, 4173, 1332, 2540, 3092, 3196, 1454,
         733, 1751, 4194, 3838])
Epoch: 2354, Training Loss: 0.05, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2355 - Batch 1 ########################
IDs in batch 1: tensor([3628,   78, 3681, 3227,  842, 2207, 3072, 3777, 1373,  284, 2689, 2435,
        1680,  236, 1374, 2672])
Epoch: 2355, Training Loss: 0.07, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2356 - Batch 1 ########################
IDs in batch 1: tensor([3597, 3607, 1617, 1935, 2026,  892, 1841, 2493, 1526, 3962, 2041,  762,
        3528, 3795,  505, 1332])
Epoch: 2356, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2357 - Batch 1 ########################
IDs in batch 1: tensor([3053,  790, 2078, 2313, 2279, 1140, 2146, 4214, 2169,  727, 3458, 1181,
        4258, 2242, 3408, 3650])
Epoch: 2357, Training Loss: 0.13, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2358 - Batch 1 ########################
IDs in batch 1: tensor([ 685, 1334, 1996, 1134,  941, 3039, 3732,  781,  482,  258, 1436, 2771,
         785,  138,  821, 1375])
Epoch: 2358, Training Loss: 0.75, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2359 - Batch 1 ########################
IDs in batch 1: tensor([2420, 2683,  921, 4000, 3711, 3903,  888, 4125, 1028, 1866, 2620, 1012,
        3200, 1619, 2842, 3042])
Epoch: 2359, Training Loss: 0.06, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2360 - Batch 1 ########################
IDs in batch 1: tensor([ 683, 1241, 3081,   10,  106, 2752, 3569, 3786, 2650, 4072, 1485, 3894,
        3922, 3221, 3839, 2179])
Epoch: 2360, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2361 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 2812, 3259, 3507,  164, 3127, 2314, 2724, 1439, 1617, 2391, 3729,
         333, 3146, 2636, 2737])
Epoch: 2361, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2362 - Batch 1 ########################
IDs in batch 1: tensor([2052, 2285, 1289, 2476, 4113, 2938, 1081, 4118, 3471,  895,  832, 3023,
         776, 2401, 3987, 3487])
Epoch: 2362, Training Loss: 0.14, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2363 - Batch 1 ########################
IDs in batch 1: tensor([1264, 3712, 2185,  918,  740, 2936, 1748, 3581, 2841, 1093, 1196, 4124,
        3609, 2167, 3148, 2398])
Epoch: 2363, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2364 - Batch 1 ########################
IDs in batch 1: tensor([ 710, 2831,   51,   37, 2192, 3271, 1545, 3135,  120,  975, 3147, 4119,
         701, 1810, 1309, 3740])
Epoch: 2364, Training Loss: 0.15, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2365 - Batch 1 ########################
IDs in batch 1: tensor([1489, 3428, 2254, 3327, 1383, 1308, 1993, 3972, 3886, 2417, 2060, 3265,
        3573, 4009, 3627, 2010])
Epoch: 2365, Training Loss: 0.23, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2366 - Batch 1 ########################
IDs in batch 1: tensor([4240,  670, 1733, 2171, 1270, 1273,  152, 2297, 2008,  128, 4218,  883,
        4223, 2049,  258, 1239])
Epoch: 2366, Training Loss: 0.19, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2367 - Batch 1 ########################
IDs in batch 1: tensor([4030, 1285,    4, 1881,  245, 4061, 2498, 3714, 3109,  657, 4055, 1960,
        3490, 1388, 3900, 3381])
Epoch: 2367, Training Loss: 0.11, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2368 - Batch 1 ########################
IDs in batch 1: tensor([1642, 2986, 2433,  277, 1881, 2326,  607,  757, 3459,  281, 2053, 3664,
        3375, 3765, 1752, 4040])
Epoch: 2368, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2369 - Batch 1 ########################
IDs in batch 1: tensor([1552, 2039, 1193,  625, 3975,  685,  871, 1375,  612, 2355,  363, 1297,
        2669, 1476, 3558, 4101])
Epoch: 2369, Training Loss: 0.12, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2370 - Batch 1 ########################
IDs in batch 1: tensor([3192, 1372,   99, 1296, 4158, 2354, 2171,  732,  665, 3992, 2349, 1862,
        3557, 1247, 2150, 3298])
Epoch: 2370, Training Loss: 0.17, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2371 - Batch 1 ########################
IDs in batch 1: tensor([ 377, 2467,  484, 1885, 2060, 2552, 2706, 2442, 2921,  484, 2102, 1389,
        3669, 2499, 2838, 3377])
Epoch: 2371, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2372 - Batch 1 ########################
IDs in batch 1: tensor([3821, 1218, 1823, 2849, 1429, 1140,   35, 3042,  825, 2681, 3151, 2666,
         505, 3591, 4222, 4046])
Epoch: 2372, Training Loss: 0.12, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2373 - Batch 1 ########################
IDs in batch 1: tensor([2627, 4051, 1634, 2845, 1274,  490, 2036,  503, 1569, 4013, 3238,  974,
        1158, 2641, 2066, 1980])
Epoch: 2373, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2374 - Batch 1 ########################
IDs in batch 1: tensor([4039, 2338,  941,  226, 3016,  694, 1415, 2597, 3219,   42,  755, 1918,
        1289, 2257,  334, 1480])
Epoch: 2374, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 2375 - Batch 1 ########################
IDs in batch 1: tensor([1828, 1023, 2789, 2391, 2598,  588, 2332, 2003,  750, 3279,  829, 4096,
        2897, 2407, 2931, 2723])
Epoch: 2375, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2376 - Batch 1 ########################
IDs in batch 1: tensor([1972,   32, 2436,  721, 1778, 2148, 3715, 2842, 1748, 3920, 2676, 3953,
        1484, 3706, 3154, 3156])
Epoch: 2376, Training Loss: 0.04, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2377 - Batch 1 ########################
IDs in batch 1: tensor([4050, 1574, 2558,  991,  607,   21, 2912, 1250, 3437, 1562,  256, 3970,
        3658, 3534, 2504, 2203])
Epoch: 2377, Training Loss: 0.03, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2378 - Batch 1 ########################
IDs in batch 1: tensor([2797, 1592, 1296, 3804, 1775, 2680, 4266, 2279, 3221,  342, 1189, 3185,
        2382,  250, 1077, 3084])
Epoch: 2378, Training Loss: 0.06, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2379 - Batch 1 ########################
IDs in batch 1: tensor([2170,   11, 2890, 3940, 3511, 2265,  987, 1793, 4157, 4179, 2828, 3444,
         553, 1500,   86, 3655])
Epoch: 2379, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2380 - Batch 1 ########################
IDs in batch 1: tensor([3940, 3516, 2833, 3407,  864, 1841, 1247, 3698, 1938, 2183, 1375, 4115,
        3977,  432, 3435,  895])
Epoch: 2380, Training Loss: 0.07, Validation Loss: 0.61, accuracy = 0.76
######################## Epoch 2381 - Batch 1 ########################
IDs in batch 1: tensor([1937, 3675, 3833, 4204, 1414, 2145, 2224, 3425, 4214,  921,  396, 1275,
        1083, 1567,  651, 1410])
Epoch: 2381, Training Loss: 0.04, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2382 - Batch 1 ########################
IDs in batch 1: tensor([3364, 3726,  238, 3421, 1932, 2087, 2544,  644,  223, 1844, 2692, 1574,
         436, 3542, 1655, 1242])
Epoch: 2382, Training Loss: 0.09, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2383 - Batch 1 ########################
IDs in batch 1: tensor([2356, 2179,  382, 1870, 1051, 3974,   57,  862, 1258, 2945, 1804, 1489,
        3891, 4058,  530,  161])
Epoch: 2383, Training Loss: 0.04, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2384 - Batch 1 ########################
IDs in batch 1: tensor([3467, 2682, 1469, 4072, 2964, 2659, 3094,  417, 4084, 3267, 3956, 1999,
        4148,  260, 1393,   34])
Epoch: 2384, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2385 - Batch 1 ########################
IDs in batch 1: tensor([1385, 1099,  350,  875, 3072, 1123, 1975, 2092, 1404,  261, 2581, 3377,
        4110, 1405, 1870,  244])
Epoch: 2385, Training Loss: 0.10, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2386 - Batch 1 ########################
IDs in batch 1: tensor([2959,  693,  185,  348, 3455, 1035, 1599, 2177, 1799,  743, 3367, 3052,
        3972, 1255, 2379, 2697])
Epoch: 2386, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2387 - Batch 1 ########################
IDs in batch 1: tensor([1226, 1448, 1660, 1685, 1007,  303, 2873, 1986,  475, 2937, 2832,  604,
         325,  485, 2734, 3044])
Epoch: 2387, Training Loss: 0.16, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 2388 - Batch 1 ########################
IDs in batch 1: tensor([  93, 3977,  994,  915, 3942, 2246, 2323, 1508, 1504, 2493, 1698,  991,
        4204, 2559,  852, 1014])
Epoch: 2388, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 2389 - Batch 1 ########################
IDs in batch 1: tensor([1592, 2697, 1069, 1740,  384, 2257, 1592, 3340, 3430, 3905, 3478,  908,
         106,  357, 3475, 2831])
Epoch: 2389, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2390 - Batch 1 ########################
IDs in batch 1: tensor([  71, 1176, 2099, 2991, 1746,  154,  160, 3287, 3083, 2659, 1933,   30,
         758, 2522,  753, 4105])
Epoch: 2390, Training Loss: 0.03, Validation Loss: 0.60, accuracy = 0.78
######################## Epoch 2391 - Batch 1 ########################
IDs in batch 1: tensor([1590, 2144, 3082,  195, 2978, 3930, 1993,  194, 2245,  295, 3655, 1543,
          19,  154, 1223, 2737])
Epoch: 2391, Training Loss: 0.05, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2392 - Batch 1 ########################
IDs in batch 1: tensor([ 478,  225,  139, 3472,  587, 2339,  965,  341, 2897,  869,  419, 4253,
        4108, 1354, 4194, 1878])
Epoch: 2392, Training Loss: 0.07, Validation Loss: 0.60, accuracy = 0.77
######################## Epoch 2393 - Batch 1 ########################
IDs in batch 1: tensor([1351, 3688,  465, 2627, 3424, 4026, 3859, 1588,  152,  538, 3905, 3992,
        4268, 1223, 2025, 2868])
Epoch: 2393, Training Loss: 0.06, Validation Loss: 0.60, accuracy = 0.76
######################## Epoch 2394 - Batch 1 ########################
IDs in batch 1: tensor([4126,  292, 3921, 3753, 1124, 1221, 2947, 2595,  807, 1986, 2364, 1632,
        4017, 2859, 1909, 2539])
Epoch: 2394, Training Loss: 0.08, Validation Loss: 0.61, accuracy = 0.77
######################## Epoch 2395 - Batch 1 ########################
IDs in batch 1: tensor([2876, 2652, 3531, 3795, 2838, 1862, 1590, 2913,  375, 3439, 3742, 3936,
         100,  165,  834, 1886])
Epoch: 2395, Training Loss: 0.03, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2396 - Batch 1 ########################
IDs in batch 1: tensor([3382, 2358, 3287, 3760, 3197, 2522,  826, 1498, 2514, 2854, 4251,  154,
        2517,  738, 2258, 1495])
Epoch: 2396, Training Loss: 0.02, Validation Loss: 0.63, accuracy = 0.76
######################## Epoch 2397 - Batch 1 ########################
IDs in batch 1: tensor([ 982, 3091, 2579, 1190,  462, 3635,  545, 3042, 3391, 1810,  556, 1306,
        3934, 1991, 2391, 1355])
Epoch: 2397, Training Loss: 0.43, Validation Loss: 0.62, accuracy = 0.77
######################## Epoch 2398 - Batch 1 ########################
IDs in batch 1: tensor([4011, 3778, 2959, 1321, 1639,  206,  526,  357, 3673, 1850, 3592, 1094,
        3860, 2997, 2969, 3570])
Epoch: 2398, Training Loss: 0.10, Validation Loss: 0.63, accuracy = 0.77
######################## Epoch 2399 - Batch 1 ########################
IDs in batch 1: tensor([4263, 1065,  341, 2564, 3208,   82,  277,  499, 2873, 2514,  544, 2049,
         825, 1075, 2498,  424])
Epoch: 2399, Training Loss: 0.10, Validation Loss: 0.62, accuracy = 0.76
######################## Epoch 2400 - Batch 1 ########################
IDs in batch 1: tensor([3003, 2146,   50, 3127, 2603, 2094, 2418, 2894, 3378, 3314, 3202, 2879,
        2255, 2687, 1439, 1251])
Epoch: 2400, Training Loss: 0.19, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2401 - Batch 1 ########################
IDs in batch 1: tensor([1464, 3488, 2659, 4039, 3689, 2649, 1812, 1273, 3853, 2149, 4203, 4068,
          92, 3369,  844, 3597])
Epoch: 2401, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2402 - Batch 1 ########################
IDs in batch 1: tensor([1821,  505, 2586, 3277, 3699, 3609, 1923, 3367, 1053, 1086, 2177,  476,
         477, 1198, 1380, 2892])
Epoch: 2402, Training Loss: 0.03, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2403 - Batch 1 ########################
IDs in batch 1: tensor([2521, 2754, 3738, 1868, 1499, 3749, 2868, 1110,   34, 1923, 2072, 3154,
        3732, 3728, 3627, 1727])
Epoch: 2403, Training Loss: 0.34, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2404 - Batch 1 ########################
IDs in batch 1: tensor([3386, 2483, 3196, 4118, 1588, 2275, 1219, 3132,  556, 3757, 2410,  710,
        4035, 3859, 1972,  134])
Epoch: 2404, Training Loss: 0.09, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2405 - Batch 1 ########################
IDs in batch 1: tensor([ 195, 3932,   84, 3974, 3780, 2429, 2297,  822,  963, 2870,  177, 2869,
        2874, 2879,  117, 3370])
Epoch: 2405, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2406 - Batch 1 ########################
IDs in batch 1: tensor([1996, 4188,  888, 2592, 2542, 3039, 3942, 3479,  689, 3958,  130,   47,
        2908, 3514, 3115, 4026])
Epoch: 2406, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2407 - Batch 1 ########################
IDs in batch 1: tensor([ 879, 3777,  496, 2459, 1369, 1167, 1098, 3511, 4267, 3272, 1346, 2329,
         109,  950,   61,   93])
Epoch: 2407, Training Loss: 0.19, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2408 - Batch 1 ########################
IDs in batch 1: tensor([ 842, 2277, 2806, 4114,  314,  401, 3126, 3030, 1698, 3390, 2264, 2690,
         909, 2565,  512, 3878])
Epoch: 2408, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2409 - Batch 1 ########################
IDs in batch 1: tensor([2546, 1420,  909, 1458, 3856, 2504, 2365, 2660,  281, 2841, 1675,  822,
         879, 2957,  358, 2025])
Epoch: 2409, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2410 - Batch 1 ########################
IDs in batch 1: tensor([2027,  527, 1773, 2908, 1124, 1580, 2480, 2191, 4214, 2031, 3549,  323,
        1809, 3928, 3802,  981])
Epoch: 2410, Training Loss: 0.02, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2411 - Batch 1 ########################
IDs in batch 1: tensor([3810,  412,  730, 3754, 2398, 3935, 1976, 2402, 2081, 3563, 1346,  395,
        3253,  736,  305, 1083])
Epoch: 2411, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2412 - Batch 1 ########################
IDs in batch 1: tensor([ 425, 2092, 3124, 2394,  152, 2402, 4094,  361,  869, 3647, 3466, 3356,
        2609,  908, 1117, 1961])
Epoch: 2412, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2413 - Batch 1 ########################
IDs in batch 1: tensor([2241, 4228, 2851, 1456, 2400,  855, 2285, 2551, 3478, 3969, 2969, 2017,
        3465, 3640, 3757, 4022])
Epoch: 2413, Training Loss: 0.43, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2414 - Batch 1 ########################
IDs in batch 1: tensor([2951, 1863, 3432,  651,  474, 1003, 2045,  274, 2135, 1646, 1062, 3312,
         960, 3444, 3400, 1530])
Epoch: 2414, Training Loss: 0.08, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2415 - Batch 1 ########################
IDs in batch 1: tensor([3583,  977,  557, 1213,  488, 3446,  100,  965,  430, 1842, 1337, 2465,
        1484, 3624,  657, 3591])
Epoch: 2415, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2416 - Batch 1 ########################
IDs in batch 1: tensor([4116,  380, 1347, 2650, 2847, 1481, 1363, 1444, 2149, 2306,  281, 2080,
        1588, 2360,  740, 3363])
Epoch: 2416, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2417 - Batch 1 ########################
IDs in batch 1: tensor([1625, 3390, 2967, 1305, 2516, 3569, 3344, 3936, 3277, 3101, 4009, 2367,
         355, 2322, 1065, 3440])
Epoch: 2417, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2418 - Batch 1 ########################
IDs in batch 1: tensor([1290, 2002, 1103, 3451, 2291,  691, 4170,  190, 2223, 3780, 3440, 4017,
        1182, 2019, 3545,  713])
Epoch: 2418, Training Loss: 0.10, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2419 - Batch 1 ########################
IDs in batch 1: tensor([3032, 3432, 3530, 2352, 3927, 3123, 3743, 2562, 2090, 2429, 1712,  878,
        2489, 3939, 3178, 1506])
Epoch: 2419, Training Loss: 0.24, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2420 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 1044,  498,  957, 2413, 3283,  729, 2280,  496,  943,  883, 3271,
        2113, 1319, 3486, 2309])
Epoch: 2420, Training Loss: 0.20, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2421 - Batch 1 ########################
IDs in batch 1: tensor([1840, 3334,  651,  418, 1583, 3903, 3749, 3618, 1133, 2399,  379, 1099,
         351,  265,  574,  631])
Epoch: 2421, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2422 - Batch 1 ########################
IDs in batch 1: tensor([ 640, 2899, 2274, 1747,  992, 2433, 1980, 4139, 1220,  508, 2712, 2782,
        4257, 2470, 1346,  229])
Epoch: 2422, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2423 - Batch 1 ########################
IDs in batch 1: tensor([2334, 1994, 2672,  774, 2561, 2542, 1634, 4101, 3998, 2711, 1993,  586,
        1899, 1214, 1200, 1263])
Epoch: 2423, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2424 - Batch 1 ########################
IDs in batch 1: tensor([1286,  379, 2049, 3607, 1045,  888, 2108, 1180,  578, 1305,  510, 2835,
        3587, 3238, 3185, 2892])
Epoch: 2424, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2425 - Batch 1 ########################
IDs in batch 1: tensor([2870, 1938, 1247, 3092,  239, 2444, 1648,  829, 3873, 2870, 2276,  851,
        2825, 3742, 3244, 1352])
Epoch: 2425, Training Loss: 0.12, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2426 - Batch 1 ########################
IDs in batch 1: tensor([3846, 4017, 3545, 3456, 1154, 3523, 4078,  187, 1005,  109, 1773, 3803,
        3607, 3473, 2617, 2103])
Epoch: 2426, Training Loss: 0.09, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2427 - Batch 1 ########################
IDs in batch 1: tensor([1132, 3234, 3717, 3547, 3778, 2577,  232, 1526, 2353, 3081, 2099, 2226,
        3592,  325, 2189, 3087])
Epoch: 2427, Training Loss: 0.10, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2428 - Batch 1 ########################
IDs in batch 1: tensor([ 944,   43, 2521, 3592, 3060,  351, 2788, 2075, 1152, 3936, 3939, 2789,
        1247, 2154, 2450, 2812])
Epoch: 2428, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2429 - Batch 1 ########################
IDs in batch 1: tensor([ 645, 2693, 2432, 2375, 1104, 2858,  968, 3745, 1405,  279, 2551, 1496,
        3051, 1428, 3483, 2159])
Epoch: 2429, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2430 - Batch 1 ########################
IDs in batch 1: tensor([2412, 2663,  345, 1625, 3258, 2514, 3531,  186, 3640, 2435,   21, 4139,
        3289,  557,  380, 2872])
Epoch: 2430, Training Loss: 0.02, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2431 - Batch 1 ########################
IDs in batch 1: tensor([1235, 2122, 2051, 1440, 3933,  968,  289, 4014, 1414, 1747, 1760,   57,
        2767, 3053,  228, 1493])
Epoch: 2431, Training Loss: 0.15, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2432 - Batch 1 ########################
IDs in batch 1: tensor([3115, 2621,  767,  785,   50, 2822, 3152, 1163, 3102, 2727, 2314, 3407,
        2443, 3426, 1859,  436])
Epoch: 2432, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2433 - Batch 1 ########################
IDs in batch 1: tensor([2553, 2023, 3683,  265, 2441, 2480, 2898, 2807,  323,  139,  781, 3787,
         121,  437, 2776, 3216])
Epoch: 2433, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2434 - Batch 1 ########################
IDs in batch 1: tensor([1778, 1311, 3298,  478, 3489,   78, 1128, 1179, 1614, 2493, 1228, 3927,
        2627,  200, 3527, 3386])
Epoch: 2434, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2435 - Batch 1 ########################
IDs in batch 1: tensor([3426,  120, 3983, 3826, 3099, 3702, 2821, 1708, 1784, 2793, 2522, 2004,
        4005,  590, 3947,  478])
Epoch: 2435, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 2436 - Batch 1 ########################
IDs in batch 1: tensor([3706, 2317, 1055, 1993, 2912, 2322, 4011, 2476, 2150,  113, 1588, 4088,
        1650, 3485, 3695, 2115])
Epoch: 2436, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2437 - Batch 1 ########################
IDs in batch 1: tensor([ 771, 3022, 1954, 2343, 1336, 2688, 3568, 2931, 3241, 2368, 2567, 1166,
         119,  401, 2966, 1308])
Epoch: 2437, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2438 - Batch 1 ########################
IDs in batch 1: tensor([1388, 1596, 1853,  487, 3969, 3425, 3831,   50, 2565, 2041, 1257,  391,
        1931, 2835,  635, 2497])
Epoch: 2438, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2439 - Batch 1 ########################
IDs in batch 1: tensor([3743,  807,  398, 1724, 2519, 3535, 1228, 2080, 1871, 3806, 1133,  625,
        3712,   47, 2967, 1734])
Epoch: 2439, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2440 - Batch 1 ########################
IDs in batch 1: tensor([ 397, 2745, 3027,  119,   81, 3914, 1119, 3052,  102, 1990, 3389,  232,
        4055, 2178,  957, 3739])
Epoch: 2440, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2441 - Batch 1 ########################
IDs in batch 1: tensor([3998, 4089, 1244, 3131, 4194, 3683,  740, 3192, 3878,  838, 3289, 2721,
        3340, 2104, 4037, 2668])
Epoch: 2441, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 2442 - Batch 1 ########################
IDs in batch 1: tensor([3023, 1224, 3489, 1450,  968, 1774,  140, 1306,  881, 3919, 3211, 2838,
        1469,  269, 3180,  976])
Epoch: 2442, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2443 - Batch 1 ########################
IDs in batch 1: tensor([ 325,  913, 1166,  203, 3938, 3821,  205, 3563, 2624, 4014, 1031, 3113,
        1152,  250, 1993, 1818])
Epoch: 2443, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 2444 - Batch 1 ########################
IDs in batch 1: tensor([1193, 2005, 3728,  391, 2732,  130, 2614, 3398, 1457, 1045,  727,  432,
         397,  109, 1868, 2408])
Epoch: 2444, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2445 - Batch 1 ########################
IDs in batch 1: tensor([1060,  584, 2010, 2359, 3494, 4214, 2102, 2229, 1220,  881, 3358, 2897,
        2488, 1014, 3418, 3029])
Epoch: 2445, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2446 - Batch 1 ########################
IDs in batch 1: tensor([ 769, 3912, 2086, 3751, 1335, 1222, 4172, 3672, 3934, 3747, 2344,  992,
        3667, 2019, 1948, 1160])
Epoch: 2446, Training Loss: 0.10, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2447 - Batch 1 ########################
IDs in batch 1: tensor([3036, 1937, 3525,  835, 4175,  631, 1244,  356, 2552, 1640, 1429, 2984,
        3485, 3852, 2882, 1944])
Epoch: 2447, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2448 - Batch 1 ########################
IDs in batch 1: tensor([2999, 1860, 1404,  219, 1731, 1840, 3200,  407,  325,  334, 3544,  659,
         292, 2721, 3428, 2858])
Epoch: 2448, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2449 - Batch 1 ########################
IDs in batch 1: tensor([1012,  321, 2587,  988, 2758,  531, 2126,  595,   74, 2721,  119,  835,
        1056, 1980,  964, 2255])
Epoch: 2449, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2450 - Batch 1 ########################
IDs in batch 1: tensor([4165, 3538, 1247, 3374, 3038,  642,  165, 2119,  848, 3094, 4086, 3099,
        1980, 4103, 1932, 2473])
Epoch: 2450, Training Loss: 0.16, Validation Loss: 0.66, accuracy = 0.78
######################## Epoch 2451 - Batch 1 ########################
IDs in batch 1: tensor([1612,   50, 3339,  400, 2480, 3283, 2127,  212,  368,  610,  277, 4127,
        1507, 2398, 3468, 2451])
Epoch: 2451, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2452 - Batch 1 ########################
IDs in batch 1: tensor([ 512,  498, 3746,  826, 1426, 2925,  779, 3180, 4115, 1423,   95, 2473,
        3077, 3018, 4002, 3190])
Epoch: 2452, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2453 - Batch 1 ########################
IDs in batch 1: tensor([ 187,  751, 2195, 2205, 4040, 2220, 1181,  187,  685, 3661,  936, 3699,
        3423,   25, 1044, 3822])
Epoch: 2453, Training Loss: 0.11, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2454 - Batch 1 ########################
IDs in batch 1: tensor([4181, 1595, 3233,  477, 2487, 3386, 3846,  882,  284, 4165,  921,  444,
        4173, 2024,  214,  110])
Epoch: 2454, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2455 - Batch 1 ########################
IDs in batch 1: tensor([2038,  665, 3152, 2444,  663,  145, 2897, 3126, 3821, 1012,  150, 2428,
        3983, 3789, 2708, 3264])
Epoch: 2455, Training Loss: 0.22, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2456 - Batch 1 ########################
IDs in batch 1: tensor([2927, 3862,  508, 2953, 4200, 1635, 2974, 3252, 2329, 2212, 3543, 3283,
        4174, 3327,  148, 2144])
Epoch: 2456, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2457 - Batch 1 ########################
IDs in batch 1: tensor([3336, 2412, 1370, 3904, 3789, 2856, 1810, 2806,  941, 2314, 1942, 2595,
         893,  622, 2245, 1977])
Epoch: 2457, Training Loss: 0.23, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2458 - Batch 1 ########################
IDs in batch 1: tensor([4011, 4100, 4267, 3304, 3472, 2347, 2760, 3321, 4195, 2429, 2337, 2748,
        1185, 2610, 4181,  644])
Epoch: 2458, Training Loss: 0.38, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2459 - Batch 1 ########################
IDs in batch 1: tensor([3321, 3058, 2577,  625,  348, 3904,  148, 2155,  574,  132,  987, 1675,
        2122,  553, 3547, 2018])
Epoch: 2459, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2460 - Batch 1 ########################
IDs in batch 1: tensor([3271, 2798, 3496,  512,  345, 3272, 1374,   98, 3298, 1179,  756,  736,
        3583, 1272, 2505, 1189])
Epoch: 2460, Training Loss: 0.12, Validation Loss: 0.67, accuracy = 0.78
######################## Epoch 2461 - Batch 1 ########################
IDs in batch 1: tensor([ 435, 1747, 2544, 2256, 3363, 1976, 1116, 1372, 3468, 1283,  816, 1766,
         959, 3386, 3143, 3100])
Epoch: 2461, Training Loss: 0.08, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2462 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 2456, 3673, 2604, 2252, 3182,  279, 3337, 2124,  236, 3860, 3475,
         725, 3369,  672, 4143])
Epoch: 2462, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2463 - Batch 1 ########################
IDs in batch 1: tensor([ 201, 1428, 2193, 3973, 1748, 3000,  531, 1103,  787,  125, 2448,  187,
         450, 2571, 2724, 2789])
Epoch: 2463, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2464 - Batch 1 ########################
IDs in batch 1: tensor([1897,  978,  250, 4039,  563, 1045, 4105, 2141,  838,   92,  472, 2433,
        4157, 2210, 3769, 1573])
Epoch: 2464, Training Loss: 0.10, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2465 - Batch 1 ########################
IDs in batch 1: tensor([1263,  821, 3710, 4007,  302, 4116,  739, 2840, 1897, 1072, 1174, 2367,
         484, 2961,  689, 3147])
Epoch: 2465, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2466 - Batch 1 ########################
IDs in batch 1: tensor([ 967, 3131, 1566,  205,  515, 2788, 1161, 3179, 2253, 1521, 2019,  396,
         886, 3317, 3885, 3221])
Epoch: 2466, Training Loss: 0.08, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2467 - Batch 1 ########################
IDs in batch 1: tensor([2517, 3945,  730,   68, 2794, 3521, 2312, 2394, 2329, 3798, 2014, 3200,
         820, 1471, 4188, 4035])
Epoch: 2467, Training Loss: 0.31, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2468 - Batch 1 ########################
IDs in batch 1: tensor([ 770, 3523, 3618,  739,  657, 2405,   11,  946, 3344, 3938, 2437, 3958,
        1767, 1152, 3547, 2334])
Epoch: 2468, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2469 - Batch 1 ########################
IDs in batch 1: tensor([1066, 3994, 1059, 3073, 3757,  247, 1236, 4185, 1537, 3485, 1763, 1346,
         741, 1991, 3207, 1406])
Epoch: 2469, Training Loss: 0.09, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2470 - Batch 1 ########################
IDs in batch 1: tensor([3282,  149, 1310, 3507, 3047, 1140, 1733,  612, 4234, 2371, 2564, 3787,
        2565,  830,  391, 3136])
Epoch: 2470, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2471 - Batch 1 ########################
IDs in batch 1: tensor([4179, 3227, 3954, 3594, 3407, 1285,  238, 1525, 2053, 1921, 4017, 4138,
        1974, 1451, 4110,  224])
Epoch: 2471, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2472 - Batch 1 ########################
IDs in batch 1: tensor([2967, 3822, 3661, 3424, 2592,  606, 1140, 3767, 1121, 3458, 4154,  121,
        3659, 2700,  962, 3339])
Epoch: 2472, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2473 - Batch 1 ########################
IDs in batch 1: tensor([2470, 2597, 3243,  497, 2133, 2245,  129, 1849,   28, 1617,  750, 4141,
        3099, 1733,  412,  952])
Epoch: 2473, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2474 - Batch 1 ########################
IDs in batch 1: tensor([  97,  415,  497, 1861,  989, 2031, 4253, 1024,  541, 4082,  713, 1575,
        2553,  164, 1267, 1421])
Epoch: 2474, Training Loss: 0.30, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2475 - Batch 1 ########################
IDs in batch 1: tensor([ 193, 1530, 1546, 1504, 1241, 2579, 3604, 2600, 1331,  258, 3536, 4144,
        3100, 3388,  830, 3540])
Epoch: 2475, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2476 - Batch 1 ########################
IDs in batch 1: tensor([4040,  837,  886,  758,  863, 1282,  832, 4255, 3470, 2015, 2198, 1252,
        3429, 1160, 1274, 2723])
Epoch: 2476, Training Loss: 0.08, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2477 - Batch 1 ########################
IDs in batch 1: tensor([4075,  813, 2459, 1731, 4009, 3362, 1444, 1292, 3734,  663, 1077, 2257,
        3795, 3563, 2074,  239])
Epoch: 2477, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2478 - Batch 1 ########################
IDs in batch 1: tensor([2329, 3321, 3642, 4227, 1779, 3954, 3002, 4174, 2041, 1062, 2970, 3053,
         100, 1133, 3188, 1056])
Epoch: 2478, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2479 - Batch 1 ########################
IDs in batch 1: tensor([ 693, 3275,  475,  256, 3496, 3415, 2891, 3037, 2423, 1011, 2793, 4022,
        2577, 4194, 2908, 3894])
Epoch: 2479, Training Loss: 0.16, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2480 - Batch 1 ########################
IDs in batch 1: tensor([3673, 3642, 3010, 1311, 1614, 3677, 1087, 1897, 1226, 2603, 3478, 3192,
        4240,  206, 3779, 1387])
Epoch: 2480, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2481 - Batch 1 ########################
IDs in batch 1: tensor([2767, 2039, 3729, 1646, 4214, 2511, 1945,  394, 3424, 2789,  150,  141,
        2886, 4046,  556, 3162])
Epoch: 2481, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2482 - Batch 1 ########################
IDs in batch 1: tensor([3643, 3367,  892, 3157, 2758,  738, 2869, 1085, 2199,   21, 3858, 4004,
        1961, 1951, 1773, 3674])
Epoch: 2482, Training Loss: 0.11, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2483 - Batch 1 ########################
IDs in batch 1: tensor([2169, 3193,  604, 2883, 2429,  125,  203, 3711, 1451,   51,  220, 1224,
         456, 1645, 3044, 1349])
Epoch: 2483, Training Loss: 0.22, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2484 - Batch 1 ########################
IDs in batch 1: tensor([ 679, 4008, 2018, 1540, 1418, 3808, 3115, 3381, 1204,  181, 1977, 4002,
         994, 4138,  723,  445])
Epoch: 2484, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2485 - Batch 1 ########################
IDs in batch 1: tensor([2627, 2467, 2284, 3267, 1423, 1982, 1628, 4165, 2103, 2188, 1895, 3339,
         467,   95, 2855, 1387])
Epoch: 2485, Training Loss: 0.17, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2486 - Batch 1 ########################
IDs in batch 1: tensor([ 441, 3243,  996,  767, 2690, 2701, 1223, 2959, 1961, 3286, 4225, 3671,
        3339, 1886, 2414, 3394])
Epoch: 2486, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2487 - Batch 1 ########################
IDs in batch 1: tensor([1197,  895, 1234, 4105, 1213, 3476, 2815, 3673,  264, 2942,  672,  533,
        2520,  862, 3654, 2199])
Epoch: 2487, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2488 - Batch 1 ########################
IDs in batch 1: tensor([3593, 1617,  864,   27, 3852,  360, 2412, 2898, 3658,  694, 4014, 2973,
        3384, 4100, 3142, 2492])
Epoch: 2488, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2489 - Batch 1 ########################
IDs in batch 1: tensor([ 391, 1772, 4115, 2963, 3705, 3494, 2700, 4184, 3291,  884,   27, 1746,
        3527, 1728, 3135, 3558])
Epoch: 2489, Training Loss: 0.09, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2490 - Batch 1 ########################
IDs in batch 1: tensor([3783, 1063, 2070, 2957,  602,  569, 3188,  829,  672,  282,  462, 3991,
        2276, 1633, 3091,  128])
Epoch: 2490, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2491 - Batch 1 ########################
IDs in batch 1: tensor([1811,  786, 3194,  750, 3537, 2688, 2455, 2609, 1007, 4010,  636, 4040,
        3423,  960, 1351, 3532])
Epoch: 2491, Training Loss: 0.15, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2492 - Batch 1 ########################
IDs in batch 1: tensor([ 779,  255, 2748,  604,  367, 1706, 1228, 3513, 1278, 1178, 2851,  933,
        3222, 1618, 4265,  982])
Epoch: 2492, Training Loss: 0.17, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2493 - Batch 1 ########################
IDs in batch 1: tensor([2018, 3822, 4152,  232, 2954,  513, 3004, 1611, 3250, 2304,  155, 3608,
        2652, 2463,  880, 2511])
Epoch: 2493, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2494 - Batch 1 ########################
IDs in batch 1: tensor([3898, 1594, 2300,  808, 1521, 3638,  676, 1512, 4013, 3352, 3425, 4214,
        2857,  102, 1645, 1775])
Epoch: 2494, Training Loss: 0.10, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2495 - Batch 1 ########################
IDs in batch 1: tensor([3135, 1834, 1086, 3714,  475, 4118, 3183,  451, 2097, 3851,  440, 2219,
         356, 3772,  190,  640])
Epoch: 2495, Training Loss: 0.18, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2496 - Batch 1 ########################
IDs in batch 1: tensor([2993, 1935, 1343, 1559, 3031, 3903, 3351,   85, 3856, 1676, 3414, 4093,
        3435,  315, 4055, 2262])
Epoch: 2496, Training Loss: 0.09, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2497 - Batch 1 ########################
IDs in batch 1: tensor([3181, 2478,  890, 1179, 3473, 4061, 4097, 1003, 3114,  300, 1576, 3283,
        1163, 4010, 2179,  615])
Epoch: 2497, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2498 - Batch 1 ########################
IDs in batch 1: tensor([2198, 1812, 1156, 4184, 3671, 2116,  757, 2954, 1948, 1700, 3700, 2106,
        3476, 1767, 1473,  151])
Epoch: 2498, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2499 - Batch 1 ########################
IDs in batch 1: tensor([ 371, 1066, 1878, 3221, 2026, 2284,  503, 3187, 2986, 2220,  355, 4069,
        1113, 2377, 3843, 2655])
Epoch: 2499, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2500 - Batch 1 ########################
IDs in batch 1: tensor([ 985, 3000, 1425, 2851,  109, 1656, 3813, 2825,  223, 3385,  407, 1656,
        3729, 2538,  909, 3259])
Epoch: 2500, Training Loss: 0.03, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2501 - Batch 1 ########################
IDs in batch 1: tensor([3952, 3738, 4044,  183, 3262, 3306, 1364, 2691, 1677, 3744, 2545, 3222,
         895, 3385, 2521, 2394])
Epoch: 2501, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2502 - Batch 1 ########################
IDs in batch 1: tensor([1861,  818, 1524, 1050, 2553, 2190,  228,  344,  425, 3330,  666, 3490,
        1311, 1101, 1031, 1868])
Epoch: 2502, Training Loss: 0.17, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2503 - Batch 1 ########################
IDs in batch 1: tensor([ 995, 3947, 1278, 1260, 3504, 2887, 1977,  544, 2428, 2014, 1413, 3036,
         470, 1354,  982, 3771])
Epoch: 2503, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2504 - Batch 1 ########################
IDs in batch 1: tensor([3075, 1373, 3060, 3246,  180, 2412,  526, 2586,  474, 2617, 3244, 2435,
        1601, 1536, 3182, 2205])
Epoch: 2504, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2505 - Batch 1 ########################
IDs in batch 1: tensor([2682,  788, 3088, 2587, 2748,  555, 1886, 2553, 2472, 4264,  757, 3982,
        3168, 3010,  350, 2446])
Epoch: 2505, Training Loss: 0.07, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2506 - Batch 1 ########################
IDs in batch 1: tensor([3894, 3873, 2558, 2879, 2107, 1956,  257, 1496, 1442, 2432, 3585,  259,
        3673, 2078, 2388, 2277])
Epoch: 2506, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2507 - Batch 1 ########################
IDs in batch 1: tensor([1576, 3754, 1895, 1331, 1409, 2196,  494, 1580, 1399, 3078, 2545, 3990,
        3227, 1959, 3762, 3078])
Epoch: 2507, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2508 - Batch 1 ########################
IDs in batch 1: tensor([1011, 1611, 1601, 1552,  837, 3706, 4185,  688, 1256, 3161, 1684,  371,
        3583,  132, 2146, 1320])
Epoch: 2508, Training Loss: 0.34, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2509 - Batch 1 ########################
IDs in batch 1: tensor([2036, 3468,  961, 2155, 4200, 1822,  945, 1937, 2067, 3726, 2712, 3253,
        3227,  602, 3190,  688])
Epoch: 2509, Training Loss: 0.23, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2510 - Batch 1 ########################
IDs in batch 1: tensor([1625, 2134,  902, 3908,  260,  825, 2465, 1548, 3038,  459, 2026, 4125,
        3467, 3881, 1723,  635])
Epoch: 2510, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2511 - Batch 1 ########################
IDs in batch 1: tensor([3378,  172, 1179, 2251, 4268, 1645, 2688, 2773,  741, 1197,  363, 2649,
        1275, 2523, 2772, 1932])
Epoch: 2511, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2512 - Batch 1 ########################
IDs in batch 1: tensor([ 256,   60, 3795, 3178, 1984, 1088, 1853, 1984, 2347,  710,   31, 2765,
         119,  649,   97, 4190])
Epoch: 2512, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2513 - Batch 1 ########################
IDs in batch 1: tensor([1321, 2798, 4181, 1579, 1965, 2541, 3204, 2324, 2505, 3525, 2854, 3278,
          97, 1269, 2456, 3110])
Epoch: 2513, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2514 - Batch 1 ########################
IDs in batch 1: tensor([4116, 2245, 3400,  587, 2655, 4133, 2432, 1452, 3836, 2278,  974,  398,
        1331, 1381, 3956, 2372])
Epoch: 2514, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2515 - Batch 1 ########################
IDs in batch 1: tensor([ 684, 1956, 2365,   64,  622, 3795, 2815, 1032, 3114, 3530,   19,  736,
         894, 1676, 1842, 1824])
Epoch: 2515, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2516 - Batch 1 ########################
IDs in batch 1: tensor([2617, 1134, 3535, 2965, 1690, 3643, 1152, 2429, 1043, 2597, 3635, 3505,
        1026, 2134, 1355, 2754])
Epoch: 2516, Training Loss: 0.46, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2517 - Batch 1 ########################
IDs in batch 1: tensor([4058, 2653, 3449, 4062, 1163, 1772,  202, 3254, 1159,  239,  882, 2040,
         955,  145, 1726, 2564])
Epoch: 2517, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2518 - Batch 1 ########################
IDs in batch 1: tensor([2807, 3497,  442, 2963, 1684,  914,  295,  976, 3658,  659, 1388, 2190,
        1639,  826,  869,  622])
Epoch: 2518, Training Loss: 0.36, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2519 - Batch 1 ########################
IDs in batch 1: tensor([ 773, 2146, 2664, 3428, 2210, 1872, 1076,  356, 3098,  834, 2522,  902,
        2478,  308,  689, 1176])
Epoch: 2519, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2520 - Batch 1 ########################
IDs in batch 1: tensor([ 887, 3052,  987, 2640, 3949, 2087,  131, 1872, 1857, 1251, 1536,  882,
        1722,  265, 3850, 2189])
Epoch: 2520, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2521 - Batch 1 ########################
IDs in batch 1: tensor([2017, 3728,  673, 1147, 1180,  658, 3430, 3742, 2425, 1982,  603, 3160,
        1225, 3311, 2661, 3132])
Epoch: 2521, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2522 - Batch 1 ########################
IDs in batch 1: tensor([2832,  701, 3130, 2073, 1678, 1244, 3444,  890, 3749, 1006, 1668, 3896,
         625, 1099, 2564, 1399])
Epoch: 2522, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2523 - Batch 1 ########################
IDs in batch 1: tensor([1798, 3425, 1878, 1794, 1993,  187, 3467,  455,  833, 1062, 2097, 3092,
        1761, 2575, 2696, 2315])
Epoch: 2523, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2524 - Batch 1 ########################
IDs in batch 1: tensor([2449, 3663, 1104, 3432, 1682, 3871, 2059, 3283, 1167, 3433, 2642, 1491,
         850, 1006, 2683, 1927])
Epoch: 2524, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2525 - Batch 1 ########################
IDs in batch 1: tensor([3228, 3109, 2122,  376, 3382,  368,  145,  343, 1570, 1141, 4227, 2621,
        3338, 2103, 3714, 2998])
Epoch: 2525, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2526 - Batch 1 ########################
IDs in batch 1: tensor([1663, 3218, 3911, 2462,  327, 2204, 1349, 1672,  776, 3440, 2781, 1404,
          59, 3289, 2544,  682])
Epoch: 2526, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2527 - Batch 1 ########################
IDs in batch 1: tensor([3911, 2783, 2119, 4039, 4097, 2565, 1955,  451,  996, 2829,  947, 2967,
        1381,  907, 2624,   93])
Epoch: 2527, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2528 - Batch 1 ########################
IDs in batch 1: tensor([2146, 4234,  667, 2964, 3567,  287,  346, 2668, 2648, 2825, 3038, 3407,
        3593, 2463, 1324, 1693])
Epoch: 2528, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2529 - Batch 1 ########################
IDs in batch 1: tensor([1490, 1975, 3851, 3264,  515,  424, 1087, 1119, 4057, 3241, 3780, 2545,
        2244, 1860, 2189, 1583])
Epoch: 2529, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2530 - Batch 1 ########################
IDs in batch 1: tensor([1284, 1646, 2506, 4236, 3135,  478,   93,  980, 1852, 2025,  663, 1648,
        3628, 3592, 1143, 1291])
Epoch: 2530, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2531 - Batch 1 ########################
IDs in batch 1: tensor([3180, 1821,  966,  459, 4040, 3731, 3516, 2995, 1287,  642, 3624, 3839,
        3553,  915, 3487, 2280])
Epoch: 2531, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2532 - Batch 1 ########################
IDs in batch 1: tensor([3381, 2347, 2206, 2500, 3459, 1154, 2840, 1291,   38, 2297, 3343, 3460,
         357, 3473, 2777, 2913])
Epoch: 2532, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2533 - Batch 1 ########################
IDs in batch 1: tensor([1855, 2867, 2359,  888, 3798, 1130, 2363,  129, 2991,  607, 1519,  545,
        1794, 2917,  904, 2115])
Epoch: 2533, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2534 - Batch 1 ########################
IDs in batch 1: tensor([1501, 2884,  864,  858, 2858, 1911, 2312, 2592, 3428, 1618, 1302, 2807,
         324,  805, 3168,  990])
Epoch: 2534, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2535 - Batch 1 ########################
IDs in batch 1: tensor([ 833, 3447, 3749, 1201,  606,  203, 3338, 4027, 3648, 2627, 2897, 4186,
        1604, 1832, 3180,  777])
Epoch: 2535, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2536 - Batch 1 ########################
IDs in batch 1: tensor([2851, 2733, 1583,  147, 3329, 1495, 2443, 1177, 1761, 1147, 1747,  809,
         260,  451,  736,  187])
Epoch: 2536, Training Loss: 0.33, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2537 - Batch 1 ########################
IDs in batch 1: tensor([3939, 3874, 3314,  726,  829,  121,   73, 2961, 2660, 2739, 4009, 2960,
        1402, 1310, 3920, 4115])
Epoch: 2537, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2538 - Batch 1 ########################
IDs in batch 1: tensor([3866,  959, 2631, 2437, 3683, 2423, 4077, 4007, 2683,  541, 3112,  777,
        3834, 2417, 2010,  398])
Epoch: 2538, Training Loss: 0.32, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2539 - Batch 1 ########################
IDs in batch 1: tensor([1295, 2245,  170,  350, 2218,  444, 4125,  341, 2317, 1007, 2993, 3220,
         538, 3262,  862, 3471])
Epoch: 2539, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2540 - Batch 1 ########################
IDs in batch 1: tensor([ 678,  471, 1585, 3262, 2841,  610, 1442, 3609, 3535,  119, 2521, 2145,
        2953, 4120, 1409,  483])
Epoch: 2540, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.73
######################## Epoch 2541 - Batch 1 ########################
IDs in batch 1: tensor([1944,  584, 1423, 2166, 1333, 3973, 1635, 3177, 3428, 1276, 1299,  721,
        1190, 3410, 3478, 1178])
Epoch: 2541, Training Loss: 0.25, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2542 - Batch 1 ########################
IDs in batch 1: tensor([3795, 2880, 2364,  256, 2539, 1043, 4184, 3374, 3754, 3998,  777, 2484,
        3492, 1732, 2416, 2610])
Epoch: 2542, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2543 - Batch 1 ########################
IDs in batch 1: tensor([2183, 3876,  681, 1138,  352, 3781,   92, 1967, 2775,   50, 2189, 1601,
          50, 1284, 3841,  245])
Epoch: 2543, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2544 - Batch 1 ########################
IDs in batch 1: tensor([2726,  652, 2107, 1120, 3668, 3917, 4251,  572, 4254,  747, 3099, 2475,
        4213, 1186, 2644, 2524])
Epoch: 2544, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2545 - Batch 1 ########################
IDs in batch 1: tensor([  52,  180, 1179, 4101, 1236, 2119, 2188, 1592, 2127, 3765, 4038,   25,
        2863, 3644, 2926, 2841])
Epoch: 2545, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2546 - Batch 1 ########################
IDs in batch 1: tensor([2645, 1834, 1242,  283, 1507, 2204, 2207, 2025, 1972, 4222, 2292, 3196,
        2584, 3110,  902, 2781])
Epoch: 2546, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2547 - Batch 1 ########################
IDs in batch 1: tensor([1193, 4214, 3749, 1363, 1485,  604, 2591, 2356, 2355, 2837, 4139,  628,
        1391, 2356, 1294, 2132])
Epoch: 2547, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2548 - Batch 1 ########################
IDs in batch 1: tensor([2306, 1770, 4148, 3707, 2444, 2645, 2609,  574,  541, 2189, 2370, 4190,
         640, 2112, 4165,  269])
Epoch: 2548, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 2549 - Batch 1 ########################
IDs in batch 1: tensor([ 717,  936, 3659, 2601, 3764, 3253, 1832,  852,   27, 2370,  478,   56,
        1583,  966, 1025, 2385])
Epoch: 2549, Training Loss: 0.08, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2550 - Batch 1 ########################
IDs in batch 1: tensor([2951, 1711,  959, 1239, 1682, 1343,  550, 4203, 1389, 1958,  194, 1004,
        3977, 4105, 2851, 1349])
Epoch: 2550, Training Loss: 0.11, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2551 - Batch 1 ########################
IDs in batch 1: tensor([1287,  469, 1611, 2748, 3647,  790, 2840,  161, 2563,   14, 4268, 3418,
        1682, 3178, 2882, 3391])
Epoch: 2551, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2552 - Batch 1 ########################
IDs in batch 1: tensor([4086, 3569, 3945,  206,  343,  989, 3449, 2170, 1200, 3911, 2414, 3695,
        3087, 1117, 2638, 1558])
Epoch: 2552, Training Loss: 0.02, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2553 - Batch 1 ########################
IDs in batch 1: tensor([4069,  812, 2388, 1835, 1166,  790, 3594, 2334, 2587, 3299, 3119, 2583,
         185, 2858,  636, 1613])
Epoch: 2553, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2554 - Batch 1 ########################
IDs in batch 1: tensor([1335, 3862, 2980,  109,  252, 2545,  177,   24, 1844, 2719, 1967,   25,
        3747, 1650, 1179, 2562])
Epoch: 2554, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2555 - Batch 1 ########################
IDs in batch 1: tensor([3291, 2784,  636, 2492, 2467, 3073, 3474, 2667, 2897,  687, 1718,  934,
         603, 1994, 1440, 1444])
Epoch: 2555, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2556 - Batch 1 ########################
IDs in batch 1: tensor([1537,  681,   50, 3407, 2183, 3790, 2122, 1088,  498, 3311, 3541,  508,
        1423, 1872, 3216, 3503])
Epoch: 2556, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2557 - Batch 1 ########################
IDs in batch 1: tensor([3518, 4146, 2095, 1406, 2119, 1141, 2161, 3404,   31, 3467, 1434, 3010,
        3077, 2371, 1356, 2177])
Epoch: 2557, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2558 - Batch 1 ########################
IDs in batch 1: tensor([2548,  995, 4093, 1409,  829,  610, 2838, 2646, 2652,  550, 3981, 1364,
        1436, 3939, 3275, 3150])
Epoch: 2558, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2559 - Batch 1 ########################
IDs in batch 1: tensor([1458, 1361,  507, 2831, 2260,  738, 2056,  266, 3148, 1386,  183, 2248,
        3872, 2247, 1035, 2870])
Epoch: 2559, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2560 - Batch 1 ########################
IDs in batch 1: tensor([2144, 3712, 3357, 1811,  547, 4110, 2276, 1897, 2497,  190, 3974, 1226,
        4139, 3756, 1171, 1153])
Epoch: 2560, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2561 - Batch 1 ########################
IDs in batch 1: tensor([1285,  287, 4057, 2726, 1568, 3074, 2122, 3437,  141, 2945, 2196,  467,
        4049,  552, 1990, 1277])
Epoch: 2561, Training Loss: 0.09, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2562 - Batch 1 ########################
IDs in batch 1: tensor([ 709, 2997, 3989, 2363,  510,  100, 1442,   49, 1706, 1204, 3951, 4125,
         250, 2483, 1665, 1957])
Epoch: 2562, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 2563 - Batch 1 ########################
IDs in batch 1: tensor([1506, 1257, 1391,  342, 3367, 2734, 1881, 1016, 3509,  514, 2669, 4223,
        2011, 3963,  467, 4143])
Epoch: 2563, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2564 - Batch 1 ########################
IDs in batch 1: tensor([1649,  334, 3312, 2046, 1116, 1970,  942, 3382,  556, 1493, 1751, 4057,
        3810,  749, 2090, 3435])
Epoch: 2564, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2565 - Batch 1 ########################
IDs in batch 1: tensor([1393, 1287, 1264,  659, 4093, 3222, 1842,  438, 3971, 3529, 3994, 2207,
        3953,  501, 2103, 3553])
Epoch: 2565, Training Loss: 0.10, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2566 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 2196,  623, 2824, 3182, 3475, 2236, 1176, 1482, 3326,  409,  663,
        2394, 4108, 3863, 2154])
Epoch: 2566, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2567 - Batch 1 ########################
IDs in batch 1: tensor([ 128, 1911, 3514, 2836, 2458, 2487, 2176, 3921, 3190,   50,   92,  110,
        1824,  287,  660,  699])
Epoch: 2567, Training Loss: 0.12, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2568 - Batch 1 ########################
IDs in batch 1: tensor([ 615,  300, 4025, 3603, 2758,  850, 1371, 3032, 3894, 3432, 4189, 1722,
        2469,   39, 4072, 3460])
Epoch: 2568, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2569 - Batch 1 ########################
IDs in batch 1: tensor([3904,  488, 3894, 1458, 3440, 1136, 1853, 1967, 1118, 2681, 3248, 2312,
        3363, 1425,   92, 3851])
Epoch: 2569, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2570 - Batch 1 ########################
IDs in batch 1: tensor([ 530, 3029, 1730, 3523,  390,  888, 2777,  605, 3933, 3147, 2522, 2329,
        4118, 4194, 1043, 2826])
Epoch: 2570, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2571 - Batch 1 ########################
IDs in batch 1: tensor([2670, 2360, 3504, 4240, 2439, 2522, 2776,  259, 1624,  393,  505, 1223,
        3358, 1224, 2146, 2019])
Epoch: 2571, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2572 - Batch 1 ########################
IDs in batch 1: tensor([1575,  212, 1351, 3529,  713,  899, 4225, 3927, 4000, 2209, 2002, 2466,
        4065,  660, 3466, 2254])
Epoch: 2572, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2573 - Batch 1 ########################
IDs in batch 1: tensor([3259, 1536, 1959, 3834, 1455,  713,  129,  387, 2383, 2847, 4180,  993,
        1700,  508, 3109,  455])
Epoch: 2573, Training Loss: 0.10, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2574 - Batch 1 ########################
IDs in batch 1: tensor([3049, 2624, 3509, 1409,  206,  140, 2609,  923,  876, 2440, 2645, 3705,
        3057,  427, 2205, 3340])
Epoch: 2574, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2575 - Batch 1 ########################
IDs in batch 1: tensor([3534,   43, 2040, 3022, 1073,  910, 4039, 2070, 3676, 4198, 3240, 1594,
         236, 4099, 1668,  508])
Epoch: 2575, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2576 - Batch 1 ########################
IDs in batch 1: tensor([ 726, 2689, 3404, 2526, 2081, 1219,  983,  284,  593,  117, 3697,  954,
        1977,  373, 2827, 1237])
Epoch: 2576, Training Loss: 0.57, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 2577 - Batch 1 ########################
IDs in batch 1: tensor([3423,  995, 3032, 1686, 2536,  849, 1379, 3942, 1138, 3233, 1249, 2983,
         823, 3886, 1793,  681])
Epoch: 2577, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2578 - Batch 1 ########################
IDs in batch 1: tensor([1639,  941, 2780,  794, 4265, 3078,  213, 3696, 2961, 2618,  104, 2459,
        3597,  928,  151, 3277])
Epoch: 2578, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2579 - Batch 1 ########################
IDs in batch 1: tensor([1306,  593, 2548, 2615,  445, 3407,  184, 3404, 3747, 2278, 2327, 1331,
        3371, 1349, 3329, 3130])
Epoch: 2579, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2580 - Batch 1 ########################
IDs in batch 1: tensor([ 843, 2106, 3368,   35, 3214,  128, 2650, 3371, 2453, 3674, 1775, 2341,
         991, 2617,  397, 3787])
Epoch: 2580, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2581 - Batch 1 ########################
IDs in batch 1: tensor([3018,  398, 1871, 1774,  308, 2660, 1809, 3148, 3298, 1959, 3742, 2968,
         534, 2746, 4088, 2636])
Epoch: 2581, Training Loss: 0.41, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2582 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 1763,  593, 2452,  343, 3016,  126, 3384, 2258,  863, 2605, 1225,
        2437,  503, 1458, 3615])
Epoch: 2582, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2583 - Batch 1 ########################
IDs in batch 1: tensor([3816, 1160, 2619, 2171,  482, 2721, 1677,   97, 2210, 1762, 3094, 1668,
         640, 3240, 1199, 3179])
Epoch: 2583, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2584 - Batch 1 ########################
IDs in batch 1: tensor([1076, 3278, 3859, 3094, 1175, 1297, 3865, 3432,  775, 2107,   74, 2649,
        1957, 2189,   98, 2901])
Epoch: 2584, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2585 - Batch 1 ########################
IDs in batch 1: tensor([2309,  148, 2203, 1239, 1384, 1455,  674,  224, 3757, 1826, 3597, 1885,
         371, 3055, 1305, 3407])
Epoch: 2585, Training Loss: 0.18, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2586 - Batch 1 ########################
IDs in batch 1: tensor([1804, 2181, 3705, 2375, 3265, 2730, 2144, 3384, 3872, 1284, 1406, 1365,
        2781, 2688, 2882, 1934])
Epoch: 2586, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2587 - Batch 1 ########################
IDs in batch 1: tensor([3797, 3471, 2506,  514, 2488, 1625, 3815, 4254, 3340, 1775,  106,  584,
        1131, 2305,  796, 4026])
Epoch: 2587, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2588 - Batch 1 ########################
IDs in batch 1: tensor([2949, 4149, 2370, 3591, 4228, 2238, 1073, 1084, 1054, 1119, 2252, 3942,
        3128, 3258, 3856,  834])
Epoch: 2588, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2589 - Batch 1 ########################
IDs in batch 1: tensor([ 459,  779, 3777, 2831, 4056, 3468,  520, 3603, 1942, 2640,  200, 1537,
        3872, 3241, 3524,  733])
Epoch: 2589, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2590 - Batch 1 ########################
IDs in batch 1: tensor([3400,  639, 3549,  986, 3233,  261, 1299, 2847, 4056, 2180, 2796, 1159,
          56, 1384, 1613, 2956])
Epoch: 2590, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2591 - Batch 1 ########################
IDs in batch 1: tensor([ 185, 2159,  717, 2764, 2550,  411, 1921, 2640, 1330,  552, 1904, 2236,
        2874, 2313, 3364, 3727])
Epoch: 2591, Training Loss: 0.28, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2592 - Batch 1 ########################
IDs in batch 1: tensor([1418,  394, 1388, 3762, 2443, 2286, 3573, 4131,   73, 3836,  511, 2815,
        4103,  934, 3443, 2170])
Epoch: 2592, Training Loss: 0.19, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2593 - Batch 1 ########################
IDs in batch 1: tensor([2912,  908, 1737, 1976, 2002, 2616,  602,  342, 2004, 1693, 2056, 1860,
        2595, 1402, 1968, 2659])
Epoch: 2593, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2594 - Batch 1 ########################
IDs in batch 1: tensor([1464, 2874, 1357, 3706, 2783, 3997, 3053,  588, 3113, 1436, 3368, 1899,
         833, 1287,   42, 4180])
Epoch: 2594, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2595 - Batch 1 ########################
IDs in batch 1: tensor([ 950, 3976, 1762,  341, 1367, 2327, 1574, 3945, 1291, 2094, 1795, 4065,
        2451,   70, 4195,  805])
Epoch: 2595, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2596 - Batch 1 ########################
IDs in batch 1: tensor([ 914, 1313, 2172, 2343, 3368,  789, 1702, 3239,  137, 1244,  880, 2390,
        2845, 2170, 3227, 1720])
Epoch: 2596, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2597 - Batch 1 ########################
IDs in batch 1: tensor([3628, 1866, 1436, 1979, 3572, 2244,  978, 1459, 2387, 2485,  653, 3117,
        2157, 2369, 4011, 3111])
Epoch: 2597, Training Loss: 0.10, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2598 - Batch 1 ########################
IDs in batch 1: tensor([ 899, 1458, 2026, 2688, 3701, 2709,  122, 2072, 2018,   38, 3697, 1193,
        2357, 3389,  653,  787])
Epoch: 2598, Training Loss: 0.21, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2599 - Batch 1 ########################
IDs in batch 1: tensor([ 150, 2586, 2897, 3355, 3476, 2155, 2251, 3468, 2718, 3853,   95, 2022,
         185,  563,  546, 1610])
Epoch: 2599, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2600 - Batch 1 ########################
IDs in batch 1: tensor([2655, 1007, 2671, 1178, 4049, 2968, 1190, 3810, 2671, 2674, 3958, 1023,
         316, 1597, 1030, 2217])
Epoch: 2600, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2601 - Batch 1 ########################
IDs in batch 1: tensor([1436, 3468, 2350,  630, 3183, 1821, 2798, 2327, 2347,  193, 4234, 1283,
          30, 1764, 3025, 2712])
Epoch: 2601, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2602 - Batch 1 ########################
IDs in batch 1: tensor([3406, 1123,  851, 1886, 3271, 3494, 1809, 2315, 2488, 3497,  389, 3407,
          28, 3441, 1487, 3954])
Epoch: 2602, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2603 - Batch 1 ########################
IDs in batch 1: tensor([ 245, 1958, 3744, 2316, 2950, 3317, 2338,  407, 1107, 3216, 3100, 3536,
        2730, 2191, 3721,  494])
Epoch: 2603, Training Loss: 0.22, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2604 - Batch 1 ########################
IDs in batch 1: tensor([  88, 3943, 1469, 1380, 2444,  788, 1244, 4230, 3668,  103, 1869,  946,
        3378,  790, 3304,  367])
Epoch: 2604, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2605 - Batch 1 ########################
IDs in batch 1: tensor([3827, 1543, 1370, 1861, 3650,  595, 4060, 1089, 2986, 4265, 2949, 1056,
        2377, 3624, 4051, 3223])
Epoch: 2605, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2606 - Batch 1 ########################
IDs in batch 1: tensor([2936, 1344, 1496, 2437, 1576, 3969,  710, 1473, 2730, 3599, 3492, 3505,
        2120, 3856, 1199, 3744])
Epoch: 2606, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2607 - Batch 1 ########################
IDs in batch 1: tensor([3486, 3040, 2696, 3136, 1860,  471, 1628,  974, 1034, 3388, 4094, 1981,
        1710, 1918, 2292, 3355])
Epoch: 2607, Training Loss: 0.18, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2608 - Batch 1 ########################
IDs in batch 1: tensor([1482, 1802,  289, 1003, 2832, 3368, 3480, 3913,   25, 1341, 2746, 2124,
        4156, 1415,  344, 3498])
Epoch: 2608, Training Loss: 0.20, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2609 - Batch 1 ########################
IDs in batch 1: tensor([ 201, 1822,  191, 1219, 1599, 3466, 2687, 2322, 1644, 2248, 1086, 2496,
        3563, 2365, 1137, 1762])
Epoch: 2609, Training Loss: 0.14, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2610 - Batch 1 ########################
IDs in batch 1: tensor([ 489, 2030,  917, 3733, 3942, 1406, 1360, 3299,   21, 3003, 1173, 3060,
        2902, 3504, 2782, 1285])
Epoch: 2610, Training Loss: 0.06, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2611 - Batch 1 ########################
IDs in batch 1: tensor([2016, 2428, 3144, 2484, 3894, 3696,  752, 2960, 1826,  355, 2824, 1497,
        3298,  803, 1811, 4119])
Epoch: 2611, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2612 - Batch 1 ########################
IDs in batch 1: tensor([3235,  289, 4175,  321, 3543, 3897, 1267, 1842,  626, 4263, 2154, 1107,
        1747, 2724, 1066,  630])
Epoch: 2612, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2613 - Batch 1 ########################
IDs in batch 1: tensor([3060, 3242, 3765, 2356, 1305, 2367, 3299, 1423, 3655, 1305, 1589, 3836,
        1953, 1642,  957, 3051])
Epoch: 2613, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2614 - Batch 1 ########################
IDs in batch 1: tensor([3871, 2331, 3903, 1828, 1326, 3430, 4203,   46, 1499, 1927, 3526, 1077,
        1267,   20, 1317, 3343])
Epoch: 2614, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2615 - Batch 1 ########################
IDs in batch 1: tensor([3287, 1101, 3587,  762, 1809, 1015, 3881, 1803,  171,  884, 1162, 2873,
        1530, 3385, 1754,  796])
Epoch: 2615, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2616 - Batch 1 ########################
IDs in batch 1: tensor([1485, 3072, 2362, 1693, 1174, 1855, 3636, 3498,  102, 1383,  924, 3130,
        1089,  588, 2458, 1935])
Epoch: 2616, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2617 - Batch 1 ########################
IDs in batch 1: tensor([2640, 2798, 1894, 2934,  896, 3838,  395,  968,  183,    4,   30,  894,
        1370, 2976,  499, 1294])
Epoch: 2617, Training Loss: 0.25, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2618 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 3996, 3371, 1734, 3318, 3469, 2166,  505, 2312, 3548, 3372, 2172,
         678, 2238, 1551, 2017])
Epoch: 2618, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2619 - Batch 1 ########################
IDs in batch 1: tensor([1388, 1387, 1650, 1944, 1341, 4251, 2367, 3710, 3956, 4061, 3377,  835,
         372, 1810, 3356,   26])
Epoch: 2619, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2620 - Batch 1 ########################
IDs in batch 1: tensor([3587,  425, 1699,  928, 3952,  892, 2298, 3734, 3569, 2891, 1923, 1404,
        1826, 2218,  610,  488])
Epoch: 2620, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2621 - Batch 1 ########################
IDs in batch 1: tensor([4215, 2344, 2026, 3999, 4264, 1311, 3696, 1900, 1500, 1349, 1141,  601,
        1244, 1302, 3156, 3872])
Epoch: 2621, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2622 - Batch 1 ########################
IDs in batch 1: tensor([1937, 3448, 3421,  439, 2873, 3815, 3995, 2638, 1834, 2122,  835,  613,
        1266, 3760,  526, 2347])
Epoch: 2622, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2623 - Batch 1 ########################
IDs in batch 1: tensor([ 609, 2017,  944, 2748, 2069, 1136,  971, 3608,  811, 1255, 3283, 2810,
        4228, 1456, 1732, 3401])
Epoch: 2623, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2624 - Batch 1 ########################
IDs in batch 1: tensor([1627,  663,  596,  670, 3483, 3504, 1442, 2978, 1724, 3591,  534, 4245,
        3569, 4060, 1285,  180])
Epoch: 2624, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2625 - Batch 1 ########################
IDs in batch 1: tensor([ 827, 3349,  978,  819, 2298, 1693, 2352, 3914, 1648,  923, 2295, 1794,
         554,  921, 2518,  530])
Epoch: 2625, Training Loss: 0.08, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2626 - Batch 1 ########################
IDs in batch 1: tensor([3701, 3072, 2246, 2925, 1885,  820,  937, 1371, 3543, 3472, 2257, 3355,
        2448,   61, 1530, 1195])
Epoch: 2626, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2627 - Batch 1 ########################
IDs in batch 1: tensor([4144, 1501, 3244, 1728, 3181, 2065, 3870, 3282, 2145, 2884, 2965, 1369,
        1097, 1458, 2983, 2696])
Epoch: 2627, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2628 - Batch 1 ########################
IDs in batch 1: tensor([ 514,  673, 1157, 1655, 3147,  491, 3465, 3268, 1782,  673,  649, 3199,
        2199, 3110,   60, 3192])
Epoch: 2628, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2629 - Batch 1 ########################
IDs in batch 1: tensor([ 516, 1596, 2229, 2383, 3830, 2451,  101, 2498, 3123,  415, 1932, 3374,
        3098, 2403,  930,  942])
Epoch: 2629, Training Loss: 0.05, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2630 - Batch 1 ########################
IDs in batch 1: tensor([1973, 2739,  825,   24, 3871, 2399, 3020, 3902, 3200, 2298,   64, 2342,
        2024,  213, 2487, 3087])
Epoch: 2630, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2631 - Batch 1 ########################
IDs in batch 1: tensor([ 516, 3830, 2432, 2429, 2773, 2349, 2870, 1244, 1451, 2857, 4251, 2984,
        1269, 1102, 4096, 1306])
Epoch: 2631, Training Loss: 0.11, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2632 - Batch 1 ########################
IDs in batch 1: tensor([ 990,  505, 1418, 2483,  125, 3693,  252, 3987, 1120, 3449,  557, 2771,
        2660, 4146, 1956, 3589])
Epoch: 2632, Training Loss: 0.18, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2633 - Batch 1 ########################
IDs in batch 1: tensor([ 693, 1536, 1331, 3945, 1196, 3778, 1281, 3980, 3241, 4212, 1748,   78,
        2022, 3461,  413, 2198])
Epoch: 2633, Training Loss: 0.02, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2634 - Batch 1 ########################
IDs in batch 1: tensor([3241, 2437, 3328,  138, 2499, 2009, 3262, 2620, 3284, 3220, 4126, 4187,
        3610, 2453,  955,  398])
Epoch: 2634, Training Loss: 0.13, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2635 - Batch 1 ########################
IDs in batch 1: tensor([2621,  533,  499, 2141, 3713, 2895, 2122, 3289, 1143, 3589, 3267, 1918,
        4048, 3956,  876, 3304])
Epoch: 2635, Training Loss: 0.09, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2636 - Batch 1 ########################
IDs in batch 1: tensor([ 725, 1371, 1977, 4065, 1558,  119, 2437, 3136, 4264, 1056, 1478, 1242,
        4004, 4199, 3969, 2069])
Epoch: 2636, Training Loss: 0.09, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2637 - Batch 1 ########################
IDs in batch 1: tensor([3065, 4180,  397, 2399, 2737, 1199, 4264, 4188, 2649, 1641, 1399, 2898,
        1232, 4168, 4032,  194])
Epoch: 2637, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2638 - Batch 1 ########################
IDs in batch 1: tensor([2984, 1684, 1322, 1597, 4172, 1085, 1627, 1084, 1429, 2983, 1601, 1340,
        4131, 2107, 2159, 1784])
Epoch: 2638, Training Loss: 0.10, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2639 - Batch 1 ########################
IDs in batch 1: tensor([1620,  825,  914, 1050, 1451, 1241, 1034,  887, 2800, 3704, 2581, 2253,
        2092, 3101,  794, 3440])
Epoch: 2639, Training Loss: 0.07, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2640 - Batch 1 ########################
IDs in batch 1: tensor([4030, 2519, 1134, 3962, 3601, 3368, 1175, 3569,  277,  394, 3485, 4087,
        3746, 3299, 2945,  924])
Epoch: 2640, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2641 - Batch 1 ########################
IDs in batch 1: tensor([ 642, 2154,  674,  203, 3754, 2254, 2853,  278, 2262, 1532, 3425, 3729,
        1968,  437, 1680,  741])
Epoch: 2641, Training Loss: 0.04, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2642 - Batch 1 ########################
IDs in batch 1: tensor([3465,   64,  439, 1578,  544, 1508, 3490,  575,  612, 2764, 1418, 2997,
        1825, 2695,  345, 1133])
Epoch: 2642, Training Loss: 0.13, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2643 - Batch 1 ########################
IDs in batch 1: tensor([3743, 1415,  591, 3738, 3949, 1098, 3142,  159, 1086, 4222, 1702, 3683,
        2244, 3718, 2957,  376])
Epoch: 2643, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2644 - Batch 1 ########################
IDs in batch 1: tensor([ 682, 1306, 3769, 3932, 3058, 1199,  825, 4067, 4108, 4197, 4096,  391,
        1556, 1080, 3176, 1679])
Epoch: 2644, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2645 - Batch 1 ########################
IDs in batch 1: tensor([1851, 1566, 2734, 1318, 3472,   97, 3092,  615, 3762, 2703, 3141, 2144,
        4251, 1521, 3469, 1302])
Epoch: 2645, Training Loss: 0.02, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2646 - Batch 1 ########################
IDs in batch 1: tensor([3439, 2497, 2518, 1786, 1934, 1426,  185, 1117, 3423,  874,  961, 3870,
        1272, 2357, 4138, 3094])
Epoch: 2646, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2647 - Batch 1 ########################
IDs in batch 1: tensor([2300, 2950, 1626, 1426, 2355, 1473, 2536, 4115, 3581, 2604, 3333, 2050,
         721, 2073, 3830,  181])
Epoch: 2647, Training Loss: 0.12, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2648 - Batch 1 ########################
IDs in batch 1: tensor([3853,  103, 3401, 1133, 1646, 3891, 2619,  422, 1201, 3339, 1960, 3859,
        3514, 4218,  963, 1679])
Epoch: 2648, Training Loss: 0.06, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2649 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 2415, 1737, 2365, 2523,  572,  636, 1224,  736, 3248, 1195,  237,
        2280, 2730, 3024, 2036])
Epoch: 2649, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2650 - Batch 1 ########################
IDs in batch 1: tensor([2145, 1118, 2752, 2809, 3208, 2169, 2489,  606, 3323, 2348,  251, 2297,
        3895, 1285,   93, 1168])
Epoch: 2650, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2651 - Batch 1 ########################
IDs in batch 1: tensor([2763, 1067, 1137, 1052, 3424, 2524, 2315, 1397, 4261, 3617, 1341, 3875,
        3995, 1080, 1861,   81])
Epoch: 2651, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2652 - Batch 1 ########################
IDs in batch 1: tensor([ 436, 3100, 2171,  645, 3673, 2236,  497, 4190,  980,  971, 1510,  946,
        2680, 1762, 3503, 1160])
Epoch: 2652, Training Loss: 0.11, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2653 - Batch 1 ########################
IDs in batch 1: tensor([3795, 1324, 3528, 4100,  989, 1763,  649, 3181, 3161, 4203,  403, 3216,
        3597,  584, 2446, 2425])
Epoch: 2653, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2654 - Batch 1 ########################
IDs in batch 1: tensor([3753,  724, 1643, 2887, 1620, 2672,  997, 3585, 1885, 3460, 2493, 2193,
        2477, 2936,  659, 1921])
Epoch: 2654, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2655 - Batch 1 ########################
IDs in batch 1: tensor([2290, 3903, 1642, 3712,  330, 2921, 1124, 2145,  879, 2416, 1083, 1168,
        2056, 2652, 3947, 1878])
Epoch: 2655, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2656 - Batch 1 ########################
IDs in batch 1: tensor([1257, 2667, 3312, 3246, 1488, 3053, 1770, 3516, 3655, 4224,  190, 2721,
        1951, 3108, 1337,  934])
Epoch: 2656, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2657 - Batch 1 ########################
IDs in batch 1: tensor([ 287, 2039, 3219,  213, 3241, 4048, 3656, 3177, 4078, 2479,  148, 4176,
        1482, 2127, 1787, 2470])
Epoch: 2657, Training Loss: 0.29, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2658 - Batch 1 ########################
IDs in batch 1: tensor([2193, 2758, 2983,  226, 1005, 3795,  658,  358, 2661,  886, 2736, 1661,
        4113,  572, 2103, 2415])
Epoch: 2658, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2659 - Batch 1 ########################
IDs in batch 1: tensor([1937, 2238,  330, 2670, 3251, 1124,  303, 2370, 1090, 2348, 3291, 1910,
        3765, 2880, 1948,  565])
Epoch: 2659, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2660 - Batch 1 ########################
IDs in batch 1: tensor([1130, 3704, 1275, 2847, 2926, 1297,  626, 2871, 2715,  852, 3465, 3713,
        2124, 2372, 3430,  426])
Epoch: 2660, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2661 - Batch 1 ########################
IDs in batch 1: tensor([3484, 2125, 3908, 4242,  218,  517, 2586, 2287,  981, 1604, 1285, 3727,
        1993, 1590, 2320, 3459])
Epoch: 2661, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2662 - Batch 1 ########################
IDs in batch 1: tensor([2847, 3306, 1474,  122, 1332, 2387, 1840, 1548,  875, 2369, 2154, 2099,
          82, 4099, 2039, 2937])
Epoch: 2662, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2663 - Batch 1 ########################
IDs in batch 1: tensor([3746, 1490, 1573, 1389,  527, 2641, 2018, 3832, 1094,  432,  289, 2400,
        2238, 2859, 2755,  196])
Epoch: 2663, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2664 - Batch 1 ########################
IDs in batch 1: tensor([2441, 3832, 2238,  957,  511, 1043, 4007, 1737, 1138,  327, 2379,  954,
        3671, 1886,  880, 2609])
Epoch: 2664, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2665 - Batch 1 ########################
IDs in batch 1: tensor([3480, 1158, 3726, 2127, 1935, 1035, 3668, 2516, 2932, 1722, 3218, 1415,
         792, 1944, 1147, 1292])
Epoch: 2665, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2666 - Batch 1 ########################
IDs in batch 1: tensor([4152, 1568, 2617, 3549, 3469, 2134, 3503, 3128,  673, 3681, 1337, 2102,
         335, 1530, 3764, 3871])
Epoch: 2666, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2667 - Batch 1 ########################
IDs in batch 1: tensor([3432, 1337, 1126, 2638, 2111,  492, 2902,  497, 1727, 1408, 2882, 3218,
        1656, 3150, 3990, 3853])
Epoch: 2667, Training Loss: 0.21, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 2668 - Batch 1 ########################
IDs in batch 1: tensor([3313, 1309, 2401, 3786, 3856, 2968,  137, 3671, 3838,  255,  818, 1097,
        1438, 2257,  623, 3667])
Epoch: 2668, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2669 - Batch 1 ########################
IDs in batch 1: tensor([4212, 1508, 2516, 2973, 2465,  469, 2770, 1484, 2959, 2517, 3952, 3168,
        3746, 1899, 2829, 2583])
Epoch: 2669, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2670 - Batch 1 ########################
IDs in batch 1: tensor([3002, 1455, 2098, 3369, 1556, 2755, 2013, 2765,  507, 1183, 2645,  164,
        3681, 2564, 3154, 3238])
Epoch: 2670, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2671 - Batch 1 ########################
IDs in batch 1: tensor([1548, 2693, 2326, 2452, 1143, 4094,  245,  673, 1340,  289, 1965,  371,
        2493, 2998, 3192, 3354])
Epoch: 2671, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2672 - Batch 1 ########################
IDs in batch 1: tensor([3467, 1644,  993, 1242, 1951, 2400, 2416, 4196, 1575, 2256, 1402, 4035,
        3753, 3608, 2182, 3948])
Epoch: 2672, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2673 - Batch 1 ########################
IDs in batch 1: tensor([1646,  518, 2091, 1166, 3533, 1139, 2132, 2026,  322, 3976, 2370, 3658,
        2248, 3308, 3786, 2986])
Epoch: 2673, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2674 - Batch 1 ########################
IDs in batch 1: tensor([2406, 2420, 2518,  466, 3423, 1328, 1841, 1747, 4198, 2234, 3738, 3047,
        4249, 2301,  771, 4256])
Epoch: 2674, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2675 - Batch 1 ########################
IDs in batch 1: tensor([4257, 3712, 1108, 2372, 2065, 1833, 1526, 4062, 3490, 3426, 1171, 2087,
        3448, 1183,  834, 1042])
Epoch: 2675, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2676 - Batch 1 ########################
IDs in batch 1: tensor([1294, 2167,  356, 1267,   82,  946, 1618, 3146,  771, 3914, 3658, 2709,
        2348, 2595, 1082, 3489])
Epoch: 2676, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2677 - Batch 1 ########################
IDs in batch 1: tensor([1146, 2980, 3005, 2550, 2112, 1568,  569, 1702,  516,  335,  971,   59,
        1770, 2683,  217, 2177])
Epoch: 2677, Training Loss: 0.11, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2678 - Batch 1 ########################
IDs in batch 1: tensor([2410, 2111, 3250, 1885, 1996, 1309, 1841, 1559, 1774, 3827,  102,  994,
        2968,  281, 4022, 2331])
Epoch: 2678, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2679 - Batch 1 ########################
IDs in batch 1: tensor([ 887, 1971, 1575, 4058,   49, 3397, 1260, 3351,   82, 2256, 2231, 1901,
        2479, 3147, 1959, 3303])
Epoch: 2679, Training Loss: 0.19, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2680 - Batch 1 ########################
IDs in batch 1: tensor([2027, 1084, 1706,  351,   64, 3780, 1272,  842, 2960, 2074, 2015,   70,
        3778, 3257, 3488,   78])
Epoch: 2680, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2681 - Batch 1 ########################
IDs in batch 1: tensor([3655,  324, 3655, 4013, 1942, 3073, 3701, 4127, 1626, 1381, 3762, 1107,
          37,  855,  996, 1740])
Epoch: 2681, Training Loss: 0.09, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2682 - Batch 1 ########################
IDs in batch 1: tensor([ 537, 2965, 3745, 2942, 2484, 1271, 2317, 2661,  815,   98, 3985,  980,
        2413, 4121, 1163, 1693])
Epoch: 2682, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 2683 - Batch 1 ########################
IDs in batch 1: tensor([1842, 3044, 3505, 3372, 2031, 2914, 3842, 1157, 2456,  757, 3976, 4013,
        3239, 2106, 3727, 3202])
Epoch: 2683, Training Loss: 0.55, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 2684 - Batch 1 ########################
IDs in batch 1: tensor([3894, 2291,  966,  350, 2908, 2205, 1163,   13, 1182, 2036,  988, 2505,
        2366, 1175, 1736, 3569])
Epoch: 2684, Training Loss: 0.23, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2685 - Batch 1 ########################
IDs in batch 1: tensor([ 733, 1325, 1614, 3447, 3455, 4188, 3327, 1817, 3150, 1627, 2114, 1028,
        1081, 3783,  335, 3060])
Epoch: 2685, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2686 - Batch 1 ########################
IDs in batch 1: tensor([1199, 2296,  520,  182, 1279, 1618, 1670,  826, 2718,  463, 1536,  515,
        3303, 2383, 1193, 3038])
Epoch: 2686, Training Loss: 0.38, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2687 - Batch 1 ########################
IDs in batch 1: tensor([2936, 2840, 2088, 3468, 2831, 2815, 2313, 3094,  863, 2587,  974, 2056,
        3908, 1405, 1321, 2936])
Epoch: 2687, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2688 - Batch 1 ########################
IDs in batch 1: tensor([ 207, 1731, 3017,  826, 2511,  989, 1247, 2506, 1842,  475, 2600, 1034,
        1177, 3480, 1357, 3711])
Epoch: 2688, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2689 - Batch 1 ########################
IDs in batch 1: tensor([4107,  539,  340,  955, 2045, 2390, 3476,  930, 3816, 2539, 1963, 3283,
        3652, 1836, 1291, 1623])
Epoch: 2689, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2690 - Batch 1 ########################
IDs in batch 1: tensor([3697, 4113,  538, 1556, 2655, 2059, 1248, 1306, 1347,   46, 4258, 3588,
        3598, 3105, 2132, 1957])
Epoch: 2690, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2691 - Batch 1 ########################
IDs in batch 1: tensor([3521, 4256,  434,  316, 2891,  812, 1830, 2688, 3181, 3343, 2706,  725,
         518, 4175, 4254, 3099])
Epoch: 2691, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2692 - Batch 1 ########################
IDs in batch 1: tensor([3265, 3338, 1429,  377, 2746, 2245, 1699,   84, 1328,  343,  527, 3176,
         991, 3907,   56, 1948])
Epoch: 2692, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2693 - Batch 1 ########################
IDs in batch 1: tensor([1094, 4007, 1182,  466, 1798, 3664, 2978, 2346, 1042, 2245, 3987, 1471,
         617, 1195, 3961, 3289])
Epoch: 2693, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2694 - Batch 1 ########################
IDs in batch 1: tensor([ 558, 1072, 3128,  693, 2671, 3124, 1580,  323,  920, 1428,  590, 3583,
        1638, 1361, 3802,  345])
Epoch: 2694, Training Loss: 0.33, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2695 - Batch 1 ########################
IDs in batch 1: tensor([1190, 2676, 1625, 3408, 1239, 3627, 4060, 1938, 3032, 3326,  401, 4048,
        1882,  794, 1390,  878])
Epoch: 2695, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2696 - Batch 1 ########################
IDs in batch 1: tensor([ 827, 3254,  926, 2601, 1248, 1313, 2050, 2851,  498,  963, 1170, 2232,
        2234, 2624, 2736, 2586])
Epoch: 2696, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2697 - Batch 1 ########################
IDs in batch 1: tensor([2745, 3259, 1777,  147, 2322,  252, 1056, 3798, 3898, 2719, 3762, 1082,
         959, 4089,   70, 3942])
Epoch: 2697, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2698 - Batch 1 ########################
IDs in batch 1: tensor([2926, 3753, 1668, 3812, 1351,  718,  956,  196, 1152,  155, 1470, 3790,
        3417,   74, 1957, 4058])
Epoch: 2698, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2699 - Batch 1 ########################
IDs in batch 1: tensor([4072,  902,  730, 1005, 1434, 4051, 3940,  203, 3240, 3214, 3697, 2099,
        1540, 4214, 2674, 1250])
Epoch: 2699, Training Loss: 0.13, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2700 - Batch 1 ########################
IDs in batch 1: tensor([2086, 2763,  721,  553, 1923, 2144, 2480, 3738, 1181,  358, 2365, 3440,
        2927, 2329, 2437,  622])
Epoch: 2700, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2701 - Batch 1 ########################
IDs in batch 1: tensor([1497, 3507, 3866, 3185, 3836, 1920, 1977,  280,  199, 4033,  474, 3283,
        4068, 3827,  830, 4148])
Epoch: 2701, Training Loss: 0.08, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2702 - Batch 1 ########################
IDs in batch 1: tensor([2375,  245, 2428, 1216,  887, 3299, 3124, 3636, 2993, 1824, 2323, 3942,
        1965,  132, 3813, 1440])
Epoch: 2702, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2703 - Batch 1 ########################
IDs in batch 1: tensor([ 442, 3379, 1684, 2017, 3161, 1794, 1866, 2937, 2109, 4170, 2740, 2695,
        1375, 3727, 1828, 2727])
Epoch: 2703, Training Loss: 0.44, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2704 - Batch 1 ########################
IDs in batch 1: tensor([  93, 1734, 1530, 3385,  733,  871, 3337,  505,  517,  591,  382, 2251,
        4078,  518,  804, 2966])
Epoch: 2704, Training Loss: 0.24, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2705 - Batch 1 ########################
IDs in batch 1: tensor([3071, 1700, 4099, 1047, 1234, 3014, 1324, 4225, 2027, 1290, 1276, 3658,
        2927, 1233, 3029,  487])
Epoch: 2705, Training Loss: 0.03, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2706 - Batch 1 ########################
IDs in batch 1: tensor([4148, 2977, 3594, 3630, 2505,  467, 2369, 1256, 3870,  661, 2398, 3005,
         544, 1356, 1532,  399])
Epoch: 2706, Training Loss: 0.03, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2707 - Batch 1 ########################
IDs in batch 1: tensor([2978, 2860, 2060,  937, 2161, 3159, 3707, 2253, 2672, 2516, 1167, 2793,
        3873, 1242, 2950, 2467])
Epoch: 2707, Training Loss: 0.21, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2708 - Batch 1 ########################
IDs in batch 1: tensor([4240, 1088, 1728, 3588, 1052, 2723, 4212,  532, 2913, 1197, 3199, 2969,
        3680, 1679, 3971,   73])
Epoch: 2708, Training Loss: 0.03, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2709 - Batch 1 ########################
IDs in batch 1: tensor([ 835, 3187, 4035,  807, 3928,  322, 3598,  839,   98,  243, 4057, 3168,
        1499, 2347, 3644,  259])
Epoch: 2709, Training Loss: 0.11, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2710 - Batch 1 ########################
IDs in batch 1: tensor([2550,  125, 1775, 1818, 1651, 2577, 1374, 2823,  851, 2572, 2688, 1318,
        2925, 3930,  883, 2565])
Epoch: 2710, Training Loss: 0.03, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2711 - Batch 1 ########################
IDs in batch 1: tensor([3836, 3493, 2712, 2866, 3154,  724, 3856, 2990, 4025, 3135, 2475, 2522,
        1728, 2826, 2230, 3075])
Epoch: 2711, Training Loss: 0.22, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2712 - Batch 1 ########################
IDs in batch 1: tensor([1840,  723,  681, 2417,  872, 2604, 2956, 1209,  127, 1315,  818, 3114,
         674, 2056, 4127, 2385])
Epoch: 2712, Training Loss: 0.05, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2713 - Batch 1 ########################
IDs in batch 1: tensor([2109, 1553, 1133, 2974, 2431, 2729, 3087, 3121,  356, 2953,  365, 2463,
        3980, 1918,  685, 3384])
Epoch: 2713, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 2714 - Batch 1 ########################
IDs in batch 1: tensor([ 536, 1273, 1221, 1429, 3785, 2712,  594, 2680,  909, 2782, 3242, 1206,
        1673,  949,  207, 2887])
Epoch: 2714, Training Loss: 0.12, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2715 - Batch 1 ########################
IDs in batch 1: tensor([1072, 2800, 1340,  234, 2809, 2432, 1590, 1472, 3087, 4234, 4170, 3286,
        3751, 3264,  792, 3615])
Epoch: 2715, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2716 - Batch 1 ########################
IDs in batch 1: tensor([2442,  894, 1341, 4076, 2400, 3053,  665, 2745, 2631, 3621, 1970, 2761,
        3847,  430, 1052,  774])
Epoch: 2716, Training Loss: 0.16, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2717 - Batch 1 ########################
IDs in batch 1: tensor([1452, 2508, 2835, 1432,  554, 2872, 3977, 2131, 2106, 2390, 2942, 2629,
        1740,  160, 2366,  762])
Epoch: 2717, Training Loss: 0.02, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2718 - Batch 1 ########################
IDs in batch 1: tensor([1103,  321, 3005, 3355, 3528, 3913, 1972, 2652, 4068, 1980, 1585,  661,
        1237, 3705,  442, 2018])
Epoch: 2718, Training Loss: 0.02, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2719 - Batch 1 ########################
IDs in batch 1: tensor([1596, 1481, 3261, 3875, 3850, 2842, 4108,    4, 1197, 2252, 1886, 1152,
         558,  397, 2732,  220])
Epoch: 2719, Training Loss: 0.02, Validation Loss: 0.64, accuracy = 0.76
######################## Epoch 2720 - Batch 1 ########################
IDs in batch 1: tensor([ 476, 2301, 1974, 3533, 2458, 3492, 1267, 4037,  252, 3541, 2456, 1405,
        1063, 1640, 1409,   70])
Epoch: 2720, Training Loss: 0.07, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2721 - Batch 1 ########################
IDs in batch 1: tensor([1472,   92, 3401, 2645,  101, 2499,  672, 1383, 4168, 3609, 3440, 3524,
         435, 4200, 1762, 3790])
Epoch: 2721, Training Loss: 0.09, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2722 - Batch 1 ########################
IDs in batch 1: tensor([1536, 3841, 1309, 3379, 2616,  402, 3074, 2299, 2536, 3535, 1178, 3677,
        3866, 3539, 2954, 3344])
Epoch: 2722, Training Loss: 0.20, Validation Loss: 0.64, accuracy = 0.78
######################## Epoch 2723 - Batch 1 ########################
IDs in batch 1: tensor([1249, 1614, 3652, 1213, 2655, 2141, 3282,  736, 1052, 1434,  701, 1891,
        2725, 3394, 3423, 2390])
Epoch: 2723, Training Loss: 0.03, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2724 - Batch 1 ########################
IDs in batch 1: tensor([4046, 4073, 2743, 3793,  483, 1747,  786, 1770, 1862, 3797, 4035, 3771,
        4124, 1536,  822, 1830])
Epoch: 2724, Training Loss: 0.04, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2725 - Batch 1 ########################
IDs in batch 1: tensor([1630, 3287, 2668,  687, 1256, 3551, 2867,  161, 2144, 1512, 4228, 1817,
        2646,  279, 2429, 1181])
Epoch: 2725, Training Loss: 0.03, Validation Loss: 0.64, accuracy = 0.77
######################## Epoch 2726 - Batch 1 ########################
IDs in batch 1: tensor([ 147,  289, 3764, 2849, 1344,  818, 2798, 1699,  432, 1393, 1185,  884,
        3668,  201, 3227, 1354])
Epoch: 2726, Training Loss: 0.41, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2727 - Batch 1 ########################
IDs in batch 1: tensor([3176, 4268, 1491, 3673, 2041, 3364,   72, 3470, 2363,  681, 3328, 1675,
        2407,  344, 2370, 3367])
Epoch: 2727, Training Loss: 0.03, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2728 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 1954, 3518, 1673, 2148, 2015,  881, 1361,  558, 1604,  527, 2119,
        1778, 1921, 1546, 3486])
Epoch: 2728, Training Loss: 0.05, Validation Loss: 0.65, accuracy = 0.78
######################## Epoch 2729 - Batch 1 ########################
IDs in batch 1: tensor([2978, 1042, 3221, 4254,  590, 1370, 1053, 2624, 3521, 3208,  202, 1179,
        2323,  943, 2365,  232])
Epoch: 2729, Training Loss: 0.27, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2730 - Batch 1 ########################
IDs in batch 1: tensor([1274, 2296, 4128,  394,  653, 3845, 2871,  397, 3971, 3330,  373,  976,
        3185,  356, 1367, 1267])
Epoch: 2730, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2731 - Batch 1 ########################
IDs in batch 1: tensor([  10, 2090, 1056, 1237,   10, 1619,  470,  224, 3881,  936, 3674,  352,
        3851, 1244, 1710, 1326])
Epoch: 2731, Training Loss: 0.49, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2732 - Batch 1 ########################
IDs in batch 1: tensor([  46, 1153, 1638,  361,  792, 2914, 1275, 2437, 1328, 1781, 1583, 1282,
        1063,  418,  343, 2343])
Epoch: 2732, Training Loss: 0.84, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 2733 - Batch 1 ########################
IDs in batch 1: tensor([2437, 4146, 1295, 3309,   25, 4014, 3582, 1152, 1395, 1056, 1567,  723,
        3531, 2306, 2398,  915])
Epoch: 2733, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 2734 - Batch 1 ########################
IDs in batch 1: tensor([2953, 3991,  684, 4086, 3345, 2473,  693, 3340, 4119,  106,  550, 2800,
        1016, 2110, 1225, 4225])
Epoch: 2734, Training Loss: 0.08, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2735 - Batch 1 ########################
IDs in batch 1: tensor([2954,  513,  263, 3202, 1605,  452,  674, 1189,  505,  535, 2026, 1011,
        2495, 1371, 3446,  985])
Epoch: 2735, Training Loss: 0.35, Validation Loss: 0.65, accuracy = 0.76
######################## Epoch 2736 - Batch 1 ########################
IDs in batch 1: tensor([1947, 1979, 2443, 2974, 2953, 2322, 1116, 1316, 1375, 2494, 4073, 3394,
        3935, 1904, 1022,  808])
Epoch: 2736, Training Loss: 0.18, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 2737 - Batch 1 ########################
IDs in batch 1: tensor([2701, 2781, 2884, 3798, 2795, 1016, 3495, 2598, 2606,  110, 3564,   73,
        1850, 2835, 3223, 2161])
Epoch: 2737, Training Loss: 0.23, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2738 - Batch 1 ########################
IDs in batch 1: tensor([2473, 2823, 4014, 2545, 4174,  403, 2691, 2282, 1920,  766, 3427, 1051,
        1287, 2579, 4015, 2465])
Epoch: 2738, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2739 - Batch 1 ########################
IDs in batch 1: tensor([4220,  565, 1726,  316, 2217, 1007, 3475, 1179, 3563,  596, 3127, 3100,
        3014, 3786, 1947,  102])
Epoch: 2739, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 2740 - Batch 1 ########################
IDs in batch 1: tensor([ 936, 1448,  682, 1059, 3934, 3409, 1578, 2316, 3321,  787, 2953, 3434,
        2666, 1704,  135, 2149])
Epoch: 2740, Training Loss: 0.02, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 2741 - Batch 1 ########################
IDs in batch 1: tensor([4113, 2869,  857, 3999, 1256, 2142, 2827, 3299,  691,  225, 1761, 1911,
        2869, 1017, 2584, 3936])
Epoch: 2741, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2742 - Batch 1 ########################
IDs in batch 1: tensor([4218, 1429, 2155, 2708, 3651,  661,  701, 3426,  261, 2798, 1991, 1826,
        3511, 2733, 3614, 1305])
Epoch: 2742, Training Loss: 0.12, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2743 - Batch 1 ########################
IDs in batch 1: tensor([1445, 3804, 4056, 1585, 1866, 1027, 4097, 3371, 2341,  375, 2448, 3053,
        3394,  193, 1469, 4149])
Epoch: 2743, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2744 - Batch 1 ########################
IDs in batch 1: tensor([3246,  221, 2581, 2337, 3049, 2107, 1809, 4199,  403,  738, 4000, 1131,
        1361, 2206, 2536, 1706])
Epoch: 2744, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2745 - Batch 1 ########################
IDs in batch 1: tensor([ 173, 1434, 1250,  407, 1690, 3385, 3323, 2167, 2410, 1628, 1258, 4217,
        3392, 2812, 1736,  182])
Epoch: 2745, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2746 - Batch 1 ########################
IDs in batch 1: tensor([2127, 1111, 1639, 3569, 3338, 3673, 1972, 3514, 1595, 4158, 2660,  280,
        3635, 2592, 3370, 1286])
Epoch: 2746, Training Loss: 0.36, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2747 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 4188, 3397, 1373, 4105, 4005, 3701,  236,   37,  832, 3354, 1310,
        2435, 2133, 2648, 3390])
Epoch: 2747, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2748 - Batch 1 ########################
IDs in batch 1: tensor([3742, 4256, 1984, 1276,  914, 3150,  855, 3949, 2161, 1065, 1927, 1722,
         854,  656, 3592, 1747])
Epoch: 2748, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2749 - Batch 1 ########################
IDs in batch 1: tensor([2867, 1139,  182, 3874, 4173, 1084, 3960, 2098, 3534, 1836,  808, 3144,
        2121, 3846,  137, 3040])
Epoch: 2749, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2750 - Batch 1 ########################
IDs in batch 1: tensor([  88, 2028, 2034, 1067, 3148, 3299, 2631, 2045, 3353, 3441, 3005, 2845,
        3385, 2195, 1385, 1152])
Epoch: 2750, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2751 - Batch 1 ########################
IDs in batch 1: tensor([1780, 3681, 1825, 1448, 1612, 1967, 1612, 3300, 1434, 1244,  131,  282,
        1766,  106, 2589,  657])
Epoch: 2751, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2752 - Batch 1 ########################
IDs in batch 1: tensor([3452, 3947, 1099, 2353,  837, 2171, 2664, 3958, 2564, 1116, 2142, 1439,
         518, 2824, 3444, 1484])
Epoch: 2752, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2753 - Batch 1 ########################
IDs in batch 1: tensor([2959, 1658, 2375, 2517,  852, 1470, 1244, 3250, 2450,  170, 2226, 2108,
         407, 3022,  217, 2726])
Epoch: 2753, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2754 - Batch 1 ########################
IDs in batch 1: tensor([ 921, 3425,   47, 3119, 1125,  454, 1974, 3533, 1448,  915,   52, 3440,
        2210,   10,  442, 3782])
Epoch: 2754, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2755 - Batch 1 ########################
IDs in batch 1: tensor([ 250, 1732, 2886, 3436, 1591,  710, 3938, 1895,  814, 2851, 3501, 2044,
        1748,  467,  121, 2116])
Epoch: 2755, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2756 - Batch 1 ########################
IDs in batch 1: tensor([3632, 4011, 4025, 3349, 4224, 2493, 1325, 4196, 2188, 1349,  928,  578,
        2405,  265, 3208, 1796])
Epoch: 2756, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2757 - Batch 1 ########################
IDs in batch 1: tensor([ 710, 1428,  482, 2313, 3816, 3987, 1311, 1681, 2996, 3807, 1658, 3743,
        2520,  679, 4072, 1451])
Epoch: 2757, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2758 - Batch 1 ########################
IDs in batch 1: tensor([4073, 3216, 1624, 2659, 2730, 1521, 4007, 4010, 2851,  785, 2848, 1942,
        3654, 1137, 3004,  532])
Epoch: 2758, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2759 - Batch 1 ########################
IDs in batch 1: tensor([ 985, 3160,  252, 3084, 2385, 2559,  590, 4044, 1414,  141, 3738, 1763,
        3439,  673, 4161, 2016])
Epoch: 2759, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2760 - Batch 1 ########################
IDs in batch 1: tensor([1722, 1675, 3886, 4049, 2081,  363,  463, 2667, 3609, 1647, 1320,  797,
        3415, 2824,  575,  499])
Epoch: 2760, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2761 - Batch 1 ########################
IDs in batch 1: tensor([3680, 2483, 1295, 3142, 3810, 1039, 1081, 1938,   24,  914,  936, 1017,
        3251, 1902, 3569, 2446])
Epoch: 2761, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2762 - Batch 1 ########################
IDs in batch 1: tensor([2019, 2094, 4114,  712, 1862, 3330, 1913,  980,  769,  398,  574, 2968,
        3778, 1793, 1201,  325])
Epoch: 2762, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2763 - Batch 1 ########################
IDs in batch 1: tensor([3495, 3603, 2529, 3415,  343,  578,   50, 1297, 4261, 4138, 2804,  910,
        2945, 1174, 3407, 2672])
Epoch: 2763, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2764 - Batch 1 ########################
IDs in batch 1: tensor([2812, 1470, 1023,  300,  879, 2188, 1450, 2376, 4175, 3655,  439, 2672,
        3349, 2912,   61, 1455])
Epoch: 2764, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2765 - Batch 1 ########################
IDs in batch 1: tensor([2819,  151,  659, 1022,   35,  566,  379, 2254, 1931, 1272,  188, 3718,
        3837, 1996, 3654, 1774])
Epoch: 2765, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2766 - Batch 1 ########################
IDs in batch 1: tensor([3389, 2274, 2348, 3782, 3278, 3651, 2652, 3866,  977,   51,  318, 3656,
         437,  652, 2761,  842])
Epoch: 2766, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2767 - Batch 1 ########################
IDs in batch 1: tensor([1638, 4205, 4168,  110,  340, 3740,  775, 2346, 1388,  975,  805,  133,
        1001, 3310, 1644, 3073])
Epoch: 2767, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2768 - Batch 1 ########################
IDs in batch 1: tensor([1372, 1933, 2957, 3421, 4022, 1959,  794, 1085,  340, 1974, 1340, 1558,
         245, 1511, 1130, 1952])
Epoch: 2768, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2769 - Batch 1 ########################
IDs in batch 1: tensor([4025,  403, 4172, 4005, 2116, 3659, 4026, 4234, 4159, 2805, 2571, 2522,
        2521,  476, 3792,  359])
Epoch: 2769, Training Loss: 0.35, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2770 - Batch 1 ########################
IDs in batch 1: tensor([2718, 1328, 2085,  332,  511,  823, 1568, 3509, 3913,  828, 2541,  372,
        3176,  816, 1952, 2117])
Epoch: 2770, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2771 - Batch 1 ########################
IDs in batch 1: tensor([1722, 2298,  337, 1349, 1364, 4154, 4194, 2520, 1179,   72, 1678,  615,
        3197, 2234, 3513, 3238])
Epoch: 2771, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2772 - Batch 1 ########################
IDs in batch 1: tensor([2483,  826, 3460, 3977, 2045, 1024, 1558, 2748, 1315, 2265, 2734, 2382,
        2564, 3439, 2249, 2419])
Epoch: 2772, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2773 - Batch 1 ########################
IDs in batch 1: tensor([3956, 1511, 4082,  875, 4195, 3885,  511,  330,  134, 1671, 1030, 3386,
        3749, 1414,  234,  794])
Epoch: 2773, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2774 - Batch 1 ########################
IDs in batch 1: tensor([3466, 3863, 2155, 2121, 2376, 3421,  100, 1524, 2028, 3731, 1337, 4093,
        3248, 3912, 1206, 2284])
Epoch: 2774, Training Loss: 0.24, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2775 - Batch 1 ########################
IDs in batch 1: tensor([2984,  964, 3389, 3757,  937, 2228, 2362, 4004, 2475, 1070, 3539, 2482,
        1162, 2845, 1075, 4017])
Epoch: 2775, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2776 - Batch 1 ########################
IDs in batch 1: tensor([ 221, 2960, 3038, 2688, 1878, 1613,  620, 2199, 1006, 2204, 2443, 1357,
         937, 4179, 2812, 3707])
Epoch: 2776, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2777 - Batch 1 ########################
IDs in batch 1: tensor([3701, 4080, 2087,  469, 1882, 3782,  550, 3118,  117,  135, 1061, 2839,
        3696, 2687, 1042, 2151])
Epoch: 2777, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2778 - Batch 1 ########################
IDs in batch 1: tensor([1655, 2045, 3533,  773,  896, 1123, 1562, 4212, 1950, 3113, 4174, 2446,
          49,  864,  610, 1384])
Epoch: 2778, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2779 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 1123, 2206, 3898, 3423, 3878, 3310, 3423, 1399, 3780, 2468, 3219,
         659, 3162,  324,  388])
Epoch: 2779, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2780 - Batch 1 ########################
IDs in batch 1: tensor([1377,  234, 2372,  488, 1684, 2364, 2867, 1116,  199, 2794,  752, 1993,
        2485, 2974, 2887,   99])
Epoch: 2780, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2781 - Batch 1 ########################
IDs in batch 1: tensor([1291, 2106, 1223, 3300, 1419, 1160, 2124,  774, 3677, 1457, 2450,  635,
        3960, 3983, 2659,   46])
Epoch: 2781, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2782 - Batch 1 ########################
IDs in batch 1: tensor([2582,  990, 2606,  119, 2854,   77,  651, 1863, 2499, 3408, 1057, 2360,
        2356, 3917,   72, 1248])
Epoch: 2782, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2783 - Batch 1 ########################
IDs in batch 1: tensor([1952, 3874, 3821, 3132, 1178, 3074, 3254,  147, 4135,  569,  102, 3257,
        3992, 2456, 3279, 1171])
Epoch: 2783, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2784 - Batch 1 ########################
IDs in batch 1: tensor([3268, 3538, 2452,  750, 2099, 1772, 2437, 4012, 3395, 2670,  828, 3920,
         442, 1090, 1437, 3865])
Epoch: 2784, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2785 - Batch 1 ########################
IDs in batch 1: tensor([1600,  234, 2919, 3283, 3651, 3650, 2571, 1901, 3326, 1252,  937, 1491,
         873, 3023, 2627,  382])
Epoch: 2785, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2786 - Batch 1 ########################
IDs in batch 1: tensor([ 261,  743, 4069, 1474, 2452, 3101, 1596, 2656, 1671, 4161,  476, 2398,
        1098, 1920, 2117, 1459])
Epoch: 2786, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2787 - Batch 1 ########################
IDs in batch 1: tensor([2550, 3371, 3726, 2934,  201,  646, 3870, 1455, 1406,   60, 3478,  684,
        3133,  358,  303, 2210])
Epoch: 2787, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2788 - Batch 1 ########################
IDs in batch 1: tensor([2829, 3245, 4265,  952,  250, 1469, 1302, 1442,  921,  795, 1469, 2489,
         497, 1047, 3282,  150])
Epoch: 2788, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2789 - Batch 1 ########################
IDs in batch 1: tensor([2350,  393, 2680, 1699,  974, 2610, 2540,  281, 3660,  345, 3484, 3879,
        4055, 2206,   62,   35])
Epoch: 2789, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2790 - Batch 1 ########################
IDs in batch 1: tensor([3193, 2049, 1858, 4203, 1632, 1347, 3241, 2228, 4175, 1795, 2364, 1628,
        1183, 3851,  547, 1175])
Epoch: 2790, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2791 - Batch 1 ########################
IDs in batch 1: tensor([ 788, 3369, 1140, 3732, 2670, 1410, 1124, 2697, 2274, 4050, 1312, 3368,
        3000, 3709,  964, 2008])
Epoch: 2791, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2792 - Batch 1 ########################
IDs in batch 1: tensor([ 636, 3954, 2338, 2764,  478, 1222, 3159, 1818, 4255, 3557, 3088,  688,
        4018, 1423, 4033, 2299])
Epoch: 2792, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2793 - Batch 1 ########################
IDs in batch 1: tensor([3345,   64,  747, 2856, 3374, 2523, 2287, 1525,  977, 4094,  412,   22,
         841, 3500, 1950, 3352])
Epoch: 2793, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2794 - Batch 1 ########################
IDs in batch 1: tensor([ 805, 1555, 1096,  155,  758,  485, 2108,  393, 2151, 2949, 2968, 2667,
        3790, 3118, 2119, 2783])
Epoch: 2794, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2795 - Batch 1 ########################
IDs in batch 1: tensor([2213, 3075,   27, 1962, 3289,  970, 3636, 1935, 2456,  622,  474, 2618,
        4220, 2826, 1682, 3075])
Epoch: 2795, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2796 - Batch 1 ########################
IDs in batch 1: tensor([1292, 4189, 1051, 4075, 1266, 2073, 1377,  262,   43,  316, 3514,  478,
        3789, 3659, 2860, 3079])
Epoch: 2796, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2797 - Batch 1 ########################
IDs in batch 1: tensor([ 122,  586, 1306, 1469, 4121, 2942, 1330, 4060, 2296, 2817, 3950, 1592,
        1760, 2295, 1568, 3996])
Epoch: 2797, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2798 - Batch 1 ########################
IDs in batch 1: tensor([3995, 3494, 2038, 3920, 2548, 2949, 1200, 2334, 4135, 2745, 1601, 2646,
        1596, 1155, 1570, 3695])
Epoch: 2798, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2799 - Batch 1 ########################
IDs in batch 1: tensor([2232,  593,  327, 2645, 1183, 3528, 2804, 3156, 3265,  229, 3364, 4122,
        2312,  150, 1328, 1220])
Epoch: 2799, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2800 - Batch 1 ########################
IDs in batch 1: tensor([3072,  822, 1204,  400,  967, 3434, 2508, 2951, 3497,  292, 1945,  795,
        3162, 2688, 1951, 3016])
Epoch: 2800, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2801 - Batch 1 ########################
IDs in batch 1: tensor([2986, 3922, 3058, 1426,  503, 1883,   37, 1774,  776, 2326, 3704, 4226,
        1289, 2132, 2643, 3618])
Epoch: 2801, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2802 - Batch 1 ########################
IDs in batch 1: tensor([3834, 1552, 1781,  908, 1297,   77, 2947, 3514, 2765, 2224, 2606, 1570,
        4144, 4055, 3818, 2026])
Epoch: 2802, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2803 - Batch 1 ########################
IDs in batch 1: tensor([ 239, 4080,   37,  377, 3797,  524,  491, 1945, 2251, 2247, 1489, 3366,
        2431, 3240,  390,  137])
Epoch: 2803, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2804 - Batch 1 ########################
IDs in batch 1: tensor([3313, 2661, 4093, 1789, 1590, 2167, 2315, 2151, 3671, 2848,  947, 2457,
        1840, 1635, 3160, 2169])
Epoch: 2804, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2805 - Batch 1 ########################
IDs in batch 1: tensor([2797, 1999,  834, 2161, 2398,  449,  514, 1511, 3572,  872, 1228, 1429,
         942,  921, 4049, 3015])
Epoch: 2805, Training Loss: 0.22, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2806 - Batch 1 ########################
IDs in batch 1: tensor([2265, 1640,  620, 4024, 3779, 1682,  282, 4013, 1559, 3264, 1453, 3018,
        1948,  724, 3473,  908])
Epoch: 2806, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2807 - Batch 1 ########################
IDs in batch 1: tensor([4010,  396, 1088,  723, 3496,  733, 1679, 4249, 1918, 2245, 2548,  449,
        3004, 1904, 2953, 3907])
Epoch: 2807, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2808 - Batch 1 ########################
IDs in batch 1: tensor([  64, 2189,  563, 1419, 2927, 3272, 1842,  527, 3437, 1434, 3729, 3381,
        1077, 1316, 1090, 3159])
Epoch: 2808, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2809 - Batch 1 ########################
IDs in batch 1: tensor([3898, 3375, 2075, 3866, 1231, 2372,  375, 2581, 1884, 4103, 1094, 1099,
         858, 3749, 1155, 1885])
Epoch: 2809, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2810 - Batch 1 ########################
IDs in batch 1: tensor([2660,  151, 2838,  609,   61, 3343, 2262, 1562, 2213,  735, 2755,  923,
         818, 2577,  437, 1734])
Epoch: 2810, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2811 - Batch 1 ########################
IDs in batch 1: tensor([ 921, 4236, 1869,  139, 3816, 3542,  266, 2348, 1495, 3372, 3989, 2805,
        4036, 2984, 1389, 1396])
Epoch: 2811, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2812 - Batch 1 ########################
IDs in batch 1: tensor([4184, 2457, 1425, 3374, 4015,  305, 3312, 3630, 2413, 2738, 2805, 2659,
        3769, 3950,  917, 3734])
Epoch: 2812, Training Loss: 0.33, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2813 - Batch 1 ########################
IDs in batch 1: tensor([1877, 3475,  411, 1894, 3031, 2500, 3699,  854, 2090, 1498, 2805, 1617,
        3934, 3018, 3409, 1116])
Epoch: 2813, Training Loss: 0.19, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2814 - Batch 1 ########################
IDs in batch 1: tensor([1646, 3114, 1678, 4053,  987, 3527, 1957,  546, 2313,  496, 3200, 2353,
        3634, 2245,  203,  953])
Epoch: 2814, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2815 - Batch 1 ########################
IDs in batch 1: tensor([2966,  809,  644, 3765, 3859, 1111, 3115, 3815, 1612, 3501,  565,  171,
        3166, 3882, 2257, 2860])
Epoch: 2815, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2816 - Batch 1 ########################
IDs in batch 1: tensor([3161, 4069,  321, 2278, 2439, 2789, 1585, 2624, 1260, 3217,  588,  805,
        3291,  656, 1387,  674])
Epoch: 2816, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2817 - Batch 1 ########################
IDs in batch 1: tensor([ 131, 2067,  379,  351, 4166,  966, 3378,  833, 3656, 2710, 4026, 2995,
        3745, 2320, 3919,  724])
Epoch: 2817, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2818 - Batch 1 ########################
IDs in batch 1: tensor([ 517, 2196, 4087, 2010, 3101, 1884, 2348,  725, 1438, 1994, 2349, 2108,
         628,  723, 1944,  584])
Epoch: 2818, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2819 - Batch 1 ########################
IDs in batch 1: tensor([4254, 1039, 4227, 4100, 2198, 2066, 3816, 1872,  224, 3738,  148,  804,
        3518, 1645, 1134,  148])
Epoch: 2819, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2820 - Batch 1 ########################
IDs in batch 1: tensor([1733, 1812, 2244,  841, 1762,  843,  356,   25, 1370,  515, 2719, 3248,
         713, 2024,  733, 1993])
Epoch: 2820, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2821 - Batch 1 ########################
IDs in batch 1: tensor([3184, 1496, 2451,  127, 1623, 3044, 3490, 3200,  412, 3151, 1311, 1419,
        1234, 3710, 2669, 3912])
Epoch: 2821, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2822 - Batch 1 ########################
IDs in batch 1: tensor([  10, 3244, 2435, 3379,  950, 2542, 2045, 3220, 1553, 1099, 3982, 1951,
        2276,  108, 3286, 1526])
Epoch: 2822, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2823 - Batch 1 ########################
IDs in batch 1: tensor([3444, 2934, 2290,   20, 1030, 2113, 2842,  721,  377, 2951, 3271, 2693,
        1625,  379, 2038, 4065])
Epoch: 2823, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2824 - Batch 1 ########################
IDs in batch 1: tensor([2465,  218, 1878, 2131, 2680, 1605, 2003,  120, 1438,  762, 1724, 3400,
        2075, 2304, 4168, 2188])
Epoch: 2824, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2825 - Batch 1 ########################
IDs in batch 1: tensor([ 837, 2914,  305, 3069,  996, 3264, 3366, 3053, 3461,  907,  375, 2991,
        1765, 3744, 1651, 2354])
Epoch: 2825, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2826 - Batch 1 ########################
IDs in batch 1: tensor([3756, 3673, 1185,  477, 1862, 2284,  117, 1208, 1156, 1982, 1286, 1333,
        4133, 2869, 1201, 1173])
Epoch: 2826, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2827 - Batch 1 ########################
IDs in batch 1: tensor([1984, 3074, 1406, 3846, 1311,  344, 2465, 3652, 2644, 1676, 3958, 2996,
        2402, 3384, 2726, 3528])
Epoch: 2827, Training Loss: 0.20, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2828 - Batch 1 ########################
IDs in batch 1: tensor([3995, 1672, 3465,  346, 1085, 3044, 3484,  890, 1979, 1580,  103, 3099,
        1569, 1862, 2264, 1162])
Epoch: 2828, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2829 - Batch 1 ########################
IDs in batch 1: tensor([1452, 1190, 3896, 1562, 2687, 3728, 3531, 2925, 2807, 2015, 4134, 3980,
         586,   60, 3832, 2645])
Epoch: 2829, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 2830 - Batch 1 ########################
IDs in batch 1: tensor([3154,   78,  102, 1746, 3599, 1318, 2640,  279, 1147, 3132, 1899, 3885,
        3473, 1457, 1630, 2455])
Epoch: 2830, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2831 - Batch 1 ########################
IDs in batch 1: tensor([2754, 1274, 3245, 1927, 2887, 1065, 1644,  682,  110, 3812, 2974,  407,
        3706, 1487,  478, 1121])
Epoch: 2831, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2832 - Batch 1 ########################
IDs in batch 1: tensor([ 100, 1120, 2482,  405,  995,  640, 3953,  170, 1499, 2517, 1988, 3005,
        1204, 1736, 2052, 1180])
Epoch: 2832, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2833 - Batch 1 ########################
IDs in batch 1: tensor([ 126, 3304,  882,  497, 1414,  199, 2999, 2670,  259, 2586, 2932, 2414,
        2800, 2610,  552, 2980])
Epoch: 2833, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2834 - Batch 1 ########################
IDs in batch 1: tensor([1960,  552, 2405,  462, 1845, 1083, 2999, 3118, 2755, 3928, 4225,  350,
        2367,  326,  752,  475])
Epoch: 2834, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2835 - Batch 1 ########################
IDs in batch 1: tensor([2819, 1198,  308, 2603, 1247, 4139, 3203, 2210, 1331, 1728,  566,  820,
        3836, 2363, 1283, 4005])
Epoch: 2835, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2836 - Batch 1 ########################
IDs in batch 1: tensor([  73, 4194, 2005, 1454, 3390, 2869, 4204, 3701, 2819,  276,  926, 3669,
        2391, 3424,  188,   30])
Epoch: 2836, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2837 - Batch 1 ########################
IDs in batch 1: tensor([3455,  685,  975, 1899,  875, 3528, 2151, 3891, 1420,  316, 1008, 3917,
        3044,  325, 3124,  427])
Epoch: 2837, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2838 - Batch 1 ########################
IDs in batch 1: tensor([3161, 2461, 2721,  499, 1096, 1675, 1499, 2167, 1579,  787, 2449, 1248,
        1578, 1923, 3283, 2059])
Epoch: 2838, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.75
######################## Epoch 2839 - Batch 1 ########################
IDs in batch 1: tensor([3647, 3308, 3669, 1132,  976, 3132, 1076, 2712, 2428, 2193, 3540, 2529,
        1986, 2719, 3509, 3802])
Epoch: 2839, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2840 - Batch 1 ########################
IDs in batch 1: tensor([3484,  251,  864, 2323, 2432, 3458, 4120, 2148, 3120, 1284,  498, 2112,
        1024, 1125, 2272, 3585])
Epoch: 2840, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2841 - Batch 1 ########################
IDs in batch 1: tensor([2317, 1914, 2432, 3018,  886, 3769, 1030, 1488, 3557, 1195, 2783, 1686,
        2695, 2352,  341,  609])
Epoch: 2841, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 2842 - Batch 1 ########################
IDs in batch 1: tensor([3743,  229, 3268, 3357, 3804,   43, 1219, 1086,  129, 2604, 3182, 2866,
        1249, 1247, 1968, 3772])
Epoch: 2842, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2843 - Batch 1 ########################
IDs in batch 1: tensor([ 358, 1317, 3845, 2115,  710, 4005, 1950, 3719,  866, 3769, 2700, 1809,
        2706, 3808, 1225, 4157])
Epoch: 2843, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2844 - Batch 1 ########################
IDs in batch 1: tensor([ 622, 2363, 1428, 1734, 3523,  160,  942, 1596,  838, 3371, 2366, 3498,
        1072,  278, 3057, 3114])
Epoch: 2844, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2845 - Batch 1 ########################
IDs in batch 1: tensor([2115, 3185, 1072, 3501, 2260,  919, 2980, 1934, 4127, 1868, 4222, 2453,
        2044, 1882,  724, 3036])
Epoch: 2845, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2846 - Batch 1 ########################
IDs in batch 1: tensor([3707, 4227, 1984, 1352,   70, 2085, 2763, 3879, 1231, 1786,  478, 1084,
        1819,  323, 2117,  314])
Epoch: 2846, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2847 - Batch 1 ########################
IDs in batch 1: tensor([3426,  683, 2990,  373, 2095,  689,  120, 1540, 2098, 1973, 3536,  631,
        1437,  225, 2261, 1092])
Epoch: 2847, Training Loss: 0.16, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 2848 - Batch 1 ########################
IDs in batch 1: tensor([2459, 3342, 3187, 3898, 4069, 1473, 2690,   18, 2989, 4236,  341, 1600,
         160, 2555,  497,  434])
Epoch: 2848, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2849 - Batch 1 ########################
IDs in batch 1: tensor([1511,  897,  866, 2132, 2748,  873, 1199, 4180, 1241, 2740, 2957, 1882,
         815, 3516, 3991, 3042])
Epoch: 2849, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2850 - Batch 1 ########################
IDs in batch 1: tensor([2995,  539, 1707, 2323,  766, 1252,  775, 2514,  969, 3279,  172, 3667,
        1081, 3934, 2797, 3371])
Epoch: 2850, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2851 - Batch 1 ########################
IDs in batch 1: tensor([2874,  359, 2632,  843, 1042, 1623, 3898, 1798,  312,  834, 3056,  978,
        2970, 1130, 4013, 4226])
Epoch: 2851, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2852 - Batch 1 ########################
IDs in batch 1: tensor([1226, 4024, 2514, 3439, 3540, 1895, 2487, 3354, 1066, 1752,  278, 2343,
        2002, 3345,  322, 1618])
Epoch: 2852, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2853 - Batch 1 ########################
IDs in batch 1: tensor([2223, 2571, 2942, 3109, 2950, 2505, 3133, 2671, 2812, 1012, 4017,   63,
        3992,  488, 1326,  117])
Epoch: 2853, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2854 - Batch 1 ########################
IDs in batch 1: tensor([1103,  251, 2696,  854, 1200, 1684, 4015, 3530, 3079, 3298, 1553, 1935,
        3081, 2470, 2388,  103])
Epoch: 2854, Training Loss: 0.01, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2855 - Batch 1 ########################
IDs in batch 1: tensor([1793, 2664, 1546, 3643,  143, 1463, 3156, 2614,  295, 2995, 2567, 4173,
        3503, 3847, 3187, 2600])
Epoch: 2855, Training Loss: 0.13, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2856 - Batch 1 ########################
IDs in batch 1: tensor([3715,   15, 3447, 3540,  967, 1337, 1775, 2697, 3235, 1822, 1276, 1309,
        2301, 2782, 1022,  455])
Epoch: 2856, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2857 - Batch 1 ########################
IDs in batch 1: tensor([1880, 3246,  546, 3902, 3042, 3369,  774, 1088, 1391, 1153, 1975, 2519,
        3246,  320,  375, 1636])
Epoch: 2857, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.72
######################## Epoch 2858 - Batch 1 ########################
IDs in batch 1: tensor([ 290, 2544, 2831,  919, 2393, 4245, 3506, 1723,  380, 2106,  415, 1734,
        1859, 1154, 1594, 1553])
Epoch: 2858, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2859 - Batch 1 ########################
IDs in batch 1: tensor([1781, 1340, 1842, 2880, 3954, 4085, 1102, 3182, 2483,    5,  962,  287,
        1014, 3782, 2872, 2177])
Epoch: 2859, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2860 - Batch 1 ########################
IDs in batch 1: tensor([4097, 1822, 2157, 3055, 2681, 2167, 1891, 4128,   19, 1956, 4157, 1034,
        1869, 1316, 1712, 1627])
Epoch: 2860, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2861 - Batch 1 ########################
IDs in batch 1: tensor([2966, 1044, 2435,  377, 2025, 3120, 3832,  923, 1097, 1045, 1119, 2572,
         497, 2599, 3133, 3530])
Epoch: 2861, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2862 - Batch 1 ########################
IDs in batch 1: tensor([1423, 2337, 1138,   71,   71,   50, 1341, 1067,  149,  794, 2023,  111,
        3881, 1799, 2589,  661])
Epoch: 2862, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2863 - Batch 1 ########################
IDs in batch 1: tensor([1267, 3535, 3518, 1284, 1751,  946, 3074, 2497, 2373, 3760, 1982,   92,
         367, 2669,  475, 3447])
Epoch: 2863, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 2864 - Batch 1 ########################
IDs in batch 1: tensor([2120, 1524, 2940,  539, 3968,  949, 1866,  138, 1648, 3282,  278,  277,
        3440, 2855, 2135,  147])
Epoch: 2864, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2865 - Batch 1 ########################
IDs in batch 1: tensor([ 897, 2974, 1347, 4004,  874, 4018, 3882, 3583, 3015, 3953, 2362, 4229,
        2499, 2464, 2477, 2144])
Epoch: 2865, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2866 - Batch 1 ########################
IDs in batch 1: tensor([3790, 2783, 3489, 1747,  554, 3917, 1131, 2066, 1374, 3444, 3458, 3866,
        3592,   22, 3015, 3532])
Epoch: 2866, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2867 - Batch 1 ########################
IDs in batch 1: tensor([3943, 2836,  238, 3245, 2080,  617,  537, 2632,  741, 3536, 2190,  962,
        1456, 3309, 3782, 2917])
Epoch: 2867, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2868 - Batch 1 ########################
IDs in batch 1: tensor([3184, 1728,  440, 2538, 3349, 1699, 1322, 1942, 2368, 3717,  976, 1638,
         803, 2599,  807, 1644])
Epoch: 2868, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2869 - Batch 1 ########################
IDs in batch 1: tensor([3344, 3976, 3133,  899,  308, 1025, 2275,   18, 4246,  202,  194, 3131,
        2133, 1163, 2867,   59])
Epoch: 2869, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2870 - Batch 1 ########################
IDs in batch 1: tensor([4025, 4139, 2706, 1961, 2051, 1062, 3845, 3460, 1900, 3891,  851, 3345,
        2225,  968,  660, 2947])
Epoch: 2870, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2871 - Batch 1 ########################
IDs in batch 1: tensor([1775, 2107, 1970,  355, 3363, 3699, 1900, 2953,  908, 3473, 3501, 1734,
        1131,  820, 1220, 1233])
Epoch: 2871, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2872 - Batch 1 ########################
IDs in batch 1: tensor([1322, 2018, 2927, 2332, 3429, 1391, 1752,  201, 2629, 2859, 1833, 3156,
        3434,  819,  741,  934])
Epoch: 2872, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2873 - Batch 1 ########################
IDs in batch 1: tensor([1934, 4263,  450, 2069, 2329, 3793, 2789, 1075, 3632,  211, 3329, 2739,
        2614, 2514, 2099, 3132])
Epoch: 2873, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2874 - Batch 1 ########################
IDs in batch 1: tensor([ 360, 3617,  681, 3763, 3264,  180, 2669,  139,  886,  644, 2758, 2581,
         117, 2907,  140, 1061])
Epoch: 2874, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 2875 - Batch 1 ########################
IDs in batch 1: tensor([3671, 3914, 2550, 3427, 3498,  470, 3695,  105, 1773, 1195, 4179, 4258,
        1625,  785, 1575, 4107])
Epoch: 2875, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 2876 - Batch 1 ########################
IDs in batch 1: tensor([ 970,  595, 2505, 3821, 3789, 1414, 1093, 2334,  213, 1072,  554, 3282,
        3935, 3261, 3139, 2974])
Epoch: 2876, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2877 - Batch 1 ########################
IDs in batch 1: tensor([ 489, 2804, 2092, 1576, 3617, 1222, 3643,  769, 1204,  794, 3385, 1993,
         947, 2146, 3246, 3425])
Epoch: 2877, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2878 - Batch 1 ########################
IDs in batch 1: tensor([1869,  277, 2252, 2219, 3604, 1497, 2205, 2693, 3483, 1287,  398, 1828,
        2332, 1913, 2546,  213])
Epoch: 2878, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 2879 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 2650,  303, 3911, 1406, 3815,   22, 1158, 3529, 1214,  344, 1137,
        3460, 1471, 3196, 3345])
Epoch: 2879, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2880 - Batch 1 ########################
IDs in batch 1: tensor([2354, 3731,  842, 3487,  673,  403, 1504, 3336, 2504, 1613,  953, 2891,
        1397, 1272, 1782, 2829])
Epoch: 2880, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.74
######################## Epoch 2881 - Batch 1 ########################
IDs in batch 1: tensor([2346,  119, 2111, 1589, 1858,  891, 1879, 4136, 2103, 1080, 2610, 3267,
        2676, 4125, 3030, 3448])
Epoch: 2881, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2882 - Batch 1 ########################
IDs in batch 1: tensor([4195, 3676, 4254, 2298,  750, 3194, 3903, 2095, 1671, 2848, 1935, 2736,
        1144,  378, 2250, 1727])
Epoch: 2882, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2883 - Batch 1 ########################
IDs in batch 1: tensor([3740, 1927,  894, 4089, 3660, 1920,  880,  171, 4120, 1365,  630, 3391,
        3188, 2420, 2003, 1396])
Epoch: 2883, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2884 - Batch 1 ########################
IDs in batch 1: tensor([1061, 3740, 1442, 2065, 2104, 1464,  808,   43, 2921, 2159, 3456, 4157,
        3693,   35, 2951, 2646])
Epoch: 2884, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2885 - Batch 1 ########################
IDs in batch 1: tensor([2031, 4263,  790, 3238, 1168, 2821,   60, 1553, 3314,  833, 3259, 1116,
        2849, 3042, 4080, 1509])
Epoch: 2885, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2886 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 2115, 1111, 4032, 1975, 1328, 1226, 3876, 2478,  969,  977, 3336,
        3166, 3545,  198, 2798])
Epoch: 2886, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2887 - Batch 1 ########################
IDs in batch 1: tensor([ 206, 2415, 4148, 2357,  595, 3891, 2274, 1630, 2393, 3487,  442, 2758,
        3058, 3674, 1981, 3843])
Epoch: 2887, Training Loss: 0.33, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2888 - Batch 1 ########################
IDs in batch 1: tensor([ 712, 3157, 2693, 3047, 3111,  316, 3182, 2217, 3463, 3313, 2841, 2284,
         180, 2839,  314, 1326])
Epoch: 2888, Training Loss: 0.08, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 2889 - Batch 1 ########################
IDs in batch 1: tensor([1270, 1216, 3935, 4199, 1102,  593, 1498,  757,  393, 4082, 2764, 3908,
        3711,  896, 3142, 2966])
Epoch: 2889, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2890 - Batch 1 ########################
IDs in batch 1: tensor([2825, 1842, 3049, 2159,  813, 3739, 2672,  804, 2213, 3672, 3866, 2586,
        3438, 1858, 3810,  583])
Epoch: 2890, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2891 - Batch 1 ########################
IDs in batch 1: tensor([1279, 3683,  776, 2069, 1272, 3732,  858, 1632, 3837, 2385, 1748, 1011,
        2217,  375, 3991, 1798])
Epoch: 2891, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2892 - Batch 1 ########################
IDs in batch 1: tensor([1634, 1080, 1951, 3533, 1221,  620, 4044,  100, 2059, 2829, 3706, 2086,
         790,  982, 3815, 3847])
Epoch: 2892, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.73
######################## Epoch 2893 - Batch 1 ########################
IDs in batch 1: tensor([3179, 1255, 1727, 2026, 1767,  606, 2034,  943, 3429,  282, 3241, 2124,
        2334,  590, 1451, 1060])
Epoch: 2893, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2894 - Batch 1 ########################
IDs in batch 1: tensor([3949, 3960, 1553, 1601, 3547, 3655, 2468, 3874, 1351, 4018, 1418, 3913,
        3256, 1971,  846, 3311])
Epoch: 2894, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2895 - Batch 1 ########################
IDs in batch 1: tensor([3960, 1153, 3534,  631,  357, 4158, 3261,  491, 3704, 4127,  609, 1328,
        2261, 2315, 1789, 2950])
Epoch: 2895, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2896 - Batch 1 ########################
IDs in batch 1: tensor([1380, 2204, 1199, 4120, 1698, 3159, 3504, 1952, 3040, 2081, 1819, 2190,
          98, 1789,  306, 1337])
Epoch: 2896, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.73
######################## Epoch 2897 - Batch 1 ########################
IDs in batch 1: tensor([1133, 2514, 4025,   85,  518, 1958,  257, 2358, 1730,  186, 2723,  921,
        3079, 4227, 1284,   86])
Epoch: 2897, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 2898 - Batch 1 ########################
IDs in batch 1: tensor([1365,   32, 2390, 2725, 2867,  637, 2355, 2385, 1678, 2143,  769, 1063,
         333, 3726,  844, 3092])
Epoch: 2898, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2899 - Batch 1 ########################
IDs in batch 1: tensor([ 357, 2202,   71, 2765, 2993, 2452,  531, 4061, 2715,  527, 2951, 3642,
        3870,  130, 1237, 1645])
Epoch: 2899, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2900 - Batch 1 ########################
IDs in batch 1: tensor([ 914, 2700, 2176, 2510, 2420, 2536, 1646, 2936, 1089, 2459,  827,  545,
        1755,  531, 3434,  184])
Epoch: 2900, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2901 - Batch 1 ########################
IDs in batch 1: tensor([2341, 2064, 3426, 2143, 3847, 2748, 3615,  832, 2467, 3126, 1991, 3400,
         327, 1777,  653, 1059])
Epoch: 2901, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2902 - Batch 1 ########################
IDs in batch 1: tensor([ 910, 3206,  547, 4032, 2586, 2898, 1026, 1690, 3603, 3139,  644, 3192,
         465,  454, 2271, 1028])
Epoch: 2902, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2903 - Batch 1 ########################
IDs in batch 1: tensor([1746, 1176, 2908, 2349,   21, 2516, 2913, 2309, 1248, 3039,  180, 3439,
        2234, 1282, 1384, 1770])
Epoch: 2903, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2904 - Batch 1 ########################
IDs in batch 1: tensor([2182, 1984, 2709, 3912, 3354, 3446, 3757,  229, 3778, 3609, 1233, 1166,
        4095, 2444, 2732, 2420])
Epoch: 2904, Training Loss: 0.45, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2905 - Batch 1 ########################
IDs in batch 1: tensor([2237, 2183, 3148, 1289, 1751, 3742, 2198, 1318,  338, 3437, 1610,  808,
        4103,  315, 3371,  988])
Epoch: 2905, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2906 - Batch 1 ########################
IDs in batch 1: tensor([2791,  128, 2369, 3734, 3194, 1451, 3354, 3798,  964, 2338, 1039, 3390,
        2436,  200, 2545, 2070])
Epoch: 2906, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2907 - Batch 1 ########################
IDs in batch 1: tensor([3299, 4094,  941, 3071, 3525, 1027, 1313,  532, 2650, 2898,  615, 3069,
        2205, 2884,  970, 1024])
Epoch: 2907, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 2908 - Batch 1 ########################
IDs in batch 1: tensor([2858, 3268, 3590,  595,  915, 3092,  699, 3983, 3300, 3541, 2296,  260,
        4015, 3913, 3693,  740])
Epoch: 2908, Training Loss: 0.18, Validation Loss: 0.69, accuracy = 0.74
######################## Epoch 2909 - Batch 1 ########################
IDs in batch 1: tensor([3372, 3971, 3689, 3638, 3309, 2519,  983, 1634, 2873, 3131,  389, 2426,
        3769, 3813, 2067,  593])
Epoch: 2909, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2910 - Batch 1 ########################
IDs in batch 1: tensor([1737, 1563, 1489, 4268, 2945,  104,  308, 2693,  518, 1821,  809, 2536,
         308, 4184, 1536, 1690])
Epoch: 2910, Training Loss: 0.26, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2911 - Batch 1 ########################
IDs in batch 1: tensor([1072, 1775, 3829, 4093, 3504, 4146, 3545,  183, 2365, 3669,  786, 2050,
        3779, 1640, 3628, 3391])
Epoch: 2911, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2912 - Batch 1 ########################
IDs in batch 1: tensor([1947, 4033,  954, 3856,  108, 3881, 3101, 3721, 1574, 4056, 4148,  944,
        3351, 1809, 2842, 1844])
Epoch: 2912, Training Loss: 0.21, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2913 - Batch 1 ########################
IDs in batch 1: tensor([ 606, 3460, 3707, 1507, 2599,  190, 3126, 2236, 3020, 1310, 2655, 2363,
        3124, 1305,  191, 4082])
Epoch: 2913, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 2914 - Batch 1 ########################
IDs in batch 1: tensor([4122, 3425,  595,  883, 2180, 2027, 1418, 2359, 4044, 2934, 4265, 2343,
        3816, 2776, 3178, 1933])
Epoch: 2914, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 2915 - Batch 1 ########################
IDs in batch 1: tensor([1464, 2117, 3707, 2353, 1463,  517, 2640, 3432, 4125,  699, 2956, 2009,
        2558, 1383, 1935, 2103])
Epoch: 2915, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2916 - Batch 1 ########################
IDs in batch 1: tensor([3839, 2371, 3667, 1312, 3764,  384, 1347, 1371, 2990, 3238, 3922,  612,
        3543, 3597, 2970, 2945])
Epoch: 2916, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2917 - Batch 1 ########################
IDs in batch 1: tensor([2869, 3388, 1782, 3976,  601, 3386, 3673, 3717, 1440, 1702,  555, 2856,
         539,   56, 3047, 4146])
Epoch: 2917, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2918 - Batch 1 ########################
IDs in batch 1: tensor([1235, 3588, 2668, 3927,  756, 2499, 2235, 1182, 2338, 2907, 1881, 3111,
        1299, 3364, 1008, 4157])
Epoch: 2918, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2919 - Batch 1 ########################
IDs in batch 1: tensor([2880,  628, 2423, 1196, 1618, 2190,  439, 3098, 3035, 3919, 3038, 3088,
         770, 2796, 3659, 3203])
Epoch: 2919, Training Loss: 0.15, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2920 - Batch 1 ########################
IDs in batch 1: tensor([4046, 3528, 2983, 3733, 1413, 1488, 1099, 2983, 3251, 2121,  596, 2312,
         866,  917, 4040, 3699])
Epoch: 2920, Training Loss: 0.07, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2921 - Batch 1 ########################
IDs in batch 1: tensor([1231, 2919, 3141, 2712, 3433,  936, 2885,   46, 2470, 3732, 2065, 3243,
        3436,  113, 1754, 1249])
Epoch: 2921, Training Loss: 0.21, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2922 - Batch 1 ########################
IDs in batch 1: tensor([2065, 3475, 2210, 1065,  883,   47,  687, 1883,   42, 2407,  102, 3883,
        1835, 2497, 3873,  725])
Epoch: 2922, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2923 - Batch 1 ########################
IDs in batch 1: tensor([3659, 2436, 2809, 2855, 2387, 2997, 2401, 3539, 1540, 2719,  359, 2836,
        2206, 4013, 3883, 3469])
Epoch: 2923, Training Loss: 0.37, Validation Loss: 0.80, accuracy = 0.72
######################## Epoch 2924 - Batch 1 ########################
IDs in batch 1: tensor([1213,  367,  674, 1779, 1113, 3448, 1072, 1985,  417, 1351, 2198, 1679,
        1051, 1102, 3628,   85])
Epoch: 2924, Training Loss: 0.53, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2925 - Batch 1 ########################
IDs in batch 1: tensor([2225, 1295,  681,   85, 3572, 3253, 2482, 3425, 3601, 1620, 3458, 1375,
        1643, 1899, 4046, 3238])
Epoch: 2925, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.73
######################## Epoch 2926 - Batch 1 ########################
IDs in batch 1: tensor([1851, 4009, 1239,  841, 3549, 2355, 3275,  828, 4225, 1204, 3417, 3162,
        3699, 2365, 3143, 4172])
Epoch: 2926, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.73
######################## Epoch 2927 - Batch 1 ########################
IDs in batch 1: tensor([4127,  786, 2951,  736, 2942, 2873, 1116, 1038, 1999,  895, 1372, 1944,
         887,  104,  779,  862])
Epoch: 2927, Training Loss: 0.31, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2928 - Batch 1 ########################
IDs in batch 1: tensor([3516, 3982, 4049, 2179, 1026, 1123, 2908, 3206, 1892,  129, 2362,  508,
        1509,  808, 1841,  915])
Epoch: 2928, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 2929 - Batch 1 ########################
IDs in batch 1: tensor([ 117, 1884, 1024, 3024, 1530, 1474, 1452,   19, 3688, 4256, 1249, 1354,
        1469, 3734,  961, 2292])
Epoch: 2929, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 2930 - Batch 1 ########################
IDs in batch 1: tensor([3071, 3303,  943,  379, 1396, 2003, 3981,  606, 3617, 4163, 3888, 3108,
          71, 1388, 2041, 1185])
Epoch: 2930, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2931 - Batch 1 ########################
IDs in batch 1: tensor([3541,  513,  269,  538,   78, 1405, 2670, 1470, 2448, 1397,  926,  438,
        2316, 3375, 1507,  371])
Epoch: 2931, Training Loss: 0.40, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 2932 - Batch 1 ########################
IDs in batch 1: tensor([ 844, 2885,  250, 2650, 3988, 3554, 1452,  910, 1704, 2258, 3713, 4242,
        2198, 2024, 2831, 1426])
Epoch: 2932, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2933 - Batch 1 ########################
IDs in batch 1: tensor([1315, 1138, 3142, 1863, 2440, 1880,  361, 1755,  236,  637,  699, 2695,
        2957, 2937, 2721, 1136])
Epoch: 2933, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2934 - Batch 1 ########################
IDs in batch 1: tensor([ 177,  338, 2418, 2656,  132, 1292, 1693, 2908, 3808, 1895, 3715, 1519,
          63, 1051, 1111, 2895])
Epoch: 2934, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2935 - Batch 1 ########################
IDs in batch 1: tensor([4139, 3547, 1005, 3563,  804,  913,  134, 1107,  755,  401, 2030, 3471,
        1752, 1320, 3928, 2039])
Epoch: 2935, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2936 - Batch 1 ########################
IDs in batch 1: tensor([ 729, 1761,  408, 3334, 1481, 4011, 3227,  342,  893, 3304,  924, 3465,
        2229,  545, 3360, 2377])
Epoch: 2936, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 2937 - Batch 1 ########################
IDs in batch 1: tensor([3618, 2706, 2439,  359, 3540, 2102,  491,  681, 3311, 3533, 2053, 3483,
        3804, 2504,  149,   31])
Epoch: 2937, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2938 - Batch 1 ########################
IDs in batch 1: tensor([1671,  343, 2183, 3717,  244,  487, 3654, 2426, 1869, 3042, 3440,  417,
        1723, 2456,  857, 1076])
Epoch: 2938, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2939 - Batch 1 ########################
IDs in batch 1: tensor([1096, 3873,  882, 1456, 1439, 1012, 2111, 1993, 3911, 2244, 1761, 1331,
         344,  873, 1206, 2272])
Epoch: 2939, Training Loss: 0.38, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2940 - Batch 1 ########################
IDs in batch 1: tensor([2103, 3779, 2681,   10, 2390, 3995, 1526, 1281, 1084, 2352, 1937, 2940,
        1548,  955, 4189,  649])
Epoch: 2940, Training Loss: 0.21, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2941 - Batch 1 ########################
IDs in batch 1: tensor([1590, 2582, 3980, 2739, 3534,  143,  232, 2974, 2583, 3607, 1178, 3057,
        3443, 3523, 3501,  395])
Epoch: 2941, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 2942 - Batch 1 ########################
IDs in batch 1: tensor([2179, 3052, 1393, 2334, 2009,  923, 1061, 2153, 2712, 3573, 2069, 2290,
        3166,  462, 4030, 2648])
Epoch: 2942, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 2943 - Batch 1 ########################
IDs in batch 1: tensor([3221, 2400, 2724, 3203, 1956,  497,  358, 3604, 4246, 3433,  422, 2736,
        4009, 1763, 1248, 1882])
Epoch: 2943, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2944 - Batch 1 ########################
IDs in batch 1: tensor([1371, 2238,  659, 2873, 1718, 3390, 2514, 3994, 1277, 1590, 1080, 1519,
        2416, 2329, 4004,  842])
Epoch: 2944, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2945 - Batch 1 ########################
IDs in batch 1: tensor([3207, 2098, 2372, 3544,  426,  102, 3807, 3661,  143, 4119, 4046, 3671,
        2385,  454, 3151, 1852])
Epoch: 2945, Training Loss: 0.26, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2946 - Batch 1 ########################
IDs in batch 1: tensor([2080, 3203, 1241, 2885, 2229, 4144, 2407,  586, 2073, 2183, 4124, 1087,
        3668, 1778, 1794,  649])
Epoch: 2946, Training Loss: 0.09, Validation Loss: 0.79, accuracy = 0.72
######################## Epoch 2947 - Batch 1 ########################
IDs in batch 1: tensor([3340, 2980,   42, 2185, 2492,  644, 2092,  280, 1305,  914, 1896, 2788,
         470, 3993, 3358,  295])
Epoch: 2947, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.72
######################## Epoch 2948 - Batch 1 ########################
IDs in batch 1: tensor([ 501, 2522, 2053, 1050,  967, 3388, 3895,  980, 2388,  181, 1089, 2632,
        3985, 1429, 3913, 4032])
Epoch: 2948, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.72
######################## Epoch 2949 - Batch 1 ########################
IDs in batch 1: tensor([3842, 2678, 3779, 2280, 1097, 2447, 1146, 1799, 2703, 1897, 1933, 2480,
        1167,   78,  622,  355])
Epoch: 2949, Training Loss: 0.21, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 2950 - Batch 1 ########################
IDs in batch 1: tensor([1931,  835, 1526, 2511, 2726, 3020, 3030, 2901, 1779, 1374,  355, 3408,
        1022, 1026,  736, 4055])
Epoch: 2950, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 2951 - Batch 1 ########################
IDs in batch 1: tensor([3073, 3087, 1745, 2067,  701, 2745, 2874, 1059, 1182, 3456,  673, 2238,
        3471, 2044, 4131, 1309])
Epoch: 2951, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2952 - Batch 1 ########################
IDs in batch 1: tensor([2110, 3000, 2539, 2853,  152,  660, 3998,  837, 1588, 1648, 2067, 3000,
        3652, 2586,  685, 3123])
Epoch: 2952, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 2953 - Batch 1 ########################
IDs in batch 1: tensor([2821, 2841, 3852, 2483, 4136, 3886, 1108, 2849, 2223, 1075, 1852,  459,
        2177, 2412, 1910,  660])
Epoch: 2953, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2954 - Batch 1 ########################
IDs in batch 1: tensor([2123, 3115, 1496, 1404,  226, 4089,  390, 3875, 2895, 4228, 2965, 3927,
        1343, 3769, 1712, 3712])
Epoch: 2954, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2955 - Batch 1 ########################
IDs in batch 1: tensor([ 213, 2520, 3194,  190, 2807, 2931, 3202, 4008,  120,  534, 1965, 1214,
        3395, 1162,  645, 3470])
Epoch: 2955, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2956 - Batch 1 ########################
IDs in batch 1: tensor([1638, 1057, 3084, 2942, 3499, 1065, 2551,  814, 2370, 1633, 2776, 2572,
        2271, 4138, 2399, 4075])
Epoch: 2956, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 2957 - Batch 1 ########################
IDs in batch 1: tensor([ 899, 1657, 4048, 1859, 4075, 1154,   64, 3051, 1927, 3862, 3147, 1179,
        2743, 1896, 1651, 3876])
Epoch: 2957, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2958 - Batch 1 ########################
IDs in batch 1: tensor([3822, 3547, 1877, 3150, 3499, 2804, 2465, 1343, 3557, 2017, 1330, 2870,
        1458, 1200, 1399, 1009])
Epoch: 2958, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2959 - Batch 1 ########################
IDs in batch 1: tensor([2595, 4218, 3905, 2539, 1049, 2927, 3672, 1895, 3433, 4166, 4217, 2885,
        1291, 1077,  834,  851])
Epoch: 2959, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 2960 - Batch 1 ########################
IDs in batch 1: tensor([3386, 2817, 4256,  663, 3640,  439, 3387, 3047, 3027,  873,  247,  282,
        1221,   72,  818, 3905])
Epoch: 2960, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 2961 - Batch 1 ########################
IDs in batch 1: tensor([4069, 2429,  483, 3577,  841,  436, 4265, 4101,  501, 2034, 2195,  290,
        3398,  397, 2095,  956])
Epoch: 2961, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2962 - Batch 1 ########################
IDs in batch 1: tensor([  92,  234, 3478,  259,  639, 4125, 1438, 1356,  355,  812, 2472, 2655,
        3275, 1685, 2472, 2598])
Epoch: 2962, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 2963 - Batch 1 ########################
IDs in batch 1: tensor([1222,  532, 1237, 2116, 1869, 2688, 3751, 2844, 1724, 2758, 1331, 3973,
        1376, 1962, 1484, 2821])
Epoch: 2963, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 2964 - Batch 1 ########################
IDs in batch 1: tensor([1459, 1545, 2013, 2851, 1278, 4163, 3749, 3261, 1159, 3604,  503,  508,
        1510,  265, 1507, 3017])
Epoch: 2964, Training Loss: 0.12, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 2965 - Batch 1 ########################
IDs in batch 1: tensor([4077, 3962,  607, 3289, 1340, 2732, 1437, 1570, 2415, 2279, 2780,  757,
        1793,  851, 1945, 2298])
Epoch: 2965, Training Loss: 0.02, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 2966 - Batch 1 ########################
IDs in batch 1: tensor([ 968, 2523,  380, 2731,  260, 3739, 2726, 3382, 3074, 3196, 1668, 1909,
         878, 2237, 1747, 2199])
Epoch: 2966, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 2967 - Batch 1 ########################
IDs in batch 1: tensor([1275, 1832, 1927, 3003,  127, 1938, 3733, 1080, 2090, 2761, 3672, 2777,
         341, 3956, 1490,  427])
Epoch: 2967, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 2968 - Batch 1 ########################
IDs in batch 1: tensor([ 778, 4117, 1005, 3446, 1122, 2740, 1650, 1643, 1311, 2498, 1354, 2059,
          73, 1103, 1099,  724])
Epoch: 2968, Training Loss: 0.20, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 2969 - Batch 1 ########################
IDs in batch 1: tensor([3721, 2418, 2073, 2196, 3862, 4089, 3265, 3734, 3826, 1591,  573, 2959,
        4049, 1093, 1228, 1006])
Epoch: 2969, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 2970 - Batch 1 ########################
IDs in batch 1: tensor([ 602, 3905, 1932,  515,  239,  238, 2475,  397,  880,  827, 4261, 3640,
        1094, 3406, 3286, 3886])
Epoch: 2970, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 2971 - Batch 1 ########################
IDs in batch 1: tensor([1365, 3035, 1507,  897, 2648, 1724, 3478, 3949, 3628, 1870,  726, 1216,
        4033,  363, 3006, 4058])
Epoch: 2971, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 2972 - Batch 1 ########################
IDs in batch 1: tensor([1579, 1684, 1041, 2822, 3077, 3257, 1569, 2291, 4152,  773, 4049, 1961,
        1247, 3693, 1163, 1679])
Epoch: 2972, Training Loss: 0.10, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 2973 - Batch 1 ########################
IDs in batch 1: tensor([1084, 1030, 2450, 3023,  155,   74, 1457, 2890,  444, 2553, 2431, 1130,
        1379, 1970,  482, 2260])
Epoch: 2973, Training Loss: 0.09, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 2974 - Batch 1 ########################
IDs in batch 1: tensor([2550,  770, 2248, 2223, 3276, 1239, 3671, 2505, 2478, 1331, 2106, 2691,
         587,  881, 4100, 2256])
Epoch: 2974, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 2975 - Batch 1 ########################
IDs in batch 1: tensor([2363, 1370,   61, 1444, 2787, 3743, 2620, 1990,   27, 2275,   30, 1732,
        1982, 1863, 2680, 3123])
Epoch: 2975, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2976 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 2108,   51, 1953, 3075, 3192, 3343, 2256, 2291, 3091,  828, 1146,
         103, 1772, 1870, 3151])
Epoch: 2976, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2977 - Batch 1 ########################
IDs in batch 1: tensor([ 687, 1335, 2218, 3009, 1450, 3119,  534, 3406,  688, 4205, 1365, 4246,
          62, 1784, 1178, 1944])
Epoch: 2977, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2978 - Batch 1 ########################
IDs in batch 1: tensor([1508, 4157,  729,  247, 3240, 2320, 3177, 2765, 4257, 4163, 1418,  511,
        1530,  251,  615,  969])
Epoch: 2978, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 2979 - Batch 1 ########################
IDs in batch 1: tensor([2320, 1900,  102,  445, 1087, 3650, 2579, 2831, 1798, 4122, 2788, 2439,
        1417, 1767, 1088,    7])
Epoch: 2979, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 2980 - Batch 1 ########################
IDs in batch 1: tensor([3404, 3183, 2926,  151, 3745, 1296,  607,  126, 3010,  976, 1263,  732,
        3226, 2718, 3787, 2836])
Epoch: 2980, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 2981 - Batch 1 ########################
IDs in batch 1: tensor([3181,  603, 3541, 2487, 2901, 3108, 2650, 2954,  441, 3397, 2644, 1082,
        3532, 3970, 2509, 3456])
Epoch: 2981, Training Loss: 0.49, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2982 - Batch 1 ########################
IDs in batch 1: tensor([3455, 3733, 3495, 3481,  365,  563, 3843,  141,  601,  226, 3648, 2821,
        2838, 2435, 1499, 1144])
Epoch: 2982, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 2983 - Batch 1 ########################
IDs in batch 1: tensor([1133, 1496,  777, 4256, 4119, 1220, 3333, 2282, 3192, 1934, 3913, 2536,
        1952, 2316, 4212, 1372])
Epoch: 2983, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2984 - Batch 1 ########################
IDs in batch 1: tensor([3627, 3843, 2517, 3847, 2874, 3382, 2373, 2945, 1020,  407, 3591,  587,
        3252, 3143, 2110, 1482])
Epoch: 2984, Training Loss: 0.29, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2985 - Batch 1 ########################
IDs in batch 1: tensor([2053, 3087, 3447, 3900,  724, 1223, 1712,  757, 2938, 1835, 4095,  575,
        2394, 1212, 2464, 2656])
Epoch: 2985, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2986 - Batch 1 ########################
IDs in batch 1: tensor([ 283, 1568, 2418, 4094, 3435, 1273, 3255,  785, 3738,  558, 1661, 2031,
        2523, 4136, 1700, 1098])
Epoch: 2986, Training Loss: 0.14, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 2987 - Batch 1 ########################
IDs in batch 1: tensor([2775, 4222, 1390, 2154, 3823, 3852, 2725, 2004, 1766, 3386, 3110, 2644,
        3088, 1482, 1896, 4255])
Epoch: 2987, Training Loss: 0.32, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 2988 - Batch 1 ########################
IDs in batch 1: tensor([3543, 2367, 3268,  182,   81, 2745, 3990, 2538, 3699, 1117, 2815, 1937,
        3036, 1283, 2827,  358])
Epoch: 2988, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2989 - Batch 1 ########################
IDs in batch 1: tensor([3539,  774,  933,  819, 2799,  735, 1956,  172, 1175,   47, 3956, 3667,
        3287, 2870, 2492, 4148])
Epoch: 2989, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 2990 - Batch 1 ########################
IDs in batch 1: tensor([1868, 1276, 1610,  635,  454, 3772,  605,   19,  762,  628, 1779, 3421,
         814, 2482,  961, 4093])
Epoch: 2990, Training Loss: 0.44, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2991 - Batch 1 ########################
IDs in batch 1: tensor([2011, 1988, 3879, 1982, 3372, 1144, 3022, 2732, 1794, 3157, 4186, 3378,
        3558, 1257, 1733,  275])
Epoch: 2991, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2992 - Batch 1 ########################
IDs in batch 1: tensor([2926, 1583, 1326,  902,  653, 2431,  978, 3083, 2249, 3509, 4072, 1639,
        4175, 2173, 3738, 4110])
Epoch: 2992, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2993 - Batch 1 ########################
IDs in batch 1: tensor([2125,  871, 4003, 3745,  875,  714,  184,   81,  750, 1086, 2393,  449,
         263, 2133, 1704, 3681])
Epoch: 2993, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2994 - Batch 1 ########################
IDs in batch 1: tensor([2209,  740, 3675,  541,  848, 1803, 1892, 3743, 2644,  743, 2854, 1630,
        1174, 3832,  355,  657])
Epoch: 2994, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2995 - Batch 1 ########################
IDs in batch 1: tensor([3667, 1456, 1024, 3514, 3882, 2949, 2977, 3444, 3832, 3035, 3925, 1154,
         649, 1136, 4140, 4068])
Epoch: 2995, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2996 - Batch 1 ########################
IDs in batch 1: tensor([  56, 3459,  921, 3836, 1594, 3675, 2153, 2477, 2341, 2553,  789, 1388,
         465, 1822, 2236,  975])
Epoch: 2996, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 2997 - Batch 1 ########################
IDs in batch 1: tensor([ 371,  774, 3896,   30, 2170, 3194, 2636, 1974,  387, 2094, 3509,  337,
         544, 3697,   78, 2040])
Epoch: 2997, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2998 - Batch 1 ########################
IDs in batch 1: tensor([2683, 2045, 1343,  691, 1777,  971, 2782, 4013, 1167, 1370, 3379, 2709,
         866, 3765, 2819, 3323])
Epoch: 2998, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 2999 - Batch 1 ########################
IDs in batch 1: tensor([1103,   59, 3744, 3194,  699, 2328, 2800, 1932, 1443, 3023, 3827,  828,
        3616,  211,   20,  766])
Epoch: 2999, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3000 - Batch 1 ########################
IDs in batch 1: tensor([ 604, 3284, 3428, 3709, 2817,  947, 1736, 1965,  172,  462, 1157, 1852,
         880, 3022,  732,  112])
Epoch: 3000, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3001 - Batch 1 ########################
IDs in batch 1: tensor([2709, 2874,  119, 3943, 3992, 3894,  818, 3183, 2824, 2352, 1579, 2643,
        2553, 3473, 1341, 2153])
Epoch: 3001, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3002 - Batch 1 ########################
IDs in batch 1: tensor([1043,  505, 4131, 2632,  418, 3113,  566,  132,  803, 1124, 3055, 3432,
         665, 3150,  755, 2125])
Epoch: 3002, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3003 - Batch 1 ########################
IDs in batch 1: tensor([1841,  287, 3345, 1728, 4012, 1155,   81, 2711, 2188, 2627, 1885, 3004,
         928,   96, 1380, 2718])
Epoch: 3003, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3004 - Batch 1 ########################
IDs in batch 1: tensor([1420, 3637,  430, 2522, 1474, 3132, 3609,  689, 3214, 2154, 2974, 2954,
        3005, 3298, 1604, 3839])
Epoch: 3004, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3005 - Batch 1 ########################
IDs in batch 1: tensor([2506, 2412, 2179,  796,  424, 2892, 2338, 3693, 3219, 2963, 1960, 3742,
        4070,  380,  165, 3184])
Epoch: 3005, Training Loss: 0.35, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3006 - Batch 1 ########################
IDs in batch 1: tensor([2624,  243, 4215,  586,  223, 1175, 1812,  891, 1168, 1233, 1497, 1599,
         632,  490,  753,  530])
Epoch: 3006, Training Loss: 0.63, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3007 - Batch 1 ########################
IDs in batch 1: tensor([1143, 3709, 1751, 1110,  183,  382,  730, 2562, 1296,  345, 2587, 3448,
         613,  498, 2284, 3789])
Epoch: 3007, Training Loss: 0.47, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3008 - Batch 1 ########################
IDs in batch 1: tensor([1954, 3262,  774, 1740, 3128,  449,  857, 1396, 1775, 2883,  739, 3400,
        2463, 2342, 1082, 3728])
Epoch: 3008, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3009 - Batch 1 ########################
IDs in batch 1: tensor([1060, 3338,  805, 4268,  290, 4251,  888, 1648, 3945,  362, 3014, 2741,
         264, 1799, 3233,  928])
Epoch: 3009, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3010 - Batch 1 ########################
IDs in batch 1: tensor([3873, 2957, 3130, 3581, 2577, 2448, 2869,  484, 3617, 3379, 1625,  626,
         651,  683, 1811, 1045])
Epoch: 3010, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3011 - Batch 1 ########################
IDs in batch 1: tensor([3693,  897, 2879, 1226, 1979, 3821, 4118, 3207, 2476, 4214, 3203, 3275,
        2005,  257, 2849, 1179])
Epoch: 3011, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3012 - Batch 1 ########################
IDs in batch 1: tensor([3609, 1277,  553, 2914, 1125,  527, 1496,    7, 1627,  583, 4146,  211,
        3545,  300, 3206, 1614])
Epoch: 3012, Training Loss: 0.37, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3013 - Batch 1 ########################
IDs in batch 1: tensor([  50, 2063,  852, 2854, 2866, 1693, 2977, 1993, 4242,  183, 4158, 1684,
        2154, 2437, 1216,   34])
Epoch: 3013, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3014 - Batch 1 ########################
IDs in batch 1: tensor([3505, 1594, 2472, 3367, 1247, 2482, 1170,  379,  159, 4154, 2059, 1980,
         100, 1014, 2912, 1635])
Epoch: 3014, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3015 - Batch 1 ########################
IDs in batch 1: tensor([1748, 2838, 2761, 4096,  194, 3243, 3077, 1119, 3876, 3276, 1136, 2656,
         380,  274, 2890, 1156])
Epoch: 3015, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 3016 - Batch 1 ########################
IDs in batch 1: tensor([ 261, 2475, 1007, 3505, 4026, 1817, 2508, 1087, 2600, 2120, 2192, 2148,
         388,  568, 2036, 4214])
Epoch: 3016, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 3017 - Batch 1 ########################
IDs in batch 1: tensor([ 818, 3265, 3634, 1285, 2465,  714, 4236, 1780, 3470, 2466, 4138,  838,
        3290, 1965, 1283, 1999])
Epoch: 3017, Training Loss: 0.02, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 3018 - Batch 1 ########################
IDs in batch 1: tensor([2624,  933, 2405, 1508, 3119, 2998, 3498, 2703, 2364, 1562,  895, 3926,
        3549, 1464,  275, 2943])
Epoch: 3018, Training Loss: 0.02, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 3019 - Batch 1 ########################
IDs in batch 1: tensor([1642,  615, 1429, 1295, 1698,  424, 2274, 2640, 1862, 1932, 1081, 3993,
        2621, 2417, 3478,  688])
Epoch: 3019, Training Loss: 0.02, Validation Loss: 0.66, accuracy = 0.77
######################## Epoch 3020 - Batch 1 ########################
IDs in batch 1: tensor([2649,  665, 2947, 1646,  134, 2150,  342, 3108,  615, 3376, 3729, 3330,
         131, 4156, 4163, 3603])
Epoch: 3020, Training Loss: 0.06, Validation Loss: 0.66, accuracy = 0.76
######################## Epoch 3021 - Batch 1 ########################
IDs in batch 1: tensor([ 306, 1250,  899,  854, 1267, 3729, 1551, 2250, 3240, 1171, 1818, 4218,
        2942, 1672,  823, 1066])
Epoch: 3021, Training Loss: 0.20, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 3022 - Batch 1 ########################
IDs in batch 1: tensor([ 263, 1604, 2849,  750, 3156, 1985, 1086, 3374, 2379, 3031, 1754, 3585,
        3220, 2617, 4253,  587])
Epoch: 3022, Training Loss: 0.02, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 3023 - Batch 1 ########################
IDs in batch 1: tensor([3418,  524, 1650, 1678, 1836, 1017,  436, 1682, 1364, 1702, 1755, 3652,
        1682,   95, 2627, 2574])
Epoch: 3023, Training Loss: 0.17, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 3024 - Batch 1 ########################
IDs in batch 1: tensor([2182, 1346, 3526,  990,  181, 2103, 1975, 1094,  820,  324, 3485,  674,
        3506, 2645, 1974, 4140])
Epoch: 3024, Training Loss: 0.04, Validation Loss: 0.65, accuracy = 0.77
######################## Epoch 3025 - Batch 1 ########################
IDs in batch 1: tensor([1167, 3471, 4205, 1583, 2925, 2726, 2553, 2921, 2671, 4186, 3151, 2280,
         872, 3487, 4184, 1511])
Epoch: 3025, Training Loss: 0.15, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 3026 - Batch 1 ########################
IDs in batch 1: tensor([3078,  794, 2976,  667, 2951, 2045, 2367, 4232, 3797,  725, 2631, 2356,
        4172, 4135,  283, 1214])
Epoch: 3026, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 3027 - Batch 1 ########################
IDs in batch 1: tensor([1070, 4240, 1585,  199, 3253, 1896,  368, 2131, 2484, 4256, 3589, 2080,
         726, 3572, 1630, 2109])
Epoch: 3027, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3028 - Batch 1 ########################
IDs in batch 1: tensor([ 763, 3998,  850, 3715, 1704,  534, 2231, 3207, 1727,  380, 1772, 2926,
        2927, 3371, 2473,  193])
Epoch: 3028, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3029 - Batch 1 ########################
IDs in batch 1: tensor([1894, 1497, 4197, 1219, 2646, 1139,  435, 2977,  269, 2667, 2009, 3557,
         574, 2760, 3234, 1993])
Epoch: 3029, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3030 - Batch 1 ########################
IDs in batch 1: tensor([4141,  522,  603,  876, 2887, 2649, 2094, 2433,  305, 2601, 1463, 3479,
        2536, 3333,  527, 3601])
Epoch: 3030, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3031 - Batch 1 ########################
IDs in batch 1: tensor([2375, 2678, 2555, 1155, 1545,  627,  828, 1833, 3389, 3448, 1647, 2078,
         956, 1034,  252, 1604])
Epoch: 3031, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3032 - Batch 1 ########################
IDs in batch 1: tensor([3751, 2143, 4094, 2482, 2563,  132,  318, 2085, 3509, 2331, 3488,  260,
        1039, 4033, 1471, 2563])
Epoch: 3032, Training Loss: 0.20, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3033 - Batch 1 ########################
IDs in batch 1: tensor([3456, 2711, 3977, 3635, 3204, 1341, 1075, 2213, 2866,   88, 3660, 2545,
          14, 3162, 3382, 1321])
Epoch: 3033, Training Loss: 0.40, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3034 - Batch 1 ########################
IDs in batch 1: tensor([2453, 2837, 1196,   20,  727, 3787, 3797, 2674, 1252, 1478, 3806,  730,
         212,  672,  794, 1134])
Epoch: 3034, Training Loss: 0.08, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 3035 - Batch 1 ########################
IDs in batch 1: tensor([2339, 2776, 1260,  762,  636, 1993, 2167, 3969, 2359, 2641, 1646, 1434,
        3264, 2183, 4266, 2425])
Epoch: 3035, Training Loss: 0.31, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3036 - Batch 1 ########################
IDs in batch 1: tensor([1747, 3617, 1451, 3314, 2838,  335, 1005,  729, 2354, 3547, 2121,  649,
         342, 3942, 4141, 3689])
Epoch: 3036, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3037 - Batch 1 ########################
IDs in batch 1: tensor([2134,  436, 4140, 3723,  109, 1094, 2746,   38,  944, 3948, 2913, 4175,
         915,  382, 3206, 4036])
Epoch: 3037, Training Loss: 0.38, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3038 - Batch 1 ########################
IDs in batch 1: tensor([2141, 1012, 3705, 2487, 2309, 3674, 1796,  892, 1935,  833, 3598,  184,
        2473, 3092, 1445, 2621])
Epoch: 3038, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3039 - Batch 1 ########################
IDs in batch 1: tensor([2905, 1312, 1826, 4163, 2765, 3852, 3355, 1471, 4223, 4000,  781, 2884,
         138, 2731,  266, 3441])
Epoch: 3039, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3040 - Batch 1 ########################
IDs in batch 1: tensor([1660,  109, 3732, 3573, 3705, 1668, 4190, 2656,  418, 2805, 4127,  727,
        3790, 4017,  437, 1573])
Epoch: 3040, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3041 - Batch 1 ########################
IDs in batch 1: tensor([1834,   82, 3091, 1409, 3647, 3970, 4203,  604,   19, 1818, 1836, 3700,
         896, 2090, 3917, 1955])
Epoch: 3041, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3042 - Batch 1 ########################
IDs in batch 1: tensor([1376,  769,  902, 1452,  792, 3552, 4128, 2102,  732, 1139, 3427, 3842,
        3360, 4038, 1226,  395])
Epoch: 3042, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3043 - Batch 1 ########################
IDs in batch 1: tensor([2064, 2951, 1638,  430,  444, 4055,  710, 3744, 3317, 3827,  354,  797,
        2831, 3082, 1060, 4266])
Epoch: 3043, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3044 - Batch 1 ########################
IDs in batch 1: tensor([1734,  511,  828, 2373, 3789,  950, 1054, 1423, 3742, 4184, 3360,  626,
        1057, 2349,  776, 3429])
Epoch: 3044, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3045 - Batch 1 ########################
IDs in batch 1: tensor([3187, 1766, 2111, 2545, 2564, 3648, 2983,  956,  985, 2921,  459, 3449,
        2868, 3018, 4149, 1663])
Epoch: 3045, Training Loss: 0.29, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3046 - Batch 1 ########################
IDs in batch 1: tensor([4040, 3943, 1345, 2220, 2755,   56, 3000, 1297, 2028, 3310, 3913, 1858,
        4197, 1320, 2039,  955])
Epoch: 3046, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3047 - Batch 1 ########################
IDs in batch 1: tensor([1090, 4205, 1318, 2706, 2708, 3161, 1384, 2973, 1567, 3874,   18, 1619,
         186, 4100,  891, 1086])
Epoch: 3047, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3048 - Batch 1 ########################
IDs in batch 1: tensor([3040, 4149, 1948, 1379, 3253,  368, 2879, 3996, 1051, 3339, 1604, 2299,
        3711, 2010,  672, 2332])
Epoch: 3048, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3049 - Batch 1 ########################
IDs in batch 1: tensor([1386, 3962, 4016, 1161, 1220,  826, 1347, 1009, 3888, 1602,   21, 4099,
         363, 4060, 3728, 2907])
Epoch: 3049, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3050 - Batch 1 ########################
IDs in batch 1: tensor([3099, 1345, 4161, 4240, 3015,  613,  523, 1548, 1272, 2426, 1833, 3656,
         365, 2494, 1799, 1104])
Epoch: 3050, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3051 - Batch 1 ########################
IDs in batch 1: tensor([2492,  873, 3539, 2732,  438,  837, 3588, 4105,  913, 3161,  478, 1682,
        1780,  520, 3168, 3021])
Epoch: 3051, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3052 - Batch 1 ########################
IDs in batch 1: tensor([2482, 1458, 1241,  448,  136, 1949,  221,   18,   22, 1914,  578, 2378,
         279, 3943, 2643, 3900])
Epoch: 3052, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3053 - Batch 1 ########################
IDs in batch 1: tensor([2621, 1935, 3159, 3057, 1360, 1730, 3780,  357, 3065, 2040, 1049,  575,
        1600,  478,  602, 2004])
Epoch: 3053, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3054 - Batch 1 ########################
IDs in batch 1: tensor([ 226, 2991, 3447, 2914, 1229, 2542,  989, 1241,  823, 2670, 1287, 4057,
        2238, 1573,  251, 3815])
Epoch: 3054, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3055 - Batch 1 ########################
IDs in batch 1: tensor([ 360,  662,  678, 1291, 3384, 1346, 3467, 1131, 2401,  538, 2526,  363,
         413, 2317,  892, 1909])
Epoch: 3055, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3056 - Batch 1 ########################
IDs in batch 1: tensor([ 902, 1161, 1901, 1708, 1986,  685, 1836, 1420, 1420, 3180, 3841, 4093,
        1589, 3406, 3438, 2109])
Epoch: 3056, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3057 - Batch 1 ########################
IDs in batch 1: tensor([4264,  425, 3310, 3695, 3333, 3142, 3755, 1225, 3607, 1775, 2591, 3983,
        2284, 3648, 3541,   27])
Epoch: 3057, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3058 - Batch 1 ########################
IDs in batch 1: tensor([ 661, 3873,  187, 3710,  499, 3608, 4037, 4199, 1379, 1116, 2040, 1357,
         260, 1731,  135, 1285])
Epoch: 3058, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3059 - Batch 1 ########################
IDs in batch 1: tensor([2729, 1113, 3689, 2324, 2604,  275,   93, 1730, 3081,  996,   21, 1702,
         537, 2367, 2355, 1570])
Epoch: 3059, Training Loss: 0.19, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3060 - Batch 1 ########################
IDs in batch 1: tensor([1111, 2692, 3199,  957, 3342, 1698, 2419, 4099,  111, 1809, 1385,  441,
        2015, 3804, 3719, 2028])
Epoch: 3060, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3061 - Batch 1 ########################
IDs in batch 1: tensor([1275, 2999,  111, 3663, 3447,   60, 3108, 4027, 2081,  709,  305, 3951,
        4188, 2966, 2693, 3252])
Epoch: 3061, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3062 - Batch 1 ########################
IDs in batch 1: tensor([1619, 1663, 3222, 4068, 2117,  449, 3328,  725, 4046, 3846, 4245, 1853,
        2365, 3597, 2568, 3922])
Epoch: 3062, Training Loss: 0.20, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3063 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 3287, 1276, 2053, 1639, 3872, 2306,  976, 2309, 4189, 3206, 3218,
        3047, 2002, 2242, 3496])
Epoch: 3063, Training Loss: 0.11, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3064 - Batch 1 ########################
IDs in batch 1: tensor([2823, 1272, 3808,  188, 2464, 1498,  456, 2141, 1953, 3545,  947,  198,
        3484, 2118, 1931, 3245])
Epoch: 3064, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3065 - Batch 1 ########################
IDs in batch 1: tensor([1440, 1718, 1610, 3564,  879, 2687,  436, 2274, 1614, 4226, 1438, 1130,
        3376, 4267, 2642, 4173])
Epoch: 3065, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 3066 - Batch 1 ########################
IDs in batch 1: tensor([1727, 2135, 3370, 1863, 1953, 2034, 1764, 3963,  413, 1951, 2119, 1443,
        3990, 2752,  978,  894])
Epoch: 3066, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3067 - Batch 1 ########################
IDs in batch 1: tensor([ 430, 2081, 1223, 2210,  701, 2383, 3183, 1884, 1981,  794,  992, 2172,
         658,  260, 1097,  978])
Epoch: 3067, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3068 - Batch 1 ########################
IDs in batch 1: tensor([ 713, 2391, 3650,  205, 2372, 1456, 1341, 3309, 3528,  991, 3251, 3415,
        1506,  724, 1555, 1138])
Epoch: 3068, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3069 - Batch 1 ########################
IDs in batch 1: tensor([ 312, 3234, 3306, 3105, 3744, 2342, 3677, 3120, 4065,  139, 3551,  557,
        1498, 1679, 1459, 1011])
Epoch: 3069, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3070 - Batch 1 ########################
IDs in batch 1: tensor([1595, 3781,  649, 1015, 3783, 3407, 1841, 3161, 2350, 2926, 1146,  112,
        4033, 3744, 2203, 3933])
Epoch: 3070, Training Loss: 0.05, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3071 - Batch 1 ########################
IDs in batch 1: tensor([3600, 2069, 2382, 2947, 4125,  155, 3133, 2088,  787, 1061, 3731, 1349,
        2123, 2498, 2848,  775])
Epoch: 3071, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3072 - Batch 1 ########################
IDs in batch 1: tensor([3711, 1734, 4036, 1911, 3839,  594, 3113, 4173, 2359, 1200, 4080, 2394,
         535, 4176, 3851,  966])
Epoch: 3072, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3073 - Batch 1 ########################
IDs in batch 1: tensor([4267, 2091, 2341,  818, 3816, 3975, 3975, 2797, 2347,   32,   24, 1828,
        4006,  884, 1530,  604])
Epoch: 3073, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3074 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1501, 3718, 1032,  649, 1402,  154, 2291,  469, 1076, 1487, 3995,
        3927, 4072, 2142, 3859])
Epoch: 3074, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3075 - Batch 1 ########################
IDs in batch 1: tensor([2660, 2892, 4014, 1283, 4070, 3453, 4144, 2983,  930, 2059, 3144,  689,
        4176, 2400, 1497, 1167])
Epoch: 3075, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3076 - Batch 1 ########################
IDs in batch 1: tensor([2976, 3353, 3142, 2125,  980, 1996, 3972, 2970,  626,  229, 3298, 3977,
        2942,  613,  236, 1879])
Epoch: 3076, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3077 - Batch 1 ########################
IDs in batch 1: tensor([ 219, 1028, 3920, 3921, 3223, 3156, 4120,  857, 1775, 2251,  913, 1189,
        3846, 2845, 1067, 1571])
Epoch: 3077, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3078 - Batch 1 ########################
IDs in batch 1: tensor([4197, 2553, 3701, 2907, 1663,  449, 3608, 2005, 3369,  605,   42, 1828,
         547,   70, 2388,  812])
Epoch: 3078, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3079 - Batch 1 ########################
IDs in batch 1: tensor([ 870,  852, 2063,  444, 2770,  338,  466, 1409, 3667, 3644,  219, 2754,
        2963, 4016, 1591,  483])
Epoch: 3079, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3080 - Batch 1 ########################
IDs in batch 1: tensor([1226, 3699, 1081, 1155,  884, 2081, 2925, 1124, 3879,  790, 1383, 3101,
        1410, 2190,   19,  596])
Epoch: 3080, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3081 - Batch 1 ########################
IDs in batch 1: tensor([4096, 2238,  508, 2538, 4234, 4010, 1152,  605, 1960, 2317, 1877, 2417,
        3369, 1117, 2789, 1951])
Epoch: 3081, Training Loss: 0.21, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3082 - Batch 1 ########################
IDs in batch 1: tensor([ 796,  942, 3543, 2002, 2459, 1918,  151,  738,  694, 3557, 3391, 3251,
         317, 1367, 2520,  393])
Epoch: 3082, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.78
######################## Epoch 3083 - Batch 1 ########################
IDs in batch 1: tensor([1802,  987, 1335,  769,  105, 2829,  887, 1332, 2648,  337,  897, 3643,
        1209, 1171,  827, 2800])
Epoch: 3083, Training Loss: 0.40, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3084 - Batch 1 ########################
IDs in batch 1: tensor([2097, 4194, 3689, 2119,  770, 3100,   60, 1110, 3200, 2465, 2008,  763,
         741, 1408, 1944, 1442])
Epoch: 3084, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3085 - Batch 1 ########################
IDs in batch 1: tensor([1204, 3286,  989, 3384,  120, 1630, 3597, 2369, 1648,  282,  980, 3154,
        4223, 1009, 1507,    7])
Epoch: 3085, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3086 - Batch 1 ########################
IDs in batch 1: tensor([1672, 3818, 1651, 4067, 1020, 2332, 1680, 2863, 2198, 1850, 1030, 3252,
         992,  763, 3369, 2514])
Epoch: 3086, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3087 - Batch 1 ########################
IDs in batch 1: tensor([4050, 2072, 1819, 1027, 2844, 1141,  924, 3456, 2099, 2045,  839, 1380,
        1974, 1632, 2423, 1439])
Epoch: 3087, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3088 - Batch 1 ########################
IDs in batch 1: tensor([2466, 2107, 1573, 3952, 3262,  774, 1450, 4013, 4143, 2202, 2189, 2855,
         693,  829, 3598, 1512])
Epoch: 3088, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3089 - Batch 1 ########################
IDs in batch 1: tensor([ 601, 1154, 3581, 2391, 1614,  952, 1571, 1290,  327, 3765, 3572, 3447,
        1086,  434, 3701,  127])
Epoch: 3089, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3090 - Batch 1 ########################
IDs in batch 1: tensor([3650,  198, 2902, 3507, 3141, 2102,  380, 4096, 3663, 2871, 4022, 1038,
        2840, 1101, 3406,  645])
Epoch: 3090, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3091 - Batch 1 ########################
IDs in batch 1: tensor([2011,  682,  395, 1093, 3772,  852, 3479, 2388, 3947, 1204, 3051, 3765,
        2417, 2161, 1877, 4044])
Epoch: 3091, Training Loss: 0.13, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3092 - Batch 1 ########################
IDs in batch 1: tensor([  32,  884,  857, 1034, 1047, 1372,  308, 2444,  292, 2309, 1504, 1271,
        1841, 3992, 1589, 1015])
Epoch: 3092, Training Loss: 0.48, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3093 - Batch 1 ########################
IDs in batch 1: tensor([3468, 1167,  341, 1440, 1281, 2030,  530, 1258, 3514, 2132, 2253, 1846,
        3516,  219, 3030, 2260])
Epoch: 3093, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3094 - Batch 1 ########################
IDs in batch 1: tensor([3554,  996,  557, 1756, 3926,   19,  607, 2666, 1003, 2196, 3506,  422,
        2789,  627, 1702, 1991])
Epoch: 3094, Training Loss: 0.17, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3095 - Batch 1 ########################
IDs in batch 1: tensor([2355,  953, 1650, 1984, 1830,  566, 3351, 2482, 3279, 3829, 2109,  411,
         718, 2004,  476, 1039])
Epoch: 3095, Training Loss: 0.07, Validation Loss: 0.67, accuracy = 0.76
######################## Epoch 3096 - Batch 1 ########################
IDs in batch 1: tensor([3449, 4128,   73, 2736, 1296, 1090, 1872, 1464, 3382,  904,  478, 3711,
        2469, 1778, 3659, 3220])
Epoch: 3096, Training Loss: 0.01, Validation Loss: 0.67, accuracy = 0.75
######################## Epoch 3097 - Batch 1 ########################
IDs in batch 1: tensor([2131, 3057, 1993, 2810, 3785, 1267,  403,  127, 3099, 2373,  795, 2376,
        1594,  843, 4009, 3328])
Epoch: 3097, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.76
######################## Epoch 3098 - Batch 1 ########################
IDs in batch 1: tensor([1367, 3109, 2132, 2327, 1685, 1007, 3102, 3426, 3543, 1916, 2568, 2636,
        1232,  402, 2022,  418])
Epoch: 3098, Training Loss: 0.21, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3099 - Batch 1 ########################
IDs in batch 1: tensor([2202,  333, 2124, 4125,  411, 3913, 2334, 1295, 1061,  334, 3743,  437,
        2410, 1345, 1578,  820])
Epoch: 3099, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3100 - Batch 1 ########################
IDs in batch 1: tensor([ 878,  411, 3582,  378, 2546, 1660,  264, 2815, 1720, 1808,   13, 3669,
        4040, 1470, 1295, 1317])
Epoch: 3100, Training Loss: 0.18, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3101 - Batch 1 ########################
IDs in batch 1: tensor([ 455,  424,  816,  402, 2011, 3964, 2349, 3989, 4025, 4261, 3529, 1530,
        2416,  261, 2436, 3112])
Epoch: 3101, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3102 - Batch 1 ########################
IDs in batch 1: tensor([4089, 2959,  490, 3981, 3935, 3387, 2217, 2365, 2114, 1624, 3317, 1383,
        2004, 3866,  839, 3772])
Epoch: 3102, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3103 - Batch 1 ########################
IDs in batch 1: tensor([2997, 3360, 2398, 4186, 1497, 2642,  770, 3647, 3615, 2329, 2827, 3497,
        3192,  257, 2868, 1101])
Epoch: 3103, Training Loss: 0.25, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3104 - Batch 1 ########################
IDs in batch 1: tensor([1062, 4070, 2429, 1710,  259,  553,  354,  709, 3353,  917,  546, 1053,
        3933, 3243,  106, 1970])
Epoch: 3104, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3105 - Batch 1 ########################
IDs in batch 1: tensor([4135, 3504, 1680,  871, 3642, 1495,   56, 1764, 1702, 3925, 1798, 3424,
        2166, 1374,   51, 1651])
Epoch: 3105, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3106 - Batch 1 ########################
IDs in batch 1: tensor([1996, 2368,  878,  739, 1636, 1812, 2832, 1955, 1524, 2859, 3435, 2212,
        3616, 3896, 2324,  843])
Epoch: 3106, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3107 - Batch 1 ########################
IDs in batch 1: tensor([2970, 2065, 1011, 3500, 2462, 2823, 1507, 3554,  603,  529, 1775, 1916,
         887, 2298, 3536, 2212])
Epoch: 3107, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3108 - Batch 1 ########################
IDs in batch 1: tensor([1420,  849, 4218, 2995, 2099, 3677,  762, 2134, 3647, 3291, 1023, 3268,
        1858, 3610,  203, 3738])
Epoch: 3108, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3109 - Batch 1 ########################
IDs in batch 1: tensor([2051,  662, 2074, 3336, 1524,   81,  277, 4258, 3757, 1369, 1521, 3506,
        1994, 4181, 2052, 4238])
Epoch: 3109, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3110 - Batch 1 ########################
IDs in batch 1: tensor([1225, 2097,  102, 1352, 4114,  639, 1399,  348, 3270, 2982, 2583, 2238,
        1178, 2091, 3597, 3493])
Epoch: 3110, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3111 - Batch 1 ########################
IDs in batch 1: tensor([1590, 2535, 3600, 1379, 1640, 2244, 3306,  524, 2523,   44, 3344, 3974,
        2526, 3128,  261, 2488])
Epoch: 3111, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3112 - Batch 1 ########################
IDs in batch 1: tensor([4220, 3554, 2349, 1388, 3922, 1559,  699, 3432, 2443, 1160, 3151, 1213,
        4100, 2631, 3707, 1963])
Epoch: 3112, Training Loss: 0.24, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3113 - Batch 1 ########################
IDs in batch 1: tensor([2475,   88, 2346, 2166, 2203,  554, 1658,  787, 3429,   59,  888, 4065,
         920,  221, 3022, 3936])
Epoch: 3113, Training Loss: 0.21, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3114 - Batch 1 ########################
IDs in batch 1: tensor([ 415, 1764,  982,  341, 2121, 2559, 1793, 2504, 2784, 3902, 3834, 3317,
        2465, 2125, 1825, 1952])
Epoch: 3114, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3115 - Batch 1 ########################
IDs in batch 1: tensor([ 992,  961, 3813, 3721, 2357,  434,  620, 4126, 1556, 3027, 2251, 2581,
        3456, 2765, 2173, 2151])
Epoch: 3115, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3116 - Batch 1 ########################
IDs in batch 1: tensor([1620, 3404, 3357, 2034, 3983, 1156,  303,  154, 3031,   88, 2017, 1467,
        1489, 2329,  886, 2415])
Epoch: 3116, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3117 - Batch 1 ########################
IDs in batch 1: tensor([1690,  950, 4120, 4185,  110, 3624, 2377, 3591,  375,  266, 2402, 3683,
        1182, 3617, 3182, 3795])
Epoch: 3117, Training Loss: 0.19, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3118 - Batch 1 ########################
IDs in batch 1: tensor([ 926, 3712,  529,  143, 2832, 2014, 2733, 4035, 1558, 1746, 1518, 3262,
         886, 2415,  471, 1069])
Epoch: 3118, Training Loss: 0.23, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3119 - Batch 1 ########################
IDs in batch 1: tensor([2390, 1767, 3030,  536, 1299, 2868, 1082,  644, 1309, 2617,  501, 2597,
        3509, 2643, 3971, 1365])
Epoch: 3119, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3120 - Batch 1 ########################
IDs in batch 1: tensor([1010, 3338, 2428, 2754, 3525, 3659, 4170,  676, 2736, 2019, 1882, 3597,
        3481,  133, 2616, 2797])
Epoch: 3120, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3121 - Batch 1 ########################
IDs in batch 1: tensor([3692, 3470, 1282,  712, 3036, 1073, 2028, 1034,  295,  505, 2743, 3208,
        1526, 3161, 2937, 3740])
Epoch: 3121, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3122 - Batch 1 ########################
IDs in batch 1: tensor([3051, 4010, 1123, 1605, 2332, 3544, 3533, 3081, 2487, 2998, 1101, 2298,
        2577, 1796, 1684, 1817])
Epoch: 3122, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3123 - Batch 1 ########################
IDs in batch 1: tensor([2732, 4049, 3058, 2157, 3306, 2115,  119,  617, 3592, 1822, 3390,  103,
        1160,  729,  884, 2072])
Epoch: 3123, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3124 - Batch 1 ########################
IDs in batch 1: tensor([3372,  278, 2172, 2017, 3475, 3705, 1562, 2545, 2804, 3973,  514, 1648,
        1537, 1899, 3712,  183])
Epoch: 3124, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3125 - Batch 1 ########################
IDs in batch 1: tensor([ 139, 1469, 2919, 1495, 3098, 3385, 2973,  694, 2497, 2565, 3333, 2624,
        1498,  646,  714, 3284])
Epoch: 3125, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3126 - Batch 1 ########################
IDs in batch 1: tensor([2249,  472, 2565, 4227, 4108,  790, 3588,  888, 3421, 2905, 4103,  665,
        2522, 2365,   15, 1284])
Epoch: 3126, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3127 - Batch 1 ########################
IDs in batch 1: tensor([1878,  133, 3268, 1065, 2737,  317, 1294, 3831,  103, 1619, 1857, 3976,
        1004,  198, 2836, 3160])
Epoch: 3127, Training Loss: 0.35, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3128 - Batch 1 ########################
IDs in batch 1: tensor([ 324, 1592, 1060,  762, 2193, 2346, 4022,  977, 3192, 4157, 3795,  237,
        3878, 1200,  277,  456])
Epoch: 3128, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3129 - Batch 1 ########################
IDs in batch 1: tensor([1746, 4225, 1182, 3936,  335,  908, 3792, 3951,   78, 3950, 3400, 4014,
        3071, 3636, 2103, 1467])
Epoch: 3129, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3130 - Batch 1 ########################
IDs in batch 1: tensor([1602,  941, 1143, 1154,  612, 1925, 2773, 3554, 2386, 1899, 1386,  320,
         854,  469, 1032, 1233])
Epoch: 3130, Training Loss: 0.60, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3131 - Batch 1 ########################
IDs in batch 1: tensor([3984, 1726, 3600,  250, 1065, 1498, 3904, 3707, 1252,  167, 2822, 3540,
        1740,  815, 2752, 4027])
Epoch: 3131, Training Loss: 0.07, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3132 - Batch 1 ########################
IDs in batch 1: tensor([1162,  609, 4026,  662,   14, 1500, 2615, 2606,  511,  512, 1077, 2102,
        2978, 3769, 3856, 3790])
Epoch: 3132, Training Loss: 0.09, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3133 - Batch 1 ########################
IDs in batch 1: tensor([4215, 1306, 1731, 2469,  279, 3049, 2414, 3894, 1034, 1092,  601, 1166,
          70, 4139,  463, 4186])
Epoch: 3133, Training Loss: 0.38, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3134 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 2879, 1982, 2589, 3813,  161, 2546, 2551, 1648, 2847,  786, 2995,
        2674, 3459,  602, 4203])
Epoch: 3134, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3135 - Batch 1 ########################
IDs in batch 1: tensor([1012, 1369, 1821, 3971, 3833, 1952, 1386, 4057, 4181, 3973, 3964, 1041,
        2244, 2249, 3663, 1569])
Epoch: 3135, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3136 - Batch 1 ########################
IDs in batch 1: tensor([ 603,  132, 4011,  411, 4134, 1948, 2225, 1377, 3753, 1050, 3795, 1546,
        4056, 1921, 3456, 3168])
Epoch: 3136, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3137 - Batch 1 ########################
IDs in batch 1: tensor([ 578, 3501, 2609, 3922, 3228,  125, 3214, 2653,  557,  623, 1920, 2373,
        1458, 3314, 2499, 3709])
Epoch: 3137, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3138 - Batch 1 ########################
IDs in batch 1: tensor([2538, 1319,  967,  400, 2855, 3709, 3446,  379,  491, 2440, 2550, 3589,
        2741, 1897, 3449,  105])
Epoch: 3138, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3139 - Batch 1 ########################
IDs in batch 1: tensor([ 807, 3470,  316, 3336, 4075, 3459,  182, 3963, 4161, 2036, 2680, 1558,
        4205,  662, 2632, 3277])
Epoch: 3139, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3140 - Batch 1 ########################
IDs in batch 1: tensor([3078, 3398, 3673, 3710, 3039, 3485, 1633, 2391, 2056,  826, 1923, 4069,
         556,  474, 1630, 3494])
Epoch: 3140, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3141 - Batch 1 ########################
IDs in batch 1: tensor([4258,   62, 1551, 2375,  395, 1921,  995, 2806,  756,  920, 2344, 2028,
        3974,  519, 3636, 3223])
Epoch: 3141, Training Loss: 0.11, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3142 - Batch 1 ########################
IDs in batch 1: tensor([1525, 2155, 1306, 1862,  224, 1655, 3074, 3920, 1923, 2732,  284, 3996,
        4249,  688, 1393, 3802])
Epoch: 3142, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3143 - Batch 1 ########################
IDs in batch 1: tensor([ 250, 3731, 2841,  362, 1530, 3234, 1272, 3671, 1177, 1299,  282, 2207,
        3188, 2412,  738, 2901])
Epoch: 3143, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3144 - Batch 1 ########################
IDs in batch 1: tensor([3483, 3471,   10, 3458, 3105, 1945,  739, 1967, 3543, 3932, 2603, 3458,
        3594, 4005, 1287,  341])
Epoch: 3144, Training Loss: 0.08, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3145 - Batch 1 ########################
IDs in batch 1: tensor([2603,  191,  269, 3418, 2447, 1894, 3847, 2584, 3395, 4008, 3971, 3354,
        3353, 1975, 1053, 3654])
Epoch: 3145, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3146 - Batch 1 ########################
IDs in batch 1: tensor([3409,  956, 2641,  790, 3984, 3394, 1248, 3343, 4125, 3499, 1147,   26,
        4186,  182, 2371, 2599])
Epoch: 3146, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3147 - Batch 1 ########################
IDs in batch 1: tensor([1381, 1080, 1755, 2225, 2135, 2347, 2866, 1835, 3635, 1270, 1260, 2026,
        3806, 1119, 1632, 1960])
Epoch: 3147, Training Loss: 0.40, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3148 - Batch 1 ########################
IDs in batch 1: tensor([ 751, 2134, 2334,   97, 3755, 3984, 2287, 3160, 3594, 2586, 3428, 1395,
        1960,  602, 1200, 2306])
Epoch: 3148, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3149 - Batch 1 ########################
IDs in batch 1: tensor([2198, 4230, 2118,  826, 2697, 3032, 2640, 1247, 1144, 2002, 4152,  389,
         193,  921, 2514, 1337])
Epoch: 3149, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3150 - Batch 1 ########################
IDs in batch 1: tensor([ 250, 4014, 4188, 3681,  438, 1498,  824, 3469,  609,   97, 2645,  870,
        3179, 3542, 2002, 2857])
Epoch: 3150, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3151 - Batch 1 ########################
IDs in batch 1: tensor([2133, 4051, 1059, 3327, 1445, 3733,  825,  762, 1775, 2872, 4163, 3211,
        2509, 2968, 2561,   18])
Epoch: 3151, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3152 - Batch 1 ########################
IDs in batch 1: tensor([2206, 3745, 1976, 2024, 2510, 2352, 3275, 2977, 4135, 3992, 1444,  494,
         482, 4214, 2835, 1065])
Epoch: 3152, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3153 - Batch 1 ########################
IDs in batch 1: tensor([1592, 3184, 1931, 1452, 1039,  926,  371, 1005, 4088, 2367,  680, 1421,
        2669, 1234, 3837, 2782])
Epoch: 3153, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3154 - Batch 1 ########################
IDs in batch 1: tensor([2431, 3538, 1075,  128, 2106, 4003, 2484, 2867,  788, 3891, 1258, 2495,
        2391, 2255, 2872, 3762])
Epoch: 3154, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3155 - Batch 1 ########################
IDs in batch 1: tensor([2857, 1487, 1464,  529, 2124, 2590, 2751, 2339,  726,  797, 1761,  886,
         408, 3495,  757, 3803])
Epoch: 3155, Training Loss: 0.22, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3156 - Batch 1 ########################
IDs in batch 1: tensor([ 854, 1651, 4134,  113, 3587, 3552, 1911, 4195, 3783,  323, 2974, 2746,
        3370, 2854,  563, 1022])
Epoch: 3156, Training Loss: 0.16, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3157 - Batch 1 ########################
IDs in batch 1: tensor([4011, 1420, 1775, 1630,  405,   78, 2070, 1177, 1740, 2132,  602, 4268,
        1597, 3436, 1470, 1332])
Epoch: 3157, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3158 - Batch 1 ########################
IDs in batch 1: tensor([ 673,  829, 2898, 3313, 1426, 3723, 1789,  536,  290, 2074, 2761, 2997,
        3338, 1891, 2867,  539])
Epoch: 3158, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3159 - Batch 1 ########################
IDs in batch 1: tensor([1162, 2874, 1055,   46, 3767, 3176, 3535, 2563, 3235, 1866, 2452, 1951,
         736,  930, 3994, 2317])
Epoch: 3159, Training Loss: 0.18, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3160 - Batch 1 ########################
IDs in batch 1: tensor([3027, 2724, 3634, 2475, 1754, 3717, 2791,  531, 3282, 1628, 2643,  173,
        1012,  119, 2871, 4065])
Epoch: 3160, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3161 - Batch 1 ########################
IDs in batch 1: tensor([1840,  884, 3999, 2059,  985, 4055, 3366, 1345, 3177, 3718, 2443, 2945,
        2676, 3878, 4100,  527])
Epoch: 3161, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3162 - Batch 1 ########################
IDs in batch 1: tensor([1264, 2578, 3501, 3069, 1330, 3414, 2902, 3664,  658, 3494, 1418, 2844,
        4222, 1985,  946, 2352])
Epoch: 3162, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3163 - Batch 1 ########################
IDs in batch 1: tensor([ 435,  426,  324, 1385, 1737, 2375,  102,  511, 2538,   71,  753, 2592,
        1352, 2382, 2150,  569])
Epoch: 3163, Training Loss: 0.28, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3164 - Batch 1 ########################
IDs in batch 1: tensor([3342, 2938, 2357, 3016, 2858, 2806, 3648, 2248, 3240, 2074, 3834, 3747,
        2016, 3659, 1234,  830])
Epoch: 3164, Training Loss: 0.64, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3165 - Batch 1 ########################
IDs in batch 1: tensor([ 769,  727, 4096, 1957,  796, 3543, 1346, 1798, 1720, 1723, 3098,  740,
        3351, 4213,  412, 2281])
Epoch: 3165, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3166 - Batch 1 ########################
IDs in batch 1: tensor([1452, 1054, 3376, 3695, 3354, 2870, 3150, 3113, 1990, 2353, 2337, 2180,
        1299,   10, 2973, 1311])
Epoch: 3166, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3167 - Batch 1 ########################
IDs in batch 1: tensor([2322, 3345,   85, 2173, 2341, 2442, 4197, 2980,  257, 3971, 3727, 3248,
        3599,  317, 3083, 2951])
Epoch: 3167, Training Loss: 0.20, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3168 - Batch 1 ########################
IDs in batch 1: tensor([4135, 1216, 2437, 2256, 3265,  232,    4, 1975, 1878,  335,  584, 3917,
        2378,  609, 3074,  679])
Epoch: 3168, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3169 - Batch 1 ########################
IDs in batch 1: tensor([4236, 2609, 1235,  704, 3039, 3922,   14, 2567, 2050, 2092, 1862,  603,
        1665, 1954, 3494,  545])
Epoch: 3169, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3170 - Batch 1 ########################
IDs in batch 1: tensor([4204, 2519, 3754, 4266, 1160,  472, 1524, 1704, 4080, 1891,  442, 4002,
        4121, 3943, 1960, 2615])
Epoch: 3170, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3171 - Batch 1 ########################
IDs in batch 1: tensor([ 323, 3718, 1478, 3663, 2360, 3326,  775,  526, 1236,  774,  287,  501,
         295,  883,  418, 1463])
Epoch: 3171, Training Loss: 0.52, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3172 - Batch 1 ########################
IDs in batch 1: tensor([3372,  724, 1668, 2822,  501, 2638, 1102, 3558, 4184, 2364, 2252,  880,
         167,  400, 2938, 3087])
Epoch: 3172, Training Loss: 0.06, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3173 - Batch 1 ########################
IDs in batch 1: tensor([3426,  360, 3074, 4122, 1134,  687,  994, 3150, 2264,  704, 3934, 2632,
        2251, 1128,  403,  199])
Epoch: 3173, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.74
######################## Epoch 3174 - Batch 1 ########################
IDs in batch 1: tensor([ 340, 4140,  448, 4089, 2192, 1189,  516, 2349, 1020, 2511, 1233, 2024,
        1973,  305,   38,  681])
Epoch: 3174, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3175 - Batch 1 ########################
IDs in batch 1: tensor([3998, 1299, 1489, 3018, 2551, 1643, 2151,  639,  575, 2859, 4046,  985,
        1455, 2370, 3298, 2196])
Epoch: 3175, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.74
######################## Epoch 3176 - Batch 1 ########################
IDs in batch 1: tensor([2823, 2436,  236, 4032,  112, 3723,  892, 4258, 3453,  182, 3323, 3928,
        3778, 3154, 1471, 3630])
Epoch: 3176, Training Loss: 0.03, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3177 - Batch 1 ########################
IDs in batch 1: tensor([4143, 2748,  996,  928, 2648, 2937,  823, 3267, 3142, 1336, 4007, 1665,
        1418,  550, 1119, 3947])
Epoch: 3177, Training Loss: 0.04, Validation Loss: 0.81, accuracy = 0.73
######################## Epoch 3178 - Batch 1 ########################
IDs in batch 1: tensor([1657,  302, 3710, 3228, 3675, 2571, 2405, 2324, 1780,  894, 2223,  804,
        3668, 1133, 3950, 3110])
Epoch: 3178, Training Loss: 0.01, Validation Loss: 0.80, accuracy = 0.73
######################## Epoch 3179 - Batch 1 ########################
IDs in batch 1: tensor([2618,  735, 3908, 1290, 2510, 4196, 3441, 3338, 1519,  316, 4245,  437,
        1162, 2087, 3238, 1803])
Epoch: 3179, Training Loss: 0.06, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3180 - Batch 1 ########################
IDs in batch 1: tensor([2701, 1333, 2866,   98,  660,  435,  138, 1056, 3400,  317,  980, 1974,
        2135,  994,  630, 3493])
Epoch: 3180, Training Loss: 0.21, Validation Loss: 0.79, accuracy = 0.74
######################## Epoch 3181 - Batch 1 ########################
IDs in batch 1: tensor([2446, 2347, 1910, 3370, 2324, 3527, 3194, 3328, 4030, 2102, 4181, 3822,
        4114, 4006,  558, 3807])
Epoch: 3181, Training Loss: 0.87, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3182 - Batch 1 ########################
IDs in batch 1: tensor([1321, 1778, 4173, 2884, 1026, 2899, 3706, 1798, 1982, 2228, 2509, 3486,
        1990, 1351,  796, 4080])
Epoch: 3182, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3183 - Batch 1 ########################
IDs in batch 1: tensor([4126, 2516, 2213, 3468, 3894, 2309, 4195, 2761, 2567, 4093, 3974, 1113,
         735,   64, 3463, 4172])
Epoch: 3183, Training Loss: 0.15, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3184 - Batch 1 ########################
IDs in batch 1: tensor([ 786,  833, 2787, 1676, 2027, 3607, 3072, 2109,  314, 2538, 4087, 2492,
        1434,   43, 1124, 1163])
Epoch: 3184, Training Loss: 0.11, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3185 - Batch 1 ########################
IDs in batch 1: tensor([ 894, 2692, 3098, 2738,  956, 3563, 1859, 4032, 2583,   99, 3543, 4053,
        2761, 1730, 3428, 3036])
Epoch: 3185, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3186 - Batch 1 ########################
IDs in batch 1: tensor([3764,  919,  683, 3503, 3299, 1723, 3248, 3591, 3591, 1458, 3900, 2482,
        1663,  303, 3329, 3399])
Epoch: 3186, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3187 - Batch 1 ########################
IDs in batch 1: tensor([ 568,  482, 3843,  869, 1263, 2849,  617, 2257,  880, 3850, 4257, 2793,
        1275, 1953, 3692, 3798])
Epoch: 3187, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3188 - Batch 1 ########################
IDs in batch 1: tensor([1803, 3389, 3394,  462,  314, 1821,  183, 3071, 2947,  982,   86,  786,
        1647, 3410, 2271, 1065])
Epoch: 3188, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3189 - Batch 1 ########################
IDs in batch 1: tensor([1484, 4152, 2256, 3904, 2912, 4093, 1491, 1753, 4078, 3113,  342, 1733,
        4015, 1370, 2980,  167])
Epoch: 3189, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3190 - Batch 1 ########################
IDs in batch 1: tensor([3894,  751,   39, 1181,  206,  282,  369, 2807, 3399, 3581, 2504, 3689,
        1512, 2667, 3035, 1490])
Epoch: 3190, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3191 - Batch 1 ########################
IDs in batch 1: tensor([  47, 4179, 4077,   14, 3143, 2997, 1107, 3856,  660, 3387, 2241, 2334,
         527,  544, 1032, 2403])
Epoch: 3191, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3192 - Batch 1 ########################
IDs in batch 1: tensor([4168, 1156, 2348, 1119, 3075,   85, 3533, 1965, 3271, 3638, 4225, 2229,
        2350,  442, 2342, 1472])
Epoch: 3192, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3193 - Batch 1 ########################
IDs in batch 1: tensor([1154, 3914, 2761, 3919,  645, 2274, 2346, 3453,  226, 2938, 2067, 3253,
        2712, 3898,  109, 3732])
Epoch: 3193, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3194 - Batch 1 ########################
IDs in batch 1: tensor([3821, 2754, 1686,  463, 2908, 4190, 2075, 4089, 1540,  862,  699,  934,
        3410, 3427,  219, 1258])
Epoch: 3194, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3195 - Batch 1 ########################
IDs in batch 1: tensor([1618, 4065, 1618, 4060, 1364, 2863, 1367,  593, 2323, 4003, 3235, 2223,
        3021, 3954, 2292,  346])
Epoch: 3195, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3196 - Batch 1 ########################
IDs in batch 1: tensor([3643,  449, 3244, 4258,  545, 2645, 2035, 2328, 3244, 2567,  910, 1722,
        3208, 3000, 2898, 1747])
Epoch: 3196, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3197 - Batch 1 ########################
IDs in batch 1: tensor([1855, 2710, 2680, 1985, 1866, 1763, 3896, 3029,  375,  519, 1001,  846,
        4198, 1208, 1498, 3592])
Epoch: 3197, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3198 - Batch 1 ########################
IDs in batch 1: tensor([3300, 3589,  736, 3891,  519, 4087,  245,  569, 1817, 4124, 4131, 1271,
         966,  590, 2990, 4236])
Epoch: 3198, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3199 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 3448, 1977, 1498, 1057, 3939, 3734, 2482, 3738, 1351, 1228,  593,
        2726, 3743,  844, 1322])
Epoch: 3199, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3200 - Batch 1 ########################
IDs in batch 1: tensor([ 553, 1672, 2767, 3217, 3533,  323,  538,  578, 3483, 2431, 2751, 1443,
        4005, 4235, 2917, 1723])
Epoch: 3200, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3201 - Batch 1 ########################
IDs in batch 1: tensor([1895, 1880, 1975,  283, 1289, 1877, 3022, 4093, 2127, 1658, 2179, 1949,
        1979,  526, 2715, 2899])
Epoch: 3201, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3202 - Batch 1 ########################
IDs in batch 1: tensor([  62,  391,  747,  154, 2949, 4110, 2015, 1955,  411, 2833, 2712, 1126,
        2571,  508,  432, 3194])
Epoch: 3202, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3203 - Batch 1 ########################
IDs in batch 1: tensor([1573, 1710, 1628, 1118, 2589, 1051, 2461, 2982,   47, 2156, 4125, 1833,
        2927, 2113, 2034, 3126])
Epoch: 3203, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3204 - Batch 1 ########################
IDs in batch 1: tensor([2615, 3712, 1731, 1597, 3567, 2124, 1472, 1420,   20,  966, 3487, 3607,
        2123, 1996, 3718, 3219])
Epoch: 3204, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3205 - Batch 1 ########################
IDs in batch 1: tensor([2066,  539, 2236, 2663, 3658, 4236, 1975, 4075, 2960, 2464, 2248, 2840,
        1996, 2153,  330,  266])
Epoch: 3205, Training Loss: 0.19, Validation Loss: 0.76, accuracy = 0.73
######################## Epoch 3206 - Batch 1 ########################
IDs in batch 1: tensor([3886,  605, 3958,  239, 3223, 2902, 2144, 1281, 3660,  645,  980,  211,
         160, 1335, 3875, 3426])
Epoch: 3206, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.73
######################## Epoch 3207 - Batch 1 ########################
IDs in batch 1: tensor([3723, 3279, 1595, 3375,  111, 1869,  377, 4119, 3933,   62, 2913, 1702,
        1066, 2854, 1136, 3257])
Epoch: 3207, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3208 - Batch 1 ########################
IDs in batch 1: tensor([3256, 1101, 1133, 2773, 2232, 1190, 2088, 3351, 3751, 2478, 1218, 3881,
         547, 2641, 3057, 1063])
Epoch: 3208, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3209 - Batch 1 ########################
IDs in batch 1: tensor([ 454, 1277, 1937, 2450,  474, 2060, 1518, 1982, 1439, 1439, 1545, 3731,
        3496, 1352, 2706,  228])
Epoch: 3209, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3210 - Batch 1 ########################
IDs in batch 1: tensor([ 718, 3334, 1799, 4181,  164, 2780, 1634, 1096, 2365,  547, 2009, 2669,
        1862, 3300,  250,  666])
Epoch: 3210, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3211 - Batch 1 ########################
IDs in batch 1: tensor([  18, 3711, 3178, 2832, 2005, 1938, 2924, 3945, 1658, 1179, 3588, 1962,
        2388, 1777,  449, 2587])
Epoch: 3211, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 3212 - Batch 1 ########################
IDs in batch 1: tensor([3628, 2917, 2257, 3516, 3573, 4255, 2207, 1269, 1641, 1519, 3528, 4049,
        4016,  507, 1011, 2598])
Epoch: 3212, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3213 - Batch 1 ########################
IDs in batch 1: tensor([3455, 2655,   41, 3057,  402, 1499, 3182, 2770,  839,  519, 1276, 4198,
        3124, 1575, 4184, 3479])
Epoch: 3213, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3214 - Batch 1 ########################
IDs in batch 1: tensor([2821, 3930, 3651, 1724, 2248,  627,  469,  186, 3423, 3898, 3208, 3547,
        2676, 1665,  354, 1030])
Epoch: 3214, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3215 - Batch 1 ########################
IDs in batch 1: tensor([1332, 2915, 3223, 4180, 3156, 1996, 3876, 4267, 3952, 3489, 1077,   84,
         678,  394, 2765, 2413])
Epoch: 3215, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3216 - Batch 1 ########################
IDs in batch 1: tensor([1160, 3888, 2419, 3136, 4051,  689, 1716, 2724,  435, 2837, 2652,  354,
        1590, 1627, 3241, 2810])
Epoch: 3216, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3217 - Batch 1 ########################
IDs in batch 1: tensor([3267, 1502,  887, 2238, 3977,  662, 1141, 4067, 3542,  476, 3985, 1817,
        1852, 3573, 2005,  519])
Epoch: 3217, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3218 - Batch 1 ########################
IDs in batch 1: tensor([ 281, 3874, 3404, 2782,   84, 2826, 2044,  753, 3184, 4220, 4084, 3370,
        3126,  965, 3654,  520])
Epoch: 3218, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3219 - Batch 1 ########################
IDs in batch 1: tensor([1996, 3713,  947, 1702, 1789, 2837, 2817,   22, 1264, 3392,   99,  841,
        1296, 2091, 2844, 1052])
Epoch: 3219, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3220 - Batch 1 ########################
IDs in batch 1: tensor([1702, 1506, 1967, 3430,  854,  177,   14, 3016, 3131, 3603, 2788, 2797,
         665, 1417, 3726,  211])
Epoch: 3220, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3221 - Batch 1 ########################
IDs in batch 1: tensor([ 714, 1545, 2285, 4004, 3513, 3756, 3984,  803, 3862, 1583, 4173, 4088,
        2144, 1034, 3311,  184])
Epoch: 3221, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3222 - Batch 1 ########################
IDs in batch 1: tensor([1880, 1037, 4195, 1821,  781, 3114, 3728, 1331, 4025, 1996,   27,  818,
        1060, 1990,  390,  150])
Epoch: 3222, Training Loss: 0.13, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 3223 - Batch 1 ########################
IDs in batch 1: tensor([4161, 1415, 2025, 2212, 1660, 2959,  751, 2292, 1017, 3521, 2123, 2894,
        2719, 2781, 1439, 3264])
Epoch: 3223, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 3224 - Batch 1 ########################
IDs in batch 1: tensor([1509,  797, 4002,  710,   72, 1235, 4117, 2088, 1869, 1597, 2591,  812,
        2517, 2997,  167, 1478])
Epoch: 3224, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 3225 - Batch 1 ########################
IDs in batch 1: tensor([2874, 2519, 2542, 1782,  947, 2695, 3439, 2172, 1269, 3818, 2655,  957,
         721, 4215,    7, 2725])
Epoch: 3225, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 3226 - Batch 1 ########################
IDs in batch 1: tensor([ 766,  785, 3343, 1315, 2739, 3246, 1651, 3258, 3863, 1810, 1751,  445,
        2866, 3707, 2605, 1968])
Epoch: 3226, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.73
######################## Epoch 3227 - Batch 1 ########################
IDs in batch 1: tensor([2890, 3790, 2265, 2466,  688, 2494, 3182,  452, 1812, 1124,   21, 1883,
        3599, 1613,  481, 3017])
Epoch: 3227, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.74
######################## Epoch 3228 - Batch 1 ########################
IDs in batch 1: tensor([1370, 2668, 2066, 3845,  182, 1525, 3390,  484, 1006, 2098, 2432, 4018,
        2433, 1988,  992,  975])
Epoch: 3228, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3229 - Batch 1 ########################
IDs in batch 1: tensor([2618, 3804, 2825, 2402, 1284, 2723, 3299, 4136, 2027, 4125, 2291,  662,
        1784, 1443, 2536, 1991])
Epoch: 3229, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3230 - Batch 1 ########################
IDs in batch 1: tensor([ 173, 1330, 4040, 3352, 3507,  816, 4075, 2867, 4255,  523, 1650, 2606,
        2781,  513, 1104, 3804])
Epoch: 3230, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.74
######################## Epoch 3231 - Batch 1 ########################
IDs in batch 1: tensor([3831, 2805, 2075, 3970, 2182,  577,  730, 3308,  982,  390, 1500,  229,
        3025, 2218,   10, 2463])
Epoch: 3231, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3232 - Batch 1 ########################
IDs in batch 1: tensor([ 733, 1332,  538, 3236, 1451, 2938, 2482,   35, 2828, 3083, 1157, 2209,
        1179, 1833, 2115, 3208])
Epoch: 3232, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.74
######################## Epoch 3233 - Batch 1 ########################
IDs in batch 1: tensor([ 229, 1103, 1383,  971, 2661, 2078, 3783, 3652, 1789, 1508,  830, 4061,
        2838, 1635,  995, 2031])
Epoch: 3233, Training Loss: 0.25, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3234 - Batch 1 ########################
IDs in batch 1: tensor([ 601,  723, 3459,  915, 4256, 2232, 1189, 2347, 2426, 2599, 1866, 2592,
        2370,  529, 1766, 2143])
Epoch: 3234, Training Loss: 0.27, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3235 - Batch 1 ########################
IDs in batch 1: tensor([1734, 1310, 1614, 3591,  516, 2206, 3105, 3927, 4039, 3672,  474, 1256,
        1812,  257, 1702, 1578])
Epoch: 3235, Training Loss: 0.17, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3236 - Batch 1 ########################
IDs in batch 1: tensor([1846, 1870, 1894, 1530, 2742, 1082, 3345, 3985, 1053,  953, 4135, 1020,
         826, 1496,  926,  883])
Epoch: 3236, Training Loss: 0.28, Validation Loss: 0.77, accuracy = 0.74
######################## Epoch 3237 - Batch 1 ########################
IDs in batch 1: tensor([3501, 2407,  354, 2403, 2441, 3490, 2171,  652, 1763,  693, 3627, 1881,
        1711,  498, 3504,  555])
Epoch: 3237, Training Loss: 0.10, Validation Loss: 0.76, accuracy = 0.74
######################## Epoch 3238 - Batch 1 ########################
IDs in batch 1: tensor([1333, 1208, 2772, 2932, 4263, 1017, 4161, 2719, 2990, 2984, 3065,   14,
        3091, 3479, 2703, 1511])
Epoch: 3238, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3239 - Batch 1 ########################
IDs in batch 1: tensor([ 749, 1024, 1159, 3874,  995, 1748,  838,  852, 1753, 1069,  106, 2931,
        2509, 1404,  292, 3982])
Epoch: 3239, Training Loss: 0.45, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3240 - Batch 1 ########################
IDs in batch 1: tensor([3590, 1020, 1951, 2854, 1128,   25,  340, 3199, 1290, 2605,  659, 1568,
        4050, 2108, 3552,  767])
Epoch: 3240, Training Loss: 0.29, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3241 - Batch 1 ########################
IDs in batch 1: tensor([2924, 2717, 4225, 4077, 3838, 3206, 3927, 4135, 1213,  550,  846, 3615,
        3926, 1949, 1960,  352])
Epoch: 3241, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3242 - Batch 1 ########################
IDs in batch 1: tensor([3199, 4139, 4144, 3312, 2114, 1661, 4076,  678,  348, 2978, 3853, 3500,
        3159,  499, 2828, 3244])
Epoch: 3242, Training Loss: 0.17, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3243 - Batch 1 ########################
IDs in batch 1: tensor([ 255, 3178, 3922,  475, 3058, 1623, 2610, 2558, 2575, 2176,  149,  228,
        2044, 1532,  483,  170])
Epoch: 3243, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3244 - Batch 1 ########################
IDs in batch 1: tensor([2692, 3803, 2477, 1419, 2631,  827,  171, 3049,  348, 3216,   37, 4218,
        1296,  864, 3244,  968])
Epoch: 3244, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3245 - Batch 1 ########################
IDs in batch 1: tensor([3525, 3976,  615, 3020, 1228, 1509, 2347, 3554,  283, 2600, 2966, 2514,
         444, 1727, 2551, 3872])
Epoch: 3245, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3246 - Batch 1 ########################
IDs in batch 1: tensor([3373, 3415, 2976, 4174,  625, 1286, 2133,  139, 3303, 3423, 1251, 1472,
        2090, 3309, 3859, 3022])
Epoch: 3246, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3247 - Batch 1 ########################
IDs in batch 1: tensor([  21, 1892, 3964,  854, 2366, 1510,  975, 2039, 2301, 2863, 3228,  284,
        3289,  245,  487, 1031])
Epoch: 3247, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3248 - Batch 1 ########################
IDs in batch 1: tensor([  21, 1066, 2815,  482, 2095, 4158, 2494, 1421, 2236, 3461, 2851, 3382,
        2880, 2806, 4119, 1657])
Epoch: 3248, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3249 - Batch 1 ########################
IDs in batch 1: tensor([2927, 2908, 4264, 3157, 3128,  356, 2352, 3789, 1167, 1060,   41, 1070,
        1090, 1635, 1634, 2314])
Epoch: 3249, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3250 - Batch 1 ########################
IDs in batch 1: tensor([ 921, 3872, 2614,  726, 3473, 3356, 2075,   64, 1916, 1380, 2195,  101,
        2063, 2926,  236,  960])
Epoch: 3250, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3251 - Batch 1 ########################
IDs in batch 1: tensor([1028,  463, 3992, 1693, 4228, 1183, 3713, 2840, 1605, 1437,  289,  255,
        3436, 2536, 1567,  510])
Epoch: 3251, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3252 - Batch 1 ########################
IDs in batch 1: tensor([2798, 3354, 1012, 3536, 2464, 2312, 2841, 3501, 2522,  756, 2228, 1163,
         219, 2529,  796, 1732])
Epoch: 3252, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3253 - Batch 1 ########################
IDs in batch 1: tensor([3634,   47, 4204,  628,  259, 2232, 1182,   59, 4152, 4175,  848, 1767,
        4108, 1223, 4018, 1618])
Epoch: 3253, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3254 - Batch 1 ########################
IDs in batch 1: tensor([3044, 3084, 2122, 4069, 1294,  989,  724, 3570,  970, 3851,  369,  103,
         623, 1728,   98,  527])
Epoch: 3254, Training Loss: 0.21, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3255 - Batch 1 ########################
IDs in batch 1: tensor([3338, 1934, 3112, 2407, 1932, 1077, 1175, 2794, 2891, 2538, 1625, 4166,
        2379, 3362, 3032,  717])
Epoch: 3255, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3256 - Batch 1 ########################
IDs in batch 1: tensor([3351, 3418, 2523, 1156, 1863, 3286,  455, 1642,  635, 3921,  934, 1668,
        3826, 2204, 3732, 1780])
Epoch: 3256, Training Loss: 0.23, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3257 - Batch 1 ########################
IDs in batch 1: tensor([1822, 3729, 1991, 3480, 1956, 1063, 2469,  704, 2823, 2013,  391, 1458,
         517, 4027, 1824, 1057])
Epoch: 3257, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3258 - Batch 1 ########################
IDs in batch 1: tensor([ 481, 2548, 1385, 1152, 4068, 2514, 3410, 4229,  359, 1618, 2300,  661,
         455, 1126, 1391, 2087])
Epoch: 3258, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3259 - Batch 1 ########################
IDs in batch 1: tensor([1391,  955, 2858, 3668, 2414, 2331, 3747,  484, 3115,  967, 3714, 3942,
         393, 2839, 3392, 2199])
Epoch: 3259, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3260 - Batch 1 ########################
IDs in batch 1: tensor([2890, 2869, 3461, 1214, 1575, 2947, 3816, 2581, 3783, 2279, 3180, 3841,
        4194, 2868, 2090, 3211])
Epoch: 3260, Training Loss: 0.32, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3261 - Batch 1 ########################
IDs in batch 1: tensor([3496, 1225, 1367, 2586, 3227, 1730, 4067,  584, 2758, 3330, 1283, 3015,
        2314, 3496, 3303, 4185])
Epoch: 3261, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3262 - Batch 1 ########################
IDs in batch 1: tensor([3135,  426, 1334, 3433, 3282, 1252,  749, 3588, 1313,  739,  910, 3318,
        2718, 2616, 2218,  693])
Epoch: 3262, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3263 - Batch 1 ########################
IDs in batch 1: tensor([2924, 1951,  262, 1558, 4218, 4238, 3827, 3764,  725, 1042, 4181, 3037,
         400, 4242, 1658, 1730])
Epoch: 3263, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3264 - Batch 1 ########################
IDs in batch 1: tensor([2984,  452,  871, 2529, 3807, 2053, 3952, 3031, 2078, 2343, 3395,  523,
        4190, 3668,  359, 1977])
Epoch: 3264, Training Loss: 0.26, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3265 - Batch 1 ########################
IDs in batch 1: tensor([ 337, 1916, 3222, 2802, 1745, 3370, 3651, 2485, 1668, 3711, 3862, 2145,
        3807, 2718,  536, 3100])
Epoch: 3265, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3266 - Batch 1 ########################
IDs in batch 1: tensor([ 546,  657, 1499,   81, 2352,  919, 2305,  952, 2898, 2018, 1125, 2461,
        4017,  658, 4031, 2316])
Epoch: 3266, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3267 - Batch 1 ########################
IDs in batch 1: tensor([1764, 2472, 3246,  419, 4218, 3894, 1897,  269,  604, 3074, 2829, 2523,
        3829, 4088, 2536, 2393])
Epoch: 3267, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3268 - Batch 1 ########################
IDs in batch 1: tensor([1413, 2693, 2213,  613,  781,  921, 3326, 2915, 3765, 3430, 3700, 3779,
        3181, 3872, 2770, 1419])
Epoch: 3268, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3269 - Batch 1 ########################
IDs in batch 1: tensor([3018, 2185, 2562,  445,   42, 3367, 2110, 3945,  378, 1824, 2053,   57,
        2884, 1264, 2459, 1524])
Epoch: 3269, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3270 - Batch 1 ########################
IDs in batch 1: tensor([3282,  312, 3913, 1574,  100, 3940, 1212,  149,  990, 2825,  541,  247,
        2376, 2044, 3973, 2123])
Epoch: 3270, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3271 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 2589, 1206, 3663, 2167, 1082, 1337, 4011, 1439, 2045, 2030, 4176,
          95, 2086, 1948, 4003])
Epoch: 3271, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3272 - Batch 1 ########################
IDs in batch 1: tensor([3526, 2451, 3432, 2355,  823, 1974, 3057, 3005, 2125, 3806, 1399, 3242,
         603, 4036, 2403, 2183])
Epoch: 3272, Training Loss: 0.13, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3273 - Batch 1 ########################
IDs in batch 1: tensor([3432,  352, 3408, 2193, 2894, 3822, 2063, 1234,  766,   50, 4025, 4135,
        1938, 3998, 2482, 3695])
Epoch: 3273, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3274 - Batch 1 ########################
IDs in batch 1: tensor([3192, 1440, 3945, 3781,  956, 2166, 3707, 2401, 1088, 1994,  839, 1233,
        3342, 2649, 1041, 3179])
Epoch: 3274, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3275 - Batch 1 ########################
IDs in batch 1: tensor([3831, 1355, 1499, 2462,  982, 3363, 3102,   46, 3227, 1648, 1397, 3958,
         255,  676, 2015, 3911])
Epoch: 3275, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3276 - Batch 1 ########################
IDs in batch 1: tensor([2640, 2261, 2467, 3535, 2436, 3418,  588, 1853, 1958, 3065, 1045, 2003,
        2256, 4261, 2901, 3818])
Epoch: 3276, Training Loss: 0.30, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3277 - Batch 1 ########################
IDs in batch 1: tensor([ 252,  539,  109, 3006, 1006, 2256, 2782,  139, 2455, 3216, 2137,  557,
        3098, 2606, 1006, 3663])
Epoch: 3277, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3278 - Batch 1 ########################
IDs in batch 1: tensor([2087, 3264, 3108, 3712, 3071, 1476,  418, 3747, 2367, 2102, 1132, 3338,
        1242, 1273, 1772,  645])
Epoch: 3278, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3279 - Batch 1 ########################
IDs in batch 1: tensor([1208, 1193, 1976, 1423,  442, 2993, 1638, 3387, 2038,  852, 2718,  228,
        3739, 2894, 1471, 1724])
Epoch: 3279, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3280 - Batch 1 ########################
IDs in batch 1: tensor([ 368, 3821, 3352,  476,  662,  439, 1102, 4176, 1914, 2710,  637,  407,
        1044, 1438, 4218, 1041])
Epoch: 3280, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3281 - Batch 1 ########################
IDs in batch 1: tensor([ 333, 2443, 3738, 3157,   84, 2516, 2441, 2730, 3344, 2921,  670, 2934,
        1370, 2157, 4068,  463])
Epoch: 3281, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3282 - Batch 1 ########################
IDs in batch 1: tensor([3521, 1991,   81, 2799,  184,  489, 1420,  137,  694, 2663,  321, 1197,
         459,  305, 2271, 1736])
Epoch: 3282, Training Loss: 0.39, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3283 - Batch 1 ########################
IDs in batch 1: tensor([1316,  524, 1248, 1648, 2108,  141, 2589,  321,  252, 2476, 3128, 1576,
        3017, 3371, 1131, 2416])
Epoch: 3283, Training Loss: 0.20, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3284 - Batch 1 ########################
IDs in batch 1: tensor([2331,  186, 1484, 3771, 4086, 2518, 3652, 1198, 1175, 2066,  300, 3743,
         344, 1234, 1260,   26])
Epoch: 3284, Training Loss: 0.21, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3285 - Batch 1 ########################
IDs in batch 1: tensor([2107, 2672, 2649,  637,  920, 1267,  884, 3771, 1156, 4176, 1066, 4261,
         471, 1950, 2509, 4055])
Epoch: 3285, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3286 - Batch 1 ########################
IDs in batch 1: tensor([ 884,  369, 1753, 4057,  417, 1141, 3952, 3178, 1968, 1900, 1132, 1746,
        2802, 3208, 2230, 3287])
Epoch: 3286, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3287 - Batch 1 ########################
IDs in batch 1: tensor([3729, 2767,   37, 2524,  632, 3472, 2996, 3652, 1374,  681, 4127, 1346,
        3261,  809,  990, 3384])
Epoch: 3287, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3288 - Batch 1 ########################
IDs in batch 1: tensor([3833, 2664, 2990,  454, 3207, 1174, 3934, 3674, 2098, 3940, 3357, 1113,
         202, 3795, 1663,  590])
Epoch: 3288, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3289 - Batch 1 ########################
IDs in batch 1: tensor([1914, 3993, 1869, 4174, 2836, 3689, 2668, 4022, 3535, 1711,  119, 1186,
         237, 2954, 3881,  351])
Epoch: 3289, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3290 - Batch 1 ########################
IDs in batch 1: tensor([2937, 1333, 2225, 3028, 1543, 1853, 3765, 3746, 1160, 1248,  541,  452,
        2398, 1168, 3958,   96])
Epoch: 3290, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.75
######################## Epoch 3291 - Batch 1 ########################
IDs in batch 1: tensor([2472, 2226,  515,  494, 1344, 1440, 2697,  435, 3355, 3513, 1158, 3551,
        3551,  964, 1546, 1440])
Epoch: 3291, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3292 - Batch 1 ########################
IDs in batch 1: tensor([2428,  813, 1110, 1551, 3531, 1518,  514,  738, 1443, 3715,  987, 2433,
        4107, 1499, 2600, 2219])
Epoch: 3292, Training Loss: 0.18, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3293 - Batch 1 ########################
IDs in batch 1: tensor([1370,  324, 3065,  188,   13, 2185,  839,  472,  476,  452, 3912,  919,
        1849, 2114, 1775,  324])
Epoch: 3293, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3294 - Batch 1 ########################
IDs in batch 1: tensor([4069,  369, 1299, 2548, 3363, 2072,  996, 2218, 1675, 3154, 1269, 4067,
        2461, 3389, 3143,  842])
Epoch: 3294, Training Loss: 0.02, Validation Loss: 0.67, accuracy = 0.78
######################## Epoch 3295 - Batch 1 ########################
IDs in batch 1: tensor([ 532, 2121, 2212, 3695, 2386, 1085, 3345, 4076, 2605,  206, 3878,  743,
         874, 3710,  701, 1179])
Epoch: 3295, Training Loss: 0.10, Validation Loss: 0.67, accuracy = 0.77
######################## Epoch 3296 - Batch 1 ########################
IDs in batch 1: tensor([2951,  154, 2885,  101,   21, 1292,  826, 1698, 2541, 1846, 1756,  379,
        2859, 4067, 2764,   56])
Epoch: 3296, Training Loss: 0.10, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3297 - Batch 1 ########################
IDs in batch 1: tensor([3939, 3112, 1601, 1793, 2088, 1257, 2118, 2131, 1635,  290, 1393, 3870,
        2717, 1803,  226, 1934])
Epoch: 3297, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3298 - Batch 1 ########################
IDs in batch 1: tensor([3983, 2824,  361, 1326,  212, 3373, 3696, 1452, 2667, 3785,  462, 3404,
        2945, 1748,  483, 1347])
Epoch: 3298, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3299 - Batch 1 ########################
IDs in batch 1: tensor([1374, 2982, 3902, 3572, 2169, 3238,   88, 3037, 2067, 1711, 2934,  239,
        1436, 1518, 3233, 1354])
Epoch: 3299, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3300 - Batch 1 ########################
IDs in batch 1: tensor([1722, 3594, 3400, 3588, 2403, 3378, 3023,  387, 2853, 2863, 1597, 2265,
        3406, 2271, 1027, 1794])
Epoch: 3300, Training Loss: 0.52, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3301 - Batch 1 ########################
IDs in batch 1: tensor([3846, 2827, 1421,  287, 3497, 1877, 1384,  379,  161, 1773, 1886, 2341,
        3409, 1821, 2618,  644])
Epoch: 3301, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3302 - Batch 1 ########################
IDs in batch 1: tensor([3695, 1228, 2498, 2575,  786,  388, 1953, 2272,  424, 1624, 2408,  140,
        1224, 3112, 1496, 1273])
Epoch: 3302, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3303 - Batch 1 ########################
IDs in batch 1: tensor([2782, 1136, 1347, 2122, 3598,  344,  952,  565, 1006, 2003,  350, 3982,
        1556, 3369, 1229, 3760])
Epoch: 3303, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3304 - Batch 1 ########################
IDs in batch 1: tensor([ 361,  206, 4094, 2387,  136, 2518, 2179, 2695, 2839,  615,  688, 1413,
        2019, 3159, 1784, 3792])
Epoch: 3304, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3305 - Batch 1 ########################
IDs in batch 1: tensor([ 882, 1206, 1143, 2103, 3813, 3846,  207,  408, 1849, 2664, 1760, 3278,
        2572, 2674, 1175, 1650])
Epoch: 3305, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3306 - Batch 1 ########################
IDs in batch 1: tensor([2416, 3388, 3871, 2856, 1322, 1914, 2467, 1751,  717, 2376, 3342, 1012,
         957, 3020, 2587, 3268])
Epoch: 3306, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3307 - Batch 1 ########################
IDs in batch 1: tensor([ 239, 1487, 1883, 1161, 1952, 2505, 4049,  541,  224,  133, 2357, 3040,
         382,   74, 3207, 3996])
Epoch: 3307, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3308 - Batch 1 ########################
IDs in batch 1: tensor([2066, 1237, 3038, 1137,  658, 3463, 3255, 1720, 3334, 1026, 1296, 2492,
        1911, 3968, 1640,  316])
Epoch: 3308, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3309 - Batch 1 ########################
IDs in batch 1: tensor([2773, 3044, 1437, 1569, 2206,  888, 2921, 1260, 2624, 2567, 2245, 3344,
         219,  498, 3081,  481])
Epoch: 3309, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3310 - Batch 1 ########################
IDs in batch 1: tensor([3904, 2016,  757, 2558, 2837, 2117, 1481, 4057, 1553, 1108, 2937, 2276,
        4166, 3660,    5,  151])
Epoch: 3310, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3311 - Batch 1 ########################
IDs in batch 1: tensor([3802, 3146, 3363,  811, 3394, 3913, 3251, 4189, 3236, 4175,  334, 4258,
        1220, 3162, 1056, 2755])
Epoch: 3311, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3312 - Batch 1 ########################
IDs in batch 1: tensor([1947, 3025, 3659,  777, 3497, 3245, 3964, 2950,  109,  201, 1585, 2725,
        3433, 3433, 3942, 3438])
Epoch: 3312, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3313 - Batch 1 ########################
IDs in batch 1: tensor([2646, 1022, 2712,  854, 3707, 1198, 1870, 2926, 1497, 2524, 1354, 3179,
         389,  612, 1457, 4127])
Epoch: 3313, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3314 - Batch 1 ########################
IDs in batch 1: tensor([  25, 1087, 1780,  490,  849,   37, 1956,  396, 2582, 2052,  184,  880,
        1281, 3214, 1639, 3264])
Epoch: 3314, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3315 - Batch 1 ########################
IDs in batch 1: tensor([2942, 2866, 3514, 2621, 3729, 4058, 1396, 3699, 2145, 3960, 3133, 2826,
        3885,  726,  437, 1504])
Epoch: 3315, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3316 - Batch 1 ########################
IDs in batch 1: tensor([2482, 3865, 2695, 4168,  292, 2180, 1639, 3733, 2119, 3451,  482, 2412,
        1553, 2467, 4026,  422])
Epoch: 3316, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3317 - Batch 1 ########################
IDs in batch 1: tensor([1272, 3701, 1081, 2371,  822,  424, 1453, 4056, 4184, 3017, 1139, 4254,
        1118,  132, 1009, 3668])
Epoch: 3317, Training Loss: 0.20, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3318 - Batch 1 ########################
IDs in batch 1: tensor([ 229,  873, 1073,  937, 1672, 2831,  244,  762,  628,  578,  701, 2947,
        1313, 3267, 4213, 3912])
Epoch: 3318, Training Loss: 0.40, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3319 - Batch 1 ########################
IDs in batch 1: tensor([ 490, 1478, 3238, 3876, 1950,  193, 3410,  756, 2739, 1877,  584,  645,
        1855, 3088, 3495, 1892])
Epoch: 3319, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3320 - Batch 1 ########################
IDs in batch 1: tensor([ 369, 3298, 3334,  484, 4204, 4097, 3489, 2112, 2764,  213,  388, 2492,
        3821, 3833,  565, 2035])
Epoch: 3320, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3321 - Batch 1 ########################
IDs in batch 1: tensor([4174, 2341, 2807, 1556,  467,  833,  895, 3536, 3940, 3117,  895, 2983,
        3073, 2332, 4139, 1781])
Epoch: 3321, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3322 - Batch 1 ########################
IDs in batch 1: tensor([ 120, 3207, 3338, 3161, 2891,  884, 3470, 1147,  312, 2478, 1551, 4139,
        2296, 4166, 2505, 3342])
Epoch: 3322, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3323 - Batch 1 ########################
IDs in batch 1: tensor([3031, 1883,  547, 1330,  373, 2417, 1660, 2242, 2300, 2246,  221, 2709,
        1751, 1536, 1892, 3663])
Epoch: 3323, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3324 - Batch 1 ########################
IDs in batch 1: tensor([ 857, 3992,  411,  445, 1489,  365, 2159,  322, 2770, 1229,  312,  498,
         983, 1263, 2143, 2494])
Epoch: 3324, Training Loss: 0.26, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3325 - Batch 1 ########################
IDs in batch 1: tensor([3136,   19, 2453, 1596,  419, 3593, 4077, 1141, 1640, 1332,  795, 2312,
         605, 3299, 3898, 3193])
Epoch: 3325, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3326 - Batch 1 ########################
IDs in batch 1: tensor([2341, 1319, 1266, 2746, 3673,  590, 2039, 1399,  620,  258, 3471, 4035,
        1209,  462, 3745, 2541])
Epoch: 3326, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.74
######################## Epoch 3327 - Batch 1 ########################
IDs in batch 1: tensor([2182,  694, 1617, 1180, 1752,  964, 3548,  140, 2505, 3907, 1315, 2646,
        1219,  919,  996,  236])
Epoch: 3327, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3328 - Batch 1 ########################
IDs in batch 1: tensor([3443, 3387, 1551, 3904, 2810, 1299,  411, 1996, 3118,  355, 3374,  338,
        2575, 3535, 1347, 1723])
Epoch: 3328, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3329 - Batch 1 ########################
IDs in batch 1: tensor([1180, 3728,  792, 2241, 2751, 3963, 3503, 2461,  779,   31, 2116, 3745,
        1660, 3777, 2455, 2583])
Epoch: 3329, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3330 - Batch 1 ########################
IDs in batch 1: tensor([3672, 2188,  781, 1740, 2807, 4161, 2969, 1518, 1690, 1991,  186, 2189,
         245, 2287, 1566, 1198])
Epoch: 3330, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3331 - Batch 1 ########################
IDs in batch 1: tensor([ 900, 4163, 3142, 3989, 2668, 1911,  102, 2417, 3200, 2087,  569, 3127,
         928,  975, 2614, 3079])
Epoch: 3331, Training Loss: 0.22, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3332 - Batch 1 ########################
IDs in batch 1: tensor([3897,  830, 2467, 1167, 1199, 3790, 3672,  723, 1390, 1209,   11,  625,
          93, 1718, 2614, 4232])
Epoch: 3332, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3333 - Batch 1 ########################
IDs in batch 1: tensor([3004, 3395, 3865, 3821, 2262, 2760, 3236, 3435, 3135, 3781, 3290, 1099,
        2485, 4263, 3564, 1267])
Epoch: 3333, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3334 - Batch 1 ########################
IDs in batch 1: tensor([ 776,  363, 2400,  679, 3303, 3478,  933, 3188,  688,  946,  130, 4166,
        1934, 2703,  586, 1453])
Epoch: 3334, Training Loss: 0.23, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3335 - Batch 1 ########################
IDs in batch 1: tensor([ 147, 1642, 2441, 2177, 1710, 1212, 2394, 2886, 3554,  343, 2329, 2636,
         773, 2589, 2835, 3599])
Epoch: 3335, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3336 - Batch 1 ########################
IDs in batch 1: tensor([3353, 3827, 2680, 1753, 4008, 2457, 2286, 1464,  357, 3258, 1579,  583,
         851,  459, 2028,  237])
Epoch: 3336, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3337 - Batch 1 ########################
IDs in batch 1: tensor([4234, 2453, 2812,  238,  489, 2371, 1552, 2484, 3594, 2372, 1139, 1556,
        2511, 1377, 2690, 3739])
Epoch: 3337, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3338 - Batch 1 ########################
IDs in batch 1: tensor([2127,   34,  858, 3655, 2360, 2791, 2546, 3952,  825,  622, 3961, 3810,
        4173, 1345, 2483, 3742])
Epoch: 3338, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.75
######################## Epoch 3339 - Batch 1 ########################
IDs in batch 1: tensor([1110,  769, 3539,  738, 3831, 3408, 1007, 3390, 4185, 1682, 2828,  522,
        4240, 1292, 2339, 4075])
Epoch: 3339, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3340 - Batch 1 ########################
IDs in batch 1: tensor([ 513, 3813, 3656, 3414, 2176,   71, 1144,  809, 2851, 1440, 2176, 2464,
        3323, 3065, 4268, 3432])
Epoch: 3340, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.74
######################## Epoch 3341 - Batch 1 ########################
IDs in batch 1: tensor([2154,  382, 2990, 1419, 2599,  827, 4135, 3557, 1887,  492, 2815,   68,
         882, 3950,  658, 3439])
Epoch: 3341, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3342 - Batch 1 ########################
IDs in batch 1: tensor([  15, 1949,  993, 1679, 1264,  781, 1357, 2671, 2228, 3552, 2218, 1035,
          10, 4227, 4002, 2587])
Epoch: 3342, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.75
######################## Epoch 3343 - Batch 1 ########################
IDs in batch 1: tensor([3069, 1279, 1271, 3071, 2696, 2462, 1845, 1613, 2127, 2468, 3358,  343,
        3371, 2287, 3146, 4139])
Epoch: 3343, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3344 - Batch 1 ########################
IDs in batch 1: tensor([2516, 1020, 1737, 3185,  842, 1170, 1707, 3702, 2169, 1139, 2621, 1321,
        3983, 3114,   28, 4115])
Epoch: 3344, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3345 - Batch 1 ########################
IDs in batch 1: tensor([3387, 2172, 3005, 3960, 3767, 2919,  251, 3474, 2109, 3022, 2876, 2835,
         682,  295, 2369, 2767])
Epoch: 3345, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3346 - Batch 1 ########################
IDs in batch 1: tensor([3440, 2218, 3886,  710, 2908, 1923, 2416, 3251, 1490,  593, 2993,  919,
         434, 2482,  513, 1167])
Epoch: 3346, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3347 - Batch 1 ########################
IDs in batch 1: tensor([3537, 2086, 3998, 1846, 3614, 2555, 3744,  259, 3241, 2965,  472,  305,
         976, 3024,  250, 3397])
Epoch: 3347, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3348 - Batch 1 ########################
IDs in batch 1: tensor([1909, 4266, 2010, 2506,  819, 4016, 3568, 1835,  508,  829, 4011, 2931,
        3385, 1221, 1537, 1902])
Epoch: 3348, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3349 - Batch 1 ########################
IDs in batch 1: tensor([2800, 2737,  397,  843,  432, 2760, 1103, 2883, 2025, 1901, 2970,  455,
        3673, 2859, 2241, 1005])
Epoch: 3349, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3350 - Batch 1 ########################
IDs in batch 1: tensor([2040, 1617,  914, 1332, 3010, 2332, 3630, 2866, 3270, 1784,  837,  333,
        3610, 3650, 1612, 1555])
Epoch: 3350, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3351 - Batch 1 ########################
IDs in batch 1: tensor([1868, 3597, 1881, 2348, 2205, 2010, 3428, 4008, 2824, 3166, 3664, 3871,
        3374, 2143, 1374, 1351])
Epoch: 3351, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3352 - Batch 1 ########################
IDs in batch 1: tensor([3872,   14,  699, 3109, 1996, 3540,  462, 2876,  858, 2444, 1279, 2860,
        3480, 1390,   78,  880])
Epoch: 3352, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3353 - Batch 1 ########################
IDs in batch 1: tensor([3638, 1656,  354, 2098, 3147, 2195, 4103,  507, 3760, 1055, 3185, 4172,
        2500, 1087, 2013, 3827])
Epoch: 3353, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3354 - Batch 1 ########################
IDs in batch 1: tensor([1644, 3995, 2497, 1724, 3241, 1846, 3850, 4227,  398, 3238,  693, 3379,
         670, 3756,  372, 2494])
Epoch: 3354, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3355 - Batch 1 ########################
IDs in batch 1: tensor([3077, 3789, 2220, 3878, 1789, 3227, 1111, 3194, 1911, 1710, 2290, 4037,
         726, 1153, 3823, 2789])
Epoch: 3355, Training Loss: 0.10, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3356 - Batch 1 ########################
IDs in batch 1: tensor([3827, 3141, 1660, 2107, 2965, 1388, 4069, 3851, 2895, 1937, 2659, 3023,
        3654, 3521, 3810, 3489])
Epoch: 3356, Training Loss: 0.44, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3357 - Batch 1 ########################
IDs in batch 1: tensor([1794, 2913, 1737, 3114, 3787, 1680, 2386, 2019, 2681, 1136, 3542, 1012,
        1764,  891, 3881, 2024])
Epoch: 3357, Training Loss: 0.04, Validation Loss: 0.80, accuracy = 0.76
######################## Epoch 3358 - Batch 1 ########################
IDs in batch 1: tensor([2251, 3604, 3427, 3660,  701, 2919, 1337,  459, 1101, 1185,  148, 2627,
        4203, 2145, 1798, 3926])
Epoch: 3358, Training Loss: 0.09, Validation Loss: 0.81, accuracy = 0.76
######################## Epoch 3359 - Batch 1 ########################
IDs in batch 1: tensor([4249, 4170, 4095, 2418, 3065,  513, 2324, 2425, 1991, 2697, 3667, 1708,
        2203, 1278, 2111, 1077])
Epoch: 3359, Training Loss: 0.14, Validation Loss: 0.82, accuracy = 0.76
######################## Epoch 3360 - Batch 1 ########################
IDs in batch 1: tensor([ 151,  992, 4070, 3732, 4078, 2247,   46, 1756, 2976,  924, 3870, 3487,
        2624, 4135,  312, 3264])
Epoch: 3360, Training Loss: 0.10, Validation Loss: 0.82, accuracy = 0.75
######################## Epoch 3361 - Batch 1 ########################
IDs in batch 1: tensor([1295, 3862, 2028, 3688,  305, 2734, 3972, 2382, 3245,  858, 3711, 1083,
        4125,  103, 3444, 3996])
Epoch: 3361, Training Loss: 0.06, Validation Loss: 0.82, accuracy = 0.75
######################## Epoch 3362 - Batch 1 ########################
IDs in batch 1: tensor([2990,  942, 3282, 2606, 1501, 3369, 3025, 1897, 3492, 2680, 3827,  359,
        1228, 3563, 3194, 3695])
Epoch: 3362, Training Loss: 0.07, Validation Loss: 0.81, accuracy = 0.75
######################## Epoch 3363 - Batch 1 ########################
IDs in batch 1: tensor([3131,  606, 1053, 1332, 3119, 3244, 1028, 3912, 1835, 2780, 4100, 3521,
        1155, 3506,  361, 2840])
Epoch: 3363, Training Loss: 0.02, Validation Loss: 0.80, accuracy = 0.75
######################## Epoch 3364 - Batch 1 ########################
IDs in batch 1: tensor([2809,  917,  811, 2895,  604, 4096, 1049,  325, 2357, 3330, 3443, 3786,
        1273, 1180, 2167, 4096])
Epoch: 3364, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3365 - Batch 1 ########################
IDs in batch 1: tensor([3368, 2542,   11,  588, 2851,  434,  409, 1991, 4095, 2711,  184, 2110,
        4088, 3516, 2649,  880])
Epoch: 3365, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3366 - Batch 1 ########################
IDs in batch 1: tensor([3588, 1841,  259,  797, 2109, 2131, 1409, 2797, 3029,  584, 4253, 3712,
        1408, 1111, 2255, 1502])
Epoch: 3366, Training Loss: 0.04, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3367 - Batch 1 ########################
IDs in batch 1: tensor([4157, 2229, 3712, 3569,  371,  879, 3407,  977, 4121, 4037, 2276, 2519,
        2572, 3098, 1153, 1309])
Epoch: 3367, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3368 - Batch 1 ########################
IDs in batch 1: tensor([3587,  553,  552,  195, 3950,  207,  211,  583, 2181, 3951,  432,  459,
         892, 2385, 2067, 1679])
Epoch: 3368, Training Loss: 0.22, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3369 - Batch 1 ########################
IDs in batch 1: tensor([ 108, 2368, 1173, 1204, 4159,  750,  125, 2360, 1417, 2261, 1131, 1950,
        2141, 1685,  287, 1804])
Epoch: 3369, Training Loss: 0.06, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3370 - Batch 1 ########################
IDs in batch 1: tensor([3484, 3399, 3176, 2301, 3878, 3995, 3309, 1266, 2192, 2860, 1778, 2102,
         198,  403, 3989,   10])
Epoch: 3370, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3371 - Batch 1 ########################
IDs in batch 1: tensor([2653,  100, 2391,  173, 4144, 3808, 1384, 1859, 2122, 3467, 1450, 1220,
        2112,  234, 1012, 2770])
Epoch: 3371, Training Loss: 0.27, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3372 - Batch 1 ########################
IDs in batch 1: tensor([ 953, 3381, 3474, 1381, 3705,  252, 3841, 1957,   99, 1257, 2408, 2743,
        1866, 3772, 1630, 1231])
Epoch: 3372, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3373 - Batch 1 ########################
IDs in batch 1: tensor([1620,  515, 2829, 2701, 2423, 3439,  623, 1624, 1183, 4044,  632, 2709,
        2025, 3968, 3312, 3369])
Epoch: 3373, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3374 - Batch 1 ########################
IDs in batch 1: tensor([1457, 1448, 1588, 1871,  635,  195, 3806, 3022, 1321, 3044, 3021, 2659,
        2860, 2742, 3894, 3310])
Epoch: 3374, Training Loss: 0.09, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3375 - Batch 1 ########################
IDs in batch 1: tensor([4149,  775, 2917, 2420,  221,  395, 1251, 4107, 4203, 3208, 4125, 2196,
         574, 1638, 2051, 4024])
Epoch: 3375, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3376 - Batch 1 ########################
IDs in batch 1: tensor([ 787, 4076, 3707,  741, 3074, 2969, 2712, 2839,  281,  591, 4149, 2377,
        3000, 1287, 2879,  358])
Epoch: 3376, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3377 - Batch 1 ########################
IDs in batch 1: tensor([ 660, 3415, 4240, 1562,  181, 1014, 3621,  396, 2320, 3177, 2014, 3017,
         736, 3451, 1678, 2188])
Epoch: 3377, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3378 - Batch 1 ########################
IDs in batch 1: tensor([3053, 3816, 1620, 3587, 2718,  202, 1391,  881, 1027,  533, 3723, 4044,
        1627, 3797, 2457,  363])
Epoch: 3378, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3379 - Batch 1 ########################
IDs in batch 1: tensor([1154, 3257, 1226,  848, 2461, 1980, 3409, 2104, 2052,  101, 1818, 3197,
        3465, 1162, 1369, 3058])
Epoch: 3379, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3380 - Batch 1 ########################
IDs in batch 1: tensor([  34,  952, 2127, 1310, 1491, 2998, 4070, 2659,  529, 1640, 1473,  345,
         351, 2891, 2180,  427])
Epoch: 3380, Training Loss: 0.24, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3381 - Batch 1 ########################
IDs in batch 1: tensor([2341, 1450, 3182, 1872,   73,  676, 1063,  213, 2898, 2236, 4185,  821,
         952,  150, 4026,  399])
Epoch: 3381, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3382 - Batch 1 ########################
IDs in batch 1: tensor([3404, 2855,  397, 2690, 3745, 4217, 3727, 3219, 2902, 3856,  456, 2226,
        4220, 1417, 3386, 3284])
Epoch: 3382, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3383 - Batch 1 ########################
IDs in batch 1: tensor([4122, 1973,  165, 1956, 1960, 1968, 2193, 1967, 1085, 2167, 1960, 2170,
        2141, 3481, 2689, 3648])
Epoch: 3383, Training Loss: 0.42, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3384 - Batch 1 ########################
IDs in batch 1: tensor([1276, 2213,  182, 2102, 3651, 2360, 2536, 1665, 2938, 2484, 3610, 2433,
        2134,  808, 1853,  923])
Epoch: 3384, Training Loss: 0.03, Validation Loss: 0.79, accuracy = 0.75
######################## Epoch 3385 - Batch 1 ########################
IDs in batch 1: tensor([3211,  211, 1001, 2856, 4025, 1212,  890, 1959,  529,  261,  128,  663,
        3786, 1511, 3277, 2464])
Epoch: 3385, Training Loss: 0.13, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3386 - Batch 1 ########################
IDs in batch 1: tensor([2193, 3256, 4082, 2013, 4018, 2119, 1963,  991, 3551, 3187, 4144,  594,
        1374, 3192, 1819, 4232])
Epoch: 3386, Training Loss: 0.13, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3387 - Batch 1 ########################
IDs in batch 1: tensor([1826, 2831, 3707,  558, 1404, 1469, 3702, 2510, 1576, 3240, 1521, 1931,
        3388, 2540, 1383, 2080])
Epoch: 3387, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3388 - Batch 1 ########################
IDs in batch 1: tensor([2529,  721, 2583, 1317, 2978,  250, 3728,  265, 3769, 1291, 3437, 3079,
         187, 3188, 2643, 4072])
Epoch: 3388, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3389 - Batch 1 ########################
IDs in batch 1: tensor([3299, 3481, 4044, 2011, 1141, 1485,  591, 1671,  837, 2456, 1647,  489,
        2976, 1346, 2018, 4228])
Epoch: 3389, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3390 - Batch 1 ########################
IDs in batch 1: tensor([3452, 3111,  714, 2234,  556, 2773, 3902, 4165, 3143, 1870,   61, 3255,
        2433,  758, 2497, 3378])
Epoch: 3390, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3391 - Batch 1 ########################
IDs in batch 1: tensor([4016, 2727, 2523, 2504, 3102, 1016, 3088, 2598, 3807, 3110, 1756, 1840,
        1124, 2799, 2275, 4236])
Epoch: 3391, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3392 - Batch 1 ########################
IDs in batch 1: tensor([3495, 1004, 1319, 3777, 2123, 1645, 2277, 2853, 2652, 2244, 1567, 2026,
         122,  762, 4117, 3689])
Epoch: 3392, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3393 - Batch 1 ########################
IDs in batch 1: tensor([2524,  949,  322,  557, 1047, 3092,  575,  930, 2499, 1617, 2078, 2485,
        3147, 3082, 3443, 3672])
Epoch: 3393, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3394 - Batch 1 ########################
IDs in batch 1: tensor([2478, 3387, 4070, 3914, 1869, 2731, 2070, 3497, 2074, 1558, 2135, 3995,
        3248,  345, 3336, 3614])
Epoch: 3394, Training Loss: 0.25, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3395 - Batch 1 ########################
IDs in batch 1: tensor([3701, 1597,  150,  149, 2437, 1718,  841,  673, 3286,  546, 2758, 3310,
        3303, 3983,  732, 3317])
Epoch: 3395, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3396 - Batch 1 ########################
IDs in batch 1: tensor([1626, 4238,  660,  261, 3433, 1901, 4110, 3778, 1258, 1753, 4003, 1085,
        3624, 2090,  199, 1037])
Epoch: 3396, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3397 - Batch 1 ########################
IDs in batch 1: tensor([ 546,  866, 3598, 2781, 1927, 2692, 3349,  785,  110,  318, 4118, 1380,
        1506,  807,  284, 2468])
Epoch: 3397, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3398 - Batch 1 ########################
IDs in batch 1: tensor([2466, 3120, 1257,  129,  909, 2205, 2272,  334, 3476, 1894, 1558, 2406,
        1389, 3438, 3797,  892])
Epoch: 3398, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3399 - Batch 1 ########################
IDs in batch 1: tensor([1317,  637, 2669, 2478,  701, 1062, 3731, 3969, 4051,  930, 3381,  710,
        3299,  919,   81, 3928])
Epoch: 3399, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3400 - Batch 1 ########################
IDs in batch 1: tensor([3845, 2010, 1124, 1555, 3310, 3017,  126, 3797,  983, 3470,  627, 3124,
        3058, 3152, 1732,   39])
Epoch: 3400, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3401 - Batch 1 ########################
IDs in batch 1: tensor([ 172, 1377,  989, 3503,  438, 3630, 2669,  880,  187, 3091, 2085, 1753,
        2305, 1679, 2845, 4026])
Epoch: 3401, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3402 - Batch 1 ########################
IDs in batch 1: tensor([2092, 2572,  790, 1981, 2322, 2141, 2773, 1794, 2300, 1200, 3470, 2017,
         517, 3270,  662, 2146])
Epoch: 3402, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3403 - Batch 1 ########################
IDs in batch 1: tensor([1220,  602,  738, 1937,   49,  769, 2035, 3912, 3975, 1836, 2495, 1859,
        3498, 2482,  842, 1299])
Epoch: 3403, Training Loss: 0.12, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3404 - Batch 1 ########################
IDs in batch 1: tensor([1345,  471, 3020, 1981,  691, 3492, 2895, 2767,  387,  835, 3143, 1440,
        2435, 3078,  501, 1032])
Epoch: 3404, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3405 - Batch 1 ########################
IDs in batch 1: tensor([4005, 4095, 4004, 3969, 3732,  546, 2743, 3166, 1678, 1423, 3363, 2437,
        3837,  662, 3427,  678])
Epoch: 3405, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3406 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 4157,  470, 1017,  536, 1305, 3680, 1136, 1385,  897, 1289,  556,
        1589, 1376,  891, 3459])
Epoch: 3406, Training Loss: 0.83, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3407 - Batch 1 ########################
IDs in batch 1: tensor([  68, 1369, 2314, 3506, 1452, 1255,  863, 2459,  788, 3888, 2176, 4190,
        1580, 1835,  531, 3590])
Epoch: 3407, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3408 - Batch 1 ########################
IDs in batch 1: tensor([2106,  976, 1965,  676, 2986, 1284,  520, 1817, 2619, 1178,   56, 1189,
        2567, 3547, 1347, 2504])
Epoch: 3408, Training Loss: 0.34, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3409 - Batch 1 ########################
IDs in batch 1: tensor([ 140, 2969, 2149, 3938, 4089, 2080, 2011,  637, 1660, 3988, 2669, 3652,
        2413,  109, 3180,  292])
Epoch: 3409, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3410 - Batch 1 ########################
IDs in batch 1: tensor([1787, 1745, 2517,  187, 3236, 1996,  976,  620, 3763, 2898, 1376, 4224,
         424,  895,  128,  830])
Epoch: 3410, Training Loss: 0.25, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3411 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 3504, 3081, 2159, 2655, 3029, 1708, 1130, 1116, 2536,  170, 1007,
         262, 3083, 2025,  402])
Epoch: 3411, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3412 - Batch 1 ########################
IDs in batch 1: tensor([2151, 3256, 4232, 3055, 2562, 2683, 3607,  809, 3418, 2212, 2575,   35,
         896,  941, 3886,  779])
Epoch: 3412, Training Loss: 0.34, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3413 - Batch 1 ########################
IDs in batch 1: tensor([3734,  245, 2151, 2440, 3358, 3022,  426,  923, 1322, 1644, 4120, 3655,
        3927, 2291, 1712, 2891])
Epoch: 3413, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3414 - Batch 1 ########################
IDs in batch 1: tensor([3468, 3993, 2748, 4186, 1335,   34,   86, 2359, 4099, 2845,  662, 1003,
        3196, 1234, 3143, 1679])
Epoch: 3414, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3415 - Batch 1 ########################
IDs in batch 1: tensor([ 880, 2448, 3087, 2700, 1052,  149, 3049, 1927, 4249,  470, 2343, 3782,
         812, 2671, 2004, 1585])
Epoch: 3415, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3416 - Batch 1 ########################
IDs in batch 1: tensor([1384, 2343, 2568, 1985,  652, 2880, 1082, 4203, 3897,  211, 1990,  470,
        3876,  726, 2066, 2717])
Epoch: 3416, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3417 - Batch 1 ########################
IDs in batch 1: tensor([2272, 2282,  418,  866, 3489, 1626, 2682,  732,  520,   49, 3930, 1773,
        1302, 3075,  685, 2693])
Epoch: 3417, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3418 - Batch 1 ########################
IDs in batch 1: tensor([3822, 1391, 2261,  238, 2522, 3905, 1521, 2539, 2376, 1976,   46, 3733,
        2717,  775, 2328, 1126])
Epoch: 3418, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3419 - Batch 1 ########################
IDs in batch 1: tensor([1830, 4254, 2044, 2026, 1141,  161, 3400, 3099, 4036,  776, 3391, 1099,
        1795,  545,  636, 3747])
Epoch: 3419, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3420 - Batch 1 ########################
IDs in batch 1: tensor([ 639,  752, 2218, 2804,  753, 1640,  265, 2146, 4053, 3990,  808, 1571,
        2516, 1972,  993, 1330])
Epoch: 3420, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3421 - Batch 1 ########################
IDs in batch 1: tensor([ 689, 3223, 3950, 1094, 3956, 3497, 2258, 3907,  137, 2535, 2957, 1884,
        3834, 1136, 1380, 3785])
Epoch: 3421, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3422 - Batch 1 ########################
IDs in batch 1: tensor([2974, 2414,  224,  367, 3142,  863,  224, 3091, 3460, 2567, 2931, 2572,
         915, 2018,  822,   88])
Epoch: 3422, Training Loss: 0.01, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3423 - Batch 1 ########################
IDs in batch 1: tensor([3742,  337, 4143, 2884,  862, 2206, 1425, 2173, 3636, 2492,  803,  516,
        1508, 3826, 3850, 2812])
Epoch: 3423, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3424 - Batch 1 ########################
IDs in batch 1: tensor([1361,  900,  316,  541, 2666,  572, 1954, 3894, 2826, 2885,  200, 2249,
        1762,  507, 2919, 2339])
Epoch: 3424, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3425 - Batch 1 ########################
IDs in batch 1: tensor([3343, 3756, 1459,  358,   10, 2024, 2167, 1618, 3370, 2529, 2225, 3983,
        1201, 1130,  863, 1568])
Epoch: 3425, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3426 - Batch 1 ########################
IDs in batch 1: tensor([4117, 1306, 3428,  946, 3204, 3540, 3885,  269, 2495, 3930, 1812, 1406,
        2648, 3905, 2712, 3199])
Epoch: 3426, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3427 - Batch 1 ########################
IDs in batch 1: tensor([3337, 1341, 3392, 2485, 2135,  228, 4197, 3843, 3014, 1134, 2251, 1745,
        1385, 2978,  897,  545])
Epoch: 3427, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3428 - Batch 1 ########################
IDs in batch 1: tensor([2172, 1391, 2312,   18, 2127, 4190, 3521, 1434, 2238, 2821,  575, 3642,
        1897, 2275,  637,  251])
Epoch: 3428, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3429 - Batch 1 ########################
IDs in batch 1: tensor([2866, 2717, 2672,  568, 2696, 4227, 3441, 1679, 2446,   49, 1028,  773,
        3658, 1562, 2146, 3271])
Epoch: 3429, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3430 - Batch 1 ########################
IDs in batch 1: tensor([ 315,  283,  205, 3168, 3218, 1456, 1272, 3723,  637, 3949, 2309, 2466,
        1909, 3972, 3180, 1976])
Epoch: 3430, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3431 - Batch 1 ########################
IDs in batch 1: tensor([ 824, 2485, 2205, 1488,  534, 4253, 3521, 2874, 3740, 3669, 3492, 1650,
        2925, 3506, 3769, 4249])
Epoch: 3431, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3432 - Batch 1 ########################
IDs in batch 1: tensor([2603,  435, 1824, 4057,  369, 3148,  536, 3027, 2348,  658, 2511, 2508,
        3792, 1699,  280,  950])
Epoch: 3432, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3433 - Batch 1 ########################
IDs in batch 1: tensor([4173, 2019, 3886, 3156, 3252, 2199, 3846, 3538, 1980, 1467, 1061, 3112,
        1389,  147,   71,  733])
Epoch: 3433, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3434 - Batch 1 ########################
IDs in batch 1: tensor([3547, 1313, 2161, 1377, 3982,  325, 3755,  738, 2418, 2999,  511,  264,
        2291, 1512, 1810, 1704])
Epoch: 3434, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3435 - Batch 1 ########################
IDs in batch 1: tensor([3597, 1054, 1920, 4225, 1168,   51, 3432, 2793, 3030, 1384, 1017, 4242,
        1984, 3948, 3234, 1618])
Epoch: 3435, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3436 - Batch 1 ########################
IDs in batch 1: tensor([3042, 1267,  200,   52, 2841,  126, 2897,  977, 2235, 3751,  478, 3268,
        4149, 1193, 3695, 3651])
Epoch: 3436, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3437 - Batch 1 ########################
IDs in batch 1: tensor([3863, 1123, 4108, 1673, 3118, 3306,  139,  463, 2917, 2291, 3894, 1397,
        3885, 3130,  188, 3912])
Epoch: 3437, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3438 - Batch 1 ########################
IDs in batch 1: tensor([3693, 1426,  185, 2986, 1852, 2155,  199, 1716, 3353, 1081, 2616, 2708,
         682,   43, 3105, 2420])
Epoch: 3438, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3439 - Batch 1 ########################
IDs in batch 1: tensor([1024, 2480, 4116,  969, 1904, 2495,  269, 3185, 1934,  809, 2088,  625,
         269, 2366, 3783, 2567])
Epoch: 3439, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3440 - Batch 1 ########################
IDs in batch 1: tensor([   4, 1011, 2483, 2362, 2591, 2812,  129,  777, 2441, 4154, 1708,  902,
        1774,   38, 2314, 4121])
Epoch: 3440, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3441 - Batch 1 ########################
IDs in batch 1: tensor([1558, 2337,  733,  687, 2788, 1073,  689,  482,  902, 1756, 2257,  102,
        1916, 2026, 1840,  148])
Epoch: 3441, Training Loss: 0.06, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3442 - Batch 1 ########################
IDs in batch 1: tensor([1389, 3376, 4099, 2019, 3874, 1425, 1445, 1218, 3115, 2936,  653, 1305,
        3644,  203, 2180, 1376])
Epoch: 3442, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3443 - Batch 1 ########################
IDs in batch 1: tensor([2487, 1099, 3709, 3444,  217, 4007,   46, 1113, 2489,  726, 1154, 2167,
        3216, 3912, 3234, 1279])
Epoch: 3443, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3444 - Batch 1 ########################
IDs in batch 1: tensor([2553, 1473,  498, 3354, 2072, 2807,  538, 2034, 3823,  645, 2090,  558,
         102, 3928, 2967, 3492])
Epoch: 3444, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3445 - Batch 1 ########################
IDs in batch 1: tensor([4203, 2331, 3544,  258, 2238, 2440,   51,  426,  444, 2418, 1649, 4154,
        1167,  417, 1331,  325])
Epoch: 3445, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3446 - Batch 1 ########################
IDs in batch 1: tensor([1193,  928, 4078, 4227,  814, 3206,  661, 3862, 2516, 3349, 4065, 3886,
         128, 2516, 2963,  996])
Epoch: 3446, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3447 - Batch 1 ########################
IDs in batch 1: tensor([2143, 1476, 2754, 3489, 1578, 3220,  739, 3389, 1458, 4128, 3506,  333,
        3108,   93,  811, 3267])
Epoch: 3447, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3448 - Batch 1 ########################
IDs in batch 1: tensor([3496, 3109,  284, 1762,  594, 3460,  237, 1305,  789, 3597, 1680, 2793,
        1158, 1219, 1836, 3221])
Epoch: 3448, Training Loss: 0.13, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3449 - Batch 1 ########################
IDs in batch 1: tensor([1190,  412, 2966, 3709, 1414, 3243, 1049, 2002, 4230, 2578, 2398,  955,
        1634,  187, 2653,  161])
Epoch: 3449, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3450 - Batch 1 ########################
IDs in batch 1: tensor([ 483, 3664, 1524, 2040, 1823,  149,  636, 1198, 4115, 2440, 3676,  933,
        3282,  455, 2796, 3099])
Epoch: 3450, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3451 - Batch 1 ########################
IDs in batch 1: tensor([4266, 2849, 1862, 3845, 4050, 3077, 3603,  797, 1237, 3329, 4121, 3511,
         723, 4012,  829, 4044])
Epoch: 3451, Training Loss: 0.24, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3452 - Batch 1 ########################
IDs in batch 1: tensor([ 180, 3270, 3148, 1025, 3969, 1347, 3154, 2511, 1180, 3932,  956, 1787,
        2738, 1859,  202, 2403])
Epoch: 3452, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3453 - Batch 1 ########################
IDs in batch 1: tensor([  93, 3117, 3713, 1773, 4175,   68, 1349, 1098, 1916, 1724, 1015, 3112,
         501, 3160, 2725, 3874])
Epoch: 3453, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3454 - Batch 1 ########################
IDs in batch 1: tensor([2970, 3233, 4012, 2196, 2582,  177, 4268,  448, 3261,  848, 3388,  514,
        1545, 1233, 3218,   78])
Epoch: 3454, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3455 - Batch 1 ########################
IDs in batch 1: tensor([3257, 2969, 3499, 4184, 2338, 3326, 3465, 1974, 3321, 3999, 2731, 1008,
        1753,  139, 3039,  546])
Epoch: 3455, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3456 - Batch 1 ########################
IDs in batch 1: tensor([3267,  306, 3962, 3732, 2407, 2450, 3382,  874,  295, 1811, 1136, 3436,
        2821, 2185, 4114, 3000])
Epoch: 3456, Training Loss: 0.12, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3457 - Batch 1 ########################
IDs in batch 1: tensor([ 946, 1764, 2339,  837, 2661, 3487, 1961,   57, 3511, 3743, 4258, 1647,
         389,  380,  797, 1252])
Epoch: 3457, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3458 - Batch 1 ########################
IDs in batch 1: tensor([4013, 2369, 2927, 3952,  699, 2024, 2615,   56, 4156, 1724, 2388,  915,
        1173, 4049,  250, 2190])
Epoch: 3458, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3459 - Batch 1 ########################
IDs in batch 1: tensor([2035, 2765, 2641, 2767, 3471, 1442,  199, 1333, 3648, 2125, 2897, 4008,
        3395, 2783, 3544, 2541])
Epoch: 3459, Training Loss: 0.33, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3460 - Batch 1 ########################
IDs in batch 1: tensor([2483, 1134, 3240, 2961, 1055, 3345, 1371, 1206, 2035, 2468, 2172, 2845,
        2189, 2413, 4254, 2592])
Epoch: 3460, Training Loss: 0.16, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3461 - Batch 1 ########################
IDs in batch 1: tensor([3262, 3239,  184, 2111, 3088, 2618,  914, 1720,  890, 1179, 2758,  229,
         213,  961, 3277,  487])
Epoch: 3461, Training Loss: 0.10, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3462 - Batch 1 ########################
IDs in batch 1: tensor([1347, 2967, 2555, 2004,  265, 3733, 1425,  547, 1242,  185, 2223,   82,
        3553, 1672, 3262, 4114])
Epoch: 3462, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3463 - Batch 1 ########################
IDs in batch 1: tensor([2758, 2516, 4016, 1318, 2495, 2299, 1766, 1093, 2763,   32, 1512, 1428,
        2499, 2332, 2643, 2592])
Epoch: 3463, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3464 - Batch 1 ########################
IDs in batch 1: tensor([4012,  631, 3150, 1968, 2936, 3976,  615, 4004, 3141, 1498, 3608, 1871,
        4179, 2653, 2257, 3112])
Epoch: 3464, Training Loss: 0.08, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3465 - Batch 1 ########################
IDs in batch 1: tensor([3624, 4017,  550, 2431, 3127, 3162, 1219, 2669, 1316, 2327, 3344, 1909,
         942, 2023, 1242, 1144])
Epoch: 3465, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3466 - Batch 1 ########################
IDs in batch 1: tensor([3168, 2908, 2489, 2674,   71, 4080, 4012,  554, 1389, 2644, 3364, 3548,
        2091, 2412, 2731, 4087])
Epoch: 3466, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3467 - Batch 1 ########################
IDs in batch 1: tensor([ 753, 1740,    5, 3088, 1132, 2393, 3071, 2616, 3181, 3228, 1600, 3988,
        2526, 3435, 3958, 3650])
Epoch: 3467, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3468 - Batch 1 ########################
IDs in batch 1: tensor([1124, 2354, 3473, 2833,  470, 1887, 1443, 1057, 3985, 3018, 2398, 1883,
         411, 1740, 2417,  483])
Epoch: 3468, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3469 - Batch 1 ########################
IDs in batch 1: tensor([ 747, 1955, 4097, 2890, 2469, 1454, 2572, 3152, 3755,  893, 3723, 3757,
        3022, 1944, 3544, 1702])
Epoch: 3469, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3470 - Batch 1 ########################
IDs in batch 1: tensor([2044, 3961, 1497, 3845,  915, 2003,  773, 3926, 1055, 3869,  871, 1379,
         891, 3152, 2739, 1104])
Epoch: 3470, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3471 - Batch 1 ########################
IDs in batch 1: tensor([3133, 2517, 2423, 2412, 1120, 4222, 1183,  196, 3219,  959,  491, 2708,
        2497, 3417, 3771, 2767])
Epoch: 3471, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3472 - Batch 1 ########################
IDs in batch 1: tensor([3997, 3377, 2180, 3740, 4027, 3094, 3932,  631, 3635,  818,  658, 1417,
         224, 2410, 2600, 3673])
Epoch: 3472, Training Loss: 0.51, Validation Loss: 0.72, accuracy = 0.75
######################## Epoch 3473 - Batch 1 ########################
IDs in batch 1: tensor([3977,  996, 3489, 1097, 2676, 3127, 1313, 1595, 3150, 3644, 2839, 2937,
        4002, 2073, 1315, 1563])
Epoch: 3473, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3474 - Batch 1 ########################
IDs in batch 1: tensor([2044,  572,  143, 3806, 4197, 1601,  378, 2049, 2577, 4005, 3079, 2024,
         617,  507, 3253, 1842])
Epoch: 3474, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3475 - Batch 1 ########################
IDs in batch 1: tensor([1868,  483, 4078, 3726, 2770,  753, 3448, 1214, 2798, 4215, 3246, 4089,
        3813, 2476,  926, 1585])
Epoch: 3475, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3476 - Batch 1 ########################
IDs in batch 1: tensor([4157, 1393, 4031,  804, 2073, 1099, 1219, 3038, 2577, 4002, 2417,  586,
        2188,  418, 3035, 1285])
Epoch: 3476, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3477 - Batch 1 ########################
IDs in batch 1: tensor([3472,  300, 4119, 3912, 4138,  308,  136, 2300, 1770, 2337, 3440,  391,
        1671, 2777, 2853,  393])
Epoch: 3477, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3478 - Batch 1 ########################
IDs in batch 1: tensor([2025, 1700, 2538, 2894,  219, 3988, 2432,  424, 1960, 1871, 1306, 1232,
        3713, 2249, 4095, 1396])
Epoch: 3478, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3479 - Batch 1 ########################
IDs in batch 1: tensor([ 193, 2447, 4168, 2696, 1948, 4124, 1988, 4107,  823, 3415,  673, 1364,
        3898,   31, 1116,  921])
Epoch: 3479, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3480 - Batch 1 ########################
IDs in batch 1: tensor([2393, 2098, 2301,  602,  109, 1011, 1278, 2223, 3025, 2188, 3395,  834,
        1855,  880,  596, 1627])
Epoch: 3480, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3481 - Batch 1 ########################
IDs in batch 1: tensor([2839, 2827, 1432,  900, 1752, 3947, 2182, 2509, 3842, 2765, 1146,  259,
        3591,  384, 1308, 3568])
Epoch: 3481, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3482 - Batch 1 ########################
IDs in batch 1: tensor([ 553, 2103, 1623, 1958, 1355, 2901,   85, 2196, 1517, 2306, 3031, 3251,
        2419, 2537, 3314, 1710])
Epoch: 3482, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3483 - Batch 1 ########################
IDs in batch 1: tensor([3675, 1955,  630, 1712, 3330, 3312, 2836,  756, 1682, 2064,  260, 1480,
        1451, 1732, 2435, 3471])
Epoch: 3483, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3484 - Batch 1 ########################
IDs in batch 1: tensor([4089, 1235,   49, 2255, 1984, 3509,  812, 3763, 1452, 1543, 2863, 3709,
        2819, 1076, 1617, 2817])
Epoch: 3484, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3485 - Batch 1 ########################
IDs in batch 1: tensor([ 945,  141, 1365, 2544, 3141,   78, 1830,  586,  367,  808,  555, 3494,
        3390,  387,  814, 2483])
Epoch: 3485, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3486 - Batch 1 ########################
IDs in batch 1: tensor([4168, 2035,  131, 2751,  482, 1377, 2230, 3501, 3369, 2382, 2265, 1093,
        2467, 2895, 1266, 1967])
Epoch: 3486, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3487 - Batch 1 ########################
IDs in batch 1: tensor([ 265, 1614, 2746, 2016, 1498,  375, 1034, 2980, 1402, 1208,  908,  512,
        1540,  487, 1711, 1059])
Epoch: 3487, Training Loss: 0.61, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3488 - Batch 1 ########################
IDs in batch 1: tensor([2883,  520,  445, 1084, 2154,  902, 1993, 4022,  478, 3934, 3757, 2652,
        1569,  771,  778, 1613])
Epoch: 3488, Training Loss: 0.04, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3489 - Batch 1 ########################
IDs in batch 1: tensor([3845, 4072, 1849,  666, 3469, 3368, 3139,  966,  263, 3843, 3953,  437,
        1432,  387, 3970,  644])
Epoch: 3489, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3490 - Batch 1 ########################
IDs in batch 1: tensor([3056, 3135, 2688,  822, 1927, 2039, 2749, 3732,  803, 3479, 3948, 2598,
        3142, 1636, 2418, 1657])
Epoch: 3490, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3491 - Batch 1 ########################
IDs in batch 1: tensor([2189, 3803, 3486, 1927,  963,  936, 1817, 1954, 2514,   98, 3917, 2418,
         899,   63,  871, 3543])
Epoch: 3491, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3492 - Batch 1 ########################
IDs in batch 1: tensor([ 959, 1979, 3610, 2066, 2418, 2329, 2799, 2005, 3355, 2969, 1786, 3081,
        3764, 1443,   38,  915])
Epoch: 3492, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3493 - Batch 1 ########################
IDs in batch 1: tensor([1639,  660, 3488,  723, 3695, 2028, 3267, 2050,  918, 3091,  258, 2886,
         527,   93, 3358, 2907])
Epoch: 3493, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3494 - Batch 1 ########################
IDs in batch 1: tensor([3718, 1024, 2991, 3717, 3588,  305, 2277, 3702, 3672, 1383, 1090, 1489,
        1852, 1897,   38, 2066])
Epoch: 3494, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3495 - Batch 1 ########################
IDs in batch 1: tensor([1870,  317, 3785, 3406,  595,  277,  375,  814, 1830, 3025,   62, 3729,
         788, 3386, 3261, 3707])
Epoch: 3495, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3496 - Batch 1 ########################
IDs in batch 1: tensor([1075,  290, 3351, 2275, 2821, 1618, 1161, 2196,  140, 1646, 3511, 2973,
        2024,  164, 3643, 1408])
Epoch: 3496, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3497 - Batch 1 ########################
IDs in batch 1: tensor([1111, 3306, 2973,  505, 1120,  875, 2191,  300, 1641,  642, 1176, 3984,
         145, 2667, 2826, 1675])
Epoch: 3497, Training Loss: 0.35, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3498 - Batch 1 ########################
IDs in batch 1: tensor([2250, 1330,  881,  448,  492, 2839, 1685, 1646,  635, 1223, 1844, 3570,
        2956, 2356, 2721,  604])
Epoch: 3498, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3499 - Batch 1 ########################
IDs in batch 1: tensor([ 833, 1500, 1722, 3407, 1186, 3723, 1122, 3700,  632, 3939,  637, 1470,
        4097, 1911, 3754, 1082])
Epoch: 3499, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3500 - Batch 1 ########################
IDs in batch 1: tensor([ 190, 3749, 1414, 3528, 2204,  605,   56, 2292, 1524, 1724, 2961, 3845,
        1141, 2645, 2261, 3358])
Epoch: 3500, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3501 - Batch 1 ########################
IDs in batch 1: tensor([ 701, 2223, 3453, 4022,  338, 2192,  776, 2314, 2788, 2483,  434, 1613,
        2696,  604,  848,  609])
Epoch: 3501, Training Loss: 0.07, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3502 - Batch 1 ########################
IDs in batch 1: tensor([1519, 3276, 3656, 3031, 1540, 3071, 1682, 3744, 2998, 3465, 4094,  474,
        2350, 2144, 1451, 3399])
Epoch: 3502, Training Loss: 0.09, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3503 - Batch 1 ########################
IDs in batch 1: tensor([3587, 1760,   86,  346, 2746, 2462, 1960, 2067, 2440, 1899, 1063, 3206,
        2615,  530,  786, 1177])
Epoch: 3503, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3504 - Batch 1 ########################
IDs in batch 1: tensor([ 314, 3248, 3521, 1521,  546, 3594, 1311, 2770, 3511, 3744,  980, 1524,
        3984, 1521, 3970, 1132])
Epoch: 3504, Training Loss: 0.10, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3505 - Batch 1 ########################
IDs in batch 1: tensor([1237, 3221, 3589, 3870,  510, 2739, 3207,  645, 2435, 1134, 2051, 3238,
         206,  899, 3020, 3047])
Epoch: 3505, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3506 - Batch 1 ########################
IDs in batch 1: tensor([3287, 3998, 2668, 3187, 1619, 1066, 3058, 1855, 3547, 2767,   52, 2432,
        2290, 3228,  136, 2425])
Epoch: 3506, Training Loss: 0.14, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3507 - Batch 1 ########################
IDs in batch 1: tensor([3303, 2514, 1273, 4222, 2040, 4240, 2936, 3036, 3711, 3211,  533, 2332,
        2867,  645,  106, 4077])
Epoch: 3507, Training Loss: 0.16, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3508 - Batch 1 ########################
IDs in batch 1: tensor([2575, 3484, 3616, 1933,  149, 1001, 2912, 2193,  863, 4126, 1761,  752,
         821,  681, 2334, 1444])
Epoch: 3508, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3509 - Batch 1 ########################
IDs in batch 1: tensor([4264, 2965,  968, 3563, 2963, 4139, 2444, 4197,  659, 2085,   14, 3872,
         350, 4105, 1283, 3693])
Epoch: 3509, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3510 - Batch 1 ########################
IDs in batch 1: tensor([3299, 4251,  933, 1777, 2905, 2823, 1341, 1405, 4220, 4062, 3990, 1686,
        1028, 4101, 3371, 1364])
Epoch: 3510, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3511 - Batch 1 ########################
IDs in batch 1: tensor([2650,  337,  723, 1649,  367, 4254, 1811, 2106,  910, 2672, 3700, 3537,
         245, 2498, 1963, 3078])
Epoch: 3511, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3512 - Batch 1 ########################
IDs in batch 1: tensor([2687, 2936, 1605, 1123, 1020, 4008, 4094, 4044, 2415, 4026, 2305, 2388,
        3927,  262, 3767, 2802])
Epoch: 3512, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3513 - Batch 1 ########################
IDs in batch 1: tensor([3055,  777, 1233, 3956, 1942, 3869, 1326, 4038, 3567, 3914, 3047, 2087,
        2387, 2822, 1026,  735])
Epoch: 3513, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3514 - Batch 1 ########################
IDs in batch 1: tensor([  99,  483, 2241, 2672, 1493, 2670, 2094, 3484,  651, 4144, 1252, 3425,
        1613, 3460, 4264,  217])
Epoch: 3514, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3515 - Batch 1 ########################
IDs in batch 1: tensor([3488, 1612, 2484, 2357, 1349, 3701,  308, 2579, 1944, 2329, 4039, 1212,
        2564,  340, 4013, 3948])
Epoch: 3515, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3516 - Batch 1 ########################
IDs in batch 1: tensor([2405, 4240, 1141, 2691, 1668,  642,  243,  769, 2925, 1360, 3009, 3480,
        4099, 3435, 2974, 1005])
Epoch: 3516, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3517 - Batch 1 ########################
IDs in batch 1: tensor([3925,  767, 1336,  838, 1793, 1278, 4176, 3902,  678,  332,  140, 2671,
        2552, 1754, 2957, 2417])
Epoch: 3517, Training Loss: 0.13, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3518 - Batch 1 ########################
IDs in batch 1: tensor([1289, 1960, 4038, 1296, 2225, 1863, 2451,  426, 3749, 2812, 1947, 1357,
        2516, 4205, 3630, 1090])
Epoch: 3518, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3519 - Batch 1 ########################
IDs in batch 1: tensor([2947,  290, 2606,  575, 2016, 2327, 2185, 1787, 3787, 1543,  818, 2940,
        3984, 3597, 1162, 2436])
Epoch: 3519, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3520 - Batch 1 ########################
IDs in batch 1: tensor([4172, 3553, 3423, 2963,  365, 1413, 2238, 2708,  636, 3755,  393, 3728,
        2195,  963, 2539, 3846])
Epoch: 3520, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3521 - Batch 1 ########################
IDs in batch 1: tensor([2748, 2009, 2271, 2433, 1824, 4065, 4224,  193, 3992, 4176, 3257, 2126,
        1872,   92, 2951, 2575])
Epoch: 3521, Training Loss: 0.22, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3522 - Batch 1 ########################
IDs in batch 1: tensor([2653,  644, 2067,  954, 3206,  613, 4205,  258, 3792, 1319, 1660, 1734,
        4214, 1361, 3904, 4118])
Epoch: 3522, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3523 - Batch 1 ########################
IDs in batch 1: tensor([1077, 1229, 2104, 3746, 3903,  238, 1656, 2857, 3395,   49,  864, 2763,
        2265, 3523, 1390, 3551])
Epoch: 3523, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3524 - Batch 1 ########################
IDs in batch 1: tensor([3024, 1195, 4040,  518, 2386, 2375, 2255, 1760, 2842,  325, 1083,  159,
        1012, 1147, 1596,  140])
Epoch: 3524, Training Loss: 0.12, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3525 - Batch 1 ########################
IDs in batch 1: tensor([2995, 2907, 1347,  661, 3642, 1644, 1315,  165, 1031,  685, 2298, 2464,
        4120, 3429, 3188, 4223])
Epoch: 3525, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3526 - Batch 1 ########################
IDs in batch 1: tensor([ 223,  422,  390, 4051,  795, 3251,  689, 2134, 1248, 3328,  323,  308,
         645,  779, 2342, 1170])
Epoch: 3526, Training Loss: 0.26, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3527 - Batch 1 ########################
IDs in batch 1: tensor([2537,    5, 3290, 3604, 3072,  941, 2936, 1252, 2350, 3356, 3311,   51,
        1716, 3040,  214, 3526])
Epoch: 3527, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3528 - Batch 1 ########################
IDs in batch 1: tensor([2817,  830,  665, 2680, 1846,  968, 2010, 3312, 3958, 3526, 3813,  573,
        1283, 1894, 1027, 2518])
Epoch: 3528, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3529 - Batch 1 ########################
IDs in batch 1: tensor([ 111,  721, 1670, 3815, 1087, 3837,  781, 3749, 1507,  553, 2732, 1487,
        1923,  183, 1861,  652])
Epoch: 3529, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3530 - Batch 1 ########################
IDs in batch 1: tensor([3002, 2436, 3115, 1050, 1935, 1252, 1235, 3968, 2855, 1390, 1318, 3976,
        3781,   19,  933, 1027])
Epoch: 3530, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3531 - Batch 1 ########################
IDs in batch 1: tensor([1204,  966, 3218, 2901, 1170, 3570, 1251, 3102,  814, 1708, 2253, 3984,
        1623, 2366,  819, 1067])
Epoch: 3531, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3532 - Batch 1 ########################
IDs in batch 1: tensor([ 274,  991, 1035, 3940, 3739, 1778, 2544, 1599, 2241, 3683,  207,  527,
         838,  676, 3267, 3676])
Epoch: 3532, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3533 - Batch 1 ########################
IDs in batch 1: tensor([4088, 1080, 4124, 4134, 4240, 1754, 3827, 1450,   27, 2844, 1731, 3802,
        2565, 2692, 1158, 2418])
Epoch: 3533, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3534 - Batch 1 ########################
IDs in batch 1: tensor([1663, 3037, 3227, 2752, 2123, 1442, 2859, 3283, 2664, 1959, 3300, 3299,
        2746,  102,  736, 1222])
Epoch: 3534, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3535 - Batch 1 ########################
IDs in batch 1: tensor([3964, 3056,  741,  881, 2167,  358, 3024,  365,  962, 1677, 1487, 1092,
         337, 4149,  360, 1225])
Epoch: 3535, Training Loss: 0.40, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3536 - Batch 1 ########################
IDs in batch 1: tensor([ 225, 2574, 2028,  726, 1415,  472, 3652, 3871, 1404, 2876,  112, 1686,
        3207, 2190,  636, 2459])
Epoch: 3536, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3537 - Batch 1 ########################
IDs in batch 1: tensor([3715, 2371, 1361,  402,   47, 3843, 3987, 3728, 3379, 4133, 3391, 2067,
        1485,  613, 3481,  396])
Epoch: 3537, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3538 - Batch 1 ########################
IDs in batch 1: tensor([3630, 2272, 1834, 1780, 1753, 3786, 2027,  666,  187, 2842, 2701, 4022,
        1186, 4159, 1868, 3615])
Epoch: 3538, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3539 - Batch 1 ########################
IDs in batch 1: tensor([ 684, 2457, 1321,  205,  617,  893, 2480,  499,  399, 2131,  820, 2414,
        2615,  213, 2844, 4173])
Epoch: 3539, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3540 - Batch 1 ########################
IDs in batch 1: tensor([3156,  726, 1442,  857, 4013, 2614, 2913, 1481, 1417, 2066, 3329, 3563,
        1731, 3707,  908, 3166])
Epoch: 3540, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3541 - Batch 1 ########################
IDs in batch 1: tensor([3598,  930, 2934, 3409,  150, 4170, 2401,   47,  452, 2444, 2183, 2003,
        3415, 3886, 4179, 1389])
Epoch: 3541, Training Loss: 0.08, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3542 - Batch 1 ########################
IDs in batch 1: tensor([2206, 1313,  251, 2667,  558, 3700, 3049, 2521,  264, 3911, 1678, 3461,
         482, 3557, 1116, 4197])
Epoch: 3542, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3543 - Batch 1 ########################
IDs in batch 1: tensor([2159, 3148, 1869, 1871, 1726, 3038, 3812,  262, 3493, 3003,  663,  645,
        2726, 1737, 2848, 2151])
Epoch: 3543, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3544 - Batch 1 ########################
IDs in batch 1: tensor([2836, 2371, 4024, 1381,  830, 1752, 4119, 2499, 1883, 3709,  375,   97,
        2708, 1351, 3240, 3765])
Epoch: 3544, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3545 - Batch 1 ########################
IDs in batch 1: tensor([2149, 1376, 3461, 1124, 1176, 3947,  129, 3261, 1962, 3208,  126, 1913,
        2209, 4249, 1977, 2590])
Epoch: 3545, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3546 - Batch 1 ########################
IDs in batch 1: tensor([2915, 2880, 3807,  395, 3881, 2011, 1567,  605, 2149, 1180,  975, 1580,
        2365, 3384,  637, 2098])
Epoch: 3546, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3547 - Batch 1 ########################
IDs in batch 1: tensor([2149,    5,  835, 1562,   49, 2629, 1850, 2470, 4016, 1247, 1457,  659,
         214, 2217, 3071,   39])
Epoch: 3547, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3548 - Batch 1 ########################
IDs in batch 1: tensor([2667, 1234, 4124, 2324, 3572, 3181, 2989, 2951, 3862, 3467,  379, 1272,
         202, 1720, 3495, 3872])
Epoch: 3548, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3549 - Batch 1 ########################
IDs in batch 1: tensor([3339, 2153, 2180,  359, 2648, 1645,  167, 3538, 2991,  688, 2322, 2450,
        1710, 1752, 1583, 1196])
Epoch: 3549, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3550 - Batch 1 ########################
IDs in batch 1: tensor([3022,  244, 1530,  637, 1968, 1844, 4236, 2969, 2553, 4187, 4049, 3092,
         637, 2378,   92, 1410])
Epoch: 3550, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3551 - Batch 1 ########################
IDs in batch 1: tensor([1700, 2405, 1218, 1566, 1381,  921, 1834,  910,  884, 1556, 3426, 1644,
         902, 4115, 3024, 2046])
Epoch: 3551, Training Loss: 0.24, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3552 - Batch 1 ########################
IDs in batch 1: tensor([ 332, 1470,  723, 3521, 1110,  149,  330, 3233, 3654, 1602,  613, 3615,
        1050, 3583, 3002, 1034])
Epoch: 3552, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3553 - Batch 1 ########################
IDs in batch 1: tensor([2399,  342, 3092, 4113, 3235, 2853,  426, 1266, 2226, 2296,  484, 2098,
        2212,  665, 3108, 3727])
Epoch: 3553, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3554 - Batch 1 ########################
IDs in batch 1: tensor([3386, 2806,  863, 2562,  710,  747,  205, 4159,  276,  897, 2073, 3485,
        3449, 3108, 3524, 1119])
Epoch: 3554, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3555 - Batch 1 ########################
IDs in batch 1: tensor([4118, 3219, 2729, 1502, 4264, 1685,  584,  891, 1914, 3932,  422, 2897,
        2982, 4212, 1014, 2604])
Epoch: 3555, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3556 - Batch 1 ########################
IDs in batch 1: tensor([2696,  346, 1996,   86, 1779, 2385, 2849, 2734,  607,  533, 4154, 4055,
         499, 2731, 1497,  941])
Epoch: 3556, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3557 - Batch 1 ########################
IDs in batch 1: tensor([3271,  323, 3815,  281,  829,  432, 3399,  854, 2327,  563, 2296, 3900,
        3760, 1351, 2886, 3669])
Epoch: 3557, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3558 - Batch 1 ########################
IDs in batch 1: tensor([3270, 3139, 2475, 3604, 3832, 2659, 3113,  191, 2847, 2205,   24,  967,
        1824, 1096, 3971,  352])
Epoch: 3558, Training Loss: 0.07, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3559 - Batch 1 ########################
IDs in batch 1: tensor([1075,  995, 3630, 1588, 1546, 3700, 1047, 1442, 3493, 2141, 3856, 1229,
        3289, 2827, 2857, 1942])
Epoch: 3559, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3560 - Batch 1 ########################
IDs in batch 1: tensor([3446, 3627,  436,  149, 3439, 3404,   47, 3179,   39,  756, 2672, 2203,
        3429, 4011, 1751, 3115])
Epoch: 3560, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3561 - Batch 1 ########################
IDs in batch 1: tensor([ 771, 4110, 1065, 1855, 1642, 1602, 1504, 1345,  190,  140,  862, 2970,
        2841, 3597, 3707, 1355])
Epoch: 3561, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3562 - Batch 1 ########################
IDs in batch 1: tensor([4224, 3178, 1563, 2784, 2127, 2520, 1065, 1306, 3397, 2860, 1955, 4050,
        1910, 4257, 3218, 2069])
Epoch: 3562, Training Loss: 0.29, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3563 - Batch 1 ########################
IDs in batch 1: tensor([1235, 1051, 3408, 1618,  415, 1518, 1045, 2741, 1600, 3701, 2355, 2951,
        1247, 1568, 3534, 3599])
Epoch: 3563, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3564 - Batch 1 ########################
IDs in batch 1: tensor([2558, 3248, 1795,  391,  425,  588, 1600, 2169, 2176, 1138, 1369, 2120,
        3936,  239, 1325,  869])
Epoch: 3564, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3565 - Batch 1 ########################
IDs in batch 1: tensor([4225, 1825, 2193,    4, 2605, 3952, 3267, 1682, 2146, 2890,  895,  752,
        3197, 1878, 1311, 2558])
Epoch: 3565, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3566 - Batch 1 ########################
IDs in batch 1: tensor([1991, 3609,   25, 2934, 1484, 3444, 3847,  739, 1158, 1808, 2770, 4163,
         590, 2572, 3664, 2578])
Epoch: 3566, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3567 - Batch 1 ########################
IDs in batch 1: tensor([2586, 4049, 3277,   15, 3920,  344, 1488,  330, 3968, 2024,  342,  864,
        1897,  795,  844,  387])
Epoch: 3567, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3568 - Batch 1 ########################
IDs in batch 1: tensor([1828, 2500, 1834,  678, 2169,  565,  518, 3655, 1883, 2599, 2255, 2417,
         588, 3527, 1380, 1519])
Epoch: 3568, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3569 - Batch 1 ########################
IDs in batch 1: tensor([2102, 3875, 1977, 2004, 2819, 2595, 3897, 3539, 2937, 2868,  833, 2652,
        1619, 3592,  644, 2649])
Epoch: 3569, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3570 - Batch 1 ########################
IDs in batch 1: tensor([2678, 1681, 3394, 4096, 2798, 2157, 1672, 3436, 2371, 2715, 3513, 2003,
        2247, 1904, 1778, 3700])
Epoch: 3570, Training Loss: 0.08, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3571 - Batch 1 ########################
IDs in batch 1: tensor([1328, 1809, 3962, 3973, 3717, 4257, 1732,  451, 3429,  869, 1269, 1152,
        2614,  312, 2457, 3903])
Epoch: 3571, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3572 - Batch 1 ########################
IDs in batch 1: tensor([3470, 2432, 2523, 1474, 2480, 3717, 1690, 2401, 3698, 2069,  141,  469,
         841, 3754, 2118, 1537])
Epoch: 3572, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3573 - Batch 1 ########################
IDs in batch 1: tensor([4146, 2315, 2428, 3489,  651, 2415,  505, 1999, 2098, 1883,  221,  657,
         825, 2177, 3681, 3876])
Epoch: 3573, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3574 - Batch 1 ########################
IDs in batch 1: tensor([ 573, 3757, 2008,  954, 3700, 3423,  682,  900, 2003, 2895, 1414, 1988,
        2106,  361, 3219, 2463])
Epoch: 3574, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3575 - Batch 1 ########################
IDs in batch 1: tensor([2414, 3960, 4203,   41,   68, 3114, 3397,  825, 3635, 4134,   44, 2989,
        3655, 3568, 2060, 1275])
Epoch: 3575, Training Loss: 0.34, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3576 - Batch 1 ########################
IDs in batch 1: tensor([3870, 1953, 2196, 1619,  820,  920, 3790, 2701, 2986, 1439, 3600,  354,
        2787,   86, 2322, 3643])
Epoch: 3576, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3577 - Batch 1 ########################
IDs in batch 1: tensor([1949,  833, 1809, 4120,  553, 1937,  991, 3131, 3926, 4094, 3729, 3265,
        2275, 1185, 3958, 2825])
Epoch: 3577, Training Loss: 0.12, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3578 - Batch 1 ########################
IDs in batch 1: tensor([1181, 1053,  203, 2561, 2892, 2584,  811,   68, 2821, 1619, 1020, 2246,
        1736,  132,  126, 4232])
Epoch: 3578, Training Loss: 0.27, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3579 - Batch 1 ########################
IDs in batch 1: tensor([2590, 1982, 1885, 2976, 4101, 3339, 3842, 3833, 1360, 3031, 2545,  196,
         855, 1996, 4122, 1985])
Epoch: 3579, Training Loss: 0.35, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3580 - Batch 1 ########################
IDs in batch 1: tensor([3390, 2961, 3441, 3460, 3244, 1076, 3188, 3408, 2589, 1751,  191,  325,
        1296, 4015,  934, 1154])
Epoch: 3580, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3581 - Batch 1 ########################
IDs in batch 1: tensor([2953,  432,  964, 3318,  550, 4266, 3500, 4039, 4058, 1573,  606, 2402,
        1206, 1604, 3441, 1878])
Epoch: 3581, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3582 - Batch 1 ########################
IDs in batch 1: tensor([  61, 4188, 1235, 2890, 3807, 2108, 2179,  338,  943, 1396, 3376, 1156,
        2338, 2795,  895, 2148])
Epoch: 3582, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3583 - Batch 1 ########################
IDs in batch 1: tensor([2755, 2729, 3608, 3816, 2230,  196, 2231, 1012, 2687, 1727, 2480,  181,
         401, 2107, 3433, 1066])
Epoch: 3583, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3584 - Batch 1 ########################
IDs in batch 1: tensor([3443, 3415,  136, 2642, 1464,  346, 3418, 2220, 1892, 1434, 3156,  354,
        2488, 2132, 3936, 3386])
Epoch: 3584, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3585 - Batch 1 ########################
IDs in batch 1: tensor([2228, 1282,  467,  243, 2868, 1075, 2161,  159, 3806, 3701, 2137,  909,
        2472, 3206, 3017,  289])
Epoch: 3585, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3586 - Batch 1 ########################
IDs in batch 1: tensor([ 994, 3415, 2876, 2927, 1312,  894, 2260,  891,  177,  949, 1723,  740,
        3323, 2825, 2232, 2599])
Epoch: 3586, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3587 - Batch 1 ########################
IDs in batch 1: tensor([ 852,  276, 2064, 2151, 1498, 2974, 3342,  377, 2382, 1567, 3895, 2493,
        2831,  526, 3392, 3963])
Epoch: 3587, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3588 - Batch 1 ########################
IDs in batch 1: tensor([2383,   60, 2182,  763, 1619, 1195, 1355, 3898,  223, 3139, 1753, 2249,
        1855, 2090,  316, 1157])
Epoch: 3588, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3589 - Batch 1 ########################
IDs in batch 1: tensor([1737,  828, 3723, 1198, 1043, 1935, 1001, 3744, 1080,  257, 3935, 4148,
         829, 4198, 3651, 2748])
Epoch: 3589, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3590 - Batch 1 ########################
IDs in batch 1: tensor([3787,  923, 2535, 3414, 3407, 2841, 2919, 2536, 1949, 2337, 2371, 2874,
        2171, 1082, 4189, 4222])
Epoch: 3590, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3591 - Batch 1 ########################
IDs in batch 1: tensor([3196, 2406, 3841, 3846,  956,  518,  741, 1026, 2730, 1925,   51, 3139,
        3506, 1445, 3434, 4000])
Epoch: 3591, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3592 - Batch 1 ########################
IDs in batch 1: tensor([2748, 2729, 1455, 4240, 2847, 1501, 3532, 3435, 2091,  133,  256, 3409,
        1599, 2791, 3821, 1011])
Epoch: 3592, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3593 - Batch 1 ########################
IDs in batch 1: tensor([1991, 2190, 2781, 2966,  320, 1132, 1772,  133, 2177,   13, 1795, 3930,
        3344, 2897,  966, 3314])
Epoch: 3593, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3594 - Batch 1 ########################
IDs in batch 1: tensor([3038, 1836,    4, 3010, 3410,  409, 2284, 2206, 1617, 4256, 2371, 2339,
        2406,  667, 4119, 3897])
Epoch: 3594, Training Loss: 0.29, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3595 - Batch 1 ########################
IDs in batch 1: tensor([ 620,  172, 1174, 1711, 3481, 3803, 2236, 3536, 4005, 1818, 3618, 4154,
         492, 3538, 3594, 1209])
Epoch: 3595, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3596 - Batch 1 ########################
IDs in batch 1: tensor([2301, 4048, 3005, 1495, 2859, 2784, 3591, 2436, 1596, 1111, 3130, 3697,
        1185, 1011,  371, 3710])
Epoch: 3596, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3597 - Batch 1 ########################
IDs in batch 1: tensor([4048, 3804, 3942, 1084, 3036, 1540,  569, 3785, 3863,  949, 2800,  265,
        2244, 1840,  477, 3429])
Epoch: 3597, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3598 - Batch 1 ########################
IDs in batch 1: tensor([1981,  740,  213, 3152, 1868, 1147, 1642, 1082, 3461,  321,  814, 2582,
        2745, 2337, 3608, 3688])
Epoch: 3598, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3599 - Batch 1 ########################
IDs in batch 1: tensor([3905, 2541, 2552, 2122, 2234, 1871, 3265,  401,  919,  320, 3852, 1935,
        1881, 3719, 3506,  520])
Epoch: 3599, Training Loss: 0.14, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3600 - Batch 1 ########################
IDs in batch 1: tensor([ 191, 1177, 3492, 2473, 1031, 2074, 1054, 3975, 1881, 1417, 2284,  770,
        4010, 1472, 1322, 2666])
Epoch: 3600, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3601 - Batch 1 ########################
IDs in batch 1: tensor([2730, 4013,  729, 1566, 4152,  325,  807, 3220, 3392, 2857, 4053, 2884,
        1041, 1373,  851,  398])
Epoch: 3601, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3602 - Batch 1 ########################
IDs in batch 1: tensor([3810, 3692, 2265,  725, 2110, 3311,  681, 2405, 4015,  930,  150, 3094,
          24, 1657, 2141,  183])
Epoch: 3602, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3603 - Batch 1 ########################
IDs in batch 1: tensor([1118,  399,  723, 1017, 1448, 4107, 3463,  704, 3117, 1328, 1264, 3988,
        1832, 3660, 2973, 3018])
Epoch: 3603, Training Loss: 0.15, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3604 - Batch 1 ########################
IDs in batch 1: tensor([3815, 2357, 3206, 4011, 2496, 1702, 2229, 3956, 3704, 3276, 1645, 1954,
         808, 3693,  102,  516])
Epoch: 3604, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3605 - Batch 1 ########################
IDs in batch 1: tensor([ 747, 3841, 3401, 1170,  263, 3952, 3756, 2479, 3518, 1882, 1386, 4114,
        3006, 2065, 2207, 1751])
Epoch: 3605, Training Loss: 0.09, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3606 - Batch 1 ########################
IDs in batch 1: tensor([1383, 2349, 2859, 2238, 1434,  902, 2443, 1530, 1119, 1144, 4190, 2537,
        3418, 3858, 1737, 1283])
Epoch: 3606, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3607 - Batch 1 ########################
IDs in batch 1: tensor([2274, 3398,  217, 3726, 2806, 2860, 4141, 2591, 2123, 2969,  122, 3248,
        2112, 2583, 2378, 2590])
Epoch: 3607, Training Loss: 0.28, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3608 - Batch 1 ########################
IDs in batch 1: tensor([3399, 3156, 2703, 2070, 3540,  391, 1226,  278, 2005,  508,  687,  345,
        2365,  828,  145, 2710])
Epoch: 3608, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3609 - Batch 1 ########################
IDs in batch 1: tensor([1774, 3833, 1761, 3663, 1833, 2143, 3326,   11, 2059, 3437, 4152, 3647,
        1824, 2837,  778, 1731])
Epoch: 3609, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3610 - Batch 1 ########################
IDs in batch 1: tensor([ 184, 2245, 1591,   86, 2740, 1880, 2065, 4114, 3159,  652,  430, 3697,
         878, 3343, 1894, 3943])
Epoch: 3610, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3611 - Batch 1 ########################
IDs in batch 1: tensor([2016,   39,  666, 1960, 1507, 3557,  667, 3549, 3564, 2476, 3057, 3568,
        3656, 3816, 2949, 2360])
Epoch: 3611, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3612 - Batch 1 ########################
IDs in batch 1: tensor([3551,  485,  413, 2967,  251, 3310,  743,  779, 3961, 3875, 1826, 2198,
        2456, 3900,  302, 2489])
Epoch: 3612, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3613 - Batch 1 ########################
IDs in batch 1: tensor([2499, 4170, 3279,  946, 3390, 3029, 1428, 1508, 2242,  259, 1296,  477,
        1387, 2656, 2672, 2050])
Epoch: 3613, Training Loss: 0.09, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3614 - Batch 1 ########################
IDs in batch 1: tensor([3037,  183, 4189,  317, 2715,  126, 2567, 3384,  962, 4039, 1686, 1256,
        2648, 3386, 2682, 2027])
Epoch: 3614, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3615 - Batch 1 ########################
IDs in batch 1: tensor([1236, 1880, 2027, 3693, 1085, 1545, 4245, 1051, 2447,  350,  876, 2561,
        3047,   27,  499, 1448])
Epoch: 3615, Training Loss: 0.06, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3616 - Batch 1 ########################
IDs in batch 1: tensor([1414, 2940, 1819, 3407, 1426, 2610, 2108,  942, 2134, 1155,  317,   73,
         102,  106,  915, 3049])
Epoch: 3616, Training Loss: 0.10, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3617 - Batch 1 ########################
IDs in batch 1: tensor([ 604,  644,  593, 2739, 2793, 3159,  359, 1418, 1779,  425, 2097, 1498,
        3221, 1589, 3304, 1777])
Epoch: 3617, Training Loss: 0.17, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3618 - Batch 1 ########################
IDs in batch 1: tensor([2620, 2836, 3760, 1985,  849, 1641, 3680,  848, 2721, 3542, 2144, 4223,
        4017, 1895, 2385, 1042])
Epoch: 3618, Training Loss: 0.05, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3619 - Batch 1 ########################
IDs in batch 1: tensor([ 774, 2919, 1182, 1740, 3478, 1726, 3492, 3669, 1802, 1473, 1786, 2991,
         990, 1635,  137, 1143])
Epoch: 3619, Training Loss: 0.42, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3620 - Batch 1 ########################
IDs in batch 1: tensor([2510, 2943, 2262, 1476, 1680, 2218, 2917,  967, 4224,  467, 2800,  152,
        2982, 1289,  524,  545])
Epoch: 3620, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3621 - Batch 1 ########################
IDs in batch 1: tensor([ 284, 3689, 1367,  282, 2260, 2730,  390, 2309, 3233, 1996, 2109,  511,
         644, 1119, 2449, 4213])
Epoch: 3621, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3622 - Batch 1 ########################
IDs in batch 1: tensor([2081,   22,  876, 1306, 2428, 3883,  874,  930, 4040, 2150, 3527, 1787,
        2249, 2805,  777, 3343])
Epoch: 3622, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3623 - Batch 1 ########################
IDs in batch 1: tensor([1712, 2499, 2443, 1057, 1484, 2086,  586, 2976, 3594, 1393, 1934, 3214,
        2926, 3879, 4055, 1784])
Epoch: 3623, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3624 - Batch 1 ########################
IDs in batch 1: tensor([ 739, 2002, 2022, 3921,  983, 2997, 1470, 2080, 2799,  186, 1737,  917,
        2320,  526,  356, 3807])
Epoch: 3624, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3625 - Batch 1 ########################
IDs in batch 1: tensor([3433, 1003, 2121, 1119, 2586,  627, 3002, 3904, 2562, 3079, 2738, 1083,
        4232, 2499, 2005, 2976])
Epoch: 3625, Training Loss: 0.11, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3626 - Batch 1 ########################
IDs in batch 1: tensor([1025,  875,  701, 2189, 2567, 1879, 3672, 2579,  424, 2465, 1641, 2416,
         207,  766,  803, 1218])
Epoch: 3626, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3627 - Batch 1 ########################
IDs in batch 1: tensor([1118,  462,  628, 3528, 3542, 2745, 3436,  482,  259, 1833, 1723, 1863,
          64, 4246,  636, 2237])
Epoch: 3627, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3628 - Batch 1 ########################
IDs in batch 1: tensor([1633, 1247,  574,   73, 2440, 1519, 3878, 2807, 1502, 2018, 3074, 1963,
        4006, 1672, 1842, 3246])
Epoch: 3628, Training Loss: 0.01, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3629 - Batch 1 ########################
IDs in batch 1: tensor([2394,  622,  435,  134, 1315,  620, 2772,   93, 3327, 2462, 3980, 3948,
        1053, 2067, 3440,  781])
Epoch: 3629, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3630 - Batch 1 ########################
IDs in batch 1: tensor([2203, 1144,  507, 2842, 1181, 1228, 2687, 1784, 3049, 3023, 2882, 1297,
        4088, 2964, 3470,  213])
Epoch: 3630, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3631 - Batch 1 ########################
IDs in batch 1: tensor([2782, 2844, 3681, 1438, 3530, 1678, 2092,  870, 1182, 3628, 2775,  102,
        2809,  967, 2558, 3859])
Epoch: 3631, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3632 - Batch 1 ########################
IDs in batch 1: tensor([1233, 2504, 3123,  255, 3337, 2479,  691, 1947,  466, 1686, 2356, 3701,
         150, 2154, 3188, 3206])
Epoch: 3632, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3633 - Batch 1 ########################
IDs in batch 1: tensor([2022, 3640, 1248, 1092,  280,  362, 4135, 3677,  615, 4127, 2379,  289,
        2265, 3524, 2496, 1224])
Epoch: 3633, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3634 - Batch 1 ########################
IDs in batch 1: tensor([1402, 3501, 3567,   13, 2440, 3343,  387, 1065, 4230, 1613, 3463, 3010,
        2451, 1614, 1124, 2069])
Epoch: 3634, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3635 - Batch 1 ########################
IDs in batch 1: tensor([ 623, 2176,  379,  908,  536, 3876, 3196, 1360, 1206, 2339, 1146, 3194,
        2088, 3480, 2832, 1201])
Epoch: 3635, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3636 - Batch 1 ########################
IDs in batch 1: tensor([2743, 2715, 3042,  132, 1004, 3742, 3181,  590,  378, 2309, 2231,  324,
        3398, 2306, 3098, 3756])
Epoch: 3636, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3637 - Batch 1 ########################
IDs in batch 1: tensor([4161, 1299,  777, 2516,  871, 3888, 1727, 3221, 1953, 2592,  112, 3823,
        1802,  202, 1641, 3829])
Epoch: 3637, Training Loss: 0.02, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3638 - Batch 1 ########################
IDs in batch 1: tensor([3954, 3535, 3460, 2784,  617, 1787,  694, 1156,  402, 1364, 3071, 3696,
        3177, 2452, 1488,  103])
Epoch: 3638, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3639 - Batch 1 ########################
IDs in batch 1: tensor([2789, 2984, 3304, 2621, 3698, 3166, 1755, 2837, 3856,    4, 3603,  337,
        1306, 1519,   96, 1063])
Epoch: 3639, Training Loss: 0.17, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3640 - Batch 1 ########################
IDs in batch 1: tensor([ 839,  435, 4009, 2087,  284, 1845, 2719,  819, 3664, 1089,  220,  147,
         459, 3813, 3147, 2605])
Epoch: 3640, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3641 - Batch 1 ########################
IDs in batch 1: tensor([2996, 1670, 1980,  398, 3265,  465, 3470, 3071, 2627,   64,  332,  902,
        1727, 1274, 2751,  826])
Epoch: 3641, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3642 - Batch 1 ########################
IDs in batch 1: tensor([ 138, 3742, 2277, 3525, 1284,  195, 1181, 3823,  781, 1958, 3501,  883,
        1595, 3969, 4159,  122])
Epoch: 3642, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3643 - Batch 1 ########################
IDs in batch 1: tensor([2681,  377, 1963, 1957,  733, 3778, 4253, 1087,  803, 2087, 1425,  830,
         550, 3538, 2226,  320])
Epoch: 3643, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3644 - Batch 1 ########################
IDs in batch 1: tensor([2574, 3271, 1881, 1974, 3154, 1623, 2244, 2844, 3156, 3308, 1707,  792,
        2094, 2494, 3968, 3990])
Epoch: 3644, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3645 - Batch 1 ########################
IDs in batch 1: tensor([2064, 2825, 3111, 1061, 2435, 1396, 1955, 3469, 1121, 1137,  203, 2111,
        4249, 2331, 1931, 2299])
Epoch: 3645, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3646 - Batch 1 ########################
IDs in batch 1: tensor([2581, 4148, 2646,  459, 4198, 3894, 1335, 2886, 2155,  717, 3713, 2522,
        4082, 3340, 1436, 1282])
Epoch: 3646, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3647 - Batch 1 ########################
IDs in batch 1: tensor([3308, 1030,  796, 3888,  154, 1330, 3236, 1855, 2476, 2418,  838, 1123,
        3235, 1406, 3869, 1214])
Epoch: 3647, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3648 - Batch 1 ########################
IDs in batch 1: tensor([ 797, 2717, 1707, 2898, 3607, 3258,  883, 2444, 4172, 1346,  604, 2436,
        1094,  257, 2403, 2724])
Epoch: 3648, Training Loss: 0.01, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3649 - Batch 1 ########################
IDs in batch 1: tensor([2641, 3128, 2368,  478, 2309, 3553,  177, 4085, 2868, 2755, 2315, 3196,
         871, 1445, 3947, 1633])
Epoch: 3649, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3650 - Batch 1 ########################
IDs in batch 1: tensor([  62, 1049, 2131,  843,  300, 3132, 1623, 2640,  302, 2871,  756,  771,
         813, 2142,  292, 1628])
Epoch: 3650, Training Loss: 0.36, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3651 - Batch 1 ########################
IDs in batch 1: tensor([3583, 3017, 1251, 3870, 3610,  198, 2261, 4105, 1526, 2583, 2841, 3344,
        2737,  628, 1436,  529])
Epoch: 3651, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3652 - Batch 1 ########################
IDs in batch 1: tensor([1170,  497, 2477,  661,  384, 3159, 3904, 1803,  596, 1798, 2245, 1991,
        3248, 3304, 2921, 2141])
Epoch: 3652, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3653 - Batch 1 ########################
IDs in batch 1: tensor([2287, 2986,  750, 2708, 2966, 2246, 2805, 1270, 3949, 2763, 3634,  185,
        1121, 3363, 1204,  663])
Epoch: 3653, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3654 - Batch 1 ########################
IDs in batch 1: tensor([3221, 3673, 2555, 3644, 3532, 1015,  467, 2537, 3025, 1957, 1996,  496,
         662,  890, 3630, 1263])
Epoch: 3654, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3655 - Batch 1 ########################
IDs in batch 1: tensor([3897,  928, 2907,  382, 2013,  915,  396, 3839, 3947, 2517, 2416, 3338,
        4036,  851, 1001,  721])
Epoch: 3655, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3656 - Batch 1 ########################
IDs in batch 1: tensor([  82, 3366,  837, 1226, 3664, 2733, 2017, 2346,  463, 1373, 3994, 1686,
        2332, 1278, 4121, 1140])
Epoch: 3656, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3657 - Batch 1 ########################
IDs in batch 1: tensor([1935, 3148,  870, 2798, 2687, 1944, 1264,   56, 2598, 3638,   52, 4036,
        2689, 2064, 1158, 1310])
Epoch: 3657, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3658 - Batch 1 ########################
IDs in batch 1: tensor([3808, 2701,  325, 2723, 4060,  636, 1467, 3356, 3726, 2648,  218, 3102,
         732, 3424, 1434, 3111])
Epoch: 3658, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3659 - Batch 1 ########################
IDs in batch 1: tensor([1678,  426,  917, 3537,  797,  640, 2969, 2125,   35, 1973, 3483, 3216,
        1158, 3022, 2601,  448])
Epoch: 3659, Training Loss: 0.14, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3660 - Batch 1 ########################
IDs in batch 1: tensor([1967, 2827, 1325, 2616,  132, 1781, 1402, 1408,  405, 1748, 2290,  530,
        3632, 3407, 3394, 2196])
Epoch: 3660, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3661 - Batch 1 ########################
IDs in batch 1: tensor([ 723, 2632,  224,  710,  767, 3286,  138, 1955,  278, 1819, 3239, 3339,
         730, 2656, 3443, 2207])
Epoch: 3661, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3662 - Batch 1 ########################
IDs in batch 1: tensor([ 854, 2871,  436,  211, 1182, 2406, 1626,   73, 3962, 3526, 1702, 2368,
        2097, 3336, 3489, 1612])
Epoch: 3662, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3663 - Batch 1 ########################
IDs in batch 1: tensor([3021, 1746, 2090, 1845, 1623, 3962, 1250,  851, 4010, 2761, 1745, 4220,
         687, 2247,  961, 3847])
Epoch: 3663, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3664 - Batch 1 ########################
IDs in batch 1: tensor([3148, 4084, 1004,  625, 3667, 1375, 3757, 1567, 2250,  837, 3109, 1638,
        4172, 1319, 4100, 1490])
Epoch: 3664, Training Loss: 0.15, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3665 - Batch 1 ########################
IDs in batch 1: tensor([2731,  909, 3898, 1052, 2945,  136, 3680, 3381, 2822, 1540, 3159,  963,
        1704,  758, 2715,  555])
Epoch: 3665, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3666 - Batch 1 ########################
IDs in batch 1: tensor([4002, 2463,  234, 3557,  262, 3545, 3552, 2041, 1973, 3733,  454, 1871,
        1639, 2368, 3779, 2323])
Epoch: 3666, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3667 - Batch 1 ########################
IDs in batch 1: tensor([3830, 1568,  287, 3755, 2692,  751,  541, 2800,  844, 3326, 3356,  723,
        1496,  467, 1152, 2253])
Epoch: 3667, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3668 - Batch 1 ########################
IDs in batch 1: tensor([ 879, 3052, 2605,  563,  900, 3936, 1213, 3771, 3132,  505, 4077, 2228,
        1578, 2787, 2564,  131])
Epoch: 3668, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3669 - Batch 1 ########################
IDs in batch 1: tensor([ 612, 3891, 2428, 1605, 1242,  740, 2189, 3349, 4195, 3141,  279,  787,
         771, 4189, 3456, 2489])
Epoch: 3669, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3670 - Batch 1 ########################
IDs in batch 1: tensor([2159,  890, 2133, 3981, 2412,  630, 3783, 2754,   64,  148, 1283,  407,
        1767,  514, 2428, 3995])
Epoch: 3670, Training Loss: 0.01, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3671 - Batch 1 ########################
IDs in batch 1: tensor([3862, 3842, 2660,  819,  340, 4125, 3040,  617, 3025, 2836,  155, 1299,
        3569, 1174, 4190, 3996])
Epoch: 3671, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3672 - Batch 1 ########################
IDs in batch 1: tensor([3308, 3409, 2671, 3882, 2711, 2610,  753,  787,  476, 1918, 1442, 1258,
        1956, 2858, 3706, 2260])
Epoch: 3672, Training Loss: 0.12, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3673 - Batch 1 ########################
IDs in batch 1: tensor([2968, 3018, 2276, 2143,  334, 1247, 3960, 3072, 3846,  122, 4152, 3251,
        2825, 2742, 2572, 1567])
Epoch: 3673, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3674 - Batch 1 ########################
IDs in batch 1: tensor([3461, 1356, 1851,  563, 3950, 1849, 1562, 2463, 2899, 3112, 3323, 3888,
         588, 2551, 3513, 2472])
Epoch: 3674, Training Loss: 0.27, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3675 - Batch 1 ########################
IDs in batch 1: tensor([ 937, 4096, 3367, 2627, 2224,  928, 1878, 1690, 1959, 3675,  260, 2124,
        2370, 2469, 3400, 2300])
Epoch: 3675, Training Loss: 0.23, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3676 - Batch 1 ########################
IDs in batch 1: tensor([ 873, 1979, 2473, 4174, 3439, 3452, 1883, 1878, 3927, 1370, 3429,  377,
         379, 3035, 3943, 1822])
Epoch: 3676, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3677 - Batch 1 ########################
IDs in batch 1: tensor([3433, 3239, 1318,  195, 3330, 2942,   72, 4009, 1082, 2218,  200,  755,
        1942, 2339, 3424, 1899])
Epoch: 3677, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3678 - Batch 1 ########################
IDs in batch 1: tensor([1498, 2210, 2885,  351,  897, 2178, 4204, 1085,  149, 3360,  627, 2435,
         130,  826, 2592, 3762])
Epoch: 3678, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3679 - Batch 1 ########################
IDs in batch 1: tensor([3448, 3329, 3693, 2800,  594, 3497, 3569, 3628, 1452, 2794,  258, 2473,
        3352,  656, 1469, 4075])
Epoch: 3679, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3680 - Batch 1 ########################
IDs in batch 1: tensor([2257, 2676, 1395, 3392, 3118, 1526, 1556, 4002, 2642, 1844,  635, 2870,
          34, 2775, 1456, 3858])
Epoch: 3680, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3681 - Batch 1 ########################
IDs in batch 1: tensor([2516, 3865, 2364, 2924, 3961, 3408, 3702, 4016, 1096, 1506,  436, 2250,
        4134, 3989,  138,  177])
Epoch: 3681, Training Loss: 0.08, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3682 - Batch 1 ########################
IDs in batch 1: tensor([3731, 3704, 3995,  100, 3364,  805, 2373, 3570, 1204, 2349, 4194, 4181,
        1225, 2394,  904, 4256])
Epoch: 3682, Training Loss: 0.13, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3683 - Batch 1 ########################
IDs in batch 1: tensor([3183, 3349, 2998, 1681, 3256,  645,  213,   24, 2914, 3985, 1263, 2004,
        2793, 1322, 2413,  544])
Epoch: 3683, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3684 - Batch 1 ########################
IDs in batch 1: tensor([3858, 2582, 3938, 2110, 3914, 3360, 3926, 3789,  350, 3815, 1496, 2982,
        1525,  838, 3157, 1702])
Epoch: 3684, Training Loss: 0.10, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3685 - Batch 1 ########################
IDs in batch 1: tensor([3098, 1104,  503, 3971, 1088, 1942,   43,  527,  348, 1423,  672,  368,
        2051, 3476, 2040, 3290])
Epoch: 3685, Training Loss: 0.04, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3686 - Batch 1 ########################
IDs in batch 1: tensor([  19, 3378, 1746,  382, 1375, 2632, 1141,  351,  239, 3238,  202, 3544,
         152,   52,  565, 4144])
Epoch: 3686, Training Loss: 0.12, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3687 - Batch 1 ########################
IDs in batch 1: tensor([1498,   95,  283, 2908, 1852, 2090, 3601, 3493, 2901, 2845, 3943, 3908,
        2788, 1066, 3523, 4238])
Epoch: 3687, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3688 - Batch 1 ########################
IDs in batch 1: tensor([  63, 4264, 2610, 3661,  727,  767,  520,  672, 1536, 2368, 3028, 1096,
        4138, 3443, 1052, 1648])
Epoch: 3688, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3689 - Batch 1 ########################
IDs in batch 1: tensor([  59, 3367, 3907, 2081,  255, 4204, 3367, 2561,  368,  221,  588, 1023,
        1054, 3616, 2984, 1563])
Epoch: 3689, Training Loss: 0.07, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3690 - Batch 1 ########################
IDs in batch 1: tensor([3311,  875, 3830, 1155,   63,  530, 1241, 3798, 2496, 3236, 2305, 2030,
        1521, 3743,  822, 2483])
Epoch: 3690, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3691 - Batch 1 ########################
IDs in batch 1: tensor([3728, 2646,  875, 2202, 1630, 1910, 4212,  709, 3654, 3087, 3075,  797,
         622, 2782, 3997, 3591])
Epoch: 3691, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3692 - Batch 1 ########################
IDs in batch 1: tensor([2967, 2417, 3223, 2103, 1730,  110, 1882, 3917, 2664, 1157, 1155, 3984,
        2664, 1755, 1760,  362])
Epoch: 3692, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3693 - Batch 1 ########################
IDs in batch 1: tensor([1270, 1171, 2584,  206, 4096, 3975, 2516, 2690, 3318, 1579, 1104, 1163,
        3705,  736, 2574,  125])
Epoch: 3693, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3694 - Batch 1 ########################
IDs in batch 1: tensor([4072, 1818, 3415, 4266,  257, 1977, 2126,  522,  890, 1948, 3938, 2382,
        3218,  974, 4007,  185])
Epoch: 3694, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3695 - Batch 1 ########################
IDs in batch 1: tensor([ 921, 4199,  449, 1605,  809, 2524, 2925, 3700,  469,  588, 1835,  575,
         485, 3233,  739, 3715])
Epoch: 3695, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3696 - Batch 1 ########################
IDs in batch 1: tensor([3355,  258, 1546,  322, 3982, 2650, 3933, 2506, 4213, 3852,  449, 3117,
         714, 2207, 1984, 3922])
Epoch: 3696, Training Loss: 0.19, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3697 - Batch 1 ########################
IDs in batch 1: tensor([ 974, 3381, 1138, 4166,  512, 1057, 2470,  827, 1380, 1190,  314, 1704,
        2232, 2671, 3338, 2072])
Epoch: 3697, Training Loss: 0.18, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3698 - Batch 1 ########################
IDs in batch 1: tensor([4005, 1026, 3463, 3452, 4181,  343, 3081, 3863, 1037, 2063, 2485,  275,
        2290, 2102, 3471,  303])
Epoch: 3698, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3699 - Batch 1 ########################
IDs in batch 1: tensor([1325, 1193, 1794, 4163, 2347,   39, 3256, 2620, 3364, 4026, 2255, 3000,
        3563, 3337, 2116, 2857])
Epoch: 3699, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3700 - Batch 1 ########################
IDs in batch 1: tensor([ 127, 3029, 3338, 1933,  357,  943, 2241, 3604, 2244, 2153,  914, 2353,
        4035, 3432, 1766, 2996])
Epoch: 3700, Training Loss: 0.09, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3701 - Batch 1 ########################
IDs in batch 1: tensor([ 191, 2246,  954,   82, 3771, 3604, 4016, 1070, 2544, 2545, 1429,  223,
        2678,  960, 3267, 2640])
Epoch: 3701, Training Loss: 0.01, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3702 - Batch 1 ########################
IDs in batch 1: tensor([ 913, 2320, 1409,  694,   46, 1256,  171, 3667, 1882, 3021,  287, 4069,
         343, 3765,  330,  290])
Epoch: 3702, Training Loss: 0.28, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3703 - Batch 1 ########################
IDs in batch 1: tensor([  49, 2541, 2836, 3470, 1365, 2721, 1718,  487, 2805, 3159, 3352, 1158,
         596, 3487,  159, 3222])
Epoch: 3703, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3704 - Batch 1 ########################
IDs in batch 1: tensor([ 205, 2754, 2480, 3529,  830, 2581, 3117, 1731, 3162, 1869, 3152, 1612,
        2796, 2798,  610, 1630])
Epoch: 3704, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3705 - Batch 1 ########################
IDs in batch 1: tensor([ 101, 1320,  100, 3891, 2086, 2003,  587, 1060,  975,  256, 3778,  819,
        1022, 3534,  397, 1798])
Epoch: 3705, Training Loss: 0.26, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3706 - Batch 1 ########################
IDs in batch 1: tensor([ 274, 2949, 1920, 1961, 2419,   51, 2851, 3630, 3950, 2936, 2925,   15,
        3810, 2540, 2772,   70])
Epoch: 3706, Training Loss: 0.04, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3707 - Batch 1 ########################
IDs in batch 1: tensor([1661, 3754, 1553, 1234,  214, 3441, 1030, 3925, 1532, 1044, 3486, 1732,
         855, 1031, 3160, 2226])
Epoch: 3707, Training Loss: 0.37, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3708 - Batch 1 ########################
IDs in batch 1: tensor([2940,  119, 2565,  532, 2248,  170, 2956, 2369, 1311, 1851, 1459,  809,
        3037, 2638, 3452, 1619])
Epoch: 3708, Training Loss: 0.05, Validation Loss: 0.68, accuracy = 0.77
######################## Epoch 3709 - Batch 1 ########################
IDs in batch 1: tensor([2250, 1767, 2161,  236, 3407, 1954, 3160,  181,  792, 3371, 3980, 2579,
         834, 2516, 2220, 3553])
Epoch: 3709, Training Loss: 0.03, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3710 - Batch 1 ########################
IDs in batch 1: tensor([1076, 2492, 1519,  474, 1316, 3677, 1232, 3159, 2464, 3374, 2495,   32,
        2953,  952, 1248, 2706])
Epoch: 3710, Training Loss: 0.01, Validation Loss: 0.67, accuracy = 0.78
######################## Epoch 3711 - Batch 1 ########################
IDs in batch 1: tensor([2544,  477, 1933, 3032, 2150, 2433, 3497, 3969, 3771, 2508, 3440, 2492,
         183,   64, 2234, 3277])
Epoch: 3711, Training Loss: 0.29, Validation Loss: 0.67, accuracy = 0.78
######################## Epoch 3712 - Batch 1 ########################
IDs in batch 1: tensor([1628,  758,  194, 2908, 2370, 3535,  587, 3826,  676, 1767,  795, 3765,
         425, 2473,  517, 2407])
Epoch: 3712, Training Loss: 0.04, Validation Loss: 0.67, accuracy = 0.78
######################## Epoch 3713 - Batch 1 ########################
IDs in batch 1: tensor([2458,  450, 3244, 2937, 4110, 3771, 2963, 2504, 3896, 2169,  990, 3423,
        3124, 2616, 2931, 4254])
Epoch: 3713, Training Loss: 0.39, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3714 - Batch 1 ########################
IDs in batch 1: tensor([3115,  510, 1432, 4226, 1507,  226, 3693, 3211, 1570,  338,   88,  396,
         829, 1796, 1041,  879])
Epoch: 3714, Training Loss: 0.13, Validation Loss: 0.69, accuracy = 0.79
######################## Epoch 3715 - Batch 1 ########################
IDs in batch 1: tensor([ 532,  803,  181,  887, 1316, 3099,  445, 1141, 1137, 3028, 2019, 2947,
        1575,  323, 3252, 3592])
Epoch: 3715, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3716 - Batch 1 ########################
IDs in batch 1: tensor([1454,  991, 3418,  289, 1920, 2509, 1326,  237, 3177, 1833, 1166,  104,
        3141, 4267, 4172, 2934])
Epoch: 3716, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3717 - Batch 1 ########################
IDs in batch 1: tensor([2648,  569, 2963, 3856,  848, 2718, 3492, 2059, 2458, 1810, 2022, 4000,
         191, 1756, 2236, 2376])
Epoch: 3717, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3718 - Batch 1 ########################
IDs in batch 1: tensor([ 409,  140, 2668, 2114, 3977,  949, 3932, 2457, 3582, 2343, 2035, 2063,
        1640, 3117, 1255, 1050])
Epoch: 3718, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3719 - Batch 1 ########################
IDs in batch 1: tensor([3194, 2334, 1072, 2018, 3769,  541, 4187, 3558, 1563,  670, 1778,  278,
        2858, 2917, 1526, 4107])
Epoch: 3719, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3720 - Batch 1 ########################
IDs in batch 1: tensor([3940,  359, 3954, 3459, 3845, 3934, 2725, 3392, 1057,   11, 4256,  871,
        1189, 4249, 1751, 1278])
Epoch: 3720, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3721 - Batch 1 ########################
IDs in batch 1: tensor([ 120, 4126, 4114, 1895, 3973, 1777, 3228, 2462,   62,  724, 2276,  803,
        2562, 1594, 1786, 3345])
Epoch: 3721, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3722 - Batch 1 ########################
IDs in batch 1: tensor([1526,  261,  557, 3754, 3179, 1798, 1343,  946, 1993, 2795, 2957, 4226,
        3246, 1349,  777, 4264])
Epoch: 3722, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3723 - Batch 1 ########################
IDs in batch 1: tensor([3206, 2524, 2189, 1456,  357, 3470, 4213, 3634,    4, 1967, 3729,  884,
        4062, 2015, 1242, 1784])
Epoch: 3723, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3724 - Batch 1 ########################
IDs in batch 1: tensor([4070, 2508, 1644, 1133, 3397, 2053,  452, 2192, 3883, 1258, 2106, 2154,
        1579, 2832,  688, 2372])
Epoch: 3724, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3725 - Batch 1 ########################
IDs in batch 1: tensor([ 767, 1676,   11, 3468, 2002, 1437,   19, 4002, 1765,  401, 3823, 1571,
        3614,  344, 1956, 1601])
Epoch: 3725, Training Loss: 0.25, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3726 - Batch 1 ########################
IDs in batch 1: tensor([1214, 2086, 2616, 4146,  730, 1017, 2027, 2087,  127, 3073, 1316,  125,
        3042, 1811, 3084, 4256])
Epoch: 3726, Training Loss: 0.18, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3727 - Batch 1 ########################
IDs in batch 1: tensor([1626, 1633,  514,  891,  888, 2510, 1986,  456,  476, 1809,  449, 4068,
        3891, 3995, 3105, 1393])
Epoch: 3727, Training Loss: 0.13, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3728 - Batch 1 ########################
IDs in batch 1: tensor([3022, 2073, 2339,   63, 1399,  137, 3782,  356,  152,  531,  105,  357,
        2015,   20, 2732, 3873])
Epoch: 3728, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3729 - Batch 1 ########################
IDs in batch 1: tensor([3388, 4245, 1045,  362, 2113, 1163,  785, 1511,    7, 2440, 1899, 1881,
        1220, 3659, 2586, 2202])
Epoch: 3729, Training Loss: 0.07, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3730 - Batch 1 ########################
IDs in batch 1: tensor([4242,  892, 1878, 2851, 2360, 2090, 4143, 2687, 3970, 1159, 2041, 2899,
        2365, 1673, 3536, 2870])
Epoch: 3730, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3731 - Batch 1 ########################
IDs in batch 1: tensor([2857, 1085,  790, 2420, 1102, 3569,  699, 2131, 1277, 2783, 4096, 3587,
        3112, 3795, 1039, 3119])
Epoch: 3731, Training Loss: 0.02, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3732 - Batch 1 ########################
IDs in batch 1: tensor([1526,  243, 3094, 1049,  787, 2072, 2103,  497, 1345,  717, 1967, 2734,
        2568, 2700, 3760, 2016])
Epoch: 3732, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3733 - Batch 1 ########################
IDs in batch 1: tensor([4214, 1685, 3336, 3178, 3494, 2185, 2452,  980, 3053, 2615, 3015, 3874,
        1330, 2787, 4005, 1620])
Epoch: 3733, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.76
######################## Epoch 3734 - Batch 1 ########################
IDs in batch 1: tensor([ 281,  795,  660, 4258,   11,  897, 2479,  147, 4220, 4172, 3930, 2309,
        4022,  415,  332, 2277])
Epoch: 3734, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3735 - Batch 1 ########################
IDs in batch 1: tensor([3476,  968, 2309, 3398, 3488,  704, 2505, 1471, 2788, 2352,  400, 3357,
        1081, 3702, 2153, 3755])
Epoch: 3735, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.76
######################## Epoch 3736 - Batch 1 ########################
IDs in batch 1: tensor([1798,   18, 1656, 3480, 4032,  971, 3863,  119, 3669, 2067, 2040, 1894,
        2155, 3366,  823, 3057])
Epoch: 3736, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3737 - Batch 1 ########################
IDs in batch 1: tensor([3495, 1822, 1161, 4148, 2111, 1673,  891, 1130, 4007, 4255, 2326, 2650,
        1317, 1456, 3147, 2636])
Epoch: 3737, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3738 - Batch 1 ########################
IDs in batch 1: tensor([2564, 2456, 3739, 3493, 3564,  338, 1642, 3342, 3683,  211,  350,  412,
        3394, 1798, 3440,  141])
Epoch: 3738, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3739 - Batch 1 ########################
IDs in batch 1: tensor([ 534, 3669, 1731, 1402, 1448, 4158, 1767, 4053, 1763, 1585,  908, 2723,
        1720, 3493, 2538,  425])
Epoch: 3739, Training Loss: 0.11, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3740 - Batch 1 ########################
IDs in batch 1: tensor([ 788,  203, 4048, 3841, 4108, 3883, 1454, 2368, 3223, 1332, 4172, 1367,
        2942, 3949, 1443, 2729])
Epoch: 3740, Training Loss: 0.15, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3741 - Batch 1 ########################
IDs in batch 1: tensor([3543,   10, 3999, 2106, 2441, 3987,  902, 3516, 2947, 2913,  884, 3469,
         873, 3885,  879, 3118])
Epoch: 3741, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3742 - Batch 1 ########################
IDs in batch 1: tensor([3858, 2003, 1764,  712, 1576, 1143, 3126, 1208, 2432, 1022,  996, 1103,
        3524, 1885, 2133, 4011])
Epoch: 3742, Training Loss: 0.04, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3743 - Batch 1 ########################
IDs in batch 1: tensor([ 494, 2564, 3344, 2659, 4065, 2968, 1810, 2102, 3010, 2172, 1309,  968,
          46, 3447, 2067, 2810])
Epoch: 3743, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3744 - Batch 1 ########################
IDs in batch 1: tensor([1291, 3448,  141, 2582, 3853,   28,   42, 2464, 1158,  788, 3326, 4198,
        3484,  255, 1385, 1678])
Epoch: 3744, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.76
######################## Epoch 3745 - Batch 1 ########################
IDs in batch 1: tensor([1201, 3528, 2402, 2872, 1852, 1723, 2225, 2674, 1761, 3847, 2991, 1276,
         699, 1167,  530,  924])
Epoch: 3745, Training Loss: 0.10, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3746 - Batch 1 ########################
IDs in batch 1: tensor([3787,  305, 3636, 3689, 2646, 1346, 3577, 1844, 3751, 3060, 3808, 2794,
        1672, 4264, 3091, 1728])
Epoch: 3746, Training Loss: 0.12, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3747 - Batch 1 ########################
IDs in batch 1: tensor([3697, 3214, 3881, 2010, 4212, 2225, 2874,  335, 1421, 3326, 3939, 4240,
        1153, 3677, 4017, 1762])
Epoch: 3747, Training Loss: 0.11, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3748 - Batch 1 ########################
IDs in batch 1: tensor([   4, 2196, 2656, 1537,  918, 3833, 2473,  827, 3044, 4015, 1027, 3031,
         152, 2485, 2837, 1660])
Epoch: 3748, Training Loss: 0.05, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3749 - Batch 1 ########################
IDs in batch 1: tensor([3401, 1984, 1235, 1008, 3771, 3092, 1369,  384, 2458,   85, 1360, 2563,
        1361,  710, 2535, 1221])
Epoch: 3749, Training Loss: 0.12, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3750 - Batch 1 ########################
IDs in batch 1: tensor([ 646,  980,  399, 1573, 2845, 3073, 3414, 3025, 3166, 1045,  258, 3435,
         350,  924, 2932, 3862])
Epoch: 3750, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3751 - Batch 1 ########################
IDs in batch 1: tensor([  37,  452,  398, 1882, 3071,  482, 2619, 3568,  827, 3763,  640, 1952,
        3492, 3833,  487, 1954])
Epoch: 3751, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3752 - Batch 1 ########################
IDs in batch 1: tensor([3058, 3441,  388, 1121, 2247, 3077,  351,  422,  858, 3357, 4089, 1793,
        1171, 1965, 3531, 2228])
Epoch: 3752, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3753 - Batch 1 ########################
IDs in batch 1: tensor([1673, 1573, 2561,  963, 2895, 3660, 2485, 3220,   41, 3029,  126, 3217,
        1880, 3031, 2406, 3267])
Epoch: 3753, Training Loss: 0.04, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3754 - Batch 1 ########################
IDs in batch 1: tensor([2497,  930, 1877, 4080,  892, 3390, 3688,  615, 3400, 1291,  122, 4268,
        3713,  552, 3017, 1935])
Epoch: 3754, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3755 - Batch 1 ########################
IDs in batch 1: tensor([ 173,   64, 2258, 3968,  739, 1275, 2824, 1480, 3656,  139, 4220, 3951,
        2357, 3743,  260, 2046])
Epoch: 3755, Training Loss: 0.07, Validation Loss: 0.69, accuracy = 0.77
######################## Epoch 3756 - Batch 1 ########################
IDs in batch 1: tensor([3536, 3837, 2999, 3783, 2401, 3895, 2624, 2223,  228, 3671, 3407,  572,
        1137, 3156, 3567, 1836])
Epoch: 3756, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3757 - Batch 1 ########################
IDs in batch 1: tensor([1032, 1186, 2841,  135,  874, 3206, 1601, 2784, 1306, 1073, 1731, 1274,
        1168,  113, 2489, 3110])
Epoch: 3757, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3758 - Batch 1 ########################
IDs in batch 1: tensor([  47, 2246, 3975, 2113, 2447, 1948, 3120,  591, 2153,  778, 2291,  159,
        2301, 3936, 1133, 2323])
Epoch: 3758, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3759 - Batch 1 ########################
IDs in batch 1: tensor([3695, 2470,  377, 2371, 2031, 2015, 1437, 3384,  569, 1804, 1965,  280,
        1316,  344, 3428, 1887])
Epoch: 3759, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3760 - Batch 1 ########################
IDs in batch 1: tensor([2276,  237, 1932, 2154, 1030, 1712,  470,  503,  125, 1796, 2629, 1448,
        3600,  237, 2810,  355])
Epoch: 3760, Training Loss: 0.15, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3761 - Batch 1 ########################
IDs in batch 1: tensor([ 499, 3803, 1056, 1780, 2640,  904, 1849, 3083,  351, 3083,  295, 1920,
        1042, 2189,  275,  797])
Epoch: 3761, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3762 - Batch 1 ########################
IDs in batch 1: tensor([  19,  306, 2316, 2314, 1408, 2740, 3524, 2842, 3100, 1278, 3304, 1817,
        3701, 3531,  891, 1718])
Epoch: 3762, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3763 - Batch 1 ########################
IDs in batch 1: tensor([1571,  961,  944, 1057, 3961, 1956, 3781, 2621, 1034,  627, 2618, 2342,
         858, 1464, 2624, 2498])
Epoch: 3763, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3764 - Batch 1 ########################
IDs in batch 1: tensor([  31, 1822, 1526, 4088,  200,  666, 3935, 2863, 1370, 1166,  312, 1658,
        2954,  987, 2967, 3031])
Epoch: 3764, Training Loss: 0.29, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3765 - Batch 1 ########################
IDs in batch 1: tensor([3656,  838, 3130, 4227, 1699, 1185, 2789, 2247,  348, 2523, 1476, 3883,
         770, 1546,  790,  665])
Epoch: 3765, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3766 - Batch 1 ########################
IDs in batch 1: tensor([3100,    4, 3973, 3717, 3398, 3714, 2798, 2050,  891, 3148, 2506, 1490,
        1321, 3529, 1855, 2439])
Epoch: 3766, Training Loss: 0.08, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3767 - Batch 1 ########################
IDs in batch 1: tensor([ 266, 1179,   77, 2668, 2177, 1481,  514,  402, 2359, 3760, 3010, 1897,
         857,  645, 2235, 3136])
Epoch: 3767, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3768 - Batch 1 ########################
IDs in batch 1: tensor([4238, 3252,  312, 2148, 3557, 1045, 2156, 1234,  465, 3329, 3235,  955,
        2343,  652, 1052, 2376])
Epoch: 3768, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3769 - Batch 1 ########################
IDs in batch 1: tensor([ 393, 4120, 1286, 1273, 2672, 2667, 3432,  181,  394,  129, 3426, 2624,
          38, 3029, 4258,  687])
Epoch: 3769, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3770 - Batch 1 ########################
IDs in batch 1: tensor([3178,  277, 2016, 3265,  109,   38,  582, 4032,  572, 3179, 1224, 2447,
        3664,  512, 2668,  821])
Epoch: 3770, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3771 - Batch 1 ########################
IDs in batch 1: tensor([3330, 3509, 4190, 3255, 3121, 2431,  451, 3406, 3530, 3951, 4082, 2315,
        4120, 2329, 1570, 3712])
Epoch: 3771, Training Loss: 0.17, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3772 - Batch 1 ########################
IDs in batch 1: tensor([1920, 3862, 1484,  657, 3856,  279, 4234, 3588, 2856, 4135, 1849, 2367,
        3928,   95, 1383,  891])
Epoch: 3772, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3773 - Batch 1 ########################
IDs in batch 1: tensor([3553, 1509,  635,  483, 3371,  139, 1326, 3803, 3452, 2443, 4267, 2521,
        1345,  926, 2091, 1179])
Epoch: 3773, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3774 - Batch 1 ########################
IDs in batch 1: tensor([  43, 4008, 1702, 2023, 3719, 2912, 3142, 3088, 4135, 3340, 1190, 3528,
        3621,  149,  415, 3473])
Epoch: 3774, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3775 - Batch 1 ########################
IDs in batch 1: tensor([ 193, 1222, 1963, 1084, 2810, 3994, 1596, 3885, 2412, 3932, 1858, 2285,
        1324, 3538, 2737, 2235])
Epoch: 3775, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3776 - Batch 1 ########################
IDs in batch 1: tensor([1600,  149, 3632,  369,  659, 3121, 3757, 2678, 3394, 3831, 2275, 3728,
         699, 1264, 3663, 3617])
Epoch: 3776, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3777 - Batch 1 ########################
IDs in batch 1: tensor([2041, 3336, 2403,  595,  262,  924,  794, 2780, 1226, 1214, 3075, 2150,
        3984,  777,  639, 3355])
Epoch: 3777, Training Loss: 0.27, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3778 - Batch 1 ########################
IDs in batch 1: tensor([ 243, 1331,  135, 3279,  127, 4094, 1819, 2809, 3843, 2406, 1951, 3040,
          52, 3922, 2073, 1361])
Epoch: 3778, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3779 - Batch 1 ########################
IDs in batch 1: tensor([3100, 1718, 1471, 3311, 1999, 2996, 3705, 3060, 3528,  422,  584,  399,
        1526, 4065, 3873, 2391])
Epoch: 3779, Training Loss: 0.02, Validation Loss: 0.70, accuracy = 0.79
######################## Epoch 3780 - Batch 1 ########################
IDs in batch 1: tensor([3479,  412, 3707,  594, 1216, 3300,  955,  237, 2620, 1899,  606,  758,
        3998, 1376, 2017, 2851])
Epoch: 3780, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3781 - Batch 1 ########################
IDs in batch 1: tensor([3888, 2323, 2482,  303,  735, 3156, 1116, 3200, 2480, 2919, 3132, 1110,
        3705, 2423, 2378, 3444])
Epoch: 3781, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3782 - Batch 1 ########################
IDs in batch 1: tensor([3483, 1199,  141, 3935, 2009,  220,  918, 4016, 3927, 1812, 3087, 2936,
        4194, 1886, 3894,  219])
Epoch: 3782, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3783 - Batch 1 ########################
IDs in batch 1: tensor([2462, 4196, 4149,  408,  441,  417, 1955, 1023, 2693, 3529, 4007, 3376,
        1425, 2225, 1111, 1794])
Epoch: 3783, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3784 - Batch 1 ########################
IDs in batch 1: tensor([ 970, 2919, 3527, 3388, 2414,  360, 2907,  393, 2804, 1103, 1305,  516,
        1681, 3719, 1810,  191])
Epoch: 3784, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3785 - Batch 1 ########################
IDs in batch 1: tensor([ 508,  699, 1281, 1635,  887, 1734, 4246, 4009,  921, 2261,  407, 2376,
        3399, 1267, 2822, 3513])
Epoch: 3785, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3786 - Batch 1 ########################
IDs in batch 1: tensor([ 130, 2672,  582, 3177, 3833, 3608, 2644, 1450, 2894, 1334, 2246, 2040,
         558, 3384, 2938, 1803])
Epoch: 3786, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3787 - Batch 1 ########################
IDs in batch 1: tensor([ 485, 4215, 1340, 3934, 2224, 2905, 2840, 4053,   52, 3202, 1336, 2313,
        1828, 3287,  284, 3018])
Epoch: 3787, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3788 - Batch 1 ########################
IDs in batch 1: tensor([2986, 3370, 2123, 4166, 1118, 3581,  819, 2213, 2370,  348, 2683,  956,
        4253,   18, 4266, 2964])
Epoch: 3788, Training Loss: 0.14, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3789 - Batch 1 ########################
IDs in batch 1: tensor([3997, 2649,  450, 2817, 2448, 3239,  590,  573, 2391,  763, 1639,  538,
        1490, 2773, 1197, 3628])
Epoch: 3789, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3790 - Batch 1 ########################
IDs in batch 1: tensor([2078, 1113, 1675, 4118, 1685, 2606, 3304, 3781,  167, 2579, 2418, 1404,
        4058, 1067, 2347, 2477])
Epoch: 3790, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3791 - Batch 1 ########################
IDs in batch 1: tensor([1842,  143,  878, 2213, 3444, 3980,  855, 3408, 1845, 1235, 1866, 2014,
        3235, 2915,  863, 1496])
Epoch: 3791, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3792 - Batch 1 ########################
IDs in batch 1: tensor([2921, 3991,  532, 2819, 3298, 3822,  701, 3028, 2085, 4031,  488, 2094,
        4037, 3407, 3144,  312])
Epoch: 3792, Training Loss: 0.24, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3793 - Batch 1 ########################
IDs in batch 1: tensor([2378, 2578, 3755,  430, 1045, 2996,  238, 2616, 1630, 1822, 3808, 2011,
         442, 4223, 3632, 2025])
Epoch: 3793, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3794 - Batch 1 ########################
IDs in batch 1: tensor([1228, 4172, 3829, 2166,  503, 1555, 3743,   70,  300, 2644, 1428, 1458,
        1657, 3277, 2819, 2027])
Epoch: 3794, Training Loss: 0.02, Validation Loss: 0.77, accuracy = 0.77
######################## Epoch 3795 - Batch 1 ########################
IDs in batch 1: tensor([1927,  945, 2444, 1168, 3037, 1248, 3398, 1027, 1965, 3481, 4235, 1746,
        1087, 2452,  713, 2028])
Epoch: 3795, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3796 - Batch 1 ########################
IDs in batch 1: tensor([1699, 3882,  393,  617, 3746, 4215, 3004, 2614,  642, 2617, 3131, 2956,
        2148, 2703, 2996, 2313])
Epoch: 3796, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3797 - Batch 1 ########################
IDs in batch 1: tensor([1559,  136, 2284, 3588,  674, 2413, 4268, 1409,  776, 1330, 4080, 3166,
        2205, 4268, 2844, 4118])
Epoch: 3797, Training Loss: 0.01, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3798 - Batch 1 ########################
IDs in batch 1: tensor([ 380, 3441,  196, 1530, 4068, 2582,  606, 1553,   78, 3885, 2172,  413,
        2286,  456, 4204, 1480])
Epoch: 3798, Training Loss: 0.16, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3799 - Batch 1 ########################
IDs in batch 1: tensor([1472, 2185, 3749, 4038, 2236, 3098, 2423, 1464, 3870,  974, 2115, 3458,
        2498,  137, 2693,   22])
Epoch: 3799, Training Loss: 0.06, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3800 - Batch 1 ########################
IDs in batch 1: tensor([ 992,  682, 2357, 3309,  441, 2148, 1665, 3660, 3782,  835, 3518, 1851,
        2761, 1285, 2901, 1081])
Epoch: 3800, Training Loss: 0.02, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3801 - Batch 1 ########################
IDs in batch 1: tensor([1958, 4263,  269, 4006, 3081, 2964, 2733, 1866, 1218, 3779, 1495, 3745,
        1052, 3660, 3812, 2869])
Epoch: 3801, Training Loss: 0.14, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3802 - Batch 1 ########################
IDs in batch 1: tensor([3182, 1299, 2171,  102, 2498,  923, 2385,  362, 1751, 2154, 3822, 2943,
        1496, 4176,  863, 2388])
Epoch: 3802, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3803 - Batch 1 ########################
IDs in batch 1: tensor([1526, 1476,  318, 1568, 3572, 3592,  644, 2011, 1552, 1592, 1855, 3669,
        3658,  920, 2369, 3139])
Epoch: 3803, Training Loss: 0.09, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3804 - Batch 1 ########################
IDs in batch 1: tensor([3136,  283, 1913, 1132,  678, 1568,  106, 1716, 1886, 1344, 3675, 3311,
         989, 2848, 2998, 1157])
Epoch: 3804, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3805 - Batch 1 ########################
IDs in batch 1: tensor([1220,  214, 1784, 1224, 3427, 2327, 3672, 1552, 3810, 1530, 3473, 3790,
        3643, 1752, 1237, 4108])
Epoch: 3805, Training Loss: 0.13, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3806 - Batch 1 ########################
IDs in batch 1: tensor([4135, 2914, 1976, 1772, 3459,  587, 1836,  150, 1066,  595, 1062, 1349,
        1363,  373,  607, 1540])
Epoch: 3806, Training Loss: 0.51, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3807 - Batch 1 ########################
IDs in batch 1: tensor([3475,  251, 1720,   64, 1153, 2469, 1999, 1453, 4114, 3495,   26, 3841,
        2542, 4163, 2775, 1369])
Epoch: 3807, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3808 - Batch 1 ########################
IDs in batch 1: tensor([ 917, 2575, 4010, 2827, 3839, 2015, 2715, 2725, 1093, 3472, 1231, 2619,
         250,   68,  283, 4246])
Epoch: 3808, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3809 - Batch 1 ########################
IDs in batch 1: tensor([2260, 1380, 2646, 2416, 4061,   39, 2025, 1168,  883,  639, 1686, 1736,
         775, 2195,  788,  657])
Epoch: 3809, Training Loss: 0.12, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3810 - Batch 1 ########################
IDs in batch 1: tensor([2974,  252, 1640, 1556, 1104, 2604, 3421, 2555, 1066, 2452, 2595, 3549,
         501, 3647, 3897, 2709])
Epoch: 3810, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3811 - Batch 1 ########################
IDs in batch 1: tensor([3005, 1803, 1335, 4113, 1396, 1646, 3374, 2027,  368, 1080, 1023, 1899,
        3568, 2347, 4113, 3531])
Epoch: 3811, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3812 - Batch 1 ########################
IDs in batch 1: tensor([3397, 1004, 2540, 1457, 3150,   57,  792, 1956, 2577, 2125, 3563, 1480,
        3601, 2190, 3711, 2644])
Epoch: 3812, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3813 - Batch 1 ########################
IDs in batch 1: tensor([1573, 1097, 1896,  895, 2429,  985, 1228, 2464, 3381, 3886, 3865, 3767,
        1712, 3968, 1182,  645])
Epoch: 3813, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3814 - Batch 1 ########################
IDs in batch 1: tensor([ 915, 1423, 1823, 3430, 2892, 1686, 3727,  225, 1193,   82, 2036,  887,
        2499, 3953, 2591,  483])
Epoch: 3814, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3815 - Batch 1 ########################
IDs in batch 1: tensor([1242,  727, 1118,  496, 3764, 1678, 3577,  187, 1180, 3244, 2135, 2737,
        1886, 2540, 3252, 3447])
Epoch: 3815, Training Loss: 0.18, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3816 - Batch 1 ########################
IDs in batch 1: tensor([3284, 1041, 1708, 1277,  326, 1143, 4087, 4261, 2024, 4087,   85, 1627,
        2265, 3474, 1439, 2117])
Epoch: 3816, Training Loss: 0.11, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3817 - Batch 1 ########################
IDs in batch 1: tensor([ 474, 3526, 1897, 3253, 3577, 1623, 1201, 2589, 1017, 2468, 2420,  626,
        1752, 2642,  829, 4062])
Epoch: 3817, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3818 - Batch 1 ########################
IDs in batch 1: tensor([2193, 1044, 3242, 1766, 2122, 1716, 1309, 2449, 3290, 3487,  610, 1918,
         569, 3934, 1223, 3846])
Epoch: 3818, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3819 - Batch 1 ########################
IDs in batch 1: tensor([2643, 2676, 1642, 1231, 3952, 3009, 1489, 4136,  814, 3031, 2272,  323,
        1761, 4062, 1885, 3330])
Epoch: 3819, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3820 - Batch 1 ########################
IDs in batch 1: tensor([ 635, 2098, 3583, 2301,  110,  182,  281, 3133, 4087, 1452, 2375,   38,
        2598,  816, 1853,  789])
Epoch: 3820, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3821 - Batch 1 ########################
IDs in batch 1: tensor([ 132, 2261, 4258, 4011, 1124, 3020, 2489, 1026, 3913,  812, 3812, 2253,
        2970, 2859, 2755, 1737])
Epoch: 3821, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3822 - Batch 1 ########################
IDs in batch 1: tensor([1084, 1740, 1501, 1404,  565, 1657, 3518,  757, 2905, 2385, 2842, 1437,
        3947, 2516, 1015,  318])
Epoch: 3822, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3823 - Batch 1 ########################
IDs in batch 1: tensor([1406,  741, 1084, 1076, 4082,   28, 1096,  148,  488,  653, 2687, 1070,
         622, 1387, 2974,  354])
Epoch: 3823, Training Loss: 0.53, Validation Loss: 0.72, accuracy = 0.79
######################## Epoch 3824 - Batch 1 ########################
IDs in batch 1: tensor([ 190, 1039, 4232, 1351,  111, 2313, 1365,  739, 2688, 2831, 3707, 1767,
         505, 3754, 4070, 2306])
Epoch: 3824, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3825 - Batch 1 ########################
IDs in batch 1: tensor([1984, 3871, 3964, 3643, 1706, 2741, 2882, 3180, 4223, 2614, 1632, 3250,
        4185,  282, 3969, 3717])
Epoch: 3825, Training Loss: 0.15, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3826 - Batch 1 ########################
IDs in batch 1: tensor([ 832, 2690, 1853, 1804,  200, 2406, 2091, 1625, 2854,  207, 2324, 3022,
        2309, 3632, 2359,  316])
Epoch: 3826, Training Loss: 0.41, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3827 - Batch 1 ########################
IDs in batch 1: tensor([4072, 3438, 3897, 1545, 2824, 4026, 3660, 2627, 2237, 4254, 2498, 2508,
          73, 4172,  652, 2155])
Epoch: 3827, Training Loss: 0.17, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3828 - Batch 1 ########################
IDs in batch 1: tensor([3762, 3133, 3795, 3925, 3704, 4015, 2915, 1861, 1409, 3222, 3309, 3182,
        2440, 2836, 4136,  541])
Epoch: 3828, Training Loss: 0.30, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3829 - Batch 1 ########################
IDs in batch 1: tensor([1570, 1404, 3183, 1330,  140,  981,  136, 2372, 3355, 2457, 1065,  523,
        4044, 2701, 1341, 3912])
Epoch: 3829, Training Loss: 0.01, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3830 - Batch 1 ########################
IDs in batch 1: tensor([ 167,  437, 1740,  863,  357,  595, 1892, 2931, 3751, 3971, 3954, 1571,
        2619, 2620, 3598,  988])
Epoch: 3830, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3831 - Batch 1 ########################
IDs in batch 1: tensor([ 252, 3837, 4033, 1003,   20, 2646, 3255, 2603, 2643,  256, 3211,  463,
         132,  537, 1292, 4088])
Epoch: 3831, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3832 - Batch 1 ########################
IDs in batch 1: tensor([1044,  132, 1032, 4000,  986, 2882, 2249, 3329,   28,  871, 3841,  693,
        1182, 2133, 3142, 2511])
Epoch: 3832, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3833 - Batch 1 ########################
IDs in batch 1: tensor([2183, 2425,  522, 3271, 3675,  689,  130,  275, 1305, 3987,  256,  915,
        1235, 2315, 1015, 1512])
Epoch: 3833, Training Loss: 0.03, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3834 - Batch 1 ########################
IDs in batch 1: tensor([3902,  682,  729, 3386, 1498, 3971, 2500,  788, 1144,  436, 3642, 1610,
        3990, 3360, 3942, 3290])
Epoch: 3834, Training Loss: 0.06, Validation Loss: 0.68, accuracy = 0.78
######################## Epoch 3835 - Batch 1 ########################
IDs in batch 1: tensor([4225, 3115,  582, 4174, 4188,  245,  595, 1668, 2667, 2099,  526, 3133,
        2416,   95,   84, 2804])
Epoch: 3835, Training Loss: 0.08, Validation Loss: 0.69, accuracy = 0.79
######################## Epoch 3836 - Batch 1 ########################
IDs in batch 1: tensor([3939,  968, 4190,  572, 3088, 2428, 2913, 4016, 1464,  904, 2258, 1818,
        3699,  649, 2777,  539])
Epoch: 3836, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3837 - Batch 1 ########################
IDs in batch 1: tensor([1384,  779, 3015, 3203,  788, 2739, 4026, 1568, 3242, 2645,  917, 1440,
        3480, 3831, 1499,  398])
Epoch: 3837, Training Loss: 0.09, Validation Loss: 0.68, accuracy = 0.79
######################## Epoch 3838 - Batch 1 ########################
IDs in batch 1: tensor([2688, 4011, 1144, 3952, 2132,  252,  305, 2044, 2116, 1024, 2894,  936,
        2550, 4136, 2457, 3049])
Epoch: 3838, Training Loss: 0.09, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3839 - Batch 1 ########################
IDs in batch 1: tensor([2131, 2331,  324, 1197,  403, 3406,  533,   96,  211, 2137, 2300, 1927,
        2822, 2629, 2271,  437])
Epoch: 3839, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3840 - Batch 1 ########################
IDs in batch 1: tensor([1391, 3536,  312, 3290,  689, 1828, 2978, 2028,  463, 2249, 1463, 2459,
        3669, 2908, 3024, 1070])
Epoch: 3840, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3841 - Batch 1 ########################
IDs in batch 1: tensor([3389, 1153, 2732, 1302, 3151, 2731,  395, 2564, 2809, 3818,  544, 3211,
        2536,  526,  622, 2682])
Epoch: 3841, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3842 - Batch 1 ########################
IDs in batch 1: tensor([1775, 2656, 3905, 1138, 3816, 1103,  269,  788, 3832, 1655, 2492, 1170,
         264, 1284,  771, 3732])
Epoch: 3842, Training Loss: 0.07, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3843 - Batch 1 ########################
IDs in batch 1: tensor([2511,   84, 1521, 1330, 1834, 1796,   73, 1746, 2439, 3353, 1102, 1193,
         687, 2976, 3352, 1641])
Epoch: 3843, Training Loss: 0.06, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3844 - Batch 1 ########################
IDs in batch 1: tensor([1498, 3363, 2931, 1841, 2080, 1655, 1764, 3960, 2356, 3760,  367, 4242,
        3117, 3373,   47, 4261])
Epoch: 3844, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3845 - Batch 1 ########################
IDs in batch 1: tensor([3998, 2823, 4225,  712, 2111, 3604,  769, 1590, 1990,  413, 2236, 2224,
          70,  591, 3259, 3208])
Epoch: 3845, Training Loss: 0.01, Validation Loss: 0.69, accuracy = 0.78
######################## Epoch 3846 - Batch 1 ########################
IDs in batch 1: tensor([1437, 3996, 4188, 2655, 2883, 3972, 2727,  953, 2203, 2937,  850, 3900,
        3354,  289, 2230, 1857])
Epoch: 3846, Training Loss: 0.30, Validation Loss: 0.70, accuracy = 0.78
######################## Epoch 3847 - Batch 1 ########################
IDs in batch 1: tensor([1869, 3507, 1775, 3497,   97, 2065, 1391,  767,  187,  752, 1356, 1818,
        3618, 1451, 4080, 1927])
Epoch: 3847, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3848 - Batch 1 ########################
IDs in batch 1: tensor([2286,  824,  946, 2802, 4018,  148, 3162, 1345, 3531, 2203, 3553, 1055,
        1708,  582, 4158,   31])
Epoch: 3848, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3849 - Batch 1 ########################
IDs in batch 1: tensor([1521, 3469, 1213, 2039,   82, 4236, 2072,  770, 3850,  418,  207,  263,
         322, 2403,  755,  612])
Epoch: 3849, Training Loss: 0.22, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3850 - Batch 1 ########################
IDs in batch 1: tensor([ 920,  658, 1752, 1028, 2810, 2005, 2667, 4078, 3870, 3410, 4235, 3782,
        2514, 3105, 2921, 2355])
Epoch: 3850, Training Loss: 0.12, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3851 - Batch 1 ########################
IDs in batch 1: tensor([1325, 2322,  108, 3739, 3851, 2682,   96, 1728, 3832, 1198, 2552, 1244,
        1728, 2742, 1499,  527])
Epoch: 3851, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3852 - Batch 1 ########################
IDs in batch 1: tensor([ 105, 1699, 3594, 2419, 4261, 3465, 2937, 2739,  105, 1649, 3660, 2171,
         377, 1319, 2034, 3177])
Epoch: 3852, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3853 - Batch 1 ########################
IDs in batch 1: tensor([2857, 2339,  789, 2382, 2350, 1356, 1455, 2315, 2188, 2023,  387,  553,
        3810, 3219, 2095, 1646])
Epoch: 3853, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3854 - Batch 1 ########################
IDs in batch 1: tensor([2886, 3022, 3313,  656,  508,  583, 1828, 3592, 1216, 2989, 2957, 2016,
        1490, 2767, 2097, 1156])
Epoch: 3854, Training Loss: 0.11, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3855 - Batch 1 ########################
IDs in batch 1: tensor([2854, 2666, 1779,  136, 2327, 3264, 3264, 3572, 1199, 2663, 1385,  811,
        1047, 3429, 4099, 1063])
Epoch: 3855, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3856 - Batch 1 ########################
IDs in batch 1: tensor([ 539, 3718,   18, 2296, 2181, 2871, 3208, 4134, 2835,  321, 4143,  402,
        2121,  757, 2718,  573])
Epoch: 3856, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3857 - Batch 1 ########################
IDs in batch 1: tensor([1500, 1059, 2401, 2190, 4141, 3139, 2115, 1286, 3642, 4256, 3683,  593,
        1041,  511, 1439, 3841])
Epoch: 3857, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3858 - Batch 1 ########################
IDs in batch 1: tensor([  52, 2743, 1951,  514,  553, 3282, 3599, 2583,  484,  944, 2334, 3279,
        4038, 4180, 2815,  942])
Epoch: 3858, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3859 - Batch 1 ########################
IDs in batch 1: tensor([2723,  996, 1596, 3309, 1959, 3970,  982, 4121,  424, 1038,  854, 2760,
        1306, 2574,  325, 3126])
Epoch: 3859, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3860 - Batch 1 ########################
IDs in batch 1: tensor([ 405, 3592, 2579, 1826,  550, 2102, 3570, 3771, 1821, 3023, 1467, 3009,
        1536, 2737, 3599, 1065])
Epoch: 3860, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3861 - Batch 1 ########################
IDs in batch 1: tensor([2538, 4033, 2732,  829, 2179, 1496, 2133, 1120, 1110, 2524, 2835, 2500,
        3689, 2499, 2667, 3749])
Epoch: 3861, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3862 - Batch 1 ########################
IDs in batch 1: tensor([4185, 2710, 1297, 3807, 2207, 1276, 3536, 4069, 2915,  855,  751, 2908,
        2456, 2882,  985,  689])
Epoch: 3862, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3863 - Batch 1 ########################
IDs in batch 1: tensor([2285, 3990, 2355, 1869,  196, 4100, 1037, 2708, 2437, 3573, 1746, 3381,
        3024, 1650, 2848, 1530])
Epoch: 3863, Training Loss: 0.08, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3864 - Batch 1 ########################
IDs in batch 1: tensor([ 256, 3039, 2695, 1146,  225, 1281,  578, 3449, 2706, 1955, 2844, 1525,
        3772, 3492, 2492, 1894])
Epoch: 3864, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3865 - Batch 1 ########################
IDs in batch 1: tensor([2167, 2590,  978, 1470, 3583, 2870, 3996,  471, 1786, 1073, 1077, 4212,
        4217, 1883, 3101,   31])
Epoch: 3865, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3866 - Batch 1 ########################
IDs in batch 1: tensor([3291,  852,   44,  415, 1010, 2238, 2788,  834, 3027, 2616, 3318, 3926,
         450, 2099, 2366, 1975])
Epoch: 3866, Training Loss: 0.17, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3867 - Batch 1 ########################
IDs in batch 1: tensor([3384, 3192, 2124, 2822, 3994, 1008, 1097, 1559, 1242, 2688, 2782, 3503,
        3740,  832, 3283, 3875])
Epoch: 3867, Training Loss: 0.06, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3868 - Batch 1 ########################
IDs in batch 1: tensor([1005, 1808, 3484, 2127, 2063, 2966,  864, 2924,  135, 3721, 2849, 3836,
        3130, 1817, 1711,   56])
Epoch: 3868, Training Loss: 0.09, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3869 - Batch 1 ########################
IDs in batch 1: tensor([3282, 3465, 3954, 2022, 3607,  505,  444, 1003, 3786,  361, 1698, 3782,
        1347, 1699,   56, 4031])
Epoch: 3869, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3870 - Batch 1 ########################
IDs in batch 1: tensor([2232,  605, 3616, 1312, 1309, 1075, 1817, 2552, 3414, 2876, 3856, 1657,
        1962, 2902,  173,  967])
Epoch: 3870, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3871 - Batch 1 ########################
IDs in batch 1: tensor([1810, 3803, 2538, 2604,  262,  976, 2708, 1320, 3452,  214,  340, 4159,
         103, 3132, 1937, 2081])
Epoch: 3871, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3872 - Batch 1 ########################
IDs in batch 1: tensor([2891,  665, 3577, 1219, 1252,  395, 2907, 1570, 2934, 1707, 2429, 2451,
        4120, 2203, 1144, 2518])
Epoch: 3872, Training Loss: 0.05, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3873 - Batch 1 ########################
IDs in batch 1: tensor([2242, 2826, 2370, 2867, 4024, 1069,  992,  946, 1789, 2715, 3734,  154,
        2514,  930,  102,  956])
Epoch: 3873, Training Loss: 0.04, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3874 - Batch 1 ########################
IDs in batch 1: tensor([ 459,  141, 2157, 1082,  563, 2473, 3787,  991, 3827, 1085, 1045, 1176,
        3020,  732,  220,   25])
Epoch: 3874, Training Loss: 0.20, Validation Loss: 0.78, accuracy = 0.75
######################## Epoch 3875 - Batch 1 ########################
IDs in batch 1: tensor([2210, 2857, 3672, 1495,  522, 2627, 2609,  452,  983, 1663, 2390, 1999,
        2562, 2090, 1668, 1836])
Epoch: 3875, Training Loss: 0.03, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3876 - Batch 1 ########################
IDs in batch 1: tensor([3504, 3192,  323,   10, 2331,  187, 2441, 4240, 3640,  620,  488, 3895,
        2773,  173,  451,  771])
Epoch: 3876, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3877 - Batch 1 ########################
IDs in batch 1: tensor([1251, 3181, 3925, 2990, 3352, 2800, 1803,  926, 3570, 4018,  164, 1509,
         555, 1640, 3795, 3180])
Epoch: 3877, Training Loss: 0.06, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3878 - Batch 1 ########################
IDs in batch 1: tensor([1173, 1973, 4003, 1082, 3900, 2028, 1918, 2075, 4082,  200, 3206, 3256,
        2804, 3475,  256,  459])
Epoch: 3878, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3879 - Batch 1 ########################
IDs in batch 1: tensor([3144, 3259,  988, 3710, 1396, 3404, 2065, 4099, 2640,  263, 3837, 1351,
          56, 1426, 1975,  583])
Epoch: 3879, Training Loss: 0.04, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3880 - Batch 1 ########################
IDs in batch 1: tensor([3500, 2548,  529, 3826, 3377, 2949, 3448, 4113, 2700, 2812,  699,  330,
        2770, 2991,   93,   63])
Epoch: 3880, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.74
######################## Epoch 3881 - Batch 1 ########################
IDs in batch 1: tensor([1237, 1279, 1324, 1405,  857, 2298, 3683, 2099,  512, 1677, 3658, 3727,
        1884, 3905,  260,  646])
Epoch: 3881, Training Loss: 0.10, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3882 - Batch 1 ########################
IDs in batch 1: tensor([1459, 1457, 1913, 3652, 3135, 2537, 3975, 1242, 2521,  394, 1628, 3527,
        1782,  660, 3458,  775])
Epoch: 3882, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3883 - Batch 1 ########################
IDs in batch 1: tensor([1944, 3020, 1716, 3443, 2035,  869, 2643, 1371, 1364, 3762, 3871,  584,
        2359, 3439, 3024, 2069])
Epoch: 3883, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3884 - Batch 1 ########################
IDs in batch 1: tensor([1842, 1681, 3261, 3154, 4139, 2578,   27, 3962, 2470, 2866, 2398, 2287,
        2917, 3677, 3079, 2035])
Epoch: 3884, Training Loss: 0.30, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3885 - Batch 1 ########################
IDs in batch 1: tensor([3037, 1120, 2444,  519, 1166, 2563, 1257, 3832,  851,  779, 4235, 2610,
         358, 3874, 3005, 1844])
Epoch: 3885, Training Loss: 0.05, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3886 - Batch 1 ########################
IDs in batch 1: tensor([ 171,  610,  138, 1179, 3573, 3813, 2953, 3540, 4225, 2039, 4046, 1001,
        1737, 2652, 2836, 1772])
Epoch: 3886, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3887 - Batch 1 ########################
IDs in batch 1: tensor([ 492, 3022, 1038, 3000, 1910, 2398,  110, 3004, 3655, 1869,   73, 2371,
           5, 1754,  687,  338])
Epoch: 3887, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3888 - Batch 1 ########################
IDs in batch 1: tensor([1786, 1264,   97, 1862, 3440,  481, 2775, 1726,  284, 1126, 1118,   88,
        1661, 1981, 1415, 3384])
Epoch: 3888, Training Loss: 0.19, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3889 - Batch 1 ########################
IDs in batch 1: tensor([1390, 1356,  372,  393, 1373, 4143, 3317, 3980, 3568,  893,  603, 3672,
        3521, 3243, 3399,  805])
Epoch: 3889, Training Loss: 0.01, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3890 - Batch 1 ########################
IDs in batch 1: tensor([2459, 1684, 1015, 2545, 2563, 3543, 1578, 4076,   25, 1199, 2253,  327,
         957, 4120, 1634, 3250])
Epoch: 3890, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3891 - Batch 1 ########################
IDs in batch 1: tensor([  47,  290, 3379, 3366,  483, 2511, 1200, 2615, 2872, 2229, 1811, 2056,
        3531,  673,  848, 2829])
Epoch: 3891, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3892 - Batch 1 ########################
IDs in batch 1: tensor([ 482, 4165, 3142, 4082, 1591,   35, 2495,  276, 1794,  893,  890, 2482,
        3839, 2114, 2567, 3388])
Epoch: 3892, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3893 - Batch 1 ########################
IDs in batch 1: tensor([1588, 2737, 2897,  361,  662, 3147, 1937,  483,  792, 3634, 3278, 1639,
        2572, 2710, 1365, 3664])
Epoch: 3893, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3894 - Batch 1 ########################
IDs in batch 1: tensor([1665, 3617, 1239,  871, 2748, 3259, 1385, 3488,  956,  133,  566, 2683,
        1195,  195, 3878, 1822])
Epoch: 3894, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3895 - Batch 1 ########################
IDs in batch 1: tensor([ 776,  578, 3375, 1271,  259,  117,  863, 2615, 3240, 3721, 3370, 2649,
         870,  147, 1178, 3408])
Epoch: 3895, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.75
######################## Epoch 3896 - Batch 1 ########################
IDs in batch 1: tensor([ 439, 2718, 2217, 1360, 2641,   62,  741,  755, 1084, 1698, 3513, 3166,
        1471, 1239, 2855,  165])
Epoch: 3896, Training Loss: 0.14, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3897 - Batch 1 ########################
IDs in batch 1: tensor([ 891, 4256,  652, 2484,  380,  280, 2103, 1842, 1186, 3474, 3251, 3486,
        4004, 3833,  368, 3289])
Epoch: 3897, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3898 - Batch 1 ########################
IDs in batch 1: tensor([2045, 1945,  514, 1764, 1062, 4073, 3970, 1161, 3808, 1526, 3004,  777,
        2495, 4220, 3157, 3609])
Epoch: 3898, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3899 - Batch 1 ########################
IDs in batch 1: tensor([ 990, 3640, 2238, 3921, 3647, 3499,  400, 3143, 1252, 1318, 1648, 3036,
        4190, 2398, 1331,  884])
Epoch: 3899, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3900 - Batch 1 ########################
IDs in batch 1: tensor([3704, 4189, 2599, 2800, 3660, 2052, 1375, 2391, 3888,  365,  825, 2544,
        2561, 3851, 3968,  407])
Epoch: 3900, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3901 - Batch 1 ########################
IDs in batch 1: tensor([ 337, 2953, 2137, 1249, 1244, 1319, 4014,  150,  106, 3496, 3991, 1386,
          96, 2298,  436, 4148])
Epoch: 3901, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3902 - Batch 1 ########################
IDs in batch 1: tensor([3389, 2279, 3126,  830,  787, 1083, 1213, 3025, 2349,  104, 3699, 1521,
        2465, 2867, 2465, 1094])
Epoch: 3902, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3903 - Batch 1 ########################
IDs in batch 1: tensor([2740,  121, 4094, 3156, 2540, 2604, 3836,  234, 3990, 3432, 2382,  131,
        1208, 3568, 2418, 2610])
Epoch: 3903, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3904 - Batch 1 ########################
IDs in batch 1: tensor([1808,   19,  481, 1976, 3467, 2719, 3983,   62, 1341, 3755, 2102,   61,
        2120, 4011, 3902, 3881])
Epoch: 3904, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3905 - Batch 1 ########################
IDs in batch 1: tensor([ 379, 1883, 3782, 2117, 2072, 3790,  914, 1344, 2202, 1061, 1153, 2150,
         866, 2420, 3948, 1925])
Epoch: 3905, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3906 - Batch 1 ########################
IDs in batch 1: tensor([ 909,  615, 3110,  733, 1158, 3898, 2059,  303, 2274,  359, 4200, 4133,
        2552, 3400, 2745, 3803])
Epoch: 3906, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3907 - Batch 1 ########################
IDs in batch 1: tensor([2508, 1426, 1189, 3764, 2908,  766, 1824, 3000, 1573, 1292, 1817,  466,
        1077,  709, 3543, 1834])
Epoch: 3907, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3908 - Batch 1 ########################
IDs in batch 1: tensor([ 846, 1981,  971, 3734, 3406, 1111,  121, 1932, 3746, 3563, 3206, 1753,
        3421, 1007,  815,  725])
Epoch: 3908, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3909 - Batch 1 ########################
IDs in batch 1: tensor([2290, 3162, 1083, 1756,  136, 3160, 1229,  694, 3952,  127, 2332, 1159,
        3124, 1532, 1363, 4068])
Epoch: 3909, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3910 - Batch 1 ########################
IDs in batch 1: tensor([1811, 2847, 3052, 1485, 3785, 2155, 1399, 1386, 1189,  400,  462,  315,
        1241, 2584, 3707, 3706])
Epoch: 3910, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3911 - Batch 1 ########################
IDs in batch 1: tensor([1559, 2942,  807, 2127, 1817, 3970, 1780, 2059, 2135, 1405, 1051, 3193,
        2353, 3110,  338, 3754])
Epoch: 3911, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3912 - Batch 1 ########################
IDs in batch 1: tensor([ 212,  552, 4189, 2172, 1015, 3353,  826, 4065, 4060, 1828, 2550, 2725,
         612, 1676, 3543,   28])
Epoch: 3912, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3913 - Batch 1 ########################
IDs in batch 1: tensor([2873, 2921,  970, 2880,  850, 3988, 4154,  108,  556,  590,  200, 2641,
        2535, 3642, 3017,  360])
Epoch: 3913, Training Loss: 0.07, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3914 - Batch 1 ########################
IDs in batch 1: tensor([ 615, 1224,   97, 2469, 1916, 4069,   63, 2271, 4181,  978, 1767, 1951,
        2056,  918, 2391, 2121])
Epoch: 3914, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3915 - Batch 1 ########################
IDs in batch 1: tensor([1286, 1579, 1971, 2703,  419,  282, 2797,  976, 1570, 2989, 2640, 3949,
        2754,  626, 4037, 3987])
Epoch: 3915, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3916 - Batch 1 ########################
IDs in batch 1: tensor([3534, 3039,  399, 1676, 1452, 3993,  422,  335,  343, 1408, 1277, 1463,
        3391, 1511, 2876, 1897])
Epoch: 3916, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3917 - Batch 1 ########################
IDs in batch 1: tensor([2932, 3650, 2489, 4245, 2191, 1443,  963, 4095,  775,  318, 1920, 3463,
        1281, 2195, 4078, 3282])
Epoch: 3917, Training Loss: 0.19, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3918 - Batch 1 ########################
IDs in batch 1: tensor([3681, 1901, 1223, 2367, 2390, 4072, 2295, 3871, 1678, 1320, 2249, 3942,
        2853, 2839,  120, 1904])
Epoch: 3918, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3919 - Batch 1 ########################
IDs in batch 1: tensor([3399,  133, 1977, 1099,  469, 3762,  945,   63, 4232, 2568, 2581, 3217,
          11, 2322, 3441, 1647])
Epoch: 3919, Training Loss: 0.01, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3920 - Batch 1 ########################
IDs in batch 1: tensor([4200, 1485, 1315,  326, 3100, 2091, 2954, 2112, 2522, 2745, 1574,  975,
        3025,  775, 2349, 3563])
Epoch: 3920, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3921 - Batch 1 ########################
IDs in batch 1: tensor([2379,  544, 1931,  850, 2982, 2761, 4117, 2420, 2014, 3934,  171, 3265,
        1283, 1724,  476, 3394])
Epoch: 3921, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3922 - Batch 1 ########################
IDs in batch 1: tensor([3808,  980, 1170, 1244, 3040, 1677, 2234, 3395, 2670, 1841, 1699, 3112,
         152, 2002, 3468,  933])
Epoch: 3922, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3923 - Batch 1 ########################
IDs in batch 1: tensor([1886, 3303, 1450, 3747, 3975, 1128,  788, 3569,  154, 2895, 2406, 1601,
         751, 2802,  739, 1489])
Epoch: 3923, Training Loss: 0.03, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3924 - Batch 1 ########################
IDs in batch 1: tensor([3551,  533, 2092,   57, 3057, 1627,  685,  120, 3981, 1846,  143, 4144,
           7, 1826,  101, 3907])
Epoch: 3924, Training Loss: 0.04, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3925 - Batch 1 ########################
IDs in batch 1: tensor([2451, 1232, 2146,  320, 1971, 1423, 1916, 2464, 1832, 2980, 1070,   52,
        1233, 1747, 3262, 3601])
Epoch: 3925, Training Loss: 0.05, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3926 - Batch 1 ########################
IDs in batch 1: tensor([2731,   70,  110, 2674, 4189,  983, 3733, 2925, 3719,  343,  140, 2674,
        3399, 3977, 2080, 3018])
Epoch: 3926, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3927 - Batch 1 ########################
IDs in batch 1: tensor([3180, 2493, 2730, 2775, 3058, 4251, 2731, 1618, 2867, 3202, 2998, 2701,
        4077,  395, 1212, 2894])
Epoch: 3927, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3928 - Batch 1 ########################
IDs in batch 1: tensor([ 154, 2060,  341, 2177, 1511, 1923, 1953, 4203, 1937, 1711, 2963, 1819,
        1720,  727, 2449, 4204])
Epoch: 3928, Training Loss: 0.03, Validation Loss: 0.75, accuracy = 0.78
######################## Epoch 3929 - Batch 1 ########################
IDs in batch 1: tensor([4048, 4120, 3284, 3098, 2448, 2368, 3521, 4158, 3746, 1728, 1297, 3052,
         388, 1860,  550, 3726])
Epoch: 3929, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.78
######################## Epoch 3930 - Batch 1 ########################
IDs in batch 1: tensor([2943, 3257, 4138,  778, 1357,  605, 3895, 3511, 3914, 1221, 1958, 3488,
        3627, 1209,  167, 1855])
Epoch: 3930, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3931 - Batch 1 ########################
IDs in batch 1: tensor([3706, 3616,  133, 1532, 2413, 1159, 1239, 3998, 1313, 3398, 2347, 1402,
         917, 3432, 3283,  283])
Epoch: 3931, Training Loss: 0.02, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3932 - Batch 1 ########################
IDs in batch 1: tensor([3228, 2372, 1630,  225, 3032, 3267, 2121, 1087, 1869, 3311, 1171, 2261,
        3650,  995, 2350, 2159])
Epoch: 3932, Training Loss: 0.15, Validation Loss: 0.74, accuracy = 0.78
######################## Epoch 3933 - Batch 1 ########################
IDs in batch 1: tensor([ 554, 2682, 1638, 4050,  961,  636, 2019, 1536, 2629, 3644, 3585, 3543,
        4018, 3018,  674, 2932])
Epoch: 3933, Training Loss: 0.07, Validation Loss: 0.73, accuracy = 0.78
######################## Epoch 3934 - Batch 1 ########################
IDs in batch 1: tensor([1092, 2312, 3763, 4189, 3217,  354, 1585, 2729,  141, 2298, 3746, 2741,
        1861, 1519, 3177, 1397])
Epoch: 3934, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3935 - Batch 1 ########################
IDs in batch 1: tensor([3132, 3628,  258, 2510, 1456, 1574, 3124,   63, 2464, 3614,  816, 2228,
        2568, 2112, 1421, 3936])
Epoch: 3935, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3936 - Batch 1 ########################
IDs in batch 1: tensor([2898, 2604,  538, 3239, 1263, 1347, 2122, 2323, 2841, 2653, 1999, 1566,
        1818, 3930,  882, 1809])
Epoch: 3936, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.78
######################## Epoch 3937 - Batch 1 ########################
IDs in batch 1: tensor([2177, 3673, 3490, 1824, 1971, 3599,  367, 1113, 2784,   50, 4116, 3202,
        2854,  593, 3747, 2261])
Epoch: 3937, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3938 - Batch 1 ########################
IDs in batch 1: tensor([3554, 2667,  513, 1568, 2931, 1395, 3860, 3834, 1309, 3384,  187, 2493,
        1092, 2760,  630, 2316])
Epoch: 3938, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3939 - Batch 1 ########################
IDs in batch 1: tensor([ 735, 1866,  259, 1445,  312, 1352, 4033, 3740, 3187,   59, 1092, 2429,
        2597, 3483,  555,  714])
Epoch: 3939, Training Loss: 0.02, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3940 - Batch 1 ########################
IDs in batch 1: tensor([ 662,  752, 2360, 3734,  258, 2155, 2978, 1083,  822,  128,  306,  603,
         736, 4189, 3126, 2782])
Epoch: 3940, Training Loss: 0.14, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3941 - Batch 1 ########################
IDs in batch 1: tensor([ 340, 2999, 3838, 2449, 4120, 1005,  607, 2467, 1450,  649, 1775, 2018,
        2088, 1612,  723, 1123])
Epoch: 3941, Training Loss: 0.07, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3942 - Batch 1 ########################
IDs in batch 1: tensor([1810, 2094,  188, 2672, 3621, 3943, 2652, 3313, 2551,  138, 1624, 3721,
        4170, 4190, 2172, 3985])
Epoch: 3942, Training Loss: 0.23, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3943 - Batch 1 ########################
IDs in batch 1: tensor([1756, 2485, 3473, 2013, 2112, 2245, 1275, 1103, 4035, 3643, 1098, 2256,
        1580, 2278, 1391,  661])
Epoch: 3943, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3944 - Batch 1 ########################
IDs in batch 1: tensor([ 788, 3437,  295, 3279, 1134, 1139, 1723, 2078,  155,  736, 2464, 3474,
        1904, 2902, 3898, 3950])
Epoch: 3944, Training Loss: 0.03, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3945 - Batch 1 ########################
IDs in batch 1: tensor([3713,  781, 2237,   44, 1663,  685, 3530, 1274,  605, 3456,  289, 2284,
        3135, 2285,  770, 3846])
Epoch: 3945, Training Loss: 0.02, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3946 - Batch 1 ########################
IDs in batch 1: tensor([2462, 3216,  182, 4217, 4223,  574, 2965, 2609, 4082, 3786, 1218, 1914,
        1432, 1174, 4060, 2718])
Epoch: 3946, Training Loss: 0.09, Validation Loss: 0.73, accuracy = 0.76
######################## Epoch 3947 - Batch 1 ########################
IDs in batch 1: tensor([2775, 3328, 2937, 2509, 3790, 3444, 3745, 1504, 4255, 1242, 1047, 1731,
        2674, 2595, 2149, 2914])
Epoch: 3947, Training Loss: 0.04, Validation Loss: 0.72, accuracy = 0.76
######################## Epoch 3948 - Batch 1 ########################
IDs in batch 1: tensor([1551, 3436, 1841,  405, 1244,  517,  154,  573, 1200, 2980, 4113, 3615,
         314,  258, 3037,  796])
Epoch: 3948, Training Loss: 0.20, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3949 - Batch 1 ########################
IDs in batch 1: tensor([1080,  672, 3907,  523, 2329, 2479, 1828, 1548,   64,  967, 2370,  152,
          47, 1632,  807,  622])
Epoch: 3949, Training Loss: 0.28, Validation Loss: 0.75, accuracy = 0.75
######################## Epoch 3950 - Batch 1 ########################
IDs in batch 1: tensor([1999, 2323, 4257, 1130, 3083,  411, 3278, 1960, 2315, 2718,   82, 4007,
        3888, 3455,  498, 3582])
Epoch: 3950, Training Loss: 0.05, Validation Loss: 0.74, accuracy = 0.75
######################## Epoch 3951 - Batch 1 ########################
IDs in batch 1: tensor([3004, 1869,  639, 3719,  603, 4072, 2934, 1965, 1010, 2765, 3859, 2115,
         803, 3547, 2451, 3373])
Epoch: 3951, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.76
######################## Epoch 3952 - Batch 1 ########################
IDs in batch 1: tensor([ 824,  603,  137, 2437,  946,  150, 2620,  228, 3806,  934,  436, 1012,
        1938,  338,  243, 1651])
Epoch: 3952, Training Loss: 0.74, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3953 - Batch 1 ########################
IDs in batch 1: tensor([3391,  412, 1050,  507, 2837, 3377, 2709,  568, 1225, 3746, 2751,  915,
        3521, 1496, 3490,  795])
Epoch: 3953, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3954 - Batch 1 ########################
IDs in batch 1: tensor([  46, 1429, 1075, 3958,  342,  164, 2932, 3308, 3178, 1779,  537, 4257,
        2837, 2595, 1044, 3971])
Epoch: 3954, Training Loss: 0.02, Validation Loss: 0.75, accuracy = 0.76
######################## Epoch 3955 - Batch 1 ########################
IDs in batch 1: tensor([1975, 3992, 2997, 3763,  485,  975,  295, 3408, 1730,  145,  602,  165,
        2807, 2934, 1396, 2951])
Epoch: 3955, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3956 - Batch 1 ########################
IDs in batch 1: tensor([3099, 2386, 2110, 1155, 2661, 2056, 1956, 1895, 1160,  994, 1195, 1485,
         678, 3439, 2668, 2709])
Epoch: 3956, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.77
######################## Epoch 3957 - Batch 1 ########################
IDs in batch 1: tensor([ 814, 3475, 1590, 3859, 1770, 3485,  688, 4014, 1452, 2577, 2701, 1459,
        2285, 1163, 1909, 3236])
Epoch: 3957, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3958 - Batch 1 ########################
IDs in batch 1: tensor([ 367, 2135, 1055, 1726,  990,  691, 3651, 2388, 2382,  855, 3908, 1039,
        3608, 2350, 3111, 1317])
Epoch: 3958, Training Loss: 0.14, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3959 - Batch 1 ########################
IDs in batch 1: tensor([1069, 3087,  109, 3762, 1364, 3485, 3958, 3243, 1080, 1171, 2296, 1817,
         262, 1642, 1698, 1325])
Epoch: 3959, Training Loss: 0.20, Validation Loss: 0.75, accuracy = 0.77
######################## Epoch 3960 - Batch 1 ########################
IDs in batch 1: tensor([ 332, 1602, 2284, 3597, 3760,  933, 1336, 1728,  844, 1911,  538, 1887,
        2017, 2451, 2442,  469])
Epoch: 3960, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3961 - Batch 1 ########################
IDs in batch 1: tensor([3541, 1274, 4203, 2773, 1617, 1676,  442, 3009, 1267, 1932, 3700, 1283,
        3634,  900, 4055, 3874])
Epoch: 3961, Training Loss: 0.01, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3962 - Batch 1 ########################
IDs in batch 1: tensor([4120,  463, 2063, 4099,   97, 1086, 3113, 3181, 4187, 2807, 1914, 2804,
         590, 2603,   73,  776])
Epoch: 3962, Training Loss: 0.02, Validation Loss: 0.76, accuracy = 0.75
######################## Epoch 3963 - Batch 1 ########################
IDs in batch 1: tensor([3196, 3015, 2202, 1596, 4116,   21, 3023,  995, 1762, 1690, 2475, 1617,
        3202, 2945, 1047,  558])
Epoch: 3963, Training Loss: 0.05, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3964 - Batch 1 ########################
IDs in batch 1: tensor([1737,  956, 2642, 3488, 2800, 1471,  494, 4032, 1316, 2880,  167, 2969,
        1828, 1469, 2831, 4107])
Epoch: 3964, Training Loss: 0.01, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3965 - Batch 1 ########################
IDs in batch 1: tensor([2663,  829,  530,  196, 1656, 1592, 1381, 2355, 1944, 3352, 3098, 1793,
        4119, 4222, 1159, 2237])
Epoch: 3965, Training Loss: 0.01, Validation Loss: 0.77, accuracy = 0.75
######################## Epoch 3966 - Batch 1 ########################
IDs in batch 1: tensor([2765, 3254, 2892, 2997, 2740, 2369, 4086,  121, 3597,   62, 4018, 3661,
        1559, 1786, 1167, 2678])
Epoch: 3966, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3967 - Batch 1 ########################
IDs in batch 1: tensor([3529, 1543,  553,  413, 3221, 2225, 3390, 3594, 2863,  753, 4113, 3871,
        4069,  405, 2159, 3953])
Epoch: 3967, Training Loss: 0.05, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3968 - Batch 1 ########################
IDs in batch 1: tensor([2276, 4131, 3874, 1711, 3354, 1126, 3808, 3815, 1397, 3353,  454, 3369,
         400, 1718, 1182, 4025])
Epoch: 3968, Training Loss: 0.02, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3969 - Batch 1 ########################
IDs in batch 1: tensor([1774, 1374,  747, 4053, 3147,  900, 3264, 3882, 3673, 4073,  432,  519,
         450, 2524, 1337, 3873])
Epoch: 3969, Training Loss: 0.03, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3970 - Batch 1 ########################
IDs in batch 1: tensor([3719, 2951, 3821, 1612, 3952,  815,  417, 3483, 2999, 2961,   56,  835,
        2440, 3057, 3634, 2880])
Epoch: 3970, Training Loss: 0.14, Validation Loss: 0.79, accuracy = 0.76
######################## Epoch 3971 - Batch 1 ########################
IDs in batch 1: tensor([3951, 2872, 4187, 1056, 3197, 1723, 4265, 2316, 3913,  258, 1122, 2368,
        2983, 1432,  710, 2328])
Epoch: 3971, Training Loss: 0.03, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3972 - Batch 1 ########################
IDs in batch 1: tensor([ 119, 4204, 2114, 2703,  239, 3998, 3489, 4025,  262, 1746, 1047, 1437,
        3531, 2817, 1819,  758])
Epoch: 3972, Training Loss: 0.01, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3973 - Batch 1 ########################
IDs in batch 1: tensor([ 266, 4057, 3440, 2938, 1632, 3408,  147, 1231, 1196, 3540, 2450, 2478,
         232, 2413, 3009, 2002])
Epoch: 3973, Training Loss: 0.05, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3974 - Batch 1 ########################
IDs in batch 1: tensor([2869, 2171,  653, 3271, 3648, 1496, 3009, 1374, 2367, 1636, 2869, 2322,
        3539,  263, 1436, 2953])
Epoch: 3974, Training Loss: 0.01, Validation Loss: 0.78, accuracy = 0.76
######################## Epoch 3975 - Batch 1 ########################
IDs in batch 1: tensor([  43, 3389,  154,  899, 4002,  895, 3675, 2561, 2433,   21, 2793, 2046,
        2567,  379, 2003,  129])
Epoch: 3975, Training Loss: 0.02, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3976 - Batch 1 ########################
IDs in batch 1: tensor([2860,  778, 3714, 2070, 3836, 2480, 1724,  991, 3769, 2472, 2521, 2806,
        3792, 3525, 3525, 3238])
Epoch: 3976, Training Loss: 0.39, Validation Loss: 0.77, accuracy = 0.76
######################## Epoch 3977 - Batch 1 ########################
IDs in batch 1: tensor([4242, 3781, 3101, 2883, 1376,  275, 3385,  773, 1747,  709, 2110,  895,
        1704, 3630, 3568, 2271])
Epoch: 3977, Training Loss: 0.06, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3978 - Batch 1 ########################
IDs in batch 1: tensor([2683, 3248, 2104, 3120, 1861, 3699, 1796, 3643, 1834, 2666,  113, 4229,
         713,  363,  864,  361])
Epoch: 3978, Training Loss: 0.23, Validation Loss: 0.76, accuracy = 0.76
######################## Epoch 3979 - Batch 1 ########################
IDs in batch 1: tensor([  41,  653,  846, 3518, 4134, 1775, 3939, 3077, 3160,  627,  996, 2603,
        2833, 1925, 1097, 2070])
Epoch: 3979, Training Loss: 0.04, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3980 - Batch 1 ########################
IDs in batch 1: tensor([1179, 1140, 2178, 1471, 3541,  422,  627, 3424,  456, 2597, 2245, 1117,
        2436, 2300, 3707, 1897])
Epoch: 3980, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3981 - Batch 1 ########################
IDs in batch 1: tensor([2966, 3674, 3581, 3323, 3124,  141, 4088, 2035,  330, 3900, 3388,  219,
        3182,   68, 1491, 1546])
Epoch: 3981, Training Loss: 0.06, Validation Loss: 0.73, accuracy = 0.77
######################## Epoch 3982 - Batch 1 ########################
IDs in batch 1: tensor([ 582, 3010,   77, 1024, 1208,  682,  159, 3881,   86, 4263,  740, 1634,
        3938, 1665, 3395, 1605])
Epoch: 3982, Training Loss: 0.43, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3983 - Batch 1 ########################
IDs in batch 1: tensor([1349, 1423, 2447, 3478, 2488,  530, 3255, 2217, 1453, 2153,  941,   98,
        4197, 1614, 1228, 3264])
Epoch: 3983, Training Loss: 0.03, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3984 - Batch 1 ########################
IDs in batch 1: tensor([2480, 2195, 4168, 4180, 2114, 2224, 2469, 1229, 2794, 1117,  547, 1156,
        1766,  786, 3974,  609])
Epoch: 3984, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.78
######################## Epoch 3985 - Batch 1 ########################
IDs in batch 1: tensor([ 359, 2371, 1069,   21, 1727, 2632, 2719, 3133, 3813,  289, 1370,  751,
        3669, 1003, 3444, 2358])
Epoch: 3985, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3986 - Batch 1 ########################
IDs in batch 1: tensor([3333, 3747, 1052,  679, 1511, 1711, 2237, 3284, 1351, 4267, 1181, 2863,
        3710,  205, 1623, 1003])
Epoch: 3986, Training Loss: 0.01, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3987 - Batch 1 ########################
IDs in batch 1: tensor([2991,  899, 3718, 2521, 1295, 3988, 2629, 2324, 1752, 1798, 4139,  628,
        2584, 3530, 2224,  577])
Epoch: 3987, Training Loss: 0.05, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3988 - Batch 1 ########################
IDs in batch 1: tensor([1526, 1984, 2348, 1038, 1311, 4214, 3821, 1147, 2385, 1510,  100, 1045,
        3105, 2441, 3577, 3014])
Epoch: 3988, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3989 - Batch 1 ########################
IDs in batch 1: tensor([1817, 4163, 1214, 1775, 3256, 2290, 3144, 2359,  362, 1619, 1317, 3642,
         200,  292,  529, 2030])
Epoch: 3989, Training Loss: 0.03, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3990 - Batch 1 ########################
IDs in batch 1: tensor([3245, 2558,  775, 1027, 3476, 3695, 3697,  991, 1500, 3907, 4235, 2624,
        4085, 2770, 2334, 3548])
Epoch: 3990, Training Loss: 0.08, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3991 - Batch 1 ########################
IDs in batch 1: tensor([3837, 2927, 3283, 3505, 1638, 1952, 2708, 2993, 1277, 3327, 2841,  426,
        2590, 3446, 1657, 2858])
Epoch: 3991, Training Loss: 0.03, Validation Loss: 0.74, accuracy = 0.77
######################## Epoch 3992 - Batch 1 ########################
IDs in batch 1: tensor([ 980, 2277,  181, 1340,  391, 2364, 1891,  946, 2947, 1784, 2457,  415,
         674, 2296, 1434, 1047])
Epoch: 3992, Training Loss: 0.16, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3993 - Batch 1 ########################
IDs in batch 1: tensor([ 351,  822, 1208, 1269,   60, 3932, 1923,  482, 3270, 2957, 2833, 3863,
        2329,  198, 2250, 3795])
Epoch: 3993, Training Loss: 0.01, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3994 - Batch 1 ########################
IDs in batch 1: tensor([2810, 4163, 2031,  102, 1248, 3421,  206, 1727, 3569, 1119, 1746, 3842,
        3446,  217, 1012, 1097])
Epoch: 3994, Training Loss: 0.10, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3995 - Batch 1 ########################
IDs in batch 1: tensor([2092, 1263,  218,  289,  572, 1588, 3772, 2636,  376, 2132, 1451, 2225,
         926, 1521, 3940, 3415])
Epoch: 3995, Training Loss: 0.04, Validation Loss: 0.70, accuracy = 0.77
######################## Epoch 3996 - Batch 1 ########################
IDs in batch 1: tensor([3815, 3323, 1208, 1030,  520, 2338, 1502,  960,  941, 4203, 2583, 2740,
        3478, 1396, 3261, 2277])
Epoch: 3996, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3997 - Batch 1 ########################
IDs in batch 1: tensor([1356, 1176, 1767, 2086, 2953, 2855, 3793, 2540,  642, 3545, 2479,  887,
        2629, 2678, 1596, 3551])
Epoch: 3997, Training Loss: 0.01, Validation Loss: 0.72, accuracy = 0.77
######################## Epoch 3998 - Batch 1 ########################
IDs in batch 1: tensor([3408, 3680,  771, 3505, 1885, 1356, 3040, 1324, 3719,  762,  555, 1080,
        4184, 1138, 3401,   11])
Epoch: 3998, Training Loss: 0.02, Validation Loss: 0.71, accuracy = 0.77
######################## Epoch 3999 - Batch 1 ########################
IDs in batch 1: tensor([3003,   11, 3483, 3863, 1275, 1546, 1803, 1241, 2740, 2232,  467, 1737,
        3667, 2989, 3055, 3746])
Epoch: 3999, Training Loss: 0.06, Validation Loss: 0.71, accuracy = 0.77
Saved file as breast_probsThresthold_0.96_batch_size_16_batchNumber_1_epochs_4000_ver_0__8859.pkl
Validation accuracy state 1: 0.7971864009378663 @ epoch 1656 
[0.43, 0.43, 0.44, 0.45, 0.46, 0.47, 0.47, 0.5, 0.51, 0.54, 0.56, 0.56, 0.56, 0.56, 0.56, 0.57, 0.58, 0.59, 0.59, 0.61, 0.61, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.59, 0.6, 0.6, 0.6, 0.59, 0.6, 0.6, 0.6, 0.59, 0.6, 0.59, 0.59, 0.59, 0.59, 0.59, 0.59, 0.6, 0.59, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.61, 0.61, 0.6, 0.61, 0.62, 0.62, 0.62, 0.62, 0.62, 0.63, 0.63, 0.64, 0.64, 0.64, 0.64, 0.64, 0.65, 0.67, 0.66, 0.67, 0.67, 0.68, 0.68, 0.67, 0.67, 0.67, 0.67, 0.68, 0.67, 0.68, 0.68, 0.69, 0.68, 0.68, 0.69, 0.69, 0.68, 0.68, 0.69, 0.68, 0.69, 0.69, 0.69, 0.69, 0.69, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.7, 0.7, 0.7, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.7, 0.7, 0.71, 0.7, 0.71, 0.71, 0.71, 0.71, 0.7, 0.71, 0.71, 0.71, 0.7, 0.7, 0.71, 0.71, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.71, 0.71, 0.71, 0.71, 0.71, 0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.71, 0.71, 0.71, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.74, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.74, 0.75, 0.75, 0.74, 0.75, 0.73, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.76, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.74, 0.74, 0.74, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.78, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.78, 0.79, 0.79, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.79, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.78, 0.79, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.78, 0.79, 0.79, 0.78, 0.79, 0.79, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.78, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.78, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.78, 0.78, 0.77, 0.77, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.79, 0.79, 0.78, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.77, 0.78, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.74, 0.74, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.74, 0.74, 0.73, 0.74, 0.73, 0.74, 0.75, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.77, 0.76, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.78, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.77, 0.78, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.79, 0.78, 0.79, 0.79, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.79, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.79, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.76, 0.76, 0.77, 0.77, 0.75, 0.75, 0.77, 0.75, 0.75, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.77, 0.77, 0.78, 0.78, 0.78, 0.79, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.8, 0.79, 0.79, 0.79, 0.79, 0.78, 0.78, 0.78, 0.79, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.79, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.77, 0.78, 0.78, 0.77, 0.77, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.76, 0.75, 0.75, 0.76, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.76, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.74, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.74, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.75, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.73, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.76, 0.75, 0.74, 0.73, 0.73, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.76, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.77, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.75, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.76, 0.75, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.74, 0.73, 0.74, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.73, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.73, 0.72, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.74, 0.74, 0.73, 0.73, 0.72, 0.72, 0.72, 0.72, 0.72, 0.72, 0.74, 0.74, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.74, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.75, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.73, 0.74, 0.74, 0.73, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.75, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.75, 0.75, 0.75, 0.74, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.75, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.78, 0.78, 0.78, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.76, 0.77, 0.77, 0.77, 0.78, 0.79, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.76, 0.77, 0.79, 0.78, 0.77, 0.77, 0.77, 0.76, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.79, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.77, 0.76, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.74, 0.74, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.75, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.76, 0.76, 0.76, 0.76, 0.75, 0.75, 0.76, 0.75, 0.76, 0.76, 0.76, 0.77, 0.76, 0.76, 0.77, 0.76, 0.76, 0.75, 0.76, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77]Using cache found in /home/huong_n_pham01/.cache/torch/hub/pytorch_vision_v0.9.0

Email sent!
